<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hang&#39;s Blog">
<meta property="og:url" content="https://example.com/page/69/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/page/69/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Hang's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Designing-an-Azure-Compute-Infrastructure-44/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Designing-an-Azure-Compute-Infrastructure-44/" class="post-title-link" itemprop="url">AZ-104-Designing-an-Azure-Compute-Infrastructure-44</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:47" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:47-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:40:36" itemprop="dateModified" datetime="2022-11-22T11:40:36-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Designing-an-Azure-Compute-Infrastructure-44/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Designing-an-Azure-Compute-Infrastructure-44/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to “Designing an Azure Compute Infrastructure”. My name’s Guy Hummel and I’ll be helping you with the compute aspects of architecting an Azure solution. I’m the Azure Content Lead at Cloud Academy and I have over 10 years of experience with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn and send me a message, or send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>.</p>
<p>This course is intended for people who want to become Azure cloud architects.</p>
<p>To get the most from this course, you should have a general knowledge of IT architecture.</p>
<p>We’ll start with how to design solutions using virtual machines. Then I’ll go over Azure Backup and Azure Site Recovery, two essential services for business continuity and disaster recovery. Next, we’ll get into serverless computing, especially Azure Functions. After that, I’ll explain how to design microservices-based solutions. Then we’ll cover how to design web solutions using Azure App Service and other supporting services. Finally, I’ll show you how to run compute-intensive applications, especially with Azure Batch.</p>
<p>By the end of this course, you should be able to design Azure solutions using virtual machines, serverless computing, and microservices; design web solutions using Azure App Service; and run compute-intensive applications using Azure Batch.</p>
<p>We’d love to get your feedback on this course, so please give it a rating when you’re finished.</p>
<p>Now, if you’re ready to learn how to get the most out of Azure’s compute services, then let’s get started.</p>
<h1 id="Azure-Virtual-Machine-Availability-and-Scalability-Solutions"><a href="#Azure-Virtual-Machine-Availability-and-Scalability-Solutions" class="headerlink" title="Azure Virtual Machine Availability and Scalability Solutions"></a>Azure Virtual Machine Availability and Scalability Solutions</h1><p>Virtual machines have gone from being revolutionary to being a standard part of nearly every organization’s infrastructure. Now containers are the revolutionary technology, but VMs are still very important. Virtual machines give you full control over not only the software that you want to run but also the operating system. This is especially useful when you’re migrating existing servers to the cloud. When you use VMs to run mission-critical applications, you need to architect the solution so that it will keep running even if there’s a hardware failure, a system update, or a spike in demand.</p>
<p>First, let’s look at high availability, which means that an application will continue to run even if there’s a hardware failure or another event that would normally cause the application to go down. Microsoft offers a few different services to help with high availability. The first one is called an availability set. Microsoft doesn’t recommend using availability sets anymore because they have better offerings now, but I’ll still tell you about them because you’ll likely still see references to them.</p>
<p>An availability set is a group of virtual machines that’s designed to handle both planned and unplanned VM downtime. Planned downtime is when Azure updates the infrastructure underlying your VMs, and this update requires a reboot of the VMs. Unplanned downtime is when a VM goes down unexpectedly, such as when it has a critical hardware failure.</p>
<p>To handle planned downtime, an availability set groups its VMs into what are called update domains. Azure will only perform planned maintenance on one update domain at a time. That way, while the VMs in a particular update domain are being rebooted, the VMs in the other update domains will keep running. You can configure up to 20 update domains when you create an availability set.</p>
<p>Unplanned downtime is handled in a similar way by using fault domains. Each fault domain has a separate power source and network switch. This limits the downtime caused by hardware failures. For example, if there’s a power failure in one fault domain, the VMs in the other fault domains should keep running because they don’t use the same power source. The maximum number of fault domains you can use depends on the region where your VMs reside. In many regions, the maximum is three, but in some, it’s only two.</p>
<p>Each VM is in both an update domain and a fault domain. Azure will distribute your VMs into these domains automatically. To qualify for Microsoft’s 99.95 percent uptime guarantee under its service level agreement, you need to have at least two VMs, at least two fault domains, and at least two update domains. </p>
<p>Using availability sets will give your applications a high level of availability, but they won’t protect against a data center failure. That’s where availability zones come in. They’re an alternative to availability sets. An availability zone is a physically separate zone within an Azure region. So, if one zone goes down, the other zones will likely stay up. Not every region offers availability zones, but in the ones that do, there are always three of them.</p>
<p>To take advantage of this capability, you should deploy multiple replicas of your application’s VMs in different availability zones. You can specify a particular availability zone when you create each VM.</p>
<p>However, even this level of redundancy won’t protect you against an outage that affects an entire region. Regional outages aren’t common, but they can happen. So, if you need higher availability than a single region can provide, you’ll have to use multiple regions. In most cases, it’d be sufficient to simply back up your VMs to another region. Then if the region where your VMs are deployed goes down, you can temporarily bring up replacement VMs in the second region by using your backups. If you can’t tolerate almost any downtime, then you could have VMs running in the backup region all the time.</p>
<p>When choosing a backup region, you should take into account regional pairs. Nearly every one of Azure’s regions is paired with another region. Some <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> services replicate their data across regional pairs if you choose certain options. For example, if you choose the geo-redundant storage option for an Azure Storage account, then your data will be replicated to the paired region.</p>
<p>Virtual machines don’t replicate across regional pairs, but you should still consider storing your VM backups in the paired region. That’s a best practice because Microsoft tries to ensure that at least one region in each pair is available. In the event of a multi-regional outage, Microsoft will prioritize the recovery of one region in each pair, so your safest option for a backup region is the paired region.</p>
<p>All right, now that we’ve covered availability, let’s move on to how you can configure your application to handle spikes in demand. This is referred to as scalability.</p>
<p>The simplest way to scale is to switch an individual VM to a larger size. This is known as vertical scaling. It’s easy to do, but there are limits to that approach. Horizontal scaling, on the other hand, is when you scale by adding more VMs. It’s more complicated to scale horizontally, though.</p>
<p>First, you need to architect your application so it can run across multiple identical machines. Ideally, you should make that tier of your application stateless. That is, the VMs should not store any data locally. Otherwise, the application wouldn’t scale well because client requests would be tied to particular VMs. So the application should save data in a shared external datastore.</p>
<p>Next, you need to create a scale set. This is similar to an availability set because the VMs are distributed across fault domains and update domains, but you can do a lot more with it.</p>
<p>You can configure a scale set to automatically increase or decrease the number of VMs in it according to rules you define. For example, you can create a rule that says if the average CPU usage goes above 80%, then add 3 more VMs. You can also use disk and network metrics in your rules. If you need to scale based on guest operating system metrics, such as available memory or number of processes, then you can enable the diagnostics extension. This will even let you use custom metrics based on something specific in your application logs. </p>
<p>You’ll also usually want to set limits on how far a scale set can scale up or down by configuring a maximum and minimum number of VMs. Considering that a scale set can have up to 1,000 VMs in it, setting a maximum is a good idea. Note that if you’re using custom VM images rather than Azure’s standard images, then the maximum is 600 VMs per scale set.</p>
<p>By default, a scale set is deployed in a single zone. This is called a zonal scale set. But for the ultimate in availability and scalability, you can deploy a scale set across availability zones. This is called a regional scale set. It evenly distributes VMs across the three availability zones in a region. This distribution happens both when you create the scale set and also when it automatically adds or removes VMs during scaling operations. As you can see, combining scale sets with availability zones gives you the best of both worlds.</p>
<p>And that’s it for virtual machine availability and scalability.</p>
<h1 id="Azure-Backup-and-Azure-Site-Recovery"><a href="#Azure-Backup-and-Azure-Site-Recovery" class="headerlink" title="Azure Backup and Azure Site Recovery"></a>Azure Backup and Azure Site Recovery</h1><p>Most Azure customers also have on-premises infrastructure, so Microsoft’s cloud services usually work with local resources as well. This is especially true for business continuity and disaster recovery. For example, Azure Backup doesn’t just back up Azure VMs—it also backs up on-premises VMs and servers. What I find surprising, though, is that in some cases, it even stores the backups on-premises. That’s a pretty unusual feature for a cloud service.</p>
<p>Do you know what else is unusual? If you search for Azure Backup in the Azure portal, it won’t find a service with that name. That’s because Azure Backup is integrated with various other products and services rather than being a separate service of its own.</p>
<p>As you can see, Azure Backup has a rather complicated set of components for different scenarios. I’ll go through the highlights.</p>
<p>Azure Infrastructure-as-a-Service VM Backup is the most straightforward component. As the name implies, it only backs up Azure VMs. Once a day, it backs up each VM’s disks, including application-aware snapshots. It stores the backups in a Recovery Services vault, which is also on Azure. All three of the other components provide some mix of Azure and on-premises options.</p>
<p>The Azure Backup Agent supports both cloud-based and local VMs, as well as physical servers. However, it only supports Windows, and you have to install the agent on every virtual and physical machine you want backed up. It will handle files, folders, and system state, but it’s not application aware. In fact, this is the only component that’s not application aware. It stores its backups in a Recovery Services vault. Confusingly, the Azure Backup Agent is usually referred to as the Microsoft Azure Recovery Services (or MARS) agent.</p>
<p>System Center DPM can basically back up anything except Oracle workloads. For example, it can back up Linux VMs on Hyper-V and VMware. You have three choices for where to store your backups: a Recovery Services vault, locally attached disk, and even tape (which is an on-premises only option).</p>
<p>Azure Backup Server is almost the same except it doesn’t require a System Center license and it doesn’t support tape backup.</p>
<p>Note that both System Center DPM and Azure Backup Server use the Azure Backup Agent to send data to Azure.</p>
<p>To enable backups for an individual Azure VM, you just select Backup from the Operations menu for that VM and click the Enable Backup button. This is really easy, but what if you want to enable backups on all of your VMs? It would be a pain to have to do this manually for each VM and you might forget to enable backups on all of them, especially when you add new VMs.</p>
<p>A much easier way is to create a Recovery Services vault and then set a backup policy there. It will list all of the VMs you have in the same region as the vault, so you can enable backups for all of them at the same time. It only applies to VMs in the same region, though, so if you use multiple regions, you’ll have to create a Recovery Services vault in each one.</p>
<p>Speaking of regions, if you want your Recovery Services vault to survive a regional outage, then it needs to be configured to use geo-redundant storage. Luckily, that’s the default. If you want, you can change it to locally-redundant storage to save money, but if there’s a regional outage where your vault resides, then you won’t be able to recover your data.</p>
<p>When you want to back up on-premises data to Azure, one potential problem is the huge quantity of data that would need to be transferred over your network connection to Azure for the initial backup. One of the best ways to deal with that problem is to use the Azure Import&#x2F;Export service. This allows you to ship physical disks to Microsoft, so they can be uploaded to Azure directly.</p>
<p>Another potential issue is related to installing the Azure Backup Agent. During installation, you need to register the machine. This involves downloading the vault credentials into the agent and also setting an encryption passphrase. It is very important that you save this passphrase somewhere secure. When you’re restoring a backup, you need to provide the vault credentials and the passphrase. If necessary, you can download the vault credentials again, but if you lose the passphrase, then your backup will be unrecoverable.</p>
<p>OK, let’s move on to the Site Recovery service. Its purpose is to get you up and running again as quickly as possible in the event of an outage. It does this by failing over to another location. Once again, this service handles both Azure and on-premises servers. It supports three failover scenarios: Azure to Azure, on-premises to Azure, and on-premises to secondary site.</p>
<p>Replicating between Azure regions is pretty straightforward, but replicating between an on-premises site and either Azure or a secondary site is more complicated, so I’ll give you an overview of those.</p>
<p>These scenarios are further subdivided based on whether you’re replicating physical servers, VMware servers, or Hyper-V servers. To support physical or VMware servers, you need a Configuration server that manages replication, a Process server that sends the replication data to Azure, and a master target server that handles replication data during failback. You also need to install a Mobility service on each server that needs to be replicated.</p>
<p>If you’re replicating to a secondary site, then you need the same components, but the Process server is in the primary site and the Configuration and Master target servers are in the secondary site.</p>
<p>The architecture for Hyper-V replication is simpler. You install the Azure Site Recovery Provider and Recovery Services agent on each Hyper-V host or cluster node. If you’re using the System Center Virtual Machine Manager (or VMM), then that’s where you need to install the Site Recovery Provider. If you’re replicating to a secondary site, then you have to use VMM.</p>
<p>There’s a matrix of supported operating systems for the replicated machines in each of the scenarios. For physical servers, the replicated machines must be running a minimum of Windows Server 2008 R2 with at least SP1. VMware servers must be running at least vSphere 5.5 or vCenter 5.5. Hyper-V servers must be running at least Windows Server 2012 R2, although guest VMs on Hyper-V only need to be running Windows Server 2008 R2 or higher.</p>
<p>In the event of an outage, you have 6 different options for which recovery point to failover to. Latest is the default. This would give you the lowest recovery point objective because it’s the latest recovery point. Considering that, you might be wondering why you wouldn’t always use this option. Well, it has the disadvantage that it delays the failover because it has to process all of the latest data that it received and turn it into a recovery point.</p>
<p>An alternative is to choose Latest processed. This ignores all of the unprocessed data, so the failover happens very quickly. This gives you a much lower recovery time objective, but a higher recovery point objective, because it doesn’t use the latest recovery point.</p>
<p>The next 3 options are all variations of this one since they all ignore unprocessed data. They are Latest application-consistent, Latest multi-VM processed, and Latest multi-VM application-consistent, which is a combination of the previous two. Finally, you can choose a custom recovery point.</p>
<p>And that’s it for this lesson.</p>
<h1 id="Designing-Solutions-for-Serverless-Computing"><a href="#Designing-Solutions-for-Serverless-Computing" class="headerlink" title="Designing Solutions for Serverless Computing"></a>Designing Solutions for Serverless Computing</h1><p>Serverless computing is a hot trend. The idea is that you don’t have to worry about the infrastructure, such as virtual machines, underlying the service because the service takes care of that for you. Although there are a wide variety of Azure services that do this for you, such as the Bot Service and Stream Analytics, the one that people usually mean when they say “serverless” is Azure Functions. That’s because with Azure Functions, you can write almost any kind of code that you want executed and the service will do the rest. It’s more of a general-purpose serverless environment than the others.</p>
<p>Azure Functions is event-driven. In other words, your code will only run when it’s triggered by a certain event. For example, if you need to process images as users upload them to a Blob storage container, then you can use the BlobTrigger to execute your image processing code. There are triggers for events occurring in many other Azure services as well, such as Event Hub, Service Bus, and Cosmos DB. Triggers don’t always come from other services, though. For example, with the HTTPTrigger, you can call your function from an application by sending an HTTP request to it. Yet another possibility is to have your function run on a fixed schedule, such as every day at midnight, by using the TimerTrigger. A function can only have one trigger.</p>
<p>A trigger will include input data, such as the name of the new blob that fired the trigger. You can easily refer to this data in your code because Azure Functions automatically creates what it calls an input binding. This saves you the trouble of having to write code to connect to the input source.</p>
<p>You can also create your own input and output bindings, either in the Azure portal or in the function.json file. Bindings use a declarative syntax, so you don’t have to say how to connect to the data source or sink. You only have to give basic details about its type and where it is.</p>
<p>A typical function gets triggered, performs some simple operations, and then ends, but there are many cases where you would need to do something more complex. For example, suppose you need to run a sequence of functions in a particular order and the output of one function is the input for another function. You could do this by writing code to maintain state and orchestrate the execution of the various functions, but it would be much simpler to use Durable Functions. This is an extension to Azure Functions that lets you create orchestrator functions. This allows you to create workflows and call other functions synchronously and asynchronously.</p>
<p>Most functions don’t run continuously. They’re triggered when an event occurs and they only run briefly. That’s why the most common pricing plan for Azure Functions is the Consumption plan. Under this model, it allocates compute resources when the function is triggered and removes them when the function is finished. It even scales out to handle high loads. You only pay for resources when your function is running.</p>
<p>This works very well most of the time, but there are circumstances when you need to use an App Service plan. Under this model, your functions run on dedicated VMs. Here are some of the reasons why you might want to do this:</p>
<ul>
<li>Your function will run almost continuously. In this case, it would be cheaper to use dedicated VMs than pay-as-you-go.</li>
<li>Your function needs to run for longer than 10 minutes, which is the maximum allowed under the Consumption plan.</li>
<li>Or your function needs to run on Linux. The Consumption plan only supports Windows.</li>
</ul>
<p>Microsoft also provides a simpler service if you don’t want or need to write custom code. It’s called Azure Logic Apps. Like Azure Functions, it’s invoked using triggers. The difference is that the actions executed by Logic Apps are not written in code. For example, an action can send an email or push an item onto a queue.</p>
<p>With Logic Apps, you can create workflows visually in the Azure portal. For example, suppose you want to make a copy of every file that gets uploaded into a Blob storage container. First, you create a Logic App. Then you create a trigger. There are lots available, so it’s usually easiest to search for the one you need. I’ll type “blob”. This trigger gets invoked when a blob is added or modified, which is what we want. Then you have to select the container where the trigger will look for new or modified files.</p>
<p>Next, you add an action. You can either search for an action or narrow down the list by selecting the connector first. Then select the “Copy blob” action. Now paste the URL for your storage account. To get the path of the specific blob from the previous step, you can go over to the dynamic content list and select “Path”.</p>
<p>Then you put in the path of the container where you want the blob to be copied to. This time, we need to select the name from the dynamic content list.</p>
<p>That’s all you have to do. No coding required. Just save it and run it. Now whenever you upload a file to the source blob container, it will get copied to the destination blob container.</p>
<p>Logic Apps is integrated with lots of other Azure services, such as Event Grid and Machine Learning. It also has connectors for products and services from lots of other vendors, including everything from Twitter to Salesforce. It’ll even connect to on-premises servers, such as an Oracle database.</p>
<p>And that’s it for serverless solutions.</p>
<h1 id="Designing-Microservices-Based-Solutions"><a href="#Designing-Microservices-Based-Solutions" class="headerlink" title="Designing Microservices-Based Solutions"></a>Designing Microservices-Based Solutions</h1><p>Another revolution in software development is the move to microservices. Traditionally, applications have been written in monolithic fashion, where all of their various functions are tightly coupled in a single stack. The advantage of this approach is that it’s easy to manage a single, self-contained application. It also tends to have relatively high performance because the components inside the application communicate very quickly with each other.</p>
<p>But there are many disadvantages to this approach. The biggest one is that you can’t easily make changes to a monolithic application. If you need to make a change to a single component, then you have to retest and redeploy the entire application. That’s a big problem, especially if you’re trying to use an agile development methodology.</p>
<p>The microservices approach solves this problem by breaking an application up into numerous independent components. Then if you need to update a single component, you can do it without having to update all of the other components. This is only possible if you have a well-defined interface for calling that microservice. As long as you don’t make a breaking change to a microservice’s interface, then other microservices can continue to call it in the same way, even after an update.</p>
<p>Another advantage of microservices is that you don’t need to use the same programming language or supporting software for all of them. Since microservices communicate with each other through language-independent APIs (usually REST APIs), you’re free to choose whatever technologies you’d like to implement a particular microservice. It’s usually better to choose a few standard technologies, though, so you don’t end up with a patchwork quilt that’s difficult to support.</p>
<p>The biggest downside of the microservices approach is complexity. It’s harder to get a coherent view of an application when it’s so fragmented. These applications may also be slower since the services communicate with each other over longer distances and through more layers. This complexity makes management much more difficult. How do you handle deployment, monitoring, and availability when your application is spread out all over the place?</p>
<p>Luckily, there are some very good solutions. First of all, containers are almost a requirement for implementing microservices. Using VMs alone would be far too expensive and difficult to manage. Containers run on top of VMs and only include the software sitting on top of the operating system, so they’re smaller and can be deployed much more easily.</p>
<p>Azure provides several alternatives for creating and managing containers. The simplest is Azure Container Instances. If you want to deploy a single container quickly, you only need to specify a few details like the number of cores and the amount of memory. Container Instances will take care of the rest and spin up a container for you in seconds. It’s a pretty limited solution, though.</p>
<p>To implement microservices effectively, you need full container orchestration and scaling. Microsoft provides two alternative services for this: Azure Kubernetes Service and Azure Service Fabric.</p>
<p>Azure Kubernetes Service supports the popular open-source Kubernetes container-orchestration system.</p>
<p>Azure Service Fabric is Microsoft’s proprietary container orchestrator. It powers a wide variety of Microsoft services, including everything from Power BI to Cosmos DB.</p>
<p>Azure Service Fabric is quite flexible. Considering that it has Azure in its name, you might think that it only runs on Azure, but surprisingly, you can also run it on-premises on both Windows and Linux, and you can even run it on other cloud platforms like AWS. You can develop microservices that run on Service Fabric using any code you like. And you can develop both stateless and stateful microservices. It also provides application management and lifecycle capabilities. You can use it to deploy, monitor, and upgrade your applications.</p>
<p>When you start building microservices-based applications, you’ll quickly run into the problem of how to make these microservices accessible. Sure, you can create APIs for them, but should you let clients call those APIs directly? If you did, then the client code would have to know the architecture of your application, which would make it complex. Even worse, what if you decide to refactor your application? Would the client code have to change? Also, how would you handle security?</p>
<p>Fortunately, you can solve these problems by using Azure API Management. This service makes it easy to provide APIs that can be used by both internal developers and external partners and customers. It acts as a gateway between clients and your backend microservices. Not only does it provide an easily accessible front-end to your application, but it also handles important management tasks, such as security, monitoring, analytics, and rate limiting.</p>
<p>It’s easy to add an existing API to the API Management service. You only need to supply a few details, such as its name and URL. Then you can secure it and manage it. You can even transform your legacy APIs into modern ones that use REST.</p>
<p>And that’s it for microservices.</p>
<h1 id="Designing-Web-Applications"><a href="#Designing-Web-Applications" class="headerlink" title="Designing Web Applications"></a>Designing Web Applications</h1><p>If you need to deploy a web application that doesn’t have a microservices architecture, then Azure App Service Web Apps is usually the best way to do it. It’s a managed service, so you don’t have to worry about provisioning and maintaining the underlying infrastructure. It’s also very flexible because you can write your application in ASP.NET, ASP.NET Core, Java, Ruby, Node.js, PHP, or Python. Web Apps runs on Windows with IIS, but there’s also a Linux version that I’ll talk about later.</p>
<p>Setting up continuous integration and deployment is easy too because it’s integrated with Azure DevOps, GitHub, BitBucket, Docker Hub, and Azure Container Registry.</p>
<p>Another great feature for software developers and testers is deployment slots. Before you put a new version of an application into production, you’ll want to test it. With App Service, you can create a deployment slot called “testing” or “staging” and another one called “production”. Then you can test the new version of your application in the staging slot, and when you’re satisfied that it works, you can swap it with the production slot, and it will be deployed as the production version. If you discover problems after doing this, you can swap it again and the old version will be back in production. Deployment slots can really reduce the stress of upgrading your apps. This feature is only available in the Standard service tier and above, though. I’ll tell you more about the service tiers in a minute.</p>
<p>Although Web Apps take care of the underlying infrastructure, you do have control over how it scales. There are two ways to do this: scaling up and scaling out. Scaling up means adding more resources, such as disk space. You do that by choosing a higher App Service pricing tier. As you go up in service tiers, you can have more apps, more disk space, and more instances.</p>
<p>The number of instances is how you scale out. For example, in the Premium tier, you can have up to 20. To actually spin up extra instances, you can either do it manually or automatically. To do it automatically, you choose a metric, such as CPU Percentage, and set the App Service to autoscale if that metric reaches a particular threshold, such as 80%. When the average CPU percentage across all of the existing instances reaches that threshold, then App Service will add more instances. How many more is determined by the value you put here. This is a percentage, so if you set it to 25, then it will add 25% more instances when the CPU average hits 80%.</p>
<p>You should also set a rule that tells it to scale <em>in</em> when the CPU average drops below a certain level, so you aren’t wasting resources during quiet times. You can even have different rules for different levels. For example, you could tell it to scale by 25% if the CPU average reaches 60%, and by 40% when the CPU average reaches 80%.</p>
<p>By default, the autoscaling rules you set are always in effect, but you can run them on a schedule if you want. You can also have different rules in effect at different times.</p>
<p>Scaling isn’t the only way to increase a web application’s performance. Another way is to use Azure Redis Cache, which stores recently accessed data in memory. This is especially helpful for caching database records that get accessed multiple times. Another example is caching a user’s session information instead of always having to retrieve it from a cookie in the user’s browser. Getting data from an in-memory cache can significantly speed up web applications.</p>
<p>Another way to speed things up is to use a Content Delivery Network (or CDN). When you put static content from your website into a CDN, users can retrieve it from a nearby edge server rather than from your website. This also reduces the load on your web app. If your entire website is static, then you can serve it from a CDN without even having to deploy any compute resources, such as a web app or VM.</p>
<p>A CDN is especially useful for reducing latency in geographic locations far from where your web app resides. There are lots of other great uses for it too, like streaming videos or distributing firmware updates to IoT devices.</p>
<p>Autoscaling, Azure Redis Cache, and Azure CDN are complementary approaches to increasing performance. You can use all three at the same time to get the best results.</p>
<p>The next thing to look at to make your web app perform reliably is high availability. An Azure App Service Web App is only deployed in one region, so to ensure that it can survive a regional outage, you need to deploy a standby copy of the web app in another region. Ideally, you should deploy it in the region that’s paired with the first region. If there’s a major outage, Microsoft will prioritize bringing up at least one region in every pair.</p>
<p>Under normal circumstances, you’ll want all of your users to go to the web app in the primary region, but when there’s an outage, you’ll want to fail over to the secondary region. Azure Traffic Manager can handle this sort of requirement using priority routing, which used to be called failover routing.</p>
<p>If you have a database behind your web app, which is usually the case, then you’ll have to configure a failover solution for that as well. For example, if you’re using Azure SQL Database, then you’ll need to configure active geo-replication.</p>
<p>Even if you’ve set up a secondary region, you’ll still want to configure backups so you can recover from data corruption problems. You can create backups manually, but of course, it’s much better to automate them. It’s quite easy to do this in the Azure portal. You go into the Backup Configuration page for your app and tell it which storage container to use. To protect against regional failures, you’ll want to use geo-redundant storage. Then you turn on “Scheduled backup”, tell it how often to run the backup, when to start the schedule, and how long to retain the backups. If your app uses a database, you can enter the connection string and it’ll back that up too. The backup and restore feature is only available in the Standard service tier and higher.</p>
<p>Speaking of service tiers, let’s have another look at those. With the Free and Shared plans, your apps share VMs with other customers, so they’re only meant to be used for development and testing. The Basic tier is the first “real” tier, but if you scroll down, you’ll see that it’s missing a lot of really important features, like deployment slots, autoscaling, Traffic Manager, and backups. So you shouldn’t use it for apps that always need to be available.</p>
<p>While we’re here, I should mention what the “Always On” feature does. Normally, when a web app is idle for a period of time, it gets unloaded, which saves resources. If you need an app to stay loaded all the time, then you can enable “Always On”. The main reason to do this is if you have long-running background jobs.</p>
<p>The main advantage of Premium over Standard is that it provides 250 gig of disk space and up to 20 instances. You can go even higher than that with the Isolated tier. This gives you an isolated, dedicated environment. You’d use this if you need more than 20 instances or if you need secure network isolation or if you need instances with a high memory to CPU ratio.</p>
<p>There’s also an option to run App Service on Linux. It’s kind of confusing the way it’s shown in this chart because it looks like it’s separate from the other tiers, but in fact, you can choose from Basic, Standard, Premium, and Isolated for Linux too. You can’t choose Free or Shared, but that isn’t much of a loss. It does have a different feature set, though, which is why it has its own column in the table. In my opinion, the most important missing feature is Traffic Manager. Nonetheless, if you have an application that needs to run on Linux, then App Service for Linux will work very well.</p>
<p>So it’s easy to host web apps using Azure App Service. How about hosting web APIs? App Service makes that easy too. First, you create an API App in Azure App Service. Then you create a REST API using a development tool, such as Visual Studio. Once your code is ready, you push it to the Azure API App. In Visual Studio, you do this by clicking “Publish” and selecting the API App you created earlier. Your API is now hosted in App Service.</p>
<p>By the way, you don’t have to develop your API in .NET. You could develop it using Java, PHP, Node.js, or Python, if you prefer.</p>
<p>There are several ways to secure your API, but they all involve Azure Active Directory (or AAD). </p>
<p>The most basic way is to use AAD alone. To get AAD to handle authentication, you need to register both the API and the client applications using it in your Azure AD tenant. Then you grant permissions in AAD for the client applications to call the API. The applications can then use OAuth2 access tokens to call the API.</p>
<p>A variation of this method is to use the AAD B2C service. It’s designed for customer-facing web and mobile apps, so it has additional capabilities, such as letting users sign up for an application using social media accounts. You still need to register your client application in your Azure AD tenant, just like with the classic AAD method.</p>
<p>You can add yet another layer on top by using the API Management service. As I mentioned earlier, this service is a gateway to your APIs. You can configure it to use either classic AAD authentication or B2C authentication to secure your APIs. This gives you all of the advantages of the API Management service, such as monitoring and rate limiting, while letting you secure your APIs using your preferred method.</p>
<p>And that’s it for web applications.</p>
<h1 id="Creating-Compute-Intensive-Applications"><a href="#Creating-Compute-Intensive-Applications" class="headerlink" title="Creating Compute-Intensive Applications"></a>Creating Compute-Intensive Applications</h1><p>Some industries need massive amounts of compute power for their applications, such as medical research and weather forecasting. Now with the rise of artificial intelligence, the need for high-performance computing is spreading to almost every organization.</p>
<p>Since you can spin up large clusters of VMs on Azure, it’s a great place for running HPC applications. You can build your own solution or you can use one of Microsoft’s offerings to make it easier.</p>
<p>One solution is to use Microsoft HPC Pack, which is a set of tools for building an HPC cluster. HPC Pack has been around since before Azure was even in existence, but running it on Azure VMs is a lot easier than running it on-premises.</p>
<p>Microsoft has another offering that was specifically designed for the cloud, though. It’s called Azure Batch. This service manages the underlying infrastructure and HPC software but still gives you the ability to specify what compute resources you need. The Batch service itself doesn’t even cost anything, but you still have to pay for the compute resources, of course.</p>
<p>Suppose you work for a digital animation company and you need to render the images in a movie. First, you’d upload the data files, which would be animation scene files in this case, to Azure Storage. You’d also upload the application that would process these data files to Azure Storage. Then you’d create a Batch pool of compute nodes. This is when you would tell it what size of VMs you want, how many to put in the pool, what operating system to run, etc. Next, you’d create a job to run on the pool. Then, you’d add tasks to the job. These tasks would be scheduled to automatically run on the pool by the Batch service. The tasks would run the application you uploaded on the data files you uploaded. When the tasks are done, the output files, which would be render files in this case, could be transferred to Azure Storage.</p>
<p>To make all of this work, you need to design the application so that multiple copies of it can run in parallel. Each node in the pool should take one part of the data and process it without having to communicate with any of the other nodes and without storing data locally. This makes it an “embarrassingly parallel” workload that can easily scale.</p>
<p>It’s also possible to run tightly coupled workloads on Azure Batch. These are applications where the nodes <em>do</em> need to communicate with each other. That’s normally done using the Message Passing Interface (or MPI).</p>
<p>When you specify what type of VMs to put in the pool, in many cases you can improve performance by selecting VMs with graphics processing units (or GPUs) on them. Many compute-intensive applications work well with these specialized processors. Alternatively, you can use traditional CPUs, but choose HPC-optimized VMs that have high-performance components. In addition to fast CPUs and storage, some of the HPC VMs also have large memory capacity. For MPI applications, you can also choose VMs with low latency, high bandwidth networking.</p>
<p>These high-performance VMs are pretty expensive, but fortunately, you can take advantage of low-priority VMs to save a huge amount of money. Low-priority VMs typically cost between 65 and 80% less than normal-priority VMs. The difference is that low-priority VMs may not be available when you need them because they run in Azure’s surplus capacity. Even if you’re able to allocate low-priority VMs for a job, they could be preempted and you would lose them. Now you can see why they’re so cheap.</p>
<p>The great thing about Azure Batch is that it’s ideally suited to using low-priority VMs. If you’re running an embarrassingly parallel job and some of the VMs get preempted, it’s not a big deal, because the job will keep running on the remaining VMs, and the interrupted tasks will be automatically requeued. You can even allocate a certain number of dedicated VMs to guarantee that your job will keep running no matter what happens to the low-priority VMs.</p>
<p>Of course, MPI-based applications aren’t well suited to using low-priority VMs because if the application loses a VM, you’d probably have to rerun the entire job. Applications with long-running tasks are also a poor fit because it would be time-consuming to rerun tasks that get interrupted.</p>
<p>Another decision to make is how long to keep your Batch pools running. If you only run jobs periodically, then it would make sense to create a pool when you need to run a job and delete it when the job is finished.</p>
<p>If you need a job to start immediately and you know when you’re going to start it, then you can create a pool ahead of time. If you run jobs almost all of the time, then you should leave your pools <em>running</em> all of the time. If you always have jobs running, but the load varies a lot, then you can scale the pool up and down as needed.</p>
<p>As with most Azure services, you can run Azure Batch from the portal, the CLI, or from your code. All three methods provide rich monitoring capabilities. For example, if you run it from your code, you can request the status of all of the tasks in a job. You can call the Get Task Counts operation to find out how many tasks are active, running, and completed, as well as how many succeeded and failed.</p>
<p>And that’s it for compute-intensive applications.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>I hope you enjoyed learning about Azure’s compute services. Let’s do a quick review of what you learned.</p>
<p>You can put an application’s VMs into availability sets to help it survive both planned and unplanned outages. An availability set lets you configure the number of update domains and fault domains.</p>
<p>Update domains put virtual machines into groups where the VMs will be rebooted at the same time. By default, your VMs will be put into 5 update domains, but you can set it to anything between 2 and 20.</p>
<p>To survive unplanned outages, put VMs into fault domains. The maximum number of fault domains is either 2 or 3, depending on the region. Fault domains are physically isolated from each other, but they’re still within the same datacenter, so they won’t protect you against a data center failure.</p>
<p>Availability zones are an alternative to availability sets. An availability zone is a physically separate zone within an Azure region. Putting VMs in separate availability zones <em>will</em> protect you against a data center failure.</p>
<p>To protect against a <em>regional</em> failure, you need to deploy your VMs in multiple regions, using an active&#x2F;active or active&#x2F;passive model.</p>
<p>To scale an application, you can use vertical scaling, which means to use bigger VMs, or horizontal scaling, which means to use more VMs. With a scale set, you can set metrics to autoscale the number of VMs in the set. You can also configure autoscaling with Azure Cloud Services and Web App for Containers.</p>
<p>You can reduce your VM costs by using either reserved instances, where you prepay for one or three years, or low-priority instances, which can be preempted at any time.</p>
<p>To speed up networking between VMs, you can enable Accelerated Networking on their network interfaces, which allows them to bypass the virtual switch.</p>
<p>Azure DevTest Labs makes it easy to spin up non-production environments using base images, formulas, and artifacts.</p>
<p>Azure IaaS VM Backup only backs up Azure VMs. The Azure Backup Agent supports both cloud-based and local VMs, as well as physical servers. However, it only supports Windows, and you have to install the agent on every virtual and physical machine you want backed up. Both of these products store their backups in a Recovery Services vault.</p>
<p>System Center DPM and Azure Backup Server can back up anything except Oracle. They can store their backups in a Recovery Services vault or locally attached disk. System Center DPM can also store them locally on tape.</p>
<p>To apply a backup policy to a large number of VMs, it’s easiest to do it from a Recovery Services vault.</p>
<p>The Site Recovery service supports three failover scenarios: Azure to Azure, on-premises to Azure, and on-premises to secondary site. To support physical or VMware servers, you need a Configuration server, a Process server, and a master target server. You also need to install a Mobility service on each server that needs to be replicated. To support Hyper-V, you install the Azure Site Recovery Provider and Recovery Services agent on each Hyper-V host or cluster node. In the event of an outage, you have 6 different options for which recovery point to failover to. Latest is the default.</p>
<p>Microsoft’s primary serverless offering is Azure Functions. It’s event-driven and it’s invoked using a trigger that you specify. Inputs and outputs are configured with bindings. Durable Functions is an extension that lets you create orchestrator functions.</p>
<p>Azure Logic Apps is simpler than Azure Functions and it doesn’t require you to write any code. It’s also invoked using triggers.</p>
<p>To implement a microservices architecture, you need to use containers. Azure Container Instances is not really suitable unless you have very simple requirements. Instead, you should use either Azure Container Service or Azure Service Fabric.</p>
<p>Azure API Management acts as a gateway between clients and microservices. It also handles management tasks like security, monitoring, analytics, and rate limiting.</p>
<p>To deploy a web application that doesn’t have a microservices architecture, Azure App Service Web Apps is usually the best choice. One useful feature is deployment slots. You can have multiple versions of your app in different slots and then swap your staging slot with your production slot when you’re ready.</p>
<p>Three typical ways to increase the performance of a web app are scaling, caching, and using an edge network. You can configure App Service to autoscale based on metrics and schedules. For caching, you can use Azure Redis Cache. To serve static content to users in different geographic regions, you can use a content delivery network.</p>
<p>To make a web app highly available, deploy a standby copy in the paired region. Use Azure Traffic Manager to handle routing during a failover.</p>
<p>If your web app needs more than 20 instances or instances with a high memory to CPU ratio or secure network isolation, then you can use the Isolated service tier.</p>
<p>You can host a web API by creating an API App in Azure App Service. To secure the API, use Azure Active Directory. You can use AAD alone or use the AAD B2C service, which is designed for customer-facing web and mobile apps. You can also use the API Management service as a gateway to your API.</p>
<p>Azure Batch is usually the best way to run HPC applications. To use it, you upload the application and data files to Azure Storage, create a pool of compute nodes, create a job, and add tasks to the job. In many cases, you can use low-priority VMs to save money. For machine learning workloads, use Azure Batch AI.</p>
<p>Now you know how to design Azure solutions using virtual machines, serverless computing, and microservices; design web solutions using Azure App Service; and run compute-intensive applications using Azure Batch.</p>
<p>To learn more about Azure’s compute services, you can read Microsoft’s documentation. Also, watch for new Microsoft Azure courses on Cloud Academy because we’re always publishing new courses. Please give this course a rating, and if you have any questions or comments, please let us know. Thanks and keep on learning!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Back-Up-and-Restore-VMs-with-Azure-Backup-43/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Back-Up-and-Restore-VMs-with-Azure-Backup-43/" class="post-title-link" itemprop="url">AZ-104-Back-Up-and-Restore-VMs-with-Azure-Backup-43</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:45" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:45-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:47:14" itemprop="dateModified" datetime="2022-11-22T11:47:14-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Back-Up-and-Restore-VMs-with-Azure-Backup-43/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Back-Up-and-Restore-VMs-with-Azure-Backup-43/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Implementing-Azure-Backup-42/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Implementing-Azure-Backup-42/" class="post-title-link" itemprop="url">AZ-104-Implementing-Azure-Backup-42</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:44" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:44-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:41:54" itemprop="dateModified" datetime="2022-11-22T11:41:54-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Implementing-Azure-Backup-42/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Implementing-Azure-Backup-42/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Course-Introduction"><a href="#Course-Introduction" class="headerlink" title="Course Introduction"></a>Course Introduction</h1><p>Hi there. Welcome to Implementing Azure Backup. My name is Thomas Mitchell and I’ll be taking you through this course.</p>
<p>I’m an Azure instructor at Cloud Academy and I have over 25 years of IT experience, several of those with cloud technologies. If you have any questions about this course, feel free to connect with me on LinkedIn, or send an email to <a href="mailto:&#x73;&#x75;&#112;&#x70;&#111;&#114;&#116;&#x40;&#x63;&#108;&#111;&#x75;&#x64;&#x61;&#x63;&#x61;&#100;&#x65;&#109;&#x79;&#46;&#99;&#111;&#x6d;">&#x73;&#x75;&#112;&#x70;&#111;&#114;&#116;&#x40;&#x63;&#108;&#111;&#x75;&#x64;&#x61;&#x63;&#x61;&#100;&#x65;&#109;&#x79;&#46;&#99;&#111;&#x6d;</a>. This course is intended for those who wish to learn about Azure Backup. </p>
<p>We’ll kick things off by taking an introductory look at Azure Backup, where you’ll learn what it is and what it does. You’ll also learn what workloads can be protected with Azure Backup. After you’ve been introduced to Azure Backup, we’ll take a look at how it works. You’ll learn about Recovery Services vaults, Backup vaults, and about backup data redundancy options. We’ll also cover the different backup types that are available.</p>
<p>Once you’ve learned how Azure Backup works, we’ll take a look at Backup Center, where you’ll learn how to use it to manage Azure Backups. Coming down the home stretch, we’ll take a look at Azure Backup policies, where you’ll learn why you use them and how to configure them.</p>
<p>We’ll round things out with a few Azure Backup demonstrations. After finishing this course, you’ll come away with an understanding of what Azure Backup is, what it offers, and how to implement it.</p>
<p>We’d love to get your feedback on this course, so please give it a rating when you’re finished. If you’re ready to learn about Azure Backup, let’s get started!</p>
<h1 id="An-Introduction-to-Azure-Backup"><a href="#An-Introduction-to-Azure-Backup" class="headerlink" title="An Introduction to Azure Backup"></a>An Introduction to Azure Backup</h1><p>Hello and welcome to Azure Backup. In this lesson, we are going to take a look at what Azure Backup is, and at what it can backup.</p>
<p>Azure Backup, as you might expect, is Microsoft’s cloud-based backup solution that requires no infrastructure to implement. Azure Backup allows you to perform one-off backups and scheduled backups through the use of backup policies. </p>
<p>You can use Azure Backup to protect many different workloads, including Azure VMs, Azure Managed Disks, SQL Server in Azure VMs, and SAP HANA databases in Azure VMs. You can also use Azure Backup to protect Azure Files Shares, Azure Blobs, and on-prem files, folders, and system state.</p>
<p>Because it’s a zero-infrastructure backup solution, Azure Backup requires no capital expenditures. Its single pane of glass streamlines backups by allowing you to discover, govern, monitor, and manage backups right from the backup portal. Over the next few lessons, we’ll take a look at some of the key aspects of the Azure Backup offering.</p>
<h1 id="How-Azure-Backup-Works"><a href="#How-Azure-Backup-Works" class="headerlink" title="How Azure Backup Works"></a>How Azure Backup Works</h1><p>So, how does Azure Backup work? Well, for starters, Azure Backup consists of a few different layers, or pieces. You have the Workload Integration Layer, the Data Plane, and the Management Plane. The Data Plane is actually broken out into two pieces: “Access Tiers” and “Availability and Security”.</p>
<p>The Workload Integration layer is where the integration of the backup extension and the workload being backed up happens. The Access Tiers within the Data Plane define where backups are stored. These access tiers include the Snapshot Tier, the Standard Tier, and then Archive Tier. The Availability and Security piece of the Data Plane defines where backup data is replicated. The redundancy options chosen by the user will determine if the backup data is replicated across zones, or regions, or both. And the Management Plane is where the Recovery Service vaults, Backup Vaults, and Backup Center sit. These tools allow you to interact with the backup service.</p>
<p>Whether it’s data, machine state, or workloads running on on-prem machines or on VMs, it’s all backed up to the cloud and stored in either a Recovery Services Vault or a Backup Vault. Backup Vaults support Azure Database for PostgreSQL server backups, Azure blob backups, and backups of Azure disks. Recovery Services Vaults support everything else, including VM backups, SQL in Azure VMs, Azure Files, SAP HANA in Azure VMs, Azure Backup Server backups, backups via Azure Backup Agents, and DPM.</p>
<p>Regardless of which type of vault you use; the vault is used to organize backup data and it allow you to monitor your backed up items. Access to Recovery Services Vaults and Backup Vaults is controlled by Azure RBAC.</p>
<p>When you backup to a vault, you need to specify how the data in the vault is replicated, because the replication you choose determines how redundant your backup data is. You have a few different choices. You have locally redundant storage, or LRS; you have GRS, or geo-redundant storage; and you have zone-redundant storage, or ZRS.</p>
<p>Locally redundant storage protects backup data from server rack failures and drive failures in Azure. LRS replicates the backed-up data three times with a single data center within the primary region.</p>
<p>Geo-redundant storage protect data against region-wide outages by replicating that data to a secondary region.</p>
<p>Zone-redundant storage replicates backup data in availability zones. This guarantees data residency and resiliency in the same region. I should mention that recovery services vaults use geo-redundant storage by default.</p>
<p>If you need to back up on-prem Windows machines, you can use the MARS agent to backup directly to Azure, right over the internet. The long name for the MARS agent is Azure Backup Microsoft Azure Recovery Services agent. You can also backup on-prem Windows machines to a backup server like System Center Data Protection Manager, or DPM, or a Microsoft Azure Backup Server, or MABS. In these cases, you would then backup the backup server to a Recovery Services Vault in Azure. I should point out that on-prem Linux machines are not supported by Azure Backup.</p>
<p>Azure VMs can be backed up directly to Azure via the backup extension that Azure Backup installs on Azure VMs. The backup extension allows you to perform a backup of the entire VM. However, if you only need to backup files and folders on a VM, you can use the MARS agent instead.</p>
<p>Azure Backup supports full backups and incremental backups. It also supports Full, Differential, and Transaction Log SQL Server backups. The table on your screen breaks down the differences between the types of backups supported by Azure Backup:</p>
<p>Notice that all backup types, including MARS agent backups, Azure VM backups and backups performed via DPM and MABS all go to a vault. What’s also important to note here is that all backup types also support incremental backups. </p>
<p>In the next lesson, we’ll take a look at the Azure Backup Center.</p>
<h1 id="Getting-Started-with-the-Azure-Backup-Center"><a href="#Getting-Started-with-the-Azure-Backup-Center" class="headerlink" title="Getting Started with the Azure Backup Center"></a>Getting Started with the Azure Backup Center</h1><p>Welcome to Backup Center! In this lesson, we’ll take a quick look at what Backup Center is and when it can be used.</p>
<p>Azure Backup Center is designed to be a single pane of glass where organizations can manage their backups at scale. It’s designed in a way that makes it especially useful in large and distributed Azure environments. The Backup Center allows you to manage backups for many different workload types, vaults, subscriptions, regions, and even Azure Lighthouse tenants.</p>
<p>Because of its Datasource-centric design, Backup center can provide views and filters that focus on data sources that are being backed up. For example, if you make use of resource tags in your Azure environment, you can filter your views in Backup center so that you see the backup information for only the resources that are tagged with a specific resource tag. This helps filter out “noise”.</p>
<p>Now, I do need to mention here that the Backup Center only supports certain resource backups. The resource backups supported include Azure VM backups, SQL in Azure VM backups, SAP HANA in Azure VM backups, Azure Files backups, Azure Blobs backups, Azure Managed Disks backups, and Azure Database for PostgreSQL Server backups.</p>
<p>On the screen here is a view of what Azure Backup looks like. The Overview page is the default page you see when you open the Backup Center. It displays existing backup jobs, backup instances, and active alerts.</p>
<p>The Jobs tab, or pane, provides a summary of all backup and restore jobs within the last 24 hours. You can view information on the number of jobs that have completed, failed, and are in-progress. Clicking on View All, or on any of the numbers provides more information on the jobs listed.</p>
<p>The Backup Instances tile provides a summary of all backup instances that you’ve configured. Clicking on the numbers in this pane provides additional information on the backup instances for a particular data source type and protection state. </p>
<p>And then, of course, the Alerts pane shows any pertinent alerts. The left navigation pane provides you with the ability to manage your backup instances, vaults, and policies, and it allows you to monitor your backups and view backup reports. You can also configure compliance and Azure policies for backup.</p>
<p> In the next lesson, we’ll take a look at Azure Backup policies.</p>
<h1 id="Azure-Backup-Policies"><a href="#Azure-Backup-Policies" class="headerlink" title="Azure Backup Policies"></a>Azure Backup Policies</h1><p>Welcome back. In this lesson, we’re just going to take a quick look at backup policies.</p>
<p>As with any other backup solution, ongoing backups in Azure are managed via backup policies. You can create backup policies for Azure VMs, SQL in Azure VMs, SAP HANA in Azure VMs, and Azure file shares. However, if you want to just backup files and folders using the MARS agent, the policy for backing up these items is specified in the MARS console.</p>
<p>Backup policies are created on a “per vault” basis and each policy that you create can be assigned to multiple resources. For example, an Azure VM backup policy is typically used to protect multiple Azure virtual machines.</p>
<p>When you create a backup policy in Azure Backup, you have to configure the policy schedule and the retention settings for the policy. The policy schedule, of course, specifies when to take the backup, while retention defines how long each backup should be retained.</p>
<p>When configuring a backup policy’s schedule, you can select a daily schedule or a weekly schedule with a specific point of time. Retention can be configured for “daily”, “weekly”, “monthly”, and “yearly” backup points. Retention for “monthly” and “yearly” backup points is considered Long Term Retention, or LTR.</p>
<p>It’s important to note that when you create a Recovery Services Vault, a default policy is also created automatically. You can use the default policy to backup your resources, or you can create your own policy as you see fit. The image you see on your screen shows what the default policy looks like when you create a Recovery Services Vault:</p>
<p>Join me in the next lesson, where I’ll show you how to create a backup policy.</p>
<h1 id="Creating-an-Azure-Backup-Policy-Demo"><a href="#Creating-an-Azure-Backup-Policy-Demo" class="headerlink" title="Creating an Azure Backup Policy Demo"></a>Creating an Azure Backup Policy Demo</h1><p>Hello and welcome back. On the screen here you can see I’m logged into my Azure portal. And what we’re going to do here is create a basic backup policy in one of our recovery services vaults. </p>
<p>Now to do this, from this screen here, I can either select a recovery services vault from my Recent resources list, or I could search for it, or I can select Recovery Services vault. What we’ll do here is we’ll just select the ‘Berk’sBatteriesRecovery’ here. And once we’re in the Recovery Services vault, if we scroll down here to the bottom, where it says Manage, we can see we have our Backup Policies option here. We’ll go ahead and select that, and what this is going to do is bring up any Backup Policies that are configured for this vault. And you’ll notice here we already have an hourly log backup on my daily policy for file shares, a default policy for the Azure Virtual Machines, and another policy I’ve configured called FileShareBackups for Azure file shares. </p>
<p>What I’m going to do here is just create a new policy called My Policy, just to walk you through the process of creating a Backup Policy in Azure Backup. So, what we’ll do here is click ‘Add,’ and then the very first thing we have to do here is select the policy type that we want to create. We have the SAP HANA, SQL server Azure file share, or Azure Virtual Machine. What we’ll do here is we’ll select ‘Azure Virtual Machine’, and then once we do that, we have to provide some information, we need to provide a Policy name, we need to specify the Backup schedule, Recovery Snapshots for instant restore, the retention range, and then any Azure Backup resource groups that uses optional here which we won’t use. </p>
<p>So, what we’ll do here is we’ll just call this MyPolicy. And then in frequency here we can select daily or weekly. We’ll just leave this at daily. And the time here we’ll set it to back up at 8:00 PM. And of course you can select the time zone here. See if I can find eastern time here anywhere. There we go, Eastern time. And if we hover over the icon for Instant Restore, what this tells us is this setting allows us to configure how to retain snapshots along with the discs for a faster restore. If we hover over the icon here, we can see what this tells us is when we configure the retained setting for the instant recovery snapshots, it tells us that at the latest snapshot is the only instant restore available. It’s going to be retained until the next successful Backup completes, regardless of what the retention setting is here. We’ll just change this to three days. So, basically this allows us to get an instant recovery for up to three days using a Recovery Snapshot. And then we have the retention for our daily backup points. We’ll leave this at the default for 180 days.</p>
<p>So, basically the daily backups is going to be kept for essentially six months, 180 days. And what we’ll do here is we’ll change the retention of our weekly backup points. We’ll set this to eight weeks, we’ll say. And then we can configure the monthly backup retention. And again, what this tells us is it runs on the first Sunday of the month. And it’s retained for 60 months. And of course, we have the retention of yearly backups, and we’ll just save this for seven years, we’ll say. </p>
<p>Now, you’ll notice in this message here tells us that Azure Backup is going to create a separate resource group to store our instant recovery points of our managed VMS. Now, it uses a default naming convention of Azure Backup RG and then the geography with a number appended to it. Down here we can actually change that and specify the Azure Backup resource group. As I mentioned, this is optional. So, we’ll just allow this to use the default naming convention. And if we’re happy with our settings here, we can go ahead and create the policy. And if we click ‘Go to Resource,’ go to ‘Backup policies.’ </p>
<p>We now have MyPolicy, that’s configured for Azure Virtual machine backups. Now, if we select associated items, we can see there’s nothing that this is associated with now, because we’re not doing any backups yet. We’ll go through a demonstration shortly, that will show you how to create a Virtual Machine Backup using this policy.</p>
<h1 id="Backing-up-a-VM-from-the-Azure-Portal-Demo"><a href="#Backing-up-a-VM-from-the-Azure-Portal-Demo" class="headerlink" title="Backing up a VM from the Azure Portal Demo"></a>Backing up a VM from the Azure Portal Demo</h1><p>Hello and welcome back. So, in the previous demonstration, I showed you how to create a backup policy. And now what we’re going to do here in this demonstration is a backup a virtual machine from the portal. </p>
<p>On the screen here, I’m in my Azure home screen. And what I’m going to do here is select this ‘DC01’ Virtual Machine. And if I select this guy here, there’s a couple of different things I can do. If I scroll down, if I select ‘Backup’ here under Operations from this VM, I can select an ‘Existing Recovery Services Vault’ or I can create a new one. I can also create a new policy or choose an existing policy. </p>
<p>What we’re going to do here is select an existing vault. You’ll notice here we have the two vaults here. I did build my policy in the BerksBatteriesRecovery vault. So, we’ll select that one. And then in the dropdown here, we can see MyPolicy that I created earlier. So, we’ll go ahead and select ‘MyPolicy’. And when I do that, what it’s going to do is give me some feedback on the backup policy details. It’s going to give me the Backup Frequency, the Instant Restore information, and the Retention of the daily, weekly, monthly, and yearly backup points. And with those settings reviewed, what we do here is simply click ‘Enable Backup’. </p>
<p>And what it does is submit the deployment. And while this is doing its thing, we’ll go into the BerksBatteriesRecovery vault. We’ll go into Backup. And what we could do here is configure our backup here. But instead, what we’ll do here is go into Backup policies. And if we select ‘MyPolicy’ here, we go Associated items, we can now see that we have DC01 associated with this policy. Remember, when we first created the policy, there was nothing associated with it. </p>
<p>But now at this point, we have a VM that we can backup or actually we are backing up with this policy called MyPolicy. The Last Backup Status is in warning state. And it’s basically telling us that the initial backup hasn’t started yet. This will actually run the first backup based on the policy settings, which I think was 8:00 pm. So, that is how you backup a VM with a backup policy in Microsoft Azure.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Congratulations! You’ve come to the end of the course. Let’s review what you’ve learned.</p>
<p>We kicked things off by taking an introductory look at Azure Backup, where you learned what it is and what it does. You also learned what workloads can be protected with Azure Backup.</p>
<p>After the introduction to Azure Backup, we took a look at how it works. You learned about Recovery Services vaults, Backup vaults, and about backup data redundancy options. We also covered the different backup types that are available.</p>
<p>After learning how Azure Backup works, you learned about Backup Center, and how to use it to manage Azure Backups.</p>
<p>Coming down the home stretch, we took a look at Azure Backup policies, where you learned why you use them and how to configure them. We rounded things out with some demonstrations.</p>
<p>At this point, you should have a good understanding of what Azure Backup is, what it does, and how to use it. To learn more about Azure Backup, you can, and should, read Microsoft’s published documentation. You should also keep an eye out for new courses on Cloud Academy because we’re always publishing new ones. </p>
<p>Be sure to give this course a rating, and if you have any questions or comments, please let us know. As always, thanks for watching and happy learning!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Monitoring-Resources-with-Azure-Monitor-41/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Monitoring-Resources-with-Azure-Monitor-41/" class="post-title-link" itemprop="url">AZ-104-Monitoring-Resources-with-Azure-Monitor-41</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:42" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:42-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:47:32" itemprop="dateModified" datetime="2022-11-22T11:47:32-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Monitoring-Resources-with-Azure-Monitor-41/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Monitoring-Resources-with-Azure-Monitor-41/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Analyzing-Resource-Utilization-on-Azure-40/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Analyzing-Resource-Utilization-on-Azure-40/" class="post-title-link" itemprop="url">AZ-104-Analyzing-Resource-Utilization-on-Azure-40</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:41" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:41-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:40:56" itemprop="dateModified" datetime="2022-11-22T11:40:56-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Analyzing-Resource-Utilization-on-Azure-40/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Analyzing-Resource-Utilization-on-Azure-40/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to Analyzing Resource Utilization on Azure. My name is Matthew Quickenden, and I’m going to be guiding you through analyzing and diagnosing resource utilization and understanding consumption. I have over 20 years of industry experience, and I’ve recently been working with cloud and hybrid cloud technologies with a specific focus on Azure and Azure Stack. If you have any questions, feel free to connect with me on LinkedIn, or send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. This course is intended for people who want to become certified Azure architects or who are simply tasked with managing and supporting resources in Azure.</p>
<p>To get the most out of this course, you should have a general understanding of Microsoft Azure and how to deploy and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/azure-arm-intro/">manage resources</a>. Being familiar with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/azure-ps-intro/course-intro-17/">PowerShell</a> is very useful but not essential. We are going to explore adding diagnostic logging to resources, collecting that data to different output locations, and creating alerts based on it. In addition, we will look into costs associated with Azure consumption and how to generate reports and track Azure spend. By the end of this course, you should be able to set up diagnostic logging to various sources, create alerts based on these logs, and understand Azure cost consumption. Your feedback on this course is important, so please give it a rating when you’re finished. Let’s get started.</p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>Azure is based on a consumption and usage model. As administrators, it is important to monitor utilization, and understand where and how the resources we have deployed are being used, and how much they’re costing us. To help facilitate this, we can use tools built into Azure. We are going to explore diagnostic logging, which is captured in a resource level and allows us to view detailed logs. Metric counters help us look at performance and cost in relation to metrics. Azure Advisor is built into Azure at many layers and leverages Azure’s power to analyze your usage, and provide recommendations to help reduce excessive spend.</p>
<p>We could set up alerts on <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/diagnostic-logging/">logs</a> or metrics to trigger a variety of actions via action groups. Log Analytics can be leveraged to perform custom queries on log data. Azure Cost Management provides a view into resource cost allocation.</p>
<h1 id="Diagnostic-Logging"><a href="#Diagnostic-Logging" class="headerlink" title="Diagnostic Logging"></a>Diagnostic Logging</h1><p>Azure provides different logging options around resources. We are going to be taking a look at diagnostic options available to tenants. The Azure monitor helps facilitate logging and collection of these logs. There are three types of logs we need to be aware of: activity logs, diagnostic logs, and application logs, or guest OS logs. Let’s take a look at where these logs exist within an <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> subscription in relation to the resources they are monitoring. Here we have a Non-Compute Resource, which is tightly integrated and delivered through Azure providers, for example a network security group. Next to this, we have a Compute Resource.</p>
<p>This is a virtual machine with a guest OS, like Windows or Linux, and it has an application installed like IIS or Apache. Activity logs provide a record of operations from a subscription level, executed against the resource. For example, when administrative tasks are performed on the resource, like creating a resource or updating the properties of an existing resource, this will generate an event in the activity log. Diagnostic logs are collected within a subscription at an Azure resource level for services like VPN gateways or network security groups. Not all Azure services have an option for diagnostic logging, and the level of detail you can capture varies. You can view a full list of resources that support diagnostic logging from the Microsoft Azure website. Application logs are logs generated by applications or services within a guest OS. These logs are collected from within the operating system through an agent. Application logs can be collected from core services, like Windows Event logs, or from applications like IIS. Diagnostic logging can be enabled in a couple of ways: using the Azure portal, PowerShell, Azure CLI or the REST API via Azure Resource Manager. </p>
<p>When enabling diagnostic logging, you can choose where you want to export your logs to. You can export them to Log Analytics, to an event hub, or directly to a storage account. The Azure Portal allows us to easily browse through resources to enable diagnostic logging. Select the resource in question under the heading Monitoring and you should see a heading Diagnostic Settings. This will open a blade that contains diagnostic logging options for the type of resource you’re currently looking at. If it’s not already enabled, you’ll see an option to turn on diagnostics, to enable diagnostic collection. This will give you a choice of export <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/creating-locations-for-diagnostic-logging/">locations</a> we looked at earlier and the options related to them. For instance, when you select storage account, you get a choice of which storage account and retention settings. You will also notice different log events to capture, specific to the resource you’re working on. One of the first steps to take if you’re experiencing an issue is to select the resource and go to the Diagnose and Solve Problems blade. </p>
<p>This shows any general issues related to this resource’s health. With regards to virtual machines on the diagnostic settings blade, you have an option to enable guest-level monitoring. Once enabled, you’ll have more capability to collect logs from within the system without having to set up anything inside the system yourself. We will investigate more about these options in the demonstration. Log Analytics, formally known as Operations Management Suite, or OMS, is a log search analytics tool. It allows you to collect logs from different sources and correlate the data. You can write queries and create charts and graphs to help gain operational insight into your environment. You can create alerts based on metric thresholds or activity log events and consume pre-built management solutions, which includes queries and graphs. We can also send our diagnostic data to an event hub, which is a big data streaming platform. It can receive, process and transform thousands of events per second. Data can be stored or displayed as needed. Anomaly detection, live dashboards and application logging are among some of the ways we can utilize event hubs. Finally, we can send logs in their raw format to a storage account. It is important to understand the naming convention used to store it. Logs can be broken down by a subscription, resource group, provider and, finally, date and time with a JSON file called PT1H.json. An example of the file structure in the blob would look like this. The PT1H.json file contains an array of records, which we can see in the image shown. </p>
<p>To help collate different logs together to determine the correlation between events, it is important to have a common structure to the logs. Azure diagnostic logs have that. This is a top-level diagnostic schema that includes several required fields and some optional fields. Required fields include time, resource ID, tenant, and operation name. Some optional fields are duration, correlation ID, and location. Each type of service will have its own specific data fields that relate to it. For instance, auditing within Azure Active Directory includes AuditEventCategory, IdentityType, OperationType, TargetResourceType, TargetResourceName, and AdditionalTargets. Or in the case of Azure Automation accounts, the additional schema fields include RunbookName, ResultType, and ResultDescription. On a virtual machine, you can enable boot diagnostics. </p>
<p>Once you specify a storage account, you can then see the screen and view the serial log that is an output from the virtual machine. This is particularly useful for Linux machines, as they often have an output log to the console screen. You can see and download a screenshot of the current state the virtual machine is in from the screenshot tab. This is also accessible through PowerShell for automation. Using Resource Manager templates, you can automatically enable Diagnostic Settings at the time of resource creation. Using templates helps ensure consistency in how settings are configured. You may decide you always want to export diagnostic logs to specific services, like event hub or a central Log Analytics instance. Using templates can help allow for standards to be applied to resources at the time of deployment without user intervention. The resource type that supports this is providers&#x2F;diagnosticSettings. Here is an example of a diagnostic resource. If we look closely we can see the storage account ID, event hub authorization rule, event hub name, or workspace ID. Now we also have settings regarding logs and the retention period and particular metrics you want to capture and retention.</p>
<h1 id="Creating-Locations-for-Diagnostic-Logging"><a href="#Creating-Locations-for-Diagnostic-Logging" class="headerlink" title="Creating Locations for Diagnostic Logging"></a>Creating Locations for Diagnostic Logging</h1><p>For this exercise we are going to set up <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/diagnostic-logging/">diagnostic logging</a> on a network security group, exploring all three export options and the different methods to configure them. This is a prerequisites video so we are going to go through what we need to have in place and set up the destinations. Here I have a resource group called Jenkins and I’ve used an Azure Marketplace template to deploy a Jenkins instance. So we have a Linux virtual machine and a Windows 2016 server. This has deployed both a jenkins-nsg and a windemo-nsg. From here we are going to create the objects in another resource group called the AzureDiagnostic. </p>
<p>So I’ve created it already. And we’re going to add the resources we need here to do our diagnostic logging. So first things first, let’s go and create the OMS or Log Analytics workspace. Log Analytics, and we’ll click create. Not a lot of parameters here. I’ll pause the video and come back in a second. So we’ve given it a name and selected the appropriate subscription. We’ve selected the existing resource group we’ve created and the location, pricing tier free. With the OMS deployment, you cannot navigate away until this window’s finished validating. So this needs to finish its process before you can do the next thing. So we can see that validation succeeded and the deployment was successful. So if we go back to the resource group we can now see the AzureDiagnostics OMS instance. Next, we will create the event hub. So we’ve given it a name, selected a pricing tier, basic. Got the subscription and resource group and a location. We’ll click create. </p>
<p>Now this job is submitted to Azure resource manager and we can continue to do the next thing. So the last thing we need is a storage account. And create. So we’ve chosen the resource group, we’ve given the storage account a name, that’s lowercase. The account kind we need to make general purpose V1. The other options don’t matter at this stage. So we’re just going to do review and create. And create. Your deployment is underway and we can go look at the resource group. We can see that our Event Hub Namespace is there. OMS workspace is here and if we just give it a moment we can see the deploying storage account and we’ll look for that success. And here we can see the success of that account. And now we have our three prerequisites for logging: event hub, storage account, and an OMS workspace.</p>
<h1 id="Enabling-Diagnostic-Logs-Using-the-Azure-Portal"><a href="#Enabling-Diagnostic-Logs-Using-the-Azure-Portal" class="headerlink" title="Enabling Diagnostic Logs Using the Azure Portal"></a>Enabling Diagnostic Logs Using the Azure Portal</h1><p>So, in this resource group, we have our prerequisite <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/creating-locations-for-diagnostic-logging/">destinations for the Diagnostic Logs</a>. We will now return to the Jenkins resource group, and take a look at the Jenkins-NSG. This is attached to the Linux machines. If we go down here to Diagnostic Settings, we get an option to turn on to collect data. So we’re going to set up one setting per output. In this case, we’ll call this Linux NSG DiagStorage Account. So archive to a storage account. Now, we would like to configure the storage account to be AZUREDIAGDEMO. Select okay and then we want to pick these two logs and their retention setting. So this setting applies to the storage account in terms of the retention. </p>
<p>If we click save for that, and we return back a screen and refresh, we can now see we have this particular setting and the setting there for storage account, with event hub and Log Analytics not selected. So next we can add the event hub. That’s optional, and we’ll pick the default policy. Give it a name. And now we can see that one and we’ll create one more for Log Analytics, which is the easiest. Just pick the workspace, and that’s it. Give it a name: LogOMSDiag. So now we have three different policies set up for diagnostic logging for the NSG. So, the next thing we can do is if we go to the monitor, so you can find this in under services and monitor, and diagnostic settings. So, here we can see these are the different objects within that resource group that we can connect diagnostic settings to diagnostic logging, and in this case, we have it connected to one of the NSGs. </p>
<p>So if we’ve also wanted to connect the Windows NSG, click on it from there. So we got to that from monitor. Turn on diagnostic settings, and we’ll call this AllInOne. We can create one for diagnostic demo. Stream on events hubs, okay. Configure the event hub again…and Log Analytics. There we go, so now we can see we’ve enabled diagnostic logging for both NSGs. So what we saw in the NSGs were two different log options. So if we go back and look at what the different settings were within here, there’s a network security event and network security group rule counter. So, if we look at the other options we have for a different type of resource - so let’s choose the Public IP addresses that are attached to these systems. If we go in here and turn on diagnostic settings, we have a different set of logs and we also have metrics. So this wasn’t shown in the last one. The metric counters are numeric n-digit numbers that allow us to track and graph things rather than event-based. So, let’s turn on one of these so we can get some other information. Just configure all of them.</p>
<p> And if we return to the monitor, logging settings have been set up for three resources now. These are address specific resource types. So, if you want to enable guest logging for the machines this is the difference of a resource based monitoring and what we’re about to do now is guest logs. So, we’ll return to the resource group Jenkins. Type in here so we can easily find it. Then we go to the Linux Virtual Machine to start with and we scroll down to diagnostic settings. Enable guest level monitoring. So, we can now see this is a Linux Machine and we’re getting different logs which are Linux specific. And if we look at the metrics, we have processor, memory, network, file system, and disk. You can also choose to do custom. So there are additional, more specific counters, if you want to enable those. In this case, we’ll just leave it with the basic.</p>
<p> And additional SYSLOG levels so you can go to higher levels so you get less information. And then there are additional settings here for the storage account that you have chosen to log that information to. So, let’s connect the Windows server where we can go look at the information that we’re collecting. So here’s the Windows machine and diagnostic settings. Choose enable guest level monitoring. This takes a while so we’ll just pause the video and return once it’s complete. And here we can see the job completed. So, we can also go and look at custom and basic performance counters and add additional Windows counters to that list. There are additional logs so you can directly click IIS logs, if you have that installed, in different levels as well. It does understand .NET applications. One thing worth noting is if you’re having trouble with the log collection you may need to remove and reinstall the agent. So, you can do that from this screen here.</p>
<h1 id="Enabling-Diagnostic-Logs-Using-PowerShell"><a href="#Enabling-Diagnostic-Logs-Using-PowerShell" class="headerlink" title="Enabling Diagnostic Logs Using PowerShell"></a>Enabling Diagnostic Logs Using PowerShell</h1><p>So we have a brief demo here of using PowerShell to view the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/enabling-diagnostic-logs-using-azure-portal/">diagnostic settings</a> that we’ve added to the Jenkins-nsg. So we’ve got the login-AzureRm PowerShell commandlet here, which I’ve already run and logged in with my credentials. We’ve got four parameters here we’re going to set which include the target resource group name, target nsg, diagnostic resource group, and diagnostic Log Analytics instance. So we’re going to assign the nsg into this variable with the Get-AzureRmNetworkSecurityGroup and the appropriate values, run that command, and we check that value. We can see we’ve got the Jenkins-nsg. If we run this command, the Get-AzureRmOperationalInsightsWorkspace with the appropriate settings, we will see we’ve got the Log Analytics instance. So to check that we’ve got the right settings already on there, we created the AllInOne setting. So if we do the Get-AzueRmDiagnosticSettings, we can see, there it is, AllInOne, and each of the different locations for storing diagnostic data. So we’ve got the workspace, the event hub, and we’re using metrics, logs, and seven days retention. So going into the storage account, it’s also in here: StorageAccountId.</p>
<p>So this is basically the outline of what we’ve already created in the portal. You should be able to use this command, but at the moment the commandlets are broken, so this is a known issue. At the time of this video, there isn’t a workaround. You need to do it in the portal, so that’s a bit unfortunate, however you should be sending in values very similar to this. So we’re going to have a quick look at the CLI commands. So here, this is sort of what the CLI version would look like. So az, then run your login. You’ve got the diagnostic-settings create, and then again just fill out the properties for each of these different items. And in the last section of this code, how we can generate these things with code, is if you’re using Azure resource group templates, the resource here, under resources, you have diagnostic settings. So the type is provider&#x2F;diagnosticSettings and then you’d create your setting name, what resource you’re going to depend on, api version will change over time, and here we have the properties for each of the different items: eventHubAuthorizationRuleId, event hub, workspace or storage account id, and the logs or metrics you want to record. These are going to be different for different types of resources and the same thing for the log categories. So you’re going to have to tailor these for your specific purposes. That was a brief overview of how to set diagnostic settings using code.</p>
<h1 id="Viewing-and-Accessing-Diagnostic-Data"><a href="#Viewing-and-Accessing-Diagnostic-Data" class="headerlink" title="Viewing and Accessing Diagnostic Data"></a>Viewing and Accessing Diagnostic Data</h1><p>So what we’re going to focus on in this session is looking at the diagnostic data that we’ve sent to the storage account and to Log Analytics. We’re going to have a look and interrogate the data and see what’s there and run a query against it. So first thing, we’ll look at the storage account because that’s an easy step. We’ll use the Storage Explorer built into <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> now. We could also use the Storage Explorer as a simple application. We’ll expand the subscription and the storage blob where we put that data, and if we have a look here under blob containers, we can see we’ve got insight logs for the network security group event and network security group event rule counter. If we drill into one of these logs, these containers, we can see we’ve got resource ID, subscriptions, and we’ll just go down through this chain, resource groups, and Jenkins. </p>
<p>So, each one of these providers you have that goes to the storage account will have a separate folder. Then if we go up to windows, we’ve got a date, time, day, hour, minute, and at the end of that, we have a PT1H.JSON file. If we download that file we can see inside the file is a lot of information about the logging that we’ve collected. So, if we scroll across we can see we’ve got deny, direction, priority. There’s a lot of information regarding the resource type that we’ve recorded. It’s very specific information to a network security group. So these logs exist one file per folder and you’ll see the breadcrumb trail to that log here. If we go back to the tables under storage account, we can see there’s also Windows diagnostic information. So this is from the event table. Under Windows metrics, we can see we’ve got…counters. So, here’s the disk times, CPU times, mirror accounts, page faults. It’s all those standard windows counters but they’re stored in this table that we can query with many different tools. So, that’s showing us what we’ve got in the storage account. </p>
<p>Next, we’re going to go to the Log Analytics instance. Go over here and log in. So if we go to the Azure Diagnostics Log Analytics instance, Workspace Summary and click add, we’re going to jumpstart our query language here with some pre-canned Microsoft queries around network security groups. So if I scroll down we can find the Azure Network Security Group Analytics. So this gives you a preview of what there is and we’ll click create. So, that’s been created. If we go to the resource, we can see the chart here is actually displaying the data that we’ve already been collecting. Click on that summary chart and we’ll drill into the solution itself and we can see some additional queries. So what we’re really interested in here is the data that’s backing these queries. This is all the stuff that we’ve set up from the security groups and merged and we’re learning how to query it ourselves. So this is diagnostic information that we want to enrich and display through graphs, charts or PowerBI and how we need to display that information. In this case, we’ll drill into one of these existing queries and what we can see is basically the query version. There’s some information here on the side with other information you could filter by. And if we look at the options here we can export to CSV files or go to PowerBI. In our case, we really want to understand how to write our own queries because that’s where we’re going to be able to get specifically what we’re interested in seeing. So, from here we can go to the advanced analytics, and on the left, we can see the Azure Diagnostics OMS workspace and then Log Management. So, in this case, we’re just going to delete this query and start again. So if we double-click on the left, on the table, and click run (we’ll start very simple), we can see we’ve been given 10,000 items (that’s been limited). </p>
<p>If we expand this we can see more information around that specific query. So there are all the different fields in the row. If we click the direction, we ought to find the blocked traffic. Down here, you can click on this and that’ll actually put in the filter for you: where TYPE_S is equal to ALLOW. When we run this query, we can see we now have 4,564 records. We also want to summarize this now. This query window has intellisense built in. If you’ve languages like SQL, TSQL, or <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/enabling-diagnostic-logs-using-powershell/">PowerShell</a>, there are a lot of similarities. Although, this language is different. The intellisense will help us summarize and understand what we need to do. So here we can see if we click summarize, there’s some information. It explains to us how we need to do it so we can do “count by” and then the field we want. In our case, we want to summarize and count records by direction. And we can see we’ve had as many packets going in as going out. The next thing we’re really interested in doing is seeing this in time boxes. What we’re going to use is a bin. Bins allow us to aggregate this data into different categories of time. So, if we do bin, I’ll need Time Generated, and we’ll do one-hour buckets, so we just type in 1HR there. And if we run that query, we can now see the total traffic going in and out over time, and if we click chart, we can see each packet coming in and out and we’ve split that data. So, once we’ve got our specific queries we can <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/alerting/">create alert rules</a>, again for diagnostic information you’re trying to find. You can generate charts to put back on the dashboard yourself. There are a lot of other things you can do once you have this query from the diagnostic data. So, that’s a brief overview of how to view the data in the storage account and how to write queries against that data.</p>
<h1 id="Alerting"><a href="#Alerting" class="headerlink" title="Alerting"></a>Alerting</h1><p>In this section, we’re going to look at the Azure Monitor. The Azure Monitor is the central component built into the Azure fabric. The Monitor provides infrastructure-level monitoring and logging for supported services and is central to all monitoring toolsets in Azure. When you’re creating an alert, you have to understand what type of signal you’re going to monitor. There are two types: Metric Alerts and Log Alerts. You can collect Metric Alerts like CPU memory, disk usage, and network usage. In addition, there are metrics specific to Azure resources like “under DDoS Attack or not”. </p>
<p>There are also activity log alerts which look for events like create or update network security groups. So you can monitor administrative changes to your infrastructure. An alert consists of three parts: the Target which is the specific Azure resource that is being monitored, the Criteria, which is the conditional logic that will trigger the Action, and finally the Action, which is the call sent to an Action Group. An action group is a reusable collection of notifications defined by the user. These notifications can be a wide variety of actions such as voice call, SMS, email, call to a webhook, or trigger an automation runbook. In addition, you can push data into other resource tools like creating an ITSM ticket or a logic app. Alerts can be set up to trigger a specific action group, and action groups can be reused by different alerts. For this email alert, the receiver will get a confirmation email letting them know that they are in the alert action group.</p>
<h1 id="Analyzing-and-Creating-Alerts"><a href="#Analyzing-and-Creating-Alerts" class="headerlink" title="Analyzing and Creating Alerts"></a>Analyzing and Creating Alerts</h1><p>For this next example, let’s use a WordPress website running as a PaaS service to create an alert looking for page 404 HTTP responses and send ourselves an email. So, the first thing you want to do is go to the Monitor in Azure and select <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/alerting/">Alerts</a>. Again, this is a central place to record all the alerts. We can see here we’ve got a total of alert rules (14), and 8 are enabled. You’ll also notice here that there are different severities, so when you create your alert, you can choose your severity. This helps you collect all your infrastructure into a single place and gives you an idea of what’s critical and what’s not. So, we’re going to create a new rule, and here are the conditions we mentioned earlier: an alert condition, which is a target, and criteria. There’s the alert action, where you define the rules, severity, and the action group. So, the first thing we do is select a target, and select App Services, and we can see Azurefieldnotes. We’ll select that. We can now see what’s our target, and we want to add the criteria. So what we do notice here is there are 168 different signals we can alert on.</p>
<p>So as we said, there are some metrics, these come from the platform itself, and there are also activity logs. Within the activity logs, there are different categories. So here’s Administrative, Security, Recommendations, and Policy. In our case, we want to alert on Http 404. When we select the metric signal, we get a sample graph of data collected over the last 6 hours. We also see, in this case, there happen to be multiple instances because, in the App Services plan, there are three instances that run this website. So we want to select all of them, and what this allows us to see is a sum of the time of each of these. So before, when we had the aggregation, we can see that above 40 is where we want alerts.</p>
<p>So we want to ignore these bumps and just alert when we have this kind of spike. So, we’ll make it 50. We’re not going to select a specific instance, and we’re just going to say when greater than a total aggregation of 50, and select Done. Now we’re going to put in an alert name for our rule. We’ll call it Page404 Greater than 50. And we’ll set it to severity 3. Enable the rule upon creation. And now we need to create an action group. We’re going to do a new action group. We’re going to call this WebAlerts and also have a short name of WebAlerts. We need to choose a resource group to put this in. We have a default resource group here that’s already set up. Then we choose email, and we’re going to send an email to Matt. Select OK…and OK.</p>
<p>So we need to wait for that action group to get created. It’s done, so it added that for us. If we already had an action group we wanted to use, we could say “Select action group” and see our existing action groups that we’ve already created. In this case, we’re using a new one. Click “Create rule”. As we wait for that rule to be created, we should get an email that tells us we’ve been added to the action monitor group. This allows us to know that we can receive the email and that the alert is set up. If we go back to Manage alerts, we can see our “Page404 Greater than 50” response. Here’s the Target Resource, Target Resource Type, and the Signal. So that’s our alert. If we look in here, we can go and modify the conditions if we need to. Here we can see the bar where it’s going to get triggered. And that’s it for creating an alert.</p>
<h1 id="Azure-Advisor"><a href="#Azure-Advisor" class="headerlink" title="Azure Advisor"></a>Azure Advisor</h1><p>Azure has some built-in algorithms to help identify cost savings. These can vary depending on how you use the system, but it’s worth taking some time to review the suggestions and recommendations. One of the most common recommendations, if you have long-running virtual machine instances, is to purchase reserved instances. If we take a look at the screenshot, the Azure Advisor shows nine VMs it has determined to be around long enough to suggest that if we had reserved instance, and made a commitment to these resources, we could potentially save $2,700 US per year. Advisor recommendations are based on the last 14 days of usage and target low utilization systems.</p>
<p>Recommendations could include:</p>
<ul>
<li>Eliminating unprovisioned ExpressRoute circuits. It identifies ExpressRoute circuits that have been in the status of Not Provisioned for more than a month.</li>
<li>Deleting or reconfiguring idle virtual network gateways (virtual network gateways that have been idle for over 90 days). Since these gateways are built hourly, you should consider reconfiguring them or deleting them if you don’t tend to use them anymore.</li>
<li>Based on usage, recommending a more appropriate VM size. Virtual machines whose CPU utilization is 5% or less, and the network usage is 7 meg or less for four days or more, are considered low utilization virtual machines.</li>
</ul>
<h1 id="Resource-Baseline"><a href="#Resource-Baseline" class="headerlink" title="Resource Baseline"></a>Resource Baseline</h1><p>A baseline is helpful to ensure that your systems operate as expected. It’s good to be able to track what has changed since the resources were first deployed. Azure Resource Manager, or ARM, allows us to use JSON files called ARM templates to define resources in <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a>. This template uses what’s described as declarative syntax rather than scripts. That allows us to repeatedly deploy resources with great consistency and allows us to determine if the resources have changed from their original state. Declarative syntax means you define what the resources look like, and their dependencies between the resources, and the Azure Resource Manager takes care of the actual deployment. With a template, you can use Desired State Configuration packages (or DSC). These packages are the same within the operating system. </p>
<p>You can define a declarative configuration, and the provider takes care of ensuring the operating system looks like what you have defined. This style of configuration is often referred to as infrastructure as code. A benefit of using this method is that the configuration code can be submitted to a version control system to ensure that the changes are tracked and approved. This is in contrast to using scripts that execute command line operations in batches. Another approach can be to use change tracking. Change tracking is a solution that can be added to Azure resources and works by using Log Analytics and Azure Automation. You can enable this on a virtual machine. Once this feature is enabled, activity logs are collected in Log Analytics and analyzed and a dashboard is created to help identify events and changes to the operating system. The screenshot here shows Windows services and software have changed on this operating system.</p>
<h1 id="Monitoring-Cost-Consumption"><a href="#Monitoring-Cost-Consumption" class="headerlink" title="Monitoring Cost Consumption"></a>Monitoring Cost Consumption</h1><p>Understanding costs is very important when operating in the cloud at any scale. Over time, it can become a difficult task to understand exactly which groups or systems are costing you a lot of money. We will cover some tools and methods that will hopefully help keep your costs under control.</p>
<p>One of the first steps is to utilize Resource Tagging. Tagging exists on every resource in <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> whether the resource is free or charged by usage. This tagging structure is completely up to you and your organization. It is department based, cost center based, or you could just put the person’s name on the resource. Here we can see we have added three tags to a resource group: Solution, Owner, and Environment. You can also include resource tags within your JSON ARM templates or through PowerShell.</p>
<p>Here’s how to view costs by resource tag. In the Azure portal, go to the ‘Cost Management and Billing’ section. In the Cost Management section, go to Cost Analysis, then select ‘Group by’ and select ‘Tag’ from the bottom of the drop-down menu. In this screenshot, we can clearly see that tagging has only been partially successful, with the largest cost under ‘Subscription’ coming from untagged resources.</p>
<h1 id="Resource-Tagging"><a href="#Resource-Tagging" class="headerlink" title="Resource Tagging"></a>Resource Tagging</h1><p>It is worth noting that you can enforce tagging through <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> policies, meaning no matter how a user or administrator tries to deploy a resource, if they don’t have appropriate tags defined, the deployment will fail. Alternatively, you can use auditing, which will allow the deployment to continue but will issue a warning. These resources will be marked as non-compliant in the Azure policy service. Let’s take a look at creating a policy to audit and enforce tags. We’re going to leverage some Azure policy samples for resource groups located here at this GitHub project. We will use PowerShell to deploy these definitions. Note that you will require subscription owner rights to execute the following commands. Here we have the “deploy audit resource tag policy” PowerShell command. We are using the New-AzureRmPolicyDefinition commandlet and referencing the GitHub project (<a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-nz/azure/governance/policy/concepts/definition-structure">https://docs.microsoft.com/en-nz/azure/governance/policy/concepts/definition-structure</a>). </p>
<p>We’ve also filled out the description and the different parameters required to execute this command. This command here will show us how to deploy the “enforce resource tag” policy PowerShell command. In the Azure portal, under policy services and definitions, if we search for the keyword “Tag”, we’ll get these results. We can see the four built-in policies and the two custom policies we just created from the JSON template using PowerShell. If you select the assignment from the left side of the navigation bar, you’ll be able to create an assignment using this policy. Here is a screen showing the fields required to create an audit policy for the resource tag Owner. We are going to create an assignment of an audit policy for the resource tag Owner. We can see here the policy definition is what we created through PowerShell and an assignment name and description with the final text box being tag name having the resource tag you want to audit. Once the policy has been evaluated, we can see the compliant and non-compliant numbers of resources. You can also assign enforce policies to ensure that during deployment tags are assigned. If they are not, the deployment will fail. If you would like to learn more about creating policy definitions, here is a reference link (<a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-nz/azure/governance/policy/concepts/definition-structure">https://docs.microsoft.com/en-nz/azure/governance/policy/concepts/definition-structure</a>).</p>
<h1 id="Azure-Cost-Management"><a href="#Azure-Cost-Management" class="headerlink" title="Azure Cost Management"></a>Azure Cost Management</h1><p>Azure Cost Management. Microsoft had previously purchased and integrated Cloudyn as a separate cost management solution that was accessible through the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> portal. This functionality has now been fully integrated into the portal. The Azure portal now provides native tooling with Azure Cost Management. You can apply budgets to create alerts, to monitor spend, and you’re able to take proactive action before the end of a billing cycle.</p>
<p>We’re going to be looking at generating some reports for use to monitor cloud spend. There are a series of built views for accumulated cost, cost by resource, daily costs, cost by service, and invoice details. There is also the ability to slice and group data so you can track down where your Azure spend is. We will look at <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/cloudyn/">Azure Cost Management</a> in the next demo.</p>
<h1 id="Azure-Cost-Management-Demo"><a href="#Azure-Cost-Management-Demo" class="headerlink" title="Azure Cost Management Demo"></a>Azure Cost Management Demo</h1><p>Let’s start the demo. For this demo, I’d like you to note that I’m using not the portal.azure.com. I’m actually gonna be using the preview portal as this will likely be in production in the near future. So that is a slight difference between what you may see.</p>
<p>Here, we have the cost analysis. So we can get to here from the dashboard, and we go down to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/analyzing-resource-utilization-azure/cost-management-report/">Cost Management</a> and Billing. Got a couple of subscriptions here. We’ll go onto the one that’s got some charges in it, and we can see cost by resource. So let’s jump into cost analysis, and we can see the charts have loaded. So we have the ability to choose different reports, different ways we view costs. There’s accumulated cost or amortized cost.</p>
<p>So the first thing here is amortized cost is used over a period of time. So if you have Windows licenses or one-off purchases, you can have that spread over a longer month or the one-off charge. We could also see it in US dollars if that’s helpful. We also have the ability to choose different views. So these are the accumulated costs.</p>
<p>So we could also look at the cost by resource, and we can see the individual resources and the meters that they’re spending. So here it’s a premium SSD, and that’s the meter, and it’s cost that much. And that’s over this time period. So we can also change that to be last month, last seven days, there’s a bunch of predefined ranges here, and you can also choose your own custom dates. So if we do this quarter, still very low charges here.</p>
<p>If I can also choose now the cost by service, we can see we’ve got it by months, and we have these charts here that we can help drill down into. So, for location or resource group, you can choose to group the data differently. So we could say, let’s group by resource rather than by resource group. Hence, now we have a different summary down here.</p>
<p>So we can see our most expensive resource group here is $74. And you can also click on these charts to filter down the graphs. So, when we look at this over the month, we’ll see, now there’s where our charges come, and this is basically one resource is taking up all our charge. There’s also the ability to choose the granularity. So the granularity, again, could be daily. How detailed do you want the data? Microsoft will summarize some of this data after a period of time, but the reporting still has an aggregate, which allows you to report on it.</p>
<p>So we can see here, these are obviously the end of the month where it rolls over, but we’ve now gone to daily granularity. And this is an interesting one. We can see it over time. So we can see this one stopped running and maintained its cost, this one’s run the same over the whole time, and here was a new charge that started, and it’s been running consistently since. Again, if we click on that one result, we can drill into it. So we can see this is a disc, it’s in US West, and it’s storage. We can also choose to save these views, and you can also make them private, so it’s useful for enterprise management. You can share these views with people.</p>
<p>The other option here under Settings is we can set up an export. The first thing we’re gonna need to do is actually register the resource provider for that. So I’ve got another page here, which has my subscription, and if I go into the subscription, we can see the resource providers down here, and we can see cost, management, exports. In this case, it’s already registered.</p>
<p>So if I go back to the schedule export, choose a name, sample, we’re gonna choose weekly cost for the last seven days, and the storage account’s gonna be me, cost, export. Next and Create. And that says there, your first export will be available in four hours. So there’s the export sample data. Run now. Successfully queued. So we can create different jobs to export data. We’ve also seen the different ways we can drill down into it. We’ve looked at granularity. You can also choose different visualizations to help you understand how your data is being displayed. I can also view it on a table, which you can download and export. So here, we can see download to Excel, CSV. If we download to Excel, we can see that cost file’s come down now, and our export data isn’t too different, and here’s our data.</p>
<p>So we can see the charges, the billing period, and if we chose by resource, we’d also have that sort of data inside this table. We also have the ability under the Settings tab to connect AWS. So if we click on that, we can add a connector. This will add AWS properties, and allow you to review those costs inside the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> portal as well. Gonna go back to the cost management, and into here again, and look at budgets as the final thing.</p>
<p>So the final thing we’re gonna do is create a budget. If we click Add, we get the choice to change the scope to a different subscription. We’re gonna add ourselves $100 budget. We can choose the expiration and start of this budget. We can see there’s a suggested amount here. Now, you have to wait for the cost data to appear, and we can see where this budget is. So previously we were spending over 120, this month was 180, and it’s dropped over since then. So I don’t wanna spend that again. Just wanna make sure that we don’t catch that cost.</p>
<p>So if we go Next, we should see the percent of budget. So I wanna know when I’m at 80%, and that’s $80, and I wanna send an email to an action group, so I’ve already created this earlier, but you can manage that through this link. And then, I also wanna know when I’m at 100% of that budget. You could send an SMS or trigger an action, different action as well. It’s saying to also make sure you add this to your spam email, just in case you miss the emails. We’re gonna click Create, and that’s our budget. Budget 100 successfully created. And we can see if we’ve got a progress through that budget at the time.</p>
<p>This brings us to the end of the demo. I hope you found this useful.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>This session covered a wide range of topics and was focused on understanding diagnostic logging and what the differences are between activity logs, resource logs, and guest OS logging. We looked at various ways to enable diagnostic logging, including through the portal, PowerShell, CLI, and through Resource Group templates. We looked at where we could send the information: into a storage account, blobs for files and tables for metrics, event hubs for streaming information, and into Log Analytics where we could run queries against the data and enable a range of out-of-the-box solutions. We also looked into creating alerts and sending them to an action group and exploring ways we could baseline deployed resources using armed templates, DSC, and change tracking. </p>
<p>In the final section, we covered material around tracking costs, including applying and enforcing resource tags, creating and running reports, and scheduling reports to be sent via email or saved to a storage account. I hope you’ve enjoyed this course and you found it useful.</p>
<h1 id="13Resource-Tagging"><a href="#13Resource-Tagging" class="headerlink" title="13Resource Tagging"></a>13<strong>Resource Tagging</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-nz/azure/governance/policy/concepts/definition-structure">Creating Policy Definitions</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Manage-Access-to-Azure-With-Role-Based-Access-Control-39/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Manage-Access-to-Azure-With-Role-Based-Access-Control-39/" class="post-title-link" itemprop="url">AZ-104-Manage-Access-to-Azure-With-Role-Based-Access-Control-39</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:39" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:39-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:45:54" itemprop="dateModified" datetime="2022-11-22T11:45:54-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Manage-Access-to-Azure-With-Role-Based-Access-Control-39/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Manage-Access-to-Azure-With-Role-Based-Access-Control-39/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Managing-Role-Based-Access-Control-on-Azure-38/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Managing-Role-Based-Access-Control-on-Azure-38/" class="post-title-link" itemprop="url">AZ-104-Managing-Role-Based-Access-Control-on-Azure-38</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:38" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:38-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:43:28" itemprop="dateModified" datetime="2022-11-22T11:43:28-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Managing-Role-Based-Access-Control-on-Azure-38/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Managing-Role-Based-Access-Control-on-Azure-38/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to Managing Role-Based Access Control on Azure. My name is Eric Leonard and I’ll be leading you through this course. I’m a Microsoft Azure MVP and an Azure content author at Cloud Academy. I have over 15 years of experience in IT, several of those working with cloud technologies in the public and private sectors. If you have a question, feel free to connect with me on LinkedIn and send me a message, or send an email to <a href="mailto:&#115;&#x75;&#x70;&#112;&#x6f;&#x72;&#x74;&#x40;&#x63;&#108;&#x6f;&#117;&#x64;&#97;&#99;&#97;&#100;&#101;&#109;&#x79;&#x2e;&#x63;&#111;&#x6d;">&#115;&#x75;&#x70;&#112;&#x6f;&#x72;&#x74;&#x40;&#x63;&#108;&#x6f;&#117;&#x64;&#97;&#99;&#97;&#100;&#101;&#109;&#x79;&#x2e;&#x63;&#111;&#x6d;</a>. Who should take this course? This course is intended for people who want to take the AZ-101 exam to become a certified Azure administrator, or for people who are tasked with administrating Azure resources and security.</p>
<p>To get the most from this course, you should have a general understanding of the Azure portal. We’ll begin the course by touching on an overview of managing role-based access control on Azure. We will then work through how we configure access to Azure resources, create custom roles, and finally go over some troubleshooting steps. By the end of this course, you should be able to configure and assign the appropriate role-based access controls. We would love to get your feedback on this course, so please give it a rating when you are finished. So if you are ready to learn more about managing role-based access control, let’s get started.</p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>RBAC provides fine-grained access management to your resources in Azure. What this does is it allows you to segregate duties between different teams in your organization. As an example, one team could be tasked with managing VMs and a subscription, or someone could be tasked with cost management, or give your IT security team access to Azure Security Center. Making these RBAC examples work is by creating role assignments. Role assignments define how you can access resources in Azure. This can be at the management group level and all the way down to the resource itself. A role assignment consists of three elements, the security principal, the role definition, and the scope you apply it to. A security principal can be a user, group, service principal, or managed identity that requires access to Azure resources. A role definition is a list of actions that you can or cannot do. Your role definition could allow you to create and manage virtual machines but prevent you from deleting them. </p>
<p>The following are the most common or known RBAC roles. Owner provides full access to resources in Azure, and you can delegate access to other users. Contributor, just like the owner role, provides full access to resources in Azure, but you cannot delegate control. As the name implies, the reader can only view resources in Azure. And lastly, the user access administrator role is granted permission to manage access to Azure resources. Beyond these fundamental roles, Azure provides many built-in roles to meet your organization needs. As an example, the security admin role provides access to Azure Security Center, where they can read, edit security policies, and view and dismiss alerts. The last element is scope. In Azure, the RBAC roles can be assigned at different levels depending on how wide you want to provide access. Scope can be applied at the management group level, or at the subscription, or at the resource group, all the way down to individual resources. Combining these three elements makes the role assignments work by defining the role definition it will apply to a security principal and then is assigned to a scope.</p>
<h1 id="Configure-Access-to-Azure-Resources"><a href="#Configure-Access-to-Azure-Resources" class="headerlink" title="Configure Access to Azure Resources"></a>Configure Access to Azure Resources</h1><p>Role-based access control is how you can manage access to resources in Azure. As you navigate through Azure, from the management group, subscription, resource group all the way down to the individual resources, you will notice a blade called Access Control IAM. This is where you can view, add and remove role assignments. Let’s go to the Azure portal and see how we can view, add and remove these role assignments. Here we are in the Azure portal under Resource Groups. Let’s select our resource group and we will notice that we have a virtual machine that is already deployed. Let’s give access to Ari as he is tasked with managing all virtual machines in this resource group. Click on Access Control. To add a role assignment, we can add it by clicking on the Add button on the right-hand side or we can hit the Add Role Assignment in the menu bar. Under Role, we will see a list of all the built-in roles possible. And we’ll scroll all the way down to Virtual Machine Contributor. In the Select field, we can search for Ari’s name, select his name and hit Save. Now Ari has access to this user’s group and to manage the virtual machine. </p>
<p>We can check Ari’s access by typing in his name. And here we’ll see the results of the access that he has. We can close that. As well as you can go to Role Assignments. Here we’ll see all of the role assignments for the resource group. Some of them are inherited and Ari is at the bottom, we’re a virtual machine contributor for this resource group. We can remove Ari’s access by selecting his user and clicking Remove. In this short demo, we added our user, Ari, to the virtual machine contributor role. We then verified his access by going to Check Access and reviewed the Role Assignments tab. We then finished off by removing the role assignment to the resource group.</p>
<h1 id="Activity-Logs"><a href="#Activity-Logs" class="headerlink" title="Activity Logs"></a>Activity Logs</h1><p>The Azure Activity Log provides visibility into subscription-level events that have occurred in Azure. Using the Activity Log, you can determine what operations were taken on the resources in your subscription. The Activity Log has eight categories. Administrative. This will contain all the records for create, update, delete, and actions operations performed. Here we will see events related to RBAC like create role assignment and delete role assignment. Service health. Service health will contain any health-related events that affect Azure. Resource health will contain the records of any resource health events that have occurred to your deployed resources in Azure. Alerts will contain all the alerts that were activated. Autoscale will include the records related to autoscaling. Recommendations. This will have the recommendations from Azure Advisor. </p>
<p>Security, which will contain all of the logs generated by Azure Security Center. And finally, policy. The policy will contain records of all effect actions performed by Azure Policy. The Azure Activity Log only retains records for the last 90 days, and if you need to keep them longer for auditing or compliance reasons, you will need to use an Azure Event Hub to send your logs to your security information and event management application or archive the records in an Azure storage account. For Role-Based Access Control, the Azure Activity Log will log any changes made to role assignments or role definitions in your subscription. The events will be recorded as create role assignment, delete role assignment, create or update custom role definition, and delete custom role definition.</p>
<h1 id="Custom-Roles"><a href="#Custom-Roles" class="headerlink" title="Custom Roles"></a>Custom Roles</h1><p>Create a custom role for RBAC. Azure has many built-in roles that cover most of the needs for any team, but sometimes those built-in roles don’t cut it. You can create your own custom role to meet those needs. Custom roles can be created using Azure PowerShell, Azure CLI or the REST API. For this demonstration we will use the Azure Cloud Shell to create a custom role using Azure CLI. Here we are back in the Azure portal, where we will create a custom role. To start we need to go to the Azure Cloud Shell. We can open the Cloud Shell by selecting the Cloud Shell icon at the top of the page, or we can open a new tab and go to shell.azure.com. We will be creating a custom role called Virtual Machine Operator. Let’s open Visual Studio Code and look at our custom role. Our template is broken down into several sections. We have the name of the custom role, then we have the IsCustom, which indicates that this is a custom role. We have the description, which provides a short description of the role so others can understand what this custom role does. Action, which specifies what you’re allowed to do. NotActions, which is to deny actions. And AssignableScope, this is where we will list our scope for our custom role. </p>
<p>Let’s apply the custom role to the subscription. Type in AZ role definition create dash dash role definition and the name of the file, which is vmoperator.json, and hit Enter. After we have applied the command we can go back to the Azure portal, where we will select our resource group and go to Access control, Roles and scroll to the bottom to find our Virtual Machine Operator custom role. You will notice that the icon is different to easily indicate that this is a custom role. If during your testing of the new custom role, you notice that the role cannot do a certain action, you can return to your role definition and add the missing action. In this instance we will allow the role the ability to schedule shutdowns. We will add the Microsoft.DevTestLab&#x2F;schedules. We will then save the file and then we’ll type AZ role definition update dash dash role-definition and the name of the file. If the custom role is no longer needed you can delete it by typing AZ role definition delete name and provide the name of the custom role. In summary, we looked at a custom role definition and reviewed all the sections. We then created a new custom role, updated the role and then deleted the roll as we no longer needed it.</p>
<h1 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h1><p>Role-based access control changes in Azure don’t always go as planned. Let’s look at some scenarios where you may encounter issues. Scenario one. You can’t create a new resource in a resource group. Check access control to verify the user has the appropriate role assignment. If the user is part of a custom role, verify that the role definition can deploy that resource. Scenario two. You attempt to add a role assignment in your subscription and you receive an error role assignment limit exceeded. In your subscription, there is a limit of 2,000 role assignments. If you see this error, consider assigning roles to groups instead of individual users. Scenario three. You attempt to create or update a custom role but you get an error. Confirm that the user has the Microsoft.Authorization&#x2F;roleDefinition&#x2F;write permission. Scenario four. You attempt to create a new custom role and you receive an error role definition limit exceeded. In your tenant, there is a limit of 2,000 custom roles. Scenario five. You make a change in Access Control or you add a custom role and the changes do not reflect in the portal or in the console. Sometimes these changes can take time to take effect. You can log out and re-log in to force the refresh.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>I hope you enjoyed learning about managing role-based access control on Azure. Let’s review what you learned in this course. RBAC provides fine-grained access management to your resources in Azure. A role assignment consists of three elements, the security principal, that’s the user group, service principal, or managed identity. Then we have the role definition, that’s the role definition which is a list of actions that you can or cannot do and lastly, the scope that it applies to. We configured access to Azure resources by going to Access Control at the resource group level where we can also make these modifications at the management group, subscription or individual resource levels. In the resource group, we added a role assignment, checked the individual access, reviewed the role assignments and then removed the access. The Azure Activity Log provides visibility into subscription-level events that have occurred in Azure. Using the Activity Log, you can determine what operations were taken on the resources in your subscription. </p>
<p>The RBAC events will be recorded as create role assignment, delete role assignment, create or update custom role definition and delete custom role definition. Activity logs are kept for only 90 days and if you need them for auditing or compliance reasons, you will need to export your logs using an event hub or a storage account. Custom roles can be created in Azure to meet the necessary requirements. You can use the Azure Cloud Shell with Azure CLI or PowerShell to create, update and delete role definitions. Adding role assignments or creating custom roles in Azure can lead to configuration errors. We reviewed some common scenarios in troubleshooting RBAC. To learn more about managing role-based access, be sure to read Microsoft’s documentation. Be sure to also watch for new Microsoft Azure courses on Cloud Academy because we’re always publishing new courses. Please give this course a rating. If you have any questions or comments, please let us know. Thanks for watching and happy learning.</p>
<h1 id="4Activity-Logs"><a href="#4Activity-Logs" class="headerlink" title="4Activity Logs"></a>4<strong>Activity Logs</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/azure/azure-monitor/essentials/activity-log#send-to-log-analytics-workspace">Sending to a Log Analytics Workspace</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Designing-for-Azure-Identity-Management-37/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Designing-for-Azure-Identity-Management-37/" class="post-title-link" itemprop="url">AZ-104-Designing-for-Azure-Identity-Management-37</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:36" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:36-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:39:38" itemprop="dateModified" datetime="2022-11-22T11:39:38-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Designing-for-Azure-Identity-Management-37/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Designing-for-Azure-Identity-Management-37/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to Designing for Azure Identity Management. My name is Thomas Mitchell and I’ll be taking you through this course on the key technologies to consider when designing an identity management solution. I’m an Azure Content Author at Cloud Academy and I have over 25 years of deep IT experience, several of those with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn, or send an email to <a href="mailto:&#115;&#117;&#x70;&#112;&#x6f;&#114;&#x74;&#x40;&#99;&#x6c;&#x6f;&#117;&#x64;&#x61;&#x63;&#97;&#100;&#x65;&#x6d;&#x79;&#46;&#99;&#111;&#109;">&#115;&#117;&#x70;&#112;&#x6f;&#114;&#x74;&#x40;&#99;&#x6c;&#x6f;&#117;&#x64;&#x61;&#x63;&#97;&#100;&#x65;&#x6d;&#x79;&#46;&#99;&#111;&#109;</a>. This course is intended for IT professionals who are interested in earning Azure certification, those who wish to become Azure architects, and those who are tasked with designing an Azure identity management solution. To get the most from this course, you should have at least a moderate understanding of Microsoft Azure, and of identity management concepts. We’ll kick off the course by discussing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a> and what it offers. We will then talk a bit about hybrid identities and what purpose they serve. Next, we’ll cover Azure AD Domain Services and how to deploy this feature. </p>
<p>After covering Azure AD Domain Services, we’ll get into <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/single-sign-on-overview/">single sign-on</a>, and how to configure it for a web application. Azure MFA or multi-factor authentication is another cool feature that we will discuss. We’ll cover what it is, what it offers, and how to enable it. After covering MFA, we will get into Azure AD B2B and Azure AD B2C. These are Azure AD Business to Business and Azure AD Business to Consumer. You will learn what they are, what they offer, and how to deploy them. We’ll then move into Privileged Identity Management, otherwise known as PIM. Rounding out the course are topics on <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/self-service-password-reset/">self-service password reset</a>, self-service group management, and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/overview-of-managed-identities-for-azure-resources/">managed identities for Azure resources</a>. There are demonstrations sprinkled throughout the course. These demos will show you how to deploy and use the technologies covered. By the end of this course, you should have a good understanding of all key technologies and features as they relate to designing for Azure identity management. You should also be able to deploy each feature with an understanding of what it offers and how it fits into any identity management solution. We’d love to get your feedback on this course, so please give it a rating when you’re finished. If you’re ready to learn about Designing for Azure Identity Management, let’s get started.</p>
<h1 id="Introduction-to-Azure-AD"><a href="#Introduction-to-Azure-AD" class="headerlink" title="Introduction to Azure AD"></a>Introduction to Azure AD</h1><p>Microsoft’s Azure Active Directory is a cloud-based identity and access management service. With it, users can sign in and access external resources such as Office 365, the Azure portal, and other software as a service applications. Azure AD, of course, also allows users to access internal resources as well. Such resources include applications inside the corporate network and on the internet along with cloud applications that have been developed and deployed by your organization. Azure AD is used to control access to applications and resources according to business requirements. For example, Azure AD can be configured to require multi-factor authentication or MFA when a user needs access to important company resources. In addition, Azure AD can be used to automate user provisioning between an existing on-prem Windows server AD and corporate cloud applications like Office 365. With Azure AD, organizations have access to tools that can used to automatically help protect user identities and credentials which allows them to meet access governance requirements. Microsoft Online services like Office 365 and Microsoft Azure leverage Azure AD for sign-in and for identity protection. As such, an organization that subscribes to any of the Microsoft Online business services automatically gets at least the free version of Azure AD along with those services. </p>
<p>Adding paid services to a tenant can enhance an Azure AD implementation. Such paid services include Azure Active Directory Basic, Azure Active Directory Premium 1, and Azure Active Directory Premium 2. These Azure AD paid licenses ride on top of an existing free directory, and they can provide additional services such as self-service, security reporting, enhanced monitoring, and secure access for mobile users. One thing to note, however, is that while all of these added features can add cool functionality and security, Azure Active Directory Basic, Azure Active Directory Premium 1, and Azure Active Directory Premium 2 are not currently supported in China. The free version of Azure Active Directory offers basic user and group management functionality and on-prem directory synchronization. It also offers basic reporting and single sign-on or SSO across Office 365, Microsoft Azure, and many popular SaaS applications. In addition to the free features available in the Azure AD Free version, Azure AD Basic provides cloud-centric application access as well as group-based access management. Other features included with the Basic version include self-service password reset for cloud apps and Azure AD Application Proxy which is a feature that allows you to publish on-prem web applications using Azure AD. Azure Active Directory Premium P1 offers quite a bit more than either Free or Basic. In addition to what those versions offer, Azure AD Premium P1 offers hybrid users access to both on-prem and cloud resources. Premium P1 also supports advanced administration tasks like self-service group management, dynamic groups, and it even integrates with Microsoft Identity Manager or MIM. Microsoft Identity Manager is an advanced, on-prem identity and access management solution. </p>
<p>Azure AD Premium P1 also offers cloud write-back capabilities which are used to allow self-service password reset for your on-prem users. Azure Active Directory Premium P2 builds upon what is offered in the P1 edition by offering everything included in the Free, Basic, and P1 versions plus Azure Active Directory Identity Protection which helps provide risk-based conditional access to applications and critical company data. Azure AD Premium P2 also offers Privileged Identity Management or PIM which is useful for discovering, restricting, and monitoring administrators as well as their access to corporate resources. Privileged Identity Management also provides just-in-time access when it’s needed, meaning access to resources can be limited to only those times when it’s required and then be taken away automatically when the access is no longer needed. Other pay-as-you-go feature licenses such as Azure AD Business-to-Consumer are also available to assist with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity management</a>. Azure AD B2C as it’s called helps provide identity and access management solutions for customer-facing applications.</p>
<h1 id="Create-Directory-and-Add-Custom-Domain"><a href="#Create-Directory-and-Add-Custom-Domain" class="headerlink" title="Create Directory and Add Custom Domain"></a>Create Directory and Add Custom Domain</h1><p>To create a new directory and add a custom domain for it, log into the Azure portal. While in the portal, open <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a> and click on the create a directory link. Provide an Organization name along with the domain to use for the directory. Select a country or region and then click create. Once the directory has been provisioned, click the link to manage the new directory and sign in if required to do so. From within Azure Active Directory click custom domain names and then add your custom domain name. Provide and internet routable custom domain name and then click add domain. </p>
<p>At this point you’re provided with the option to verify the domain via either a text record or an MX record. My preference is to typically use the text record. Copy the record value and then visit your domain’s DNS management console. Create a text record and supply the value that you were provided. Save your new text record and switch back over to Azure. Click the verify button to verify the domain using the DNS record that you’ve just created. After verifying the domain, set its primary. And then click yes to confirm.</p>
<h1 id="Azure-AD-Domain-Services-Overview"><a href="#Azure-AD-Domain-Services-Overview" class="headerlink" title="Azure AD Domain Services Overview"></a>Azure AD Domain Services Overview</h1><p>Azure AD Domain Services is a Microsoft cloud-based offering that provides managed domain services, such as domain join, group policy, LDAP, and Kerberos and NTLM authentication. The domain services provided are fully compatible with traditional on-prem Active Directory and they can be deployed without any need for deployment or management of domain controllers in the cloud. Azure AD Domain Services integrates with the existing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> tenant and makes it possible for users to log in with their corporate credentials. Existing user accounts and groups can be leveraged to secure access to resources. As such, this offers a smoother transition of on-prem resources to Microsoft Azure. Companies leveraging a hybrid IT infrastructure will typically synchronize their <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity</a> information from their on-prem directories to the Azure AD tenant. As more of their on-prem applications are migrated to Azure, Azure AD Domain Services can become more useful. An important caveat to consider when deciding if Azure AD Domain services are the right solution is that password sync is mandatory for a hybrid organization to use Azure AD Domain Services. </p>
<p>This is required because users’ credentials are needed for authentication via NTLM and Kerberos in the managed domain that is provided by Azure AD Domain Services. When considering Azure AD Domain Services, keep in mind that the managed domain is actually a stand-alone domain. It is not, and I repeat, it is not an extension of the on-prem AD domain. This is a common misconception among IT professionals. Also, because the domain is managed, the IT administrator does not need to, nor can he, manage, patch, or monitor the domain controllers for the managed domain. Likewise, there is no need to manage or even monitor AD replication within the managed domain. Quite frankly, there really isn’t much for the administrator to do in the managed domain, especially since the administrator doesn’t even have Domain Admin or Enterprise Admin privileges on the managed domain.</p>
<h1 id="Deploy-Azure-AD-Domain-Services"><a href="#Deploy-Azure-AD-Domain-Services" class="headerlink" title="Deploy Azure AD Domain Services"></a>Deploy Azure AD Domain Services</h1><p>To deploy <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/azure-ad-domain-services-overview/">Azure AD Domain Services</a> log into the Azure portal. Once in the portal click on Create a Resource and then search for Domain Services. Select Azure AD Domain Services from the search results and then click Create. Provide the basic information for the domain, including the DNS name for the domain as well as the Subscription you are deploying to, along with a Resource group. You’ll also need to supply a Location. Click Okay to move onto the next step. At this point you’re prompted to create a Virtual network for the managed domain that you are setting up. Provide a name for the network along with an address space that works for your environment. You will also need to define a Subnet and a Subnet address range that you’d like to use for the managed domain. </p>
<p>The managed domain controllers and associated infrastructure that gets deployed by <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure</a> as part of the Manage Domain setup will reside on this network and on this subnet. Click Okay and then Okay again. Next you are advised that the AAD DC Administrators group has been created. This group is used to manage the domain. It’s similar to but not quite like Domain Admins in an On-Prem Active Directory Domain. Click on the group to add members to it. When you’re done adding members that need to manage the domain go back and click Okay. This synchronization step has nothing to do with Azure AD Connect or with On-Prem AD if one exists. Instead, this synchronization step is meant to sync users and groups from Azure AD into Domain Services. You have a choice of syncing all users or scoping the sync to just certain groups. In this demonstration I’m just going to sync all users and groups from Azure AD to Domain Services. Clicking Okay takes you to the next step where you can review your options. Click Okay to commence the deployment of Azure AD Domain Services. </p>
<p>The actual deployment can take the better part of an hour because it’s deploying lots of stuff in the background. It’s deploying the network infrastructure that you’ve defined as well as two managed domain controllers. It’s also setting up the managed domain itself. After enabling Azure Active Directory Domain Services you need to enable computers within the Virtual Network to connect to and consume these services. To do so you need to update the DNS Server Settings for your Virtual Network so that it points to the two IP addresses where Azure Active Directory Domain Services are available. To update the DNS Server settings for the Virtual Network hosting your Azure Active Directory Domain Services browse to the Azure portal and open up your instance of Azure AD Domain Services. The Overview tab will list a set of required configuration steps. One of those is to update the DNS Server settings for the Virtual Network. You will be presented with two different IP addresses. These are the IP addresses where Azure AD Domain Services is available. These are essentially the managed domain controllers that were stood up as part of the deployment of Azure AD Domain Services. After making a note of these IP addresses, click the Configure button and update the DNS Server settings for the Virtual Network. With Azure AD Domain Services provisioned and your DNS updated you can now move on and enable password hash synchronization using Azure AD Connect.</p>
<h1 id="A-Word-About-Personas"><a href="#A-Word-About-Personas" class="headerlink" title="A Word About Personas"></a>A Word About Personas</h1><p>Personas can be an important tool that drives adoption and business value realization. What happens quite often is that organizations deploy technology solutions without a full understanding of the users that those solutions are intended for. When this happens, the deployed solutions do not get used, and the value of those solutions goes unrealized.</p>
<p>If an organization deploys an Azure solution, but nobody uses it, the organization doesn’t realize the value – and it becomes a waste. In order to generate value from an Azure solution, an organization must determine what users should START doing or STOP doing, in order to realize the value of the solution.</p>
<p>Essentially, its user behavior change that becomes the yardstick for evaluation, adoption, and use of solutions deployed in Azure. Personas can be useful when trying to drive adoption of new Azure solutions.</p>
<p>A persona is really just a fictitious character that represents a certain user type. Personas refer to the “who” when discussing an organization. The use of personas helps organizations characterize different sets of users, and to capture details about what a typical day looks like to those users. Personas can be used to capture the pains, needs, and desired outcomes that users have as they perform their daily tasks. </p>
<p>To build personas that reflect the workforce, organizations need to communicate with end users. Organizations need to know how work currently gets done in order to deploy Azure solutions that help users get that work done. Defining personas for each user type can help organizations accomplish this. More specifically, from an Azure perspective, an organization can build personas to assist with the creation of roles. By defining different personas, the organization has better visibility into what roles are necessary – and if custom roles are needed.</p>
<p>As a result, organizations can realize more value when deploying Azure solutions, because the solutions that are deployed can then be tailored to the users for whom the solutions are intended. Management of those solutions can be streamlined via built-roles that match the defined personas, or via custom roles, when the built-in roles are not sufficient.</p>
<h1 id="Hybrid-Identities"><a href="#Hybrid-Identities" class="headerlink" title="Hybrid Identities"></a>Hybrid Identities</h1><p>As the move to the cloud gathers steam, corporations are finding themselves supporting a mixture of on-prem and cloud applications. Users obviously are finding themselves requiring access to those applications as well. This, of course, becomes a challenge to implement. The <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity</a> solutions we previously discussed are solutions that span on-prem and cloud-based capabilities. Leveraging these solutions allows an organization to create a common user identity for authentication and authorization to all resources, regardless of whether they are on-prem or in the cloud. This concept is called hybrid identity. Achieving hybrid identity requires the development of one of three authentication methods. The authentication method that is deployed is dependent on the specific scenario being addressed. The three authentication methods include Password Hash Synchronization, Pass-Through Authentication, and Federation. Password Hash Synchronization is also referred to as PHS, while Pass-Through Authentication is referred to as PTA. Federation is referred to as, well, Federation. Password hash synchronization is a sign-in method used as part of a hybrid identity solution. This is accomplished with Azure AD Connect by synchronizing a hash, of the hash, of a user’s on-prem AD password to a cloud-based <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> instance. This feature is useful for signing in to Azure AD services like Office 365 with the same password as an on-prem AD account, which reduces end-user impact. The password hash synchronization strategy reduces, to just one, the number of passwords that an organization’s users need to maintain. As such, password hash synchronization can improve user productivity and reduce helpdesk costs. Password hash synchronization, which is the most common hybrid identity solution, requires an organization to install Azure AD Connect. </p>
<p>Once Azure AD Connect is installed, directory synchronization between the on-prem Active Directory instance and the Azure Active Directory instance is configured. As part of the synchronization configuration, password hash synchronization is enabled. Azure AD Pass-through Authentication, or PTA, much like Password Hash Synchronization, allows users to sign in to both on-prem and cloud-based apps with the same password. And much like password hash synchronization, this option offers a better end user experience. However, pass-through authentication validates user passwords directly against the on-prem Active Directory, instead of using a synced password hash. A key benefit of pass-through authentication over password hash synchronization is that it affords organizations the ability to enforce their on-prem AD security and password policies, since pass-through authentication is actually leveraging the on-prem credentials. By combining Pass-through Authentication with Seamless Single Sign-On, organizations can allow users to access applications on corporate machines inside the network without the need to type in their passwords again. Azure AD Pass-through Authentication provides an improved end-user experience because it offers end users the ability to complete self-service password management tasks in the cloud. Deployment and administration are easy because Pass-Through Authentication only requires a lightweight agent to be installed on-prem. Since the agent automatically receives updates, there is no management overhead. Pass-Through Authentication offers improved security over Password Hash Synchronization because on-prem passwords are never stored in the cloud. </p>
<p>Because it works with Azure AD Conditional Access policies, including MFA, Pass-Through Authentication offers additional account protection. Another benefit of Pass-Through Authentication is the fact that the agent only makes outbound connections from the network, removing all requirements for a DMZ as part of a solution. Communication between the on-prem agent and Azure AD is secured via cert-based authentication, which adds another layer of security. Further, the certificates that are used are automatically renewed every few months by Azure AD, removing the requirement to manually maintain them. In addition to high security, Azure AD Pass-Through Authentication offers high availability by allowing the installation of additional agents on multiple on-prem servers. Federation is a bit different from the other two solutions. It is a collection of domains with an established trust, which typically includes authentication, and almost always includes authorization. In a common configuration, a federation might include multiple organizations that have established trust for shared access to a specific set of resources. Federating an on-prem environment with Azure AD allows and organization to use the federation for authentication and authorization. Federation ensures that all user authentication happens on-prem and it provides administrators with the ability to implement more rigorous levels of access control. Federation with ADFS and PingFederate is available. To protect against a failure of the ADFS infrastructure when using federation with ADFS, organizations can set up password hash synchronization, or PHS, as a backup. Doing so allows authentication to continue, despite an ADFS infrastructure failure. All three of these authentication methods including PHS, PTA, and Federation provide single-sign on capabilities, which automatically signs users in when they are on their corporate devices inside the corporate network.</p>
<h1 id="DEMO-Managing-Users-Groups-and-Devices-in-Azure-AD"><a href="#DEMO-Managing-Users-Groups-and-Devices-in-Azure-AD" class="headerlink" title="DEMO: Managing Users, Groups, and Devices in Azure AD"></a>DEMO: Managing Users, Groups, and Devices in Azure AD</h1><p>Hello and welcome back! In this brief demonstration, I just wanted to walk you through the process of managing users and groups within Azure Active Directory. Now on the screen here, you can see I’m logged into my Azure Portal for the directory called Test9878.org. This is the custom domain I’m using for my Azure AD here.</p>
<p>Now to get to this screen from Azure, what I’ll do here is I’ll bounce back out to my homepage and here’s the homepage. To get into Azure AD, I can simply select Azure Active Directory from the top here, or I can go to the hamburger and select Azure Active Directory.</p>
<p>So from this overview page, I can browse to lots of different pieces of Azure AD. Under the manage section is where I’ll manage my users and groups along with devices, app registrations, all of this fun stuff where you’ll do your day to day management of your Azure Active Directory. Down the bottom is where you’ll perform your monitoring. And then down at the very bottom, you’ll do your troubleshooting and support.</p>
<p>So from this page, let’s go ahead and create a user in Azure Active Directory. And to do that, it’s pretty straight forward. We simply select users here. And from this screen, we can see all of the existing users in our AD.</p>
<p>We can see, we have two accounts here. One is an admin in the actual Azure Active Directory as shown here under source. The ThomasMitchell.net account is actually an external Azure Active Directory account from another directory.</p>
<p>What we’re going to do here is create a new user and we’ll just call this Dave. And in this dropdown we can select the actual domain name we want to use, we’re using the custom domain, so we’ll leave it at Test9878.org and we’ll give our username. And then we have the option to auto-generate a password or create one, we’ll leave the auto-generate here. And this will show us what the password is.</p>
<p>We can then provide that password to the new user. I would not send this out via any kind of electronic methods when possible. That’s obviously a security risk. As we create our user, we can then select a group to add our user to. So we’ll go ahead and make him a user within our box users group.</p>
<p>This is actually a group I created earlier for some other demonstration. So we’ll go ahead and we’ll select him. So now what we’re doing here is creating our <a href="mailto:&#68;&#x61;&#118;&#101;&#x40;&#x54;&#101;&#x73;&#x74;&#x39;&#56;&#55;&#56;&#46;&#x6f;&#x72;&#x67;">&#68;&#x61;&#118;&#101;&#x40;&#x54;&#101;&#x73;&#x74;&#x39;&#56;&#55;&#56;&#46;&#x6f;&#x72;&#x67;</a>, we’re auto generating a password and we’re placing this new user in the box users group.</p>
<p>The block sign in is pretty self explanatory. We can either block sign in by selecting yes or allow sign-ins by leaving the no option selected here. And then we have some additional info we can add. We can add a job title in a department.</p>
<p>We can also specify the usage location. So we’ll go ahead and we’ll select United States down here. And we’ll go ahead and create the user. And at this point, we now have a new user in our directory. If we select our user from our list, we can then look at the user’s profile, which includes his identity, his job information, any kind of special settings, contact info. This is where we manage this information as far as the profile goes.</p>
<p>We can then go into assigned roles where we can actually look at any roles that have been assigned to this user. And we can add assignments. You can see all of the different directory roles here that are included by default.</p>
<p>Now we can also see, we can assign custom roles, but if you look at the little icon up here, it tells us that if we want to assign custom roles to a user, the organization needs Azure AD Premium P1 or P2. I’m using the free Azure edition right now. But if he wanted to make, you know, Dave an application administrator, we simply check the box and add the role. And now we can see under assigned roles for Dave, we have application administrator, and of course the description tells us what an application administrator can do.</p>
<p>If we want to remove this assignment for this user, we select the assignment and remove it. Now, if we go back out to our directory, let’s take a look at groups and how we can manage groups here. By selecting groups, we can look at what groups are currently defined within our Azure AD.</p>
<p>If we want to create a new group, we simply select a new group and we can choose whether it’s a security group or an office 365 group. We’ll leave this at security and we’ll just call this marketing. And we’ll give it a description. We can see, we currently have no owners or members defined for this group.</p>
<p>So we’ll go ahead and select an owner. We’ll just make myself an owner here. And then we’ll add a new member. Let’s go ahead and add Dave. And then we create it. So now we have a new group called marketing. It’s a security group and the membership type here is assigned, which means we’re going to manually add and remove users from this group. So we’ll go ahead and select marketing here. And from here, we can look at the different properties of this group.</p>
<p>We can see when it was created, the membership type, whether it’s a cloud sourced group and what type of group it is. We can see the different direct members and any kind of group memberships. We look at properties here. We can see here, we have the name and we can actually change it here. And the description, and then members and owners will tell us who the members are and who the owners are.</p>
<p>If we select group memberships here, we can see that the marketing group is not a member of any other groups. So this is where you could see group nesting. Now in this applications area, we can see what applications are assigned to our group. So if we have a group of users that needs access to a specific application, we can create that group, assign the application to that group, and then add users to that group.</p>
<p>Any users that get added to that group are the ones that will get access to the application. Same thing with licensing. We can assign licenses to specific groups. So whatever users get added to that group also get those licenses. And same thing for Azure roleassignments.</p>
<p>So that’s the quick and dirty on how to create users and groups and how to manage them through the Azure Portal for Azure Active Directory. And before we run away here, let’s just take a look at devices.</p>
<p>Now, this devices page is where you manage any devices that are joined to your Azure AD. We can see here, I have a workstation that has been joined. And if I select that workstation, I can take a look at its device ID, its object ID, and all kinds of information about this specific device. I can then even disable the device so it’s no longer able to access Azure AD. We’re not going to do that here, but we will bounce back to our directory.</p>
<p>Now from this Azure Active Directory overview page, you can also manage password resets, manage Azure AD connect. You can take a look at the provisioning status. You can manage your custom domain names, even managed company branding. So there’s a lot you can do from your Azure Active Directory page here. And this is where all of your management will happen.</p>
<p>All of your users, all of your groups, all of your devices, all of your branding, all of your domains, all this stuff is done right here from this Azure Active Directory page. So I really recommend that you go in and you play around in here and kind of learn what you can do and do some experimentation because you really want to try to get some stick time to get a real good understanding of all of the different features in Azure Active Directory.</p>
<h1 id="Deploy-Azure-AD-Connect"><a href="#Deploy-Azure-AD-Connect" class="headerlink" title="Deploy Azure AD Connect"></a>Deploy Azure AD Connect</h1><p>In this demonstration, we’re going to deploy Azure AD Connect so we can sync our on-prem active directory users to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a>. We are also going to need to ensure that we synchronize NTLM and Kerberos credential hashes to Azure AD, since this isn’t done by default. To get started, login to the server that will run Azure AD Connect and download the Azure AD Connect software. Launch the Azure AD Connect installer that you downloaded. Because our lab environment in a single forest with an internet routable domain name, we can use the express option. </p>
<p>When prompted, we’ll connect to Azure AD by providing our global admin <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">credentials</a>. And then, we can then connect to the on-prem AD by providing an enterprise admin credential. Clicking install begins the setup of Azure AD Connect. When the installation completes, click Exit. Because Azure AD Connect does not by default synchronize NTLM and Kerberos credential hashes to Azure AD, we must ensure that these hashes get synchronized if we want to use Azure AD Domain Services. To enable synchronization of the required credential hashes from your on-premises directory to the Azure AD tenant, run the script that you see on your screen:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$adConnector = &quot;&lt;CASE SENSITIVE AD DS CONNECTOR NAME&gt;&quot;</span><br><span class="line">$azureadConnector = &quot;&lt;CASE SENSITIVE AZURE AD CONNECTOR NAME&gt;&quot;</span><br><span class="line">Import-Module -Name &quot;C:\Program Files\Microsoft Azure AD Sync\Bin\ADSync&quot;</span><br><span class="line">$c = Get-ADSyncConnector -Name $adConnector</span><br><span class="line">$p = New-Object Microsoft.IdentityManagement.PowerShell.ObjectModel.ConfigurationParameter &quot;Microsoft.Synchronize.ForceFullPasswordSync&quot;, String, ConnectorGlobal, $null, $null, $null</span><br><span class="line">$p.Value = 1</span><br><span class="line">$c.GlobalParameters.Remove($p.Name)</span><br><span class="line">$c.GlobalParameters.Add($p)</span><br><span class="line">$c = Add-ADSyncConnector -Connector $c</span><br><span class="line">Set-ADSyncAADPasswordSyncConfiguration -SourceConnector $adConnector -TargetConnector $azureadConnector -Enable $false</span><br><span class="line">Set-ADSyncAADPasswordSyncConfiguration -SourceConnector $adConnector -TargetConnector $azureadConnector -Enable $true</span><br></pre></td></tr></table></figure>

<p>What this script will do is enable all on-premises users’ NTLM and Kerberos password hashes to be synchronized to the Azure AD tenant. This script will also initiate a full synchronization in Azure AD Connect. </p>
<p>The values for $adconnector and $azureadconnector variables can be found in the Azure AD Connect synchronization service manager. What I’ve done is create a PowerShell script called NTLMSync.ps1. This script includes all of these commands. I just need to open PowerShell on the Azure AD Connect server to run the script. The output tells me that the password hash sync configuration has been updated.</p>
<h1 id="Azure-Role-Based-Access-Control"><a href="#Azure-Role-Based-Access-Control" class="headerlink" title="Azure Role-Based Access Control"></a>Azure Role-Based Access Control</h1><p>Hello and welcome back. A tool that goes hand-in-hand with Azure active directory is Azure role-based access control, or RBAC. Azure RBAC is used to manage who has access to what resources and to manage what those users can do with those resources. It’s an authorization system that is built upon Azure resource manager, and it offers fine-grained access management to your Azure resources.</p>
<p>Azure RBAC relies on role assignments for access control. Each role assignment consists of three parts, a security principal, a role definition, and a scope.</p>
<p>The Security principal is essentially an object that represents either a user, a group, a service principal, or a managed identity that requires access to resources in Microsoft Azure. </p>
<p>The role definition is essentially a collection of permissions. Role definitions are usually referred to simply as roles. A specific role will list the operations that can be performed by someone with that role. These operations include things like read, write, and delete.</p>
<p>Although there are many built-in roles in Azure that you can use, there are four fundamental roles available. These fundamental roles include owner, contributor, reader, and user access administrator. A person assigned the owner role has full access to all resources, including the rights to delegate access to others. A person assigned the contributor role can create and manage all kinds of Azure resources. However, a contributor cannot grant access to those resources to other users. The reader role allows you to view existing Azure resources, while the user access administrator role allows you to manage user access to your Azure resources.</p>
<p>In addition to the built-in roles you can also create custom roles. This allows you to tailor access to your resources in a way that best suits your organization.</p>
<p>A scope is a set of resources that the access you are setting up applies to. For example, you may provide access to a scope that includes a subscription or maybe a resource group or even a specific resource. A scope in Microsoft Azure can be specified at the management group level, the subscription level, the resource group level, or to specific resources. Because scopes are structured in parent-child relationship, access that is granted at the parent scope level will be inherited by the child scopes.</p>
<p>The process that Azure RBAC uses to determine if a user has access to a specific resource is pretty straightforward. First, the user requesting the access acquires a token from Azure resource manager. This token includes any group memberships for the user. </p>
<p>Next, the user makes a rest API call to Azure resource manager with the attached token.</p>
<p>What Azure resource manager will do next is retrieve all the role assignments and deny assignments for the resource that the user is trying to access. Azure resource manager will then narrow those role assignments down to only those that apply to the user or to groups that the user is a member of. It will also determine which roles have been assigned to the user for the resource being accessed.</p>
<p>Next, Azure resource manager will determine whether or not the requested action in the API call is allowed by the role that the user has for the specific resource being accessed.</p>
<p>Assuming the user is assigned a role that allows the action being requested at the requested scope, access is granted. Otherwise, access is blocked.</p>
<p>Azure RBAC is free and is included with all Azure subscriptions.</p>
<p>To learn more about Azure RBAC, visit the <a target="_blank" rel="noopener" href="https://docs.microsoft.com/azure/role-based-access-control/overview">URL</a> that you see on your screen.</p>
<h1 id="Single-Sign-On-Overview"><a href="#Single-Sign-On-Overview" class="headerlink" title="Single Sign-On Overview"></a>Single Sign-On Overview</h1><p>Unless an organization deploys a single sign-on solution, its users will be required to remember multiple usernames and passwords, one for each different application in use. Additionally, the IT department needs to maintain all of these different accounts and passwords manually. Single sign-on allows users to sign in once with one account in order to access domain-joined devices, corporate resources, SAS applications, and even web apps. After signing in, users can then launch apps right from the O365 portal or via the MyApps access panel. With single sign-on, IT administrators can centralize user account management, allowing them to automatically add or remove user access to applications based on group membership. In this lecture, we are going to discuss the various single sign-on options that are available when designing an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity management</a> solution that incorporates single sign-on. </p>
<p>Choosing a single sign-on solution for an application will largely depend on how the application is configured for authentication. Of all the single sign-on methods we are about to discuss, disabled is the only one that does not automatically sign users into applications without requiring a second sign-on to occur. When deciding on a single sign-on solution, it’s important to know that cloud apps can use SAML, password-based, linked, and disabled methods for single sign-on. Of the bunch, SAML is the most secure method. On-prem apps, when configured for Application Proxy, can use password-based, Integrated Windows Authentication, or IAW, header-based, linked, or the disabled methods for single sign-on. The table that you see on your screen provides a summary of the single sign-on methods that are available. Use SAML for single sign-on whenever possible. </p>
<p>This method works when applications are configured to use a SAML protocol. Use password-based single sign-on when an application authenticates with a username and password. Using password-based single sign-on offers secure application password storage and replay via a web browser extension or via mobile application. Password-based single sign-on uses the existing sign-in process that’s provided by the application while allowing an administrator to manage the passwords for it. The linked single sign-on method is useful when an application is configured for SSO in another identity provider service. This SSO option doesn’t add single sign-on to the application. Use disabled single sign-on when an application isn’t ready for single sign-on. Users of the application will need to provide their username and password each time they launch the application.</p>
<p> Use IWA SSO for applications that use Integrated Windows Authentication or for claims-aware applications. When using this method for SSO, Application Proxy connectors use Kerberos Constrained Delegation to authenticate users to the application. Header-based single sign-on should be used when an application uses headers for authentication. It should be noted that header-based single sign-on requires PingAccess for Azure AD. When using header-based SSO, Application Proxy uses <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> to authenticate the user and then passes traffic through the connector service.</p>
<h1 id="Enable-Single-Sign-On-for-Dropbox"><a href="#Enable-Single-Sign-On-for-Dropbox" class="headerlink" title="Enable Single Sign-On for Dropbox"></a>Enable Single Sign-On for Dropbox</h1><p>In this demonstration, we’re going to walk through the process of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">enabling</a> single sign-on for an application. We’re going to enable single sign-on for Steven Davis so that he can access his Dropbox for Business account. To configure single sign-on for Dropbox, browse to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a>. From here, click on Enterprise applications, and then click New application. Find the Dropbox application in the gallery, and then select the application and click Add. After adding the application to Azure, click Single sign-on located under Manage. Select SAML to open the SAML configuration screen. Retrieve the sign on URL from the application vendor and provide that URL in the Sign on URL field for the application in Azure. Provide an identifier value. In this case, we’ll just use the word Dropbox. And then next, download the SAML signing certificate from Azure. This certificate needs to be provided to the application vendor. After downloading the certificate, switch over to the application vendor’s configuration dashboard and provide the certificate you downloaded. </p>
<p>The type of certificate you download will be largely dependent on the application itself so you’ll need to refer to the vendor’s documentation for setting up single sign-on. Retrieve the login URL for the application from Azure and provide it to the application. Save the application configuration, and then after the configuration is complete in both Azure and the app vendor’s portal, you can go ahead and test the login. To test single sign-on, assign a user to the application in Azure by clicking Users and groups within the application’s Azure dashboard. Find a user and then click Assign. Ensure that there is a user account for the assigned user also configured in the application itself. Next, open an incognito window and launch the application panel and login as the user to whom the application was assigned. Launch the application from the application panel and confirm that single sign-on works.</p>
<h1 id="MFA-Overview"><a href="#MFA-Overview" class="headerlink" title="MFA Overview"></a>MFA Overview</h1><p>Two-step verification provides a layered approach to security. Even the most enterprising attacker would have problems compromising multiple authentication factors, because, even if the attacker obtains a user’s password, the password would be useless without also being in possession of the additional authentication method, a mobile phone, for example. Multi-factor authentication works by requiring two or more authentication methods, which typically include something like a password that the user knows, something the user owns, typically a mobile phone, and something the user is, biometrics, for example. Azure MFA offers the ability to safeguard access to apps and data while maintaining a simple end-user experience. By providing additional security via a second form of authentication, MFA provides much sought after security for end-user authentication, and it does so via a range of easy to use authentication methods, including passwords, security questions, email address, application, OATH hardware token, SMS, voice call, and app passwords. Multi-Factor Authentication comes as part of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> Premium.</p>
<p> A subset of MFA capabilities is also available as part of an Office 365 subscription and as a means to protect Global Administrator accounts. As part of Azure AD Premium, Azure MFA is offered in two flavors, including the Azure Multi-Factor Authentication Service, which is cloud-based, and the Azure MFA Server option, which is a good option for organizations who have deployed ADFS and that want to or need to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">manage</a> MFA on-prem. Because most users are used to using only passwords to authenticate to applications and services, it’s critical that an organization communicate with the user base when rolling out an MFA solution. Doing so will invariably reduce the number of helpdesk calls that come in during any MFA rollout. Now, despite the best laid plans and deployments, there will be times when you may need to disable MFA in a one-off scenario. For example, if a user can’t sign in because he has lost access to his authentication methods, a lost phone, for example, in such a case, you could use a conditional access policy for Azure MFA. </p>
<p>With a conditional access policy in place, you can create a user group that is excluded from the policy that requires MFA. Placing the user in the excluded group would temporarily allow access until MFA functionality or access can be restored. A way to temporarily bypass MFA for Azure MFA Server users is to allow them to authenticate without two-step verification. Such a bypass can be configured but it expires after a specified number of seconds. Two-step verification prompts can be minimized for users that are on the local network. This can be accomplished with trusted IPs or named locations. By leveraging this features, an administrator for a managed or federated tenant can bypass two-step verification for users that are signing in from a trusted network location.</p>
<h1 id="Enable-MFA-for-O365-User"><a href="#Enable-MFA-for-O365-User" class="headerlink" title="Enable MFA for O365 User"></a>Enable MFA for O365 User</h1><p>In this demonstration, we’re going to enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">Multi-Factor Authentication</a> for an Office 365 user, so you can see how the process works and have a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">log in</a> process works once it’s been enabled. To enable Multi-Factor Authentication for an Office 365 user, open the Office 365 admin portal as a global administrator. Click on Users, and then Active Users. Find the user in the list for whom you wish to enable MFA and double click that entry. On the user’s property page, down at the bottom, click “manage multi-factor authentication”. Select the user in the multi-factor authentication screen and click Enable. Confirm that you want to enable multi-factor authentication by clicking the enable multi-factor auth button, and then close the box out. You’ll notice that the multi-factor auth status now shows enabled for this particular user. Open an incognito browser window and launch the Office 365 portal. Login as the user for whom you just enabled MFA. If you’ve configured MFA properly, the user, Steve in this case, will be prompted for more information before being allowed to login. Continue the login process by providing the information requested. Be sure to save the application password, so that it can be used for other applications if necessary, and then go ahead and click Done. After providing the MFA info, you’re prompted to log back in. Log back in, and be sure to supply the proper MFA info. As you can see on your screen, MFA is now working for Steve.</p>
<h1 id="Azure-AD-B2B"><a href="#Azure-AD-B2B" class="headerlink" title="Azure AD B2B"></a>Azure AD B2B</h1><p>Azure Active Directory Business-to-Business collaboration, also known as Azure AD B2B, allows an organization to securely share company applications and company services with guest users from other organizations while retaining control over company data. With Azure AD B2B, an organization can work with external partners, even if they don’t use Azure AD. The invitation and redemption process of Azure AD B2B allows users in a partner organization to use their own credentials to access a company’s resources. Because the partner organization uses its own <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity management</a> solution, external administrative overhead for the sharing organization is essentially non-existent. There’s no requirement to manage external accounts or passwords, nor is there a need to synchronize accounts or manage account lifecycles. When guest users are invited to access resources in a partner organization, they sign into the shared applications and services with their own identities. Guest users without a Microsoft account or Azure AD account have one created for them when they redeem their invitations. Inviting a guest user to access an app or service, using AD B2B, is as simple as sending an invite to the guest user, using the guest user’s email address.</p>
<p>The guest user then follows a few easy redemption steps to sign in. Azure AD B2B offers the ability to use authorization policies to protect corporate content. Conditional access policies like <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">MFA</a> can be used to protect corporate applications and data. Such policies can be enforced at the tenant level, the application level, and even for specific guest users. With Azure AD B2B, administrators can add guest users to the organization right from the Azure portal. When the administrator creates the new guest user, which is done in a similar fashion to adding a new internal user, the guest user receives an invitation that allows him to sign into the Access Panel for that user. Guest users can be assigned to apps and even groups. By delegating guest user management to application owners, you can reduce the workload of the Azure administrators in your organization. Delegating user management allows application owners to add guest users to any application that they want. By delegating guest user management to application owners, you can reduce the workload of the Azure administrators in your organization. Delegating user management allows application owners to add guest users to any application that they want to share, even if it’s not a Microsoft application. To make this work, an administrator needs to set up self-service app and group management. Once this has been configured, non-admins can use their Access Panel to add guest users to applications or to groups.</p>
<h1 id="Add-Guest-Users-to-the-Directory"><a href="#Add-Guest-Users-to-the-Directory" class="headerlink" title="Add Guest Users to the Directory"></a>Add Guest Users to the Directory</h1><p>In this demonstration, we’re going to add a guest user to our Azure AD. To add a guest user, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">log in</a> to the Azure portal and browse to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a>. Click users and then click new guest user. Provide the new guest users email address and then click Invite. The user you’ve invited receives an invite email. Upon clicking the get started button in the invite email, the guest user is prompted to accept the invite. After accepting the invite, the guest user is taken to the applications pane, where he will be able to access applications that ultimately get assigned to him.</p>
<h1 id="Azure-AD-B2C"><a href="#Azure-AD-B2C" class="headerlink" title="Azure AD B2C"></a>Azure AD B2C</h1><p>Azure Active Directory Business-to-Consumer, also known as Azure AD B2C, is an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity management</a> service that offers organizations the ability to customize and control how customers interact with corporate applications. It allows organizations to control how users sign up, sign in, and how they manage their profiles when using the applications. Azure AD Business-to-Consumer enables this functionality while also protecting customer identities. Applications registered with Azure AD B2C can be configured to handle many identity management tasks. </p>
<p>For example, you can allow users to sign up to use a registered application, you can enable a signed-up user to edit his profile, and you can even enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">MFA</a> in the application. Other identity management tasks that can be handled include allowing users to sign up and sign in with specific identity providers, such as Facebook, for example. You can even customize the look and feel of the signup experience for users, as well as the sign-in experience. Azure AD B2C completes identity tasks by interacting in sequence with identity providers, also known as IdPs. It also interacts with users, other systems, and with the local directory. The Identity Experience Framework establishes multi-party trust and completes these steps. Along with a Trust Framework policy, this framework defines the actors, actions, protocols, and sequence of steps that need to be completed in order to make things work. Azure AD B2C makes use of SYN cookies and rate and connection limits to protect against denial-of-service and password attacks against applications. It also includes mitigation for brute-force password attacks, as well as dictionary password attacks. </p>
<p>A service that authenticates customer identities and issues security tokens is called an identity provider. Azure AD B2C offers the ability to configure several different identity providers in the tenant. Common identity providers include Microsoft accounts, Facebook, and even Amazon. Before configuring an identity provider in an Azure AD B2C tenant, the application identifier, client identifier, password secret, and client secret, or a combination of each, depending on the identity provider itself, must be recorded from the identity provider application that is created. This identifier information is then used to configure the application that will be accessed via the identity provider being configured. Every Azure AD B2C tenant is distinct and separate from other Azure AD B2C tenants. To leverage the features of AD B2C, you must deploy a B2C tenant, and link it to your Azure subscription. If you wish to allow users to sign in to an application using Facebook, Amazon, or some other identity provider, you must first register the application in the Azure AD B2C tenant.</p>
<h1 id="Create-a-Link-and-Azure-AD-B2C-Tenant"><a href="#Create-a-Link-and-Azure-AD-B2C-Tenant" class="headerlink" title="Create a Link and Azure AD B2C Tenant"></a>Create a Link and Azure AD B2C Tenant</h1><p>In this demonstration, we are going to create a new <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/azure-ad-b2c/">Azure B2C</a> tenant and then, we’re going to link the new B2C tenant to our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure subscription</a>. To get started, login to the Azure portal and make sure you’re in the directory that contains the Azure subscription. We only have one subscription here, so we’re good on that front. Click create a resource and then search for Azure Active Directory B2C. Click on Azure Active Directory B2C in the search results and then click create. Choose the option to create a new Azure AD B2C tenant. Provide an organization name and a domain name. Select a region and then click create. After creating the Azure AD B2C tenant, you now have to link it to your Azure subscription. While, again, ensuring you’re in the directory that contains your Azure subscription, create a new resource and search for Azure AD B2C, just as you did the first time. Click on Azure SD B2C in the results and click create. This time, however, choose the second option to link an existing Azure AD B2C tenant. In the Azure AD B2C tenant dropdown, choose the B2C tenant that you created earlier. Leave the subscription where it’s at and then select a resource group. Click create to complete the linking process. When the process completes, click Go to resource to manage the newly created B2C tenant.</p>
<h1 id="Privileged-Identity-Management"><a href="#Privileged-Identity-Management" class="headerlink" title="Privileged Identity Management"></a>Privileged Identity Management</h1><p>Azure Active Directory Privileged Identity Management, otherwise known as PIM, is an Azure offering that allows you to manage and control access to resources within <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure</a> and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a>, as well as within other services, such as Intune and Office 365. A valid Azure AD Premium P2 license is required for all users that will interact with or benefit from Privileged Identity Management before enabling the service on a tenant. Alternatively, you can assign an Enterprise Mobility + Security E5 license for each user that interacts with Privileged Identity Management. Generally speaking, licensing is required for users that are assigned to the Privileged Identity Role Administrator role or who are assigned as eligible to other directory roles that are manageable through Privileged Identity Management. If a user can approve or reject requests in Privileged Identity Management, that user also requires a license. Users assigned to a role with time-based assignments, such as Just in time or Direct, or those assigned to an access review role, also require licensing. With Azure AD Privileged Identity Management, an organization can see which users are assigned privileged roles that are used to manage Azure resources. Organizations can also see which users are assigned administrative roles within Azure Active Directory. </p>
<p>Privileged Identity Management also offers the ability to enable on-demand, or just in time, administrative access to services such as Office 365 and Intune, as well as to Azure subscriptions, resource groups, and even individual Azure resources, like virtual machines and such. Azure AD Privileged Identity Management offers the ability to view a history of administrator activation, along with a history of changes that administrators have made to Azure resources. Alerts can also be configured to notify you about changes in administrator assignments. Privileged Identity Management also allows you to require approval for activation of Azure AD privileged admin roles, to review membership of such administrative roles, and to force users to provide justification for ongoing membership in these roles. In Azure Active Directory, Privileged Identity Management can be used to manage users that are assigned to built-in Azure AD roles, such as Global Admin. In Azure itself, Privileged Identity Management can manage users and groups assigned via Azure RBAC roles, such as the Owner and Contributor roles.</p>
<h1 id="Enable-PIM-and-Manage-Subscriptions"><a href="#Enable-PIM-and-Manage-Subscriptions" class="headerlink" title="Enable PIM and Manage Subscriptions"></a>Enable PIM and Manage Subscriptions</h1><p>In this demonstration, we’re going to enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/privileged-identity-management/">Privileged Identity Management</a>, and we’re going to set up a subscription to be managed by Privileged Identity Management. To enable Privileged Identity Management or PIM for short, Login to the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure</a> portal, and then click on All services and search for privileged identity management. Click on the Azure AD privileged identity management in the search results. Next, click on “consent to PIM” and then verify your identity when prompted to do so. Provide the additional security verification info that is requested and then click Next. Click Verify to verify your information. At this point you’re taken back to the PIM consent screen. To complete the consent process, click the “consent” link and then click Yes to confirm. With PIM enabled, you can now sign up for PIM for Azure AD role management. To do so, click on Azure AD roles, under Manage. Click sign up for PIM in the left pane and then click the sign-up link at the top. When prompted to confirm, click Yes. After setting up PIM to manage AD roles, you need to discover resources in the subscription, so they, too, can be managed with PIM as well. To do this, go back to the quick start page and click Azure Resources. In this demo, here, we’re going to manage all resources in the subscription. Click Discover Resources and then select the subscription. Click Manage Resource to onboard the resource for management, and then click Yes to confirm. At this point, you’ve deployed PIM and configured Azure AD roles and Azure resources to be managed by it.</p>
<h1 id="Self-Service-Password-Reset"><a href="#Self-Service-Password-Reset" class="headerlink" title="Self-Service Password Reset"></a>Self-Service Password Reset</h1><p>Self-service password, or SSPR, is pretty self-explanatory. This feature allows end users to reset forgotten passwords without the need for a call to the help desk. It’s a feature that many organizations request, as it helps provide a more streamlined and pleasant end-user experience. Depending on the SSPR functionality that is required, license requirements may vary. For example, Self-Service Password Change functionality for cloud users is included in all editions of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a>. In these cases, we are talking about cloud-only users who wish to change their passwords to something new. Self-Service Password Reset functionality for cloud users is only included in Azure AD Basic and higher. It’s not offered in the free version of Azure AD. This functionality applies to cloud-only users who wish to reset their passwords to something they know. Self-Service Password Reset, Password Change, and Password Unlock, leveraging on-premises write-back, requires either Azure AD Premium P1 or Premium P2. This functionality applies to hybrid users that are synced to Azure AD from an on-prem AD. So, when considering Self-Service Password Reset, it’s important to understand the user base and how users are <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">managed</a> and provisioned.</p>
<h1 id="Configure-Self-Service-Password-Reset"><a href="#Configure-Self-Service-Password-Reset" class="headerlink" title="Configure Self-Service Password Reset"></a>Configure Self-Service Password Reset</h1><p>Enabling <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/self-service-password-reset/">self-service password</a> for end users take a huge burden off of the shoulders of the help desk. In this demonstration, we will enable self-service password reset, and test that it’s working with a test account. Before enabling self-service password reset, make sure that password writeback is turned on in Azure AD Connect. To do this, launch Azure AD Connect on the server running it. Click configure and then view the current configuration. If its disabled, relaunch Azure AD Connect, click configure, and then select customize synchronization options. Provide the global admin account to connect to Azure AD. Click next to leave the directories and domain and ou filtering options unchanged. Under optional features, check the password writeback box and click Next. Click Configure to update the configuration and then click Exit. After turning on password writeback, switch over to the Azure portal and then browse to Azure active directory. From here, click Password Reset. For this demonstration, I’m going to enable password reset for all of my users so I’m going to click All, and then save. After enabling password reset, click on Authentication methods and select the authentication methods you wish to make available, along with how many are required to set a password. </p>
<p>This is obviously going to be different for every environment. If you select the security questions option, you’ll be presented with more info to supply. We aren’t using security questions here, so I’ll turn this off. For this demonstration, I’m going to make mobile phone available as the only option. After clicking Save, I’m going to click on registration. I’m asked if I want to require users to register when <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">signing in</a>. I’m going to leave the default value set to yes. I’m also going to leave the window set to the default of 180 days. Clicking notifications allows me to set the notification options for when a user resets a password. I’m going to set both options here to yes. this ensures users receive a notification when they reset their passwords, but it also ensures that all administrators are notified when another administrator resets his password. In the customization pane, I can provide a customized helpdesk link for users to visit if they need assistance. I don’t have helpdesk here in the lab, so I’m going to leave this off for this demonstration. When I click on the on-premises integration link, Azure confirms that the on-prem writeback client is running and allows me to determine if I want passwords to writeback to on-prem AD. I need to leave this set to yes. The second option designates whether or not users should be given the option to unlock their accounts without resetting their passwords. </p>
<p>I’m going to leave this set to no for this demonstration. With password reset enabled, we can now test it. To test self-service password reset, open an incognito browser window and launch the single sign on setup process with a test account. In my case here, we previously enabled <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">MFA</a> so let me get through the authentication process here first. As you can see here, I’m prompted to to work through the process of setting up self service password reset for my account. Once I’ve completed the self service password reset setup, I’m presented with my application dashboard. To reset my password, I need to open the password reset URL in my browser. The password reset URL is <a target="_blank" rel="noopener" href="https://aka.ms/sspr">https://aka.ms/sspr</a>. On the next screen, I’m prompted to begin the reset process. I just have to provide my user ID and I need to complete the captcha. Clicking Next takes me to the verification screen, where I can request a code via mobile phone. After I click the Text button, I receive a code on my phone that I need to enter. After providing my verification code and clicking Next, I’m then prompted to create a new password. Clicking Finish completes the process.</p>
<h1 id="Self-Service-Group-Management"><a href="#Self-Service-Group-Management" class="headerlink" title="Self-Service Group Management"></a>Self-Service Group Management</h1><p>To further improve the end user experience, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> offers the ability for users to create and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">manage</a> their own security groups and Office 365 groups. In addition, users can also request security group memberships as well as Office 365 group memberships. In such cases, the owner of these groups can approve or deny their membership requests. By delegating group membership control, organizations can ensure that the people who best understand the business context for such memberships are the ones controlling group membership. It’s important to note, however, that this feature applies only to security groups and Office 365 groups. It does not apply to mail-enabled security groups nor does it apply to distribution lists. There are essentially two flavors of self-service group management currently available. These include delegated group management and self-service group management. An example of delegated group management would be a scenario where an organization uses a SaaS application, whose access is managed by an administrator. As the company grows, access management becomes a bit cumbersome for the administrator to handle. To ease the burden of granting access and revoking access to the application, the administrator requests that the application owner create a new group. </p>
<p>After the group has been created, the administrator assigns access to the application for the new group. He also adds all users who need access to the application to this group. Because the application owner created the group, he has he ability to add and remove users from it. Users added to the group are automatically granted access to the application, while users that are removed from the group have their access to the application revoked when the leave the group. By delegating group membership management to the application owner, the application owner no longer needs to wait on the administrator to provide and revoke access to the application. Of course, however, the administrator would still be able to see who has access to the application, and he could block access as necessary. A self-service group management example would be a scenario where an app owner manages an application. In order to grant a group of business users access to the application, the app owner creates a group in Azure AD, grants the group access to the application, and then enables self-service group management on the group. When a user in the organization needs access to the application, the user simply requests access to it from the Access Panel. When the request is approved, the user receives access to the application.</p>
<h1 id="Demo-Self-Service-Group-Management"><a href="#Demo-Self-Service-Group-Management" class="headerlink" title="Demo: Self-Service Group Management"></a>Demo: Self-Service Group Management</h1><p>In this demonstration we are going to enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/self-service-group-management/">Self Service group management</a>, by allowing users to create their own security groups and to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">manage</a> them. To enable Self Service group management, sign into the Azure portal and browse to Azure Active Directory. You’ll need to do this with a Global Admin account for the directory. From here select groups, and then go into the general settings for groups. Set the option for owners can manage group membership requests to yes. And then set the option for users can create security groups to yes as well. With these settings enabled users in the directory are allowed to create new security groups and to add members to those groups. These new groups will also show up in the access panel for all other users. In addition, if the policy settings on the group allow it, other users can create requests to join these groups as well.</p>
<h1 id="Overview-of-Managed-Identities-for-Azure-Resources"><a href="#Overview-of-Managed-Identities-for-Azure-Resources" class="headerlink" title="Overview of Managed Identities for Azure Resources"></a>Overview of Managed Identities for Azure Resources</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Managed Identities</a> for Azure Resources is a feature of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a>. There are several Azure services that support Managed Identities for Azure Resources. For those who build cloud applications, management of credentials within a code for authenticating to cloud services is often a common challenge. It’s critical to ensure credentials are kept secure. As a matter of fact, preferably, credentials should never appear on a developer’s workstation, nor should credentials ever be checked into source control. With Azure Key Vault, administrators have a way to securely store credentials. However, to be effective, the application code needs to authenticate to Key Vault to retrieve those credentials that are stored. Enter Managed Identities for Azure Resources. Using the Managed Identities for Azure Resources feature in Azure AD solves this problem. This solution provides supported Azure services with an automatically managed identity in Azure AD that can be used to authenticate to any service that supports Azure AD authentication without the need to store any credentials in code. Key Vault is one of the Azure services that is supported. Managed Identities for Azure Resources is a free feature that comes with all Azure AD editions. There are two types of managed identities to choose from. </p>
<p>They include a system-assigned managed identity and a user-assigned managed identity. A system-assigned managed identity is enabled directly on an Azure service instance. Once the identity has been enabled, Azure will create an identity for the instance in the Azure AD tenant that’s trusted by the subscription of the instance. The credentials for the identity are provisioned onto the instance after the identity had been created. System-assigned identities are tied to the Azure service instances that they are enabled on. Deleting an instance with a system-assigned managed identity attached to it will cause Azure to automatically clean up the credentials, along with the identity in Azure AD. A user-assigned managed identity is essentially a standalone Azure resource. Via a creation process, Azure creates the identity in the Azure AD tenant. The subscription in use, in turn, trusts the identity. An identity, once created, can be assigned to one or more Azure service instances. Unlike a system-assigned managed identity, the lifecycle of a user-assigned identity is managed separately from that of the Azure service instance, or instances, to which it’s been assigned. Application code can use managed identities to request access tokens for services that support Azure AD authentication. Azure will handle the rolling of the credentials that are used by the service instance.</p>
<h1 id="Enable-a-Systems-Designed-Management-Identity-on-a-VM"><a href="#Enable-a-Systems-Designed-Management-Identity-on-a-VM" class="headerlink" title="Enable a Systems Designed Management Identity on a VM"></a>Enable a Systems Designed Management Identity on a VM</h1><p>To enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/overview-of-managed-identities-for-azure-resources/">System Assigned Managed Identity</a> on a VM that was originally provisioned without it your account needs at least the Virtual Machine Contributor Role assignment. In the case of our demo here I’m using a global admin so that’s a non-issue. To complete this task sign into the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure</a> portal, navigate to the Resource Group that contains the VM that you wish to configure. Clock on the desired Virtual Machine and then select Identity. Under System Assigned Status select On and then click Save. Once the System Assigned Managed Identity is enabled the VM will be registered with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a>. After being registered you can then control its access to other services like Storage Accounts and the like.</p>
<h1 id="DEMO-Azure-AD-Reporting-and-Monitoring"><a href="#DEMO-Azure-AD-Reporting-and-Monitoring" class="headerlink" title="DEMO: Azure AD Reporting and Monitoring"></a>DEMO: Azure AD Reporting and Monitoring</h1><p>Hello and welcome back. In this brief demonstration here, what I wanna do is give you a tour, so to speak, of some of the Azure Active Directory Reporting and Monitoring options that are available.</p>
<p>Now, on the screen here, you can see I’m logged in to my Azure Portal, and I’m at the Overview page for my Azure Active Directory. We are working in the test9878.org directory. Now, the Azure Active Directory Reports that are available provide you with a view of the different activities that are going on in your environment.</p>
<p>You can use reports to determine how applications and services are utilized by your users, and you can detect potential risks that affect the health of your environments. You can use reports to also troubleshoot issues.</p>
<p>With Azure Active Directory Monitoring, you can route your Azure AD activity logs to different endpoints. You can then view this data to see what’s going on within your Active Directory.</p>
<p>Let’s take a look at some audit logs and some sign-in activities. Now, to take a look at the audit log for Azure Active Directory, what you do here is scroll down in the left pane from the Overview page of your directory and you select Audit logs under Monitoring. Now, what this Audit Log Report does is provide you with a record of the different system activities that have occurred.</p>
<p>For example, we can take a look and see who had access to an admin group and who gave them that access. We can also see information regarding password resets and the like. Now, in this dashboard here for our audit logs, we can see a few different activities that have occurred. We’ve seen some Add user activities. We’ve seen some Add member activities. We’ve also seen some activities revolving around roles.</p>
<p>If we select an activity here, so for example, we’ll choose this Add owner to group, what this tells us is what happened, when it happened, and what the status was. It also tells us who performed this action. Selecting the target gives us more information about the activity that occurred. And if we select Modified Properties, we can see what properties were actually modified.</p>
<p>So when you need to look at information for compliance, for example, the Audit logs report would be the report to go to. Now, if we click over to Sign-ins, we can see what was going on regarding sign-ins to our Azure Active Directory. Typically, you’d use the Sign-ins Report to find the sign-in pattern of specific users, or to see how many users have logged in in the last week, or what the sign-in status is.</p>
<p>On the screen here, we can actually see two different sign-ins that occurred. One was interrupted and one was successful. If we select the one here that was interrupted, we can see information about that specific sign-in. We can see when it happened, what happened, what the error code was, and what the failure reason was for the interrupted sign-in. We can see which user generated the alert and even the application where the sign-in occurred.</p>
<p>Along this top tab, we have lots of other different information we can look at. We can look at the location where this occurred. The Device Info. We can see that this failed login occurred on a Windows 10 machine from the Chrome browser. If we look at the Authentication Details, we can see that was a CloudOnlyPassword and that it was false. We can see any Conditional Access information that applied here.</p>
<p>In this case, there were no policies applied. And any Additional Details. Now, to configure monitoring for Azure Active Directory, what you can do is go into Diagnostic settings here below Monitoring, and we can see we have no diagnostic settings configured yet. So what we’ll do is add a diagnostic setting.</p>
<p>So we’ll go ahead and call this MyDiags. Now, what we can do here is we can collect audit logs or sign-in logs. And then when we do that, we can send them to either Log Analytics or to a storage account, or we can stream them to an event hub. For this demonstration here, what we’ll do is we’ll gather our audit logs and send them to a storage account.</p>
<p>Now, if we leave Retention here set to zero, if you look down here, you can see that setting it to zero does not apply a retention policy. This means the data that you collect is retained forever. I’ll just retain this for one day for this demonstration.</p>
<p>Now, when we select our storage account, we need to choose what storage account we want to archive to. So I already have a test9878 storage account here, so that’s what’s selected here. But I could change this to a different storage account if I wanted to. So what we’re doing here is collecting our audit logs with a retention of one day and sending them to our storage account, and then we’ll go ahead and save this.</p>
<p>Now, what we could also do here is instead of sending to a storage account, we can send to Log Analytics. Now, to send to Log Analytics, you’ll need to have a Log Analytics workspace already created. We have a default workspace here. We actually have a couple. So what we’ll do here is we’ll send to Log Analytics, and we’ll save it, and we can see we get the success here.</p>
<p>Now, to take a look at our logs, what we can do is go back out to our directory and then go into Logs here under Monitoring. Now, from the Log Analytics page here, what I can do is run different queries to track down the information I’m looking for as it relates to my Azure Active Directory. So that will call it a wrap.</p>
<p>Just keep in mind that you can run reports to track down specific information that’s reported in the Sign-ins Report and in the Audit logs report. And you can use Monitoring to send your information through logs into the Azure Monitor and&#x2F;or Log Analytics workspace.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>We’ve covered quite a bit of ground in <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">this course</a>. With so many terms and features to keep track of, it’s critical to be able to distinguish them from one another and understand what each does. By understanding what each identity management piece does, it becomes far easier to design an identity management solution. With that said, let’s walk through a high-level recap of all of the key players in the identity management space and what each offers. Microsoft’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a> is a cloud-based identity and access management service. With it, users can sign in and access external resources, such as Office 365, the Azure portal, and other SaaS applications. Azure AD is used to control access to applications and resources according to business requirements. A hybrid identity is an identity that spans on-prem and cloud-based capabilities. Leveraging hybrid identities allows an organization to create a common user identity for authentication and authorization to all resources, regardless of whether they are on-prem or in the cloud. Azure AD Domain Services is a Microsoft cloud-based offering that provides managed domain services, such as domain join, group policy, LDAP, and Kerberos and NTLM authentication. These services are fully compatible with traditional on-prem Active Directory and they can be deployed without any need for deployment or management of domain controllers in the cloud. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/single-sign-on-overview/">Single sign-on</a>, also referred to as SSO, allows users to sign in once with one account in order to access domain-joined devices, corporate resources, software as a service apps, and even web applications. </p>
<p>After signing in, users can then launch apps right from the O365 portal or via the MyApps access panel. With single sign-on, IT administrators can centralize user account management, allowing them to automatically add or remove user access to applications, based on group membership. Also known as MFA, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">multi-factor authentication</a> works by requiring two or more authentication methods, which typically include something like a password that the user knows, something the user owns, which is typically a mobile phone, and&#x2F;or something the user is, biometrics would be a good example. Azure MFA offers the ability to safeguard access to applications and data while maintaining a simple end-user experience. Azure Active Directory Business-to-Business collaboration, also known as AD B2B, allows an organization to securely share company applications and services with guest users from other organizations, while retaining control over company data. Azure Active Directory Business-to-Consumer, also known as Azure AD B2C, is an identity management service that offers organizations the ability to customize and control how customers interact with corporate applications. It allows organizations to control how users sign up, sign in, and how they manage their profiles when using the applications. Azure AD B2C enables this functionality while also protecting customer identities. Azure Active Directory Privileged Identity Management, also known as PIM, is an Azure offering that allows you to manage and control access to resources within Azure and Azure AD, as well as within other services such as Intune and Office 365. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/self-service-password-reset/">Self-Service Password Reset</a>, also known an SSPR, allows end users to reset forgotten passwords without the need for a call to the helpdesk. It’s a feature that many organizations request, as it helps provide a more streamlined and pleasant end-user experience.</p>
<p>Depending on the SSPR functionality that is required, license requirements may vary. Through self-service group membership, Azure AD offers the ability for users to create and manage their own security groups and Office 365 groups. In addition, users can also request security group memberships as well as Office 365 group memberships. In such cases, the owner of such groups can approve or deny their membership. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/overview-of-managed-identities-for-azure-resources/">Managed Identities for Azure Resources</a> provides supported Azure services with an automatically managed identity in Azure AD that can be used to authenticate to any service that supports Azure AD authentication without the need to store any credentials in code. Key Vault is one of the Azure services that is supported. Managed Identities for Azure Resources is a free feature that comes with all Azure AD editions. So, like I said, lots of terms. To learn more about each feature, you can, and should, read Microsoft’s published documentation on each. Be sure to also watch for new Microsoft Azure courses on Cloud Academy, because we’re always publishing new ones. Please give this course a rating, and if you have any questions or comments, please let us know. Thanks for watching and happy learning!</p>
<h1 id="10Azure-Role-Based-Access-Control"><a href="#10Azure-Role-Based-Access-Control" class="headerlink" title="10Azure Role-Based Access Control"></a>10<strong>Azure Role-Based Access Control</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.microsoft.com/azure/role-based-access-control/overview">Azure RBAC overview</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Managing-Azure-Subscriptions-and-Resource-Groups-36/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Managing-Azure-Subscriptions-and-Resource-Groups-36/" class="post-title-link" itemprop="url">AZ-104-Managing-Azure-Subscriptions-and-Resource-Groups-36</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:35" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:35-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:41:24" itemprop="dateModified" datetime="2022-11-22T11:41:24-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Managing-Azure-Subscriptions-and-Resource-Groups-36/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Managing-Azure-Subscriptions-and-Resource-Groups-36/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to managing Azure subscriptions and resource groups. My name is Thomas Mitchell and I’ll be leading you through this course. I’m an Azure content author at Cloud Academy and I have over 25 years of IT experience, several of those with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn or send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>.</p>
<p>This course was developed with an eye toward people who want to become certified Azure architects or those who are simply tasked with managing and supporting Azure resources. To get the most from this course, you should have a general understanding of Microsoft Azure.</p>
<p>In the first part of this course, we’ll cover the management of Azure subscriptions. More specifically, we’ll take a look at some of the key built-in roles that are used to manage Azure subscriptions. These roles include contributor, owner, reader, and user access administrator. You’ll learn what each role does and what permissions each role grants. We’ll then get into subscription policies and how to apply them.</p>
<p>The second part of the course will cover resource groups and it will talk about resource policies and how to assign them. We’ll also cover resource locks and tagging. In addition to some lecture time, we’ll work through a few demonstrations to reinforce the concepts covered.</p>
<p>We’ll wrap up the course by covering how to move resources between resource groups and how to delete resource groups altogether.</p>
<p>By the end of this course, you should be able to effectively manage Azure subscriptions as well as resource groups within those subscriptions.</p>
<p>We love to get your feedback, so please give this course a rating when you’re finished. So if you’re ready to learn about Azure subscriptions and resource groups, let’s get started.</p>
<h1 id="Overview-of-Key-Roles"><a href="#Overview-of-Key-Roles" class="headerlink" title="Overview of Key Roles"></a>Overview of Key Roles</h1><p>Hello and welcome to key roles. To effectively manage Azure subscriptions and resource groups, you must be familiar with the different RBAC roles. What we’re going to do here is take a look at some of the key built-in roles along with some of the other more important RBAC roles.</p>
<p>The four key roles that I want to introduce you to are contributor, owner, reader, and user access administrator. The contributor role is used to grant full access to manage all Azure resources. However, this role does not allow the user to whom it’s been assigned to assign roles in Azure RBAC. In other words, a user with a contributor role assigned to him can only manage resources. He cannot assign roles to other users.</p>
<p>The owner role is similar to the contributor role. However, as you might expect, it grants additional permissions. Like the contributor role, the owner role grants the user to whom it’s been assigned full access to manage all Azure resources. However, it also allows the user to assign roles to other users in Azure RBAC. The owner role can be viewed as essentially having the keys to the kingdom for whatever resource it applies to.</p>
<p>The reader role is pretty self-explanatory. A user that’s been assigned the reader role will be able to view resources or read them, but will not be allowed to make any changes. User access administrators are allowed to manage user access to Azure resources and that’s it. They have no access to the actual resources themselves. Rather, they manage the access to those resources.</p>
<p>Now, these four key roles are not by far the only roles that are used to manage Azure subscriptions and resource groups. There are literally dozens or maybe even hundreds of different roles that are available depending on the Azure resource that you’re talking about. For example, for compute resources, we have roles like the virtual machine contributor which allows you to manage virtual machines without providing access to them. This role also blocks access to the virtual networks and storage accounts that virtual machines are connected to.</p>
<p>Other compute roles include virtual machine administrator login, virtual machine user login, and classic virtual machine contributor. There are even more built-in roles for networking resources, including network contributor which allows you to manage networks, but not access them.</p>
<p>There are several CDN-related roles as well that allow for different levels of CDN management. There are also several other networking-related roles to choose from. The same thing goes for storage, web, containers, databases, and a host of other types of Azure resources. The <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles">URL</a> on your screen provides a complete and updated list of all the different built-in RBAC roles that come into play when managing Microsoft Azure.</p>
<p>Now, I should point out that you aren’t going to be expected to memorize a list of hundreds of different roles, that’s just not practical, but you should really familiarize yourself with the four key roles that I mentioned earlier. They include the contributor role, the owner role, the reader role, and the user access administrator role.</p>
<p>You should also be aware that in addition to all of these built-in roles, you can create custom roles when necessary as well. That being said, the built-in roles are more often than not sufficient for typical environments. Join me in the next lesson where I’ll demonstrate how to add an owner to an Azure subscription.</p>
<h1 id="DEMO-Add-an-RBAC-Owner"><a href="#DEMO-Add-an-RBAC-Owner" class="headerlink" title="DEMO: Add an RBAC Owner"></a>DEMO: Add an RBAC Owner</h1><p>Hello, and welcome back. what I’m going to do here in this demonstration and admittedly, it is a, a brief demonstration but I wanted to just make sure that I showed you how you can use our back to add an owner to a resource or to a subscription.</p>
<p>So what we’re going to do here is add a second owner to the Azurelabs subscription here in my Azure environment. On the screen here, I’m logged in as the administrator for my red widget corporation a fictitious organization here, I guess it you will.</p>
<p>Now to add an owner to my subscription, I simply select my Azurelabs subscription here from my Microsoft Azure homepage here and then from Azure labs here see this access control here, or I am entry. What we do here is we go into access control. And from here, we can look at the existing role assignments for this specific subscription, and we can see we have administrator here as owner.</p>
<p>Now, if I want to add an owner to this subscription what I can do is click the add button here up in the top menu pane here. And we can add a role assignment, we can add a co administrator, or we can add a custom role.</p>
<p>What we’re going to do here is Add role assignment and then from here, we’ll select Owner. And then what we’ll do is we’ll make Joe Kinish an owner of this subscription. And now we can see that under the owner role assignment here for the Azure subscription, we have Joe Kinish listed and we can do the same thing for a complete resource group.</p>
<p>If we go back home here and we go into our Azurelabs resource group here we can see the focus is at the resource group level. And again, we use the access control entry here, or I am we can look at the existing role assignments and we can see Joe Kinish is already an owner at the resource group level because it’s inherited from the subscription. But if I wanted to add a user as an owner specifically at this level directly on the resource group we do the same thing, we click Add we’d Add role assignment, select Owner. And then what we could do is we could make, say Lester Murphy an owner here and there you have it. And that’s pretty much it. That’s how you add an owner at both the subscription level and at the resource group level.</p>
<h1 id="DEMO-Add-or-Change-Azure-Subscription-Administrators"><a href="#DEMO-Add-or-Change-Azure-Subscription-Administrators" class="headerlink" title="DEMO: Add or Change Azure Subscription Administrators"></a>DEMO: Add or Change Azure Subscription Administrators</h1><p>Hello and welcome back. In this brief demonstration here, what we’re gonna do is walk through the process of adding or maybe changing an Azure subscription administrator. Now on the screen here, I’m logged into the Azure portal. I’m at my home page here, and I’m logged in as an administrator here.</p>
<p>What we’re going to do is browse to Azure labs through either the recent resources that I’ve worked with which is a subscription here, or I can navigate to subscriptions under the navigate section here or I can browse to subscriptions through Azure services.</p>
<p>What I’ll do here is browse to subscriptions. And then from here, I can see I only have one Azure subscription here and it’s called Azure labs. So we’ll go ahead and open up our subscription. And it takes us to the overview page.</p>
<p>To add or change subscription administrators for this subscription, what we’re going to do is browse into access control. And before I do that, I just wanna make a quick note here. The Azure portal changes rather frequently or at least more frequently than I’d like it to. So don’t focus as much attention on where you’re clicking, the actual physical location, but more on what you’re clicking. And in this case we want to use, I am or access control for the Azure lab subscription.</p>
<p>So if you try this in your own environment and this access control link is somewhere else in the list then that’s fine. The idea is you wanna click access control. So that PSA out of the way, let’s go ahead and get into access control here. And we can see from access control.</p>
<p>What we’re going to do is add a subscription administrator. And to do that, we click add here, and then we have a couple options. Role assignment, the co-administrator which is what we’re going to do here or we’re going to add a custom role.</p>
<p>So to add our administrator, which is essentially a co-administrator, we select the co-administrator option and then from here, we can select the user we want to make a co-administrator. So for this demonstration here, we’ll select John Gold and we’ll make him a co-administrator of this Azure labs subscription. And if we select role assignments here we can see that our new co-administrator and even administrators for that matter are not shown. That’s because these permissions are not role assignments. They’re actually permissions over the subscription for actual administrators.</p>
<p>Now to remove that co-administrator, we can actually go into classic administrators. And that’s because this is more of a classic role. If we select classic administrators, we can see that John Gold is listed as a co-admin. And this is the important piece here. We can see that classic administrators are only needed if you’re still using Azure classic deployments.</p>
<p>If you’re not using Azure classic deployments you wouldn’t be assigning co-admin roles within your subscription. But I wanted to just show you what that was because if you happen to go into, I am, you’ll see that option here. So I wanted to at least let you know what this is and how you use it.</p>
<p>So what we’re going to do here is we’re going to remove John Gold as a classic administrator. And there we now have our classic co-administrator access removed for John Gold. Then from here, we’ll bounce back to the role assignments.</p>
<p>And from here, this is where you would want to grant the permissions to the subscription as you see fit. So with that, let’s call it a wrap and I’ll see you in the next lesson.</p>
<h1 id="Configure-Subscription-Policies"><a href="#Configure-Subscription-Policies" class="headerlink" title="Configure Subscription Policies"></a>Configure Subscription Policies</h1><p>The Azure Security Center creates a default security policy automatically for each Azure subscription. These policies can be edited and monitored for compliance in Security Center. Security Center policies can also be extended by using Azure policy, which is a service in Azure that you use to create, assign, and manage policies.</p>
<p>Because security requirements for development resources typically vary from the requirements for production resources, it’s critical to maintain policies that fit these requirements. As such, security policies are used to drive security recommendations and monitoring. This helps identify potential vulnerabilities and mitigates threats.</p>
<p>As you can see on the screen, the default security policy contains numerous policies and definitions that govern among other things, system updates, security configurations, endpoint protection, and disk encryption. The system updates policy retrieves a daily list of available security and critical updates and recommends that missing updates be applied.</p>
<p>The security configurations policy analyzes OS configurations to identify virtual machine vulnerabilities and recommends configuration changes to mitigate such vulnerabilities.</p>
<p>Endpoint protection and disk encryption policies make recommendations for protecting virtual machines from viruses and data theft. In addition to these policies, other policies are also useful for protecting the environment, such as network security groups, web application firewall, next-gen firewall, SQL auditing, and threat detection, SQL encryption, vulnerability assessment, storage encryption, and just-in-time network access. By leveraging all of these different policies, you can help identify potential vulnerabilities in the environment and mitigate any threats identified.</p>
<h1 id="Overview-of-Resource-Groups"><a href="#Overview-of-Resource-Groups" class="headerlink" title="Overview of Resource Groups"></a>Overview of Resource Groups</h1><p>A resource group in Microsoft Azure is a logical container so to speak. It is used to group a collection of Azure resources, such as virtual machines, VNets, storage accounts, et cetera into logical groupings for easy provisioning, monitoring, and access control.</p>
<p>Resource groups are also very effective for management of costs. A key benefit of using resource groups in Azure is that by grouping related resources together, they typically share a unified lifecycle. Although Azure requires the admin to specify a region when creating a resource group, resources contained within that resource group can span across multiple regions.</p>
<p>The requirement of a resource group being deployed to a specific region comes from the need to store the deployment metadata and definitions associated with that resource group in a specific location. As such, it doesn’t dictate that resources belonging to that resource group need to be in the same region as the resource group itself.</p>
<p>As easy as resource groups make management of Azure resources, it’s important to use resource groups with care. The key to clean and meaningful use of resource groups is an understanding of the resources that are included in them. For example, if a line of business application requires resources that need to be updated together, it makes sense to group these resources in the same resource group.</p>
<p>It’s equally important, however, to use different resource groups to separate out dev&#x2F;test resources, staging resources, production resources, et cetera. This is important because resources in each bucket so to speak will typically have different lifecycles.</p>
<p>In the upcoming lectures and demonstrations, you are going to learn how to manage resource groups by using policies, resource locks, and tags. You’ll also learn how to move resources between resource groups and how to delete resource groups altogether.</p>
<h1 id="Resource-Policies"><a href="#Resource-Policies" class="headerlink" title="Resource Policies"></a>Resource Policies</h1><p>IT governance is critical to organizations. It ensures achievable goals through effective and efficient use of IT by creating clarity between business goals and IT projects. As such, IT governance requires careful planning of initiatives and setting priorities on a strategic level to help manage and prevent issues.</p>
<p>Azure Policy helps accomplish this. Azure Policy is an Azure service used to create, assign and manage policies that enforce different rules over Azure resources. In doing so, such resources remain compliant with corporate standards and SLAs.</p>
<p>Azure Policy accomplishes this by evaluating deployed resources and scanning for those not compliant with the policies that have been defined. An example of this would be a case in which a policy is defined to allow only a certain size of virtual machine in an Azure environment. Such a policy once implemented would be evaluated when creating and updating resources as well as over existing resources.</p>
<p>Managing resources with Azure Policy begins with the creation of a policy definition in the portal. Attached to such a definition are conditions under which it is enforced along with an effect that takes place when the defined conditions are met.</p>
<p>Azure Policy offers several built-in policies that are available by default require SQL Server 12.0 contains conditions and rules to ensure that all SQL servers deployed use version 12. This policy denies all servers that do not meet these criteria.</p>
<p>Allowed Storage Account SKUs contains conditions and rules that determine if a storage account being deployed is within a certain set of SKU sizes. It denies all storage accounts that do not adhere to the defined set of SKU sizes.</p>
<p>Allowed Resource Type contains conditions and rules to specify which resource types can be deployed. This policy denies any resources that are not part of this defined list. Allowed Locations restricts the locations to which resources can be deployed. It is used to enforce geo-compliance requirements. The Allowed Virtual Machine SKUs policy restricts the set of virtual machine SKUs that can be deployed.</p>
<p>Apply tag and its default value applies a required tag and its default value to resources if it is not specified by the user. The enforce tag and its value policy enforces a required tag and its value to a resource. Not allowed resource types enables the ability to specify resource types that cannot be deployed.</p>
<p>To leverage these policy definitions as well as any other custom definitions, they need to first be assigned. This can be accomplished through the Azure portal, PowerShell or through Azure CLI. Policy re-evaluation happens about once an hour. As such, changes to a policy definition after implementation of the policy will be re-evaluated over the resources within the hour.</p>
<h1 id="DEMO-Assigning-Policies"><a href="#DEMO-Assigning-Policies" class="headerlink" title="DEMO: Assigning Policies"></a>DEMO: Assigning Policies</h1><p>Understanding compliance in Microsoft Azure requires the ability to identify the status of resources in a subscription. In this demonstration, we’ll walk through the process of creating a policy assignment to identify virtual machines that are not using managed disks.</p>
<p>To get started, let’s create a policy assignment and assign the audit virtual machines without managed disks policy definition. To do this, browse to the Azure portal, and then click All services. From here, search for Policy, and then select it from the results list.</p>
<p>Click Assignments in the left pane. An assignment is a policy that’s been assigned to take place within a specific scope. Next, click Assign policy from the top of the Policy Assignments page. From the Assign policy page, select a scope by clicking the ellipsis, and then choosing either a management group or a subscription. The scope determines which resources the policy assignment gets applied to.</p>
<p>Click Select at the bottom of the scope page. Exclusions are optional, so we’ll leave this option blank since we aren’t excluding anything. Click the policy definition ellipsis to open the list of available definitions. By default, Azure policy offers built-in policy definitions that you can use. For this exercise, we can search through the list of policy definitions to find the Audit VMs that do not use managed disks definition.</p>
<p>Click on that policy, and then click Select. The assignment name is automatically populated with the policy name, but that can be changed. For this exercise, we’re just going to leave Audit VMs that do not use managed disks. Adding a description is optional. The description, if used, should provide details about the policy assignment itself.</p>
<p>Assigned by is filled in automatically, based on who is logged in. This field is also optional, and as such, custom information can be entered here as well. For this exercise, I’m going to leave Create a Managed Identity unchecked. This option must be checked if the policy being assigned includes a policy with the deploy if not exists effect. Since the policy we are working with in this exercise does not, we can leave it blank.</p>
<p>Click Assign to assign the policy. With the policy assigned, we can identify non-compliant resources To do so, click Compliance in the left side of the page, and then find the Audit VMS that do not use managed disks policy assignment that was created.</p>
<p>Resources that are not compliant with this new assignment will appear under Non-compliant resources. When conditions are evaluated against resources and are found to be true, those resources are marked as non-compliant with the assigned policy. Compliance State results are either compliant or non-compliant. So, as you can see from this demonstration, policies are extremely helpful when trying to ensure resource compliance with predefined standards.</p>
<h1 id="Resource-Locks"><a href="#Resource-Locks" class="headerlink" title="Resource Locks"></a>Resource Locks</h1><p>Day-to-day administration will sometimes require you to lock a subscription, resource group, or specific resource to prevent other users from accidentally deleting or modifying critical resources. When this need arises, you can set resource locks by setting lock levels to CanNotDelete or to ReadOnly you can ensure resources are not deleted or modified.</p>
<p>In the Azure portal, the locks are called Delete and ReadOnly respectively. The CanNotDelete lock allows authorized users to read and modify a resource, but not delete the resource. ReadOnly allows authorized users to read a resource but not delete or update the resource.</p>
<p>Applying the ReadOnly lock is similar to restricting all authorized users to the permissions granted by the reader role. When a lock is applied at a parent scope all resources within that scope inherit the lock. Resources added later, will also inherit the lock from the parent.</p>
<p>The most restrictive lock in any inheritance takes precedence. It’s important to note that applying ReadOnly can sometimes lead to unexpected results because some operations that appear to be read operations are actually operations that require additional actions. For example, a read-only lock on a storage account will prevent all users from listing the keys. This is because the list keys operation is handled through a post request because the keys returned are available for right operations.</p>
<p>Similarly, placing a ReadOnly lock on an app service resource will prevent visual studio server Explorer from displaying files for the resource because displaying files requires right access. To create or delete management locks, you must have access to Microsoft.authorization&#x2F;* or Microsoft.authorization&#x2F;locks&#x2F;*actions. Only the built-in owner and user access administrator roles are granted these actions.</p>
<h1 id="DEMO-Setting-a-Resource-Lock"><a href="#DEMO-Setting-a-Resource-Lock" class="headerlink" title="DEMO: Setting a Resource Lock"></a>DEMO: Setting a Resource Lock</h1><p>To set a resource lock, browse to the settings blade for the resource, resource group or subscription that you wish to lock and then click locks. To add a lock, click add. You can create a lock at a parent level by selecting the parent. Resources will inherit the lock from the parent.</p>
<p>Provide a name for the lock and specify the lock level. You can also add notes that describe the lock if you wish. You can delete a lock simply by selecting ellipsis and then clicking delete from the available options.</p>
<h1 id="Implement-and-Set-Tagging-on-Resource-Groups"><a href="#Implement-and-Set-Tagging-on-Resource-Groups" class="headerlink" title="Implement and Set Tagging on Resource Groups"></a>Implement and Set Tagging on Resource Groups</h1><p>Applying tags to Azure resources provides metadata that’s used to logically organize those resources into a taxonomy. Each tag consists of a name and a value pair. A common example is the use of a tag named Environment along with the value of Production that’s applied to all resources in production.</p>
<p>Applying tags offers the ability to retrieve all resources in a subscription that are assigned a specific tag name and value. Using tags enables the administrator to even retrieve related resources from different resource groups. This is helpful when organizing resources for billing and management.</p>
<p>As helpful as tags, there are some limitations that apply to them. For example, each resource or resource group is limited to a maximum of 15 tag name&#x2F;value pairs that can be directly applied to the resource group or resource.</p>
<p>Another limitation is tag name length. Tag names are limited to 512 characters. Tag values are limited to 256 characters. For storage accounts, the tag name is limited to 128 characters and the value is limited to 256. Virtual machines are limited to a total of 2048 characters for all tag names and values.</p>
<p>It’s important to note that tags that are applied to a resource group are not inherited by the resources within that resource group. Also, tags can’t be applied to classic resources such as Cloud Services and they can’t contain special characters. The ability to apply tags to resources requires the user to have write access to that resource type.</p>
<p>Use the Contributor role to enable the ability to apply tags to all resource types. If it’s necessary to provide the ability to apply tags to only one resource type, use the Contributor role for that particular resource. For example, to apply tags to virtual machines, use the Virtual Machine Contributor role.</p>
<h1 id="DEMO-Tagging-Resources"><a href="#DEMO-Tagging-Resources" class="headerlink" title="DEMO: Tagging Resources"></a>DEMO: Tagging Resources</h1><p>To view tags for a resource, browse to the resource and click overview. From here, click tags. If tags have been applied, they will be listed. If you have not previously applied tags, the list will be empty. To add a tag, select the name dropdown and provide a name and then a value for the new tag and then click save to add the tag. The new tag will now be displayed in the overview window.</p>
<p>You can delete a tag by highlighting it and then clicking the trash icon. Clicking save completes the deletion. If you need to bulk assign a tag to multiple resources, browse to a resource group, or really any list of resources, and click the checkbox for the resources you want to assign a tag to and then click assign tags. When done, click save.</p>
<p>To view all resources with a specific tag, click tags in the left pane and then select the tag from the dropdown box. Click the show resources icon on the right. By leveraging tags, you can make your day-to-day administration of resources far easier and more organized.</p>
<h1 id="Moving-Resources-across-Resource-Groups"><a href="#Moving-Resources-across-Resource-Groups" class="headerlink" title="Moving Resources across Resource Groups"></a>Moving Resources across Resource Groups</h1><p>Day-to-day operations will sometimes require that resources be moved from one resource group to another. While this is possible, it’s important to note that when moving resources between resource groups, both the source group and the target group are locked during the operation.</p>
<p>Write and delete operations are both blocked on the resource groups involved until the move completes. As such, resources can’t be added, updated, or deleted in the locked resource groups while the move is in progress. However, this doesn’t mean the resources themselves are frozen. For example, if you move an application server and its database to a new resource group, the application experiences no downtime. It continues to function as normal.</p>
<p>It’s important to note that the location of a resource cannot be changed. Moving a resource only moves it to a new resource group. While the new resource group may have a different location, this fact doesn’t change the location of the resource itself being moved to the new resource group.</p>
<p>Before moving a resource to a new resource group, there are some important steps to perform to prepare for such a move. By taking these steps, errors can be avoided. For starters, the source and destination subscriptions must exist within the same Azure Active Directory tenant. The destination subscription must be registered for the resource provider of the resource being moved.</p>
<p>If the destination subscription isn’t registered for that resource type being moved, you’ll see an error stating that the subscription is not registered for a resource type. This often happens when moving a resource to a new subscription but that subscription has never been used with that resource type before.</p>
<p>The account moving the resources must have the permissions you see on your screen. Before moving resources, ensure the subscription quotas for the subscription you’re moving the resources to supports the resources you plan to move.</p>
<p>If moving the resources will cause the destination subscription to exceed its limits, an increase in the quota for that resource must first be requested. When moving resources, it’s best to break large moves into separate smaller move operations. As a matter of fact, Resource Manager will immediately fail if there is an attempt to move more than 800 resources in a single move operation. That said, a move of fewer than 800 resources may also fail, but that would be due to timeouts and other miscellaneous reasons.</p>
<h1 id="DEMO-Move-Resource-to-New-Resource-Group"><a href="#DEMO-Move-Resource-to-New-Resource-Group" class="headerlink" title="DEMO: Move Resource to New Resource Group"></a>DEMO: Move Resource to New Resource Group</h1><p>To move resources to a different resource group select the resource group containing those resources, and then click the Move button. Choose move to another resource group from the dropdown, and then select the resources to move along with the destination resource group.</p>
<p>Acknowledge that you need to update scripts for these resources, and then click Okay to move the resources. In notifications, you see that the move operation is running and when the move is completed you’re notified of the result.</p>
<h1 id="Removing-Resource-Groups"><a href="#Removing-Resource-Groups" class="headerlink" title="Removing Resource Groups"></a>Removing Resource Groups</h1><p>As a course instructor, I often have dozens of resource groups provisioned, each containing resources associated with a separate course or lab. When I’m done with the course or lab I simply delete the entire resource group. Doing so deletes all of the resources contained within it. This makes it easy for me to keep my Azure subscription clean of any unused resources.</p>
<p>Deleting a resource group is pretty straightforward. To do so, simply browse to the resource group, in the Azure portal, and then click the delete icon at the top. Confirm that you want to delete the resource group and then begin the deletion. Be careful when deleting a resource group, because when it’s deleted all resources contained in it are also deleted.</p>
<p>The amount of time it takes to delete a resource group, largely depends on how many resources are inside of the resource group, at the time of deletion. Obviously, the deletion of an empty resource group will be far quicker than that of a resource group that contains 800 objects in it.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>I hope you’ve enjoyed learning about managing Azure subscriptions and resource groups. Let’s review what you’ve learned. We kicked things off by covering key roles within an Azure subscription, including the contributor role, the owner role, reader, and user access administrator. You learned what each role does and how to assign and change roles.</p>
<p>We then dove into subscription policies and what role they play within a subscription. Next, we took a look at resource groups and how to manage those. You learned about resource policies and how to assign them. You also learned what Resource Locks are and how to use them to secure Azure resources.</p>
<p>Coming down the homestretch, we cover tagging and how to use tags to group resources together. Rounding out the course, you learned how to move resources between resource groups and how to delete resource groups altogether.</p>
<p>To learn more about managing Azure subscriptions and resource groups, be sure to review the documentation published by Microsoft. Be sure to also watch for new Microsoft Azure courses on Cloud Academy because we’re always publishing new ones. Please give this course a rating, and if you have any questions or comments, please let us know. Thanks for watching and happy learning.</p>
<h1 id="2Overview-of-Key-Roles"><a href="#2Overview-of-Key-Roles" class="headerlink" title="2Overview of Key Roles"></a>2<strong>Overview of Key Roles</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles">List of built-in RBAC roles</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Configure-Azure-Virtual-Networks-Challenge-35/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/AZ-104-Configure-Azure-Virtual-Networks-Challenge-35/" class="post-title-link" itemprop="url">AZ-104-Configure-Azure-Virtual-Networks-Challenge-35</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:33" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:33-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:46:58" itemprop="dateModified" datetime="2022-11-22T11:46:58-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Configure-Azure-Virtual-Networks-Challenge-35/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Configure-Azure-Virtual-Networks-Challenge-35/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/68/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/68/">68</a><span class="page-number current">69</span><a class="page-number" href="/page/70/">70</a><span class="space">&hellip;</span><a class="page-number" href="/page/274/">274</a><a class="extend next" rel="next" href="/page/70/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
