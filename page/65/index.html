<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hang&#39;s Blog">
<meta property="og:url" content="https://example.com/page/65/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/page/65/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Configuring-Azure-API-Management-33/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Configuring-Azure-API-Management-33/" class="post-title-link" itemprop="url">AZ-204-Configuring-Azure-API-Management-33</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:54:25" itemprop="dateCreated datePublished" datetime="2022-11-14T11:54:25-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 10:00:30" itemprop="dateModified" datetime="2022-11-15T10:00:30-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Configuring-Azure-API-Management-33/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Configuring-Azure-API-Management-33/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to configuring Azure API Management. My name is Matthew Quickenden, and I am going to be guiding you through some of the key features and aspects of configuring the Azure API Management resource. I have over 20 years industry experience and have recently been working with cloud and hybrid cloud technologies, with a specific focus on <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> and Azure Stack. If you have any questions, feel free to connect with me on LinkedIn, or send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. </p>
<p>This course is intended for people who want to become a certified Azure developer, or who are tasked with creating and managing an Azure API Management resource. To get the most out of this course, you should have a general understanding of Microsoft Azure and be able to deploy and manage resources. Being familiar with restful APIs and having some experience using Postman and an understanding of OAuth token flow would be useful, but not essential. For this course, you do not need any knowledge of any specific development languages. </p>
<p>We are going to look at what Azure API Management is and what it can do, and we will create an instance in Azure. Once we have this instance, we will look at various ways we can secure the APIs and apply policies during different stages of an API request. We will use Postman to help access and consume the service external to the Azure Portal. </p>
<p>By the end of this course, you should be able to set up an instance of Azure’s API Management, secure it using OAuth endpoints, apply policies to alter API requests and responses and be able to troubleshoot and trace policies being applied. Your feedback on this course is important, so please give it a rating when you’re finished. Let’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/getting-started/">get started</a>.</p>
<h1 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h1><p>Because <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/introduction/">Azure API Management</a> takes a while to deploy and become usable we’re going to go to the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> portal and kick off the provisioning process immediately. There is only one blade you need to complete to start the creation of your service which we can review now. </p>
<p>In this case, we can see a screenshot, where I’ve named it clouddemo which is appended with the .azure-api.net suffix. I’ve select a subscription and a resource group. I’ve chosen a location and given the company name. I’ve also entered an email address, this needs to be a valid email as you will receive emails to this based on the service and selected a pricing tier which is Developer. </p>
<p>If we look at the pricing details we can see that the Developer tier costs around 33 dollars a month and contains all the features we need to develop. This includes AAD Integration, virtual networks, the things you are short on, the things like redundancy. You’re only in a single region and you can’t scale. However, all the features you need to develop are there for any of the other tiers. Once you go into production you can change the skew of your API very easily by selecting a new skew. So with all this done, let’s click create and we can let the service provision. Once the service is ready, you will receive a notification email.</p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>While that’s provisioning, let’s take a look at what the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/introduction/">Azure API Management</a> is. On the Microsoft website if you look up what is API Management, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a> defines it as API Management helps organizations publish APIs to external, partner, and internal developers to unlock the potential of their data and services. Businesses everywhere are looking to extend operations as a digital platform, creating new channels, finding new customers, and driving deeper engagement with existing ones. API Management provides the core competencies to ensure a successful API program through developer engagement, business insight, analytics, security, and protection. You can use Azure API Management to take any backend system and develop a fully-fledged API on top of it. </p>
<p>So what does that mean? Using an API is a very common way to communicate over the internet, allowing your organization to provide services in a secure manner. You can consider APIM as a gateway service that provides a developer portal, a publisher portal, and allows developers, publishers, and applications and users to access all the content and data securely hosted in your own backend systems. </p>
<p>Using API Management allows developers to easily consume APIs in different formats, including open API, which is an open standard and language agnostic, WADL XML representation of APIs, WSDL, which is SOAP representation of APIs, and other Azure-hosted services like Logic Apps, Function Apps, and API Apps. </p>
<p>Once you have ingested these APIs, you can create different products, which allows you to deliver parts of these APIs to different user groups with different restrictions and options. When a user or company connects to the API Management service, they obtain a subscription. This subscription is used to help manage incoming requests. Azure API Management also offers a flexible way to version, test, and publish APIs to internal and external users. </p>
<p>Some of the benefits of the Azure API Management are freedom of language choice, scalable, limit access or the number of calls, offloading security, insights for performance and troubleshooting. </p>
<p>Now that we have an idea of what the Azure API Management is and can do and before we proceed with configuring the service, let’s discuss the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/scenario-outline/">scenario</a> of what we’re going to try and achieve over the length of this course.</p>
<h1 id="Scenario-Outline"><a href="#Scenario-Outline" class="headerlink" title="Scenario Outline"></a>Scenario Outline</h1><p>There are a lot of components that make up the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/configuring-the-service/">configuration of the service</a>. Here we are going to explain what we are going to work through. We have already started the creation of the Clouddemo API in our subscription. Once this completes we are going to ingest an API provided by <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a>. This API contains a number of API operations around getting conference data. We will then create a simple API request in Postman. From there we can create the required applications in Azure AD, I’ve already provisioned an Azure AD called Cyber Labs for this demo. And will expect you to have your own Azure AD or if you don’t have one to configure it now. In the Azure AD we will create a backend app, a front end app along with a secret key. We will also grant the front end application permission to access the backend app. We will use the Azure Portal, the Developer Portal, and Postman to query the import of Microsoft Demo APIs using these applications. We will then add API policies and look at how we can scope and understand effective policy and how to trace these policies. Finally we will make sure that our API is secure and that requests to the API require a valid access token or bearer token from our Azure AD tenant which in this case is Cyber Labs. </p>
<p>There are a lot of configuration items throughout this demo I record into Notepad To help you here is all the text. You may just want to copy it from the transcript and fill it out with your specific data as you go through the demos.</p>
<p><a target="_blank" rel="noopener" href="https://conferenceapi.azurewebsites.net/?format=json">https://conferenceapi.azurewebsites.net?format=json
</a>https:&#x2F;&#x2F;{name}.azure-api.net&#x2F;sessions<a target="_blank" rel="noopener" href="https://clouddemo.azure-api.net/sessions">
</a>Starter Subscription Key: 76c24a0abeb94104809b0810f74a20e5<br>Subscription Header: Ocp-Apim-Subscription-Key</p>
<p>Azure AD Tenant: mycyberlabs.onmicrosoft.com<br>Azure AD Tenant GUID: fc9f98a5-2d78-4a13-afa4-2ccfe88db15a</p>
<p>Apps<br>myFrontEndApp ID: 902eef25-668f-4e58-8398-f72a5da893ea<br>myFrontEndApp Secret Key: QZdqqvNXBxm466IvJd5ociARYInUwNyPbXJuJLP3IyE&#x3D;<br>myBackEndApp ID: f9a45df4-6102-4f5c-a855-e2a2cbbab627</p>
<p>Call Back URLs<br>Postman Call back URL: <a target="_blank" rel="noopener" href="https://www.getpostman.com/oauth2/callback[](https://www.getpostman.com/oauth2/callback)">https://www.getpostman.com/oauth2/callback[](https://www.getpostman.com/oauth2/callback)</a></p>
<p>https:&#x2F;&#x2F;{name}.portal.azure-api.net&#x2F;signin<a target="_blank" rel="noopener" href="https://clouddemo.portal.azure-api.net/signin"></a></p>
<p>https:&#x2F;&#x2F;{name}.portal.azure-api.net&#x2F;docs&#x2F;services&#x2F;cyberlabs&#x2F;console&#x2F;oauth2&#x2F;authorizationcode&#x2F;callback<a target="_blank" rel="noopener" href="https://clouddemo.portal.azure-api.net/docs/services/cyberlabs/console/oauth2/authorizationcode/callback"></a></p>
<p>https:&#x2F;&#x2F;{name}.portal.azure-api.net&#x2F;signin-aad<a target="_blank" rel="noopener" href="https://clouddemo.portal.azure-api.net/signin-aad"></a></p>
<p>Endpoints<br>OAuth 2.0 (v1) Authorization Endpoint: <a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/oauth2/authorize[">https://login.microsoftonline.com/{aad-tenant}/oauth2/authorize[</a><br>](<a target="_blank" rel="noopener" href="https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/oauth2/authorize)OAuth">https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/oauth2/authorize)OAuth</a> 2.0 (v1) Token Endpoint: <a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/oauth2/token[">https://login.microsoftonline.com/{aad-tenant}/oauth2/token[</a><br>](<a target="_blank" rel="noopener" href="https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/oauth2/token">https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/oauth2/token</a>)</p>
<p>OpenID Connect meta document: <a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/v2.0/.well-known/openid-configuration[](https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/v2.0/.well-known/openid-configuration)">https://login.microsoftonline.com/{aad-tenant}/v2.0/.well-known/openid-configuration[](https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/v2.0/.well-known/openid-configuration)</a></p>
<p>V1<br><a target="_blank" rel="noopener" href="https://login.microsoftonline.com/mycyberlabs.onmicrosoft.com/.well-known/openid-configuration">https://login.microsoftonline.com/mycyberlabs.onmicrosoft.com/.well-known/openid-configuration</a></p>
<p>postman Oauth<br><a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/oauth2/authorize?resource=%7Bresource">https://login.microsoftonline.com/{aad-tenant}/oauth2/authorize?resource={resource</a> ID}</p>
<p><a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/oauth2/authorize?resource=%7Bresource">https://login.microsoftonline.com/{aad-tenant}/oauth2/authorize?resource={resource</a> ID}&amp;response_type&#x3D;code&amp;client_id&#x3D;{client ID}&amp;redirect_uri&#x3D;https:&#x2F;&#x2F;{name}.portal.azure-api.net&#x2F;docs&#x2F;services&#x2F;cyberlabs&#x2F;console&#x2F;oauth2&#x2F;authorizationcode&#x2F;callback&amp;state&#x3D;{state ID}</p>
<h1 id="Configuring-the-Service"><a href="#Configuring-the-Service" class="headerlink" title="Configuring the Service"></a>Configuring the Service</h1><p>If we go to our clouddemo API management service and we see the overview, we can see we have the clouddemo.azure-api.net. We can see we’ve got a virtual IP address, the developer tier for this queue that we selected, and the region and the status is currently online. So, this is all the information we expected, which is great. If we go to the APIs, we can see the add API and the different types we looked at earlier. We need to find an API we can import. If you go to your favorite search engine and enter democonference api, you should be able to find the Import and publish your first API from Azure Management. We can see it’s an OpenAPI Specification and it’s conferenceapi on Azure websites in the format of JSON. So I’m gonna copy this URL. I’m also gonna record all these links in just a Notepad for my own reference. So, save that there. And if we actually open this in a browser, we can see the API definition here with the different operations. So this has the GetSessions, GetTopics.</p>
<p>If we return to the API Management service, if we go into the Add API and OpenAPI, we’re gonna add here, and we paste in this URL, we can see that it recognizes the URL and calls it Demo Conference API. The products, and add the Starter and the Unlimited products, which are already defined when the service is created. And click Create. And now that’s imported. So we can see we’ve got the Demo Conference API now in this portal, and we can see a number of operations. I’m just gonna minimize displayed so that we can see more real estate and look at one of these operations itself. </p>
<p>So, can we actually get some sessions back from the Demo Conference API we’ve just imported? We’re just gonna click Test and test it within the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> portal, and click on the GetSessions. We can see here there’s a number of parameters you can pass to it. We’re not so interested in that at the moment. We just wanna see the Request URL gets us some data. So if we press Send, we can see we get the HTTP response back, 200 OK, which is good, it’s green, green is good. And if we look down, we can see a collection of items. So there’s a session here, 100, keynotes with Dan North. We can see another record, time slots. So, this looks correct. </p>
<p>We wanna test this outside of the Azure portal ‘cause we’re likely gonna be building other applications or interacting this with another way. So I’m gonna grab this Request URL here for the sessions. I’m just gonna paste that into my Notepad over here. And we’re gonna go to the Postman application. If you haven’t used Postman before, it’s a free app to download. There is a paid subscription which allows you to share your APIs with different team members. It’s a very useful tool for orchestrating and creating API requests and troubleshooting problems with APIs. </p>
<p>I’d like to go through and make sure that we can access our Azure API services that we’re creating using Postman as well. We’ve just copied in the URL for these sessions. I’ve done nothing more here than create a workspace and a collection called demo. Again, paste that URL in and we’ll just save that, and that’s gonna be called sessions. Select the collection and Save. So now, if we click the Send button, we get an Access denied due to missing subscription key. Make sure you include a subscription key when you make an API request. If we go back to the portal, when we clicked this, we went okay, so we need to understand the difference between what’s happened here and what we need to do to access this externally. </p>
<p>So, what we did do when we first added the API, we added the product Starter and Unlimited. That’s where we’re gonna get our subscription keys from. We’re gonna open up the Developer portal, so you see the link here on the API Management service. That will open another web browser for us. We can see there, it’s Cloud Company. That was the name that we had entered in originally when we created the system. And we can see we’ve got an Administrator log in here. So this is the portal which was created by the API service. You don’t have to create anything. You can customize this. </p>
<p>This is supposed to be the Developer portal on how developers would interact with your API. We wanna create a user. We don’t wanna use the Administrator. So, we’re just gonna sign out. This will allow us to go through the sign up experience. Sign up right away. And I’m just gonna pause the video and enter in some details. </p>
<p>I’ve entered an email, a password, first name, last name, and the characters we see here. And we click Sign up. We’ll save that for ease of use. And we’re told we get a verification email we need to go check. Got that email in my inbox. It’s over here. We can see we’ve got the link, welcome to Cloud Company API account, and we just need to activate this. So, it’s asking me for the password again. And sign up. Just gonna copy this out of that Chrome browser and put it in our Firefox browser here. There’s the user we’re gonna sign back in with. And we can see we have the Cloud Company API Developer portal. We have no subscriptions. So, we need to go to Products and in this case, we wanna sign up for the Starter subscription. Along with the Starter subscription, we can see we get access to the Echo API and the Demo Conference API. Just gonna click Subscribe. And we get to give that a name. Starter is fine. Confirm. </p>
<p>We can see now for Matt Quickenden, we have a subscription for Starter and we started on this date. We have a primary and secondary key. I’m gonna just click Show here and see that key. We’re gonna use this key a couple times, so I’m gonna bring this over to my Notepad and we’re gonna call this MQ Starter Subscription Key, and save. From here, let’s go back to the clouddemo API and we wanna go to the Settings for the Demo Conference API. These settings are around the import for this app, so we can see, here’s the URL we put in. Both the URL scheme are allowed or required. Here are those products we selected. We can see we have Subscription, Subscription required. The header name is this, and the query parameter subscription key. Now that we have the subscription ID and we know what the header is we need to provide, we will go back to the Postman app and add in this information. So, let’s copy out this header name here. This is Subscription Header. Bring up Postman. And we can see we have Headers over here, so let’s click header. Let’s add in the key name, which is the subscription key. And then we’re gonna wanna add in the key itself. So, we take this number we copied, put it in the value, and Send. </p>
<p>We’ve now actually created the appropriate headers to access the information for sessions using that key. We can now do in the Postman portal what we’ve seen happen in the Azure portal. So during this process, we created a subscription. Let’s go back to the API and have a look at what this actually means. Expand displayed, click on Subscriptions. We can see here that this Administrator has access to each of these products. The built-in service has a product. And there’s a Starter product subscribed to Matt Quickenden. If we wanna look at the different products, we have the Product displayed over here. By default, there’s a Starter and an Unlimited, and the access control here for different groups. So, you can create your own subscriptions for different access controls, different levels of permission, different customers, different end users, different developers. They’ll have different access and different levels and that very much depends on how you wanna utilize and segregate your APIs. We’re gonna be just using the Starter for our demo. </p>
<p>So, let’s review what we’ve done. We’ve created the API Management service in the Azure portal. We have imported a Demo Conference API from Microsoft. We’ve created a user in the portal called Matt Quickenden, and we’ve captured our subscription key. We’ve tested a call for GetSessions in the Azure portal itself. And we’ve created a GetSessions request with our subscription key in Postman. We’re gonna pause the demo session here and go back and look at some of the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/authentication/">authentication theory</a>.</p>
<h1 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h1><p>What does offloading security actually mean? It means the built-in APIM is the ability to consume other authentication services, which means you don’t have to deploy and maintain your own security layer. You can allow a range of different public identity services, so that your users can connect to your APIM portal. These services can be Azure AD, Azure B2C, Facebook, Google, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a> and Twitter accounts can all be used to protect and access your APIM. </p>
<p>With regards to securing the APIs directly, APIM has some native features to help secure APIs using OpenID Connect or OAuth 2.0. We are going to be working through the process of setting up and securing an API using OAuth 2, and our Azure AD tenant, Cyberlabs.</p>
<h1 id="What-is-OAuth"><a href="#What-is-OAuth" class="headerlink" title="What is OAuth?"></a>What is OAuth?</h1><p>Let’s review the OAuth authentication protocol. OAuth allows a user to prove their identity without having to share their secure password. It covers authorization, it does not cover <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/authentication/">authentication</a>. A user can obtain a token, which they give to an application to use as proof of that user’s identity. This token is often referred to as a bearer token. Using bearer tokens means third party services, once configured, can validate a user with their identity provider, and provide access to privileged or secure resources. </p>
<p>What is the difference between OAuth and OpenID Connect? The OAuth 2.0 protocol was designed to allow authorization to occur over HTTP. OpenID Connect was designed to be an additional layer on top of the OAuth 2.0 protocol, and adds authentication. For our scenario, we will be focusing on the OAuth 2.0 protocol.</p>
<h1 id="Oauth-Grants"><a href="#Oauth-Grants" class="headerlink" title="Oauth Grants"></a>Oauth Grants</h1><p>There are different types of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/what-is-oauth/">OAuth</a> grants: authorization code, implicit, password, client credentials, device code, and refresh token. We will be taking a look at the authorization code grant, which is what we are setting up for our scenarios. Having an understanding of the code flow is very useful when implementing and troubleshooting. </p>
<p>An authorization code flow is when a client obtains a user’s approval and gets an authorization code that can be exchanged for an access token which is used to gain access to privileged resources. </p>
<p>Let’s take a closer look at the OAuth flow for authorization code. Here we can see we have a user and their browser, a client application, the user’s authorization server, and a privileged resource server. </p>
<p>Let’s walk through the eight steps. First, the process will be initiated by the user trying to get into a client application. Second, the client will redirect the user to an authorization server that they trust. Third, the user will log into the authorization server with their username and password. Fourth, the authorization server will validate the user’s credentials and redirect them to the client application to the reply or callback URL with an authorization token. Fifth, the browser hands the authorization token to the client application. Sixth, the client application will send the authorization token to the authorization server, to the token endpoint, and get an access token. It will also gain a refresh token. Seventh, the application will submit the access token to the resource server. Eighth, the resource server will validate the access token and will allow the client application access to the resource. </p>
<p>With an authorization code grant, at no stage does the user give their credentials to the app. They enter their credentials into a server they know and trust. The other benefit of this flow is the access token does not pass through the browser, which makes it harder to be compromised. </p>
<p>Next, we are going to set up the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/oauth-prerequisites/">AAD applications and delegated permissions</a> that are required to implement this.</p>
<h1 id="OAuth-Prerequisites"><a href="#OAuth-Prerequisites" class="headerlink" title="OAuth Prerequisites"></a>OAuth Prerequisites</h1><p>This demo will be focused on setting up the prerequisites, which are critical to creating the configuration items for our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/what-is-oauth/">OAUTH</a> and making sure we have everything we need to set up the configuration. We’ll be creating two applications in Azure ID, and we will be setting this OAUTH token flow request up into Postman. </p>
<p>So the first thing we need to do is gather some information. Here is our cyber labs domain, we can see the name, there, Cyber Labs on microsoft.com, and it’s also helpful to grab sometimes the directory ID. So if you’ve got a properties, you can see the directory ID here. I’ve recorded this information in my notepad, so we have the My Cyber Labs and the Tenant ID. </p>
<p>Next we wanna create the applications. And it’s important to note here that you need to use the application registrations, not DV-2 application registrations, which are currently in preview. So if we’ve got APP registrations and we create a new application registration. We gonna call this API back end, and for the sign on URL, we want to use for now just a HTTPS on our local host. So we’ll create that and click okay. </p>
<p>Now we wanna record the application ID, so we can click this copy button here, and take that to our notepad, and turn here and we need to create the next application. So new application again, API front end, and for the sign on URL here, we want to use the API’s developer portal. If we click copy here, and return to our application creation, with forward slash sign in. And if we wanna look, I’ve recorded that information here as well, dot sign in. And click okay for create. </p>
<p>We also want to grab this application ID, so that’s API front end, and we wanna put that in our API front end text.</p>
<p>The next thing we’re going to do is create a secret key, that we’re going to use in the front end application to allow us to communicate and exchange the authorization token, to get an access token. We need to go to the settings and go to keys. Here we have no keys. So we’re gonna call this secret. And duration never expires and save. Now you’ll only get to see this value once. So it’s important that you do copy it. This is a secure key and it’s important that you keep it secret. In this case for this demo, we’re just gonna save it on this text file. We have now created the two applications. </p>
<p>The last step is we need to grant the appropriate permissions on the front end application. So under here under required permissions, we need to select the required permissions and add, select an API and we wanna grant the access to the API back end APP which is here. So we select that and we wanna say this application is allowed to access the API back end. We select okay and done. And that has added that delegated permission to this front end application. Something we can use the preview APP registrations for is getting the end points. So if we go over here and select API, we can see a API front end, and if we select in points, we can see all our OAUTH in points. There’s a V two and a V one, currently the API management service only works with the V one end points. So you’ll notice that the URL is slightly different. So in this case we wanna copy the OAUTH two authorization end point version one, and OAUTH two token end point version one. Also copying the open ID connect metadata document, would be useful later. So I’ve copied all these into this document here. </p>
<p>The next step is we wanna configure Postman to utilize all these end points in this application. If we bring up the postman application and go to authorization, under type, select OAUTH two. And we wanna add the authorization to request status, and we need to get the access token. So get new access token. We can see here, this form is blank, we gonna go through and give this a name. We’ll call this our token, the code <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/oauth-grants/">grant</a>, we can see the different types here. We had this mentioned earlier, we want to add a callback URL, as we’re using this in Postman, the callback URL will be postman. So this is copied into this callback URL, paste that in, the authorization URL we’re trying to authorize at our end point, which is the Tenant for Cyber Labs and we’re wanna authorize a particular resource which happens to be our back end application. That’s where we wanna actually get access to. We look at this is the fully constructed URL. So if you can see we’ve got the login from <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a>, the tenant ID, OAUTH and authorize, and after that we do a question mark, resource equals and then the ID of our back end APP. So we’ve already constructed that. I’m gonna copy that and put it under the authorization URL. </p>
<p>Next, we wanna go to the access token URL. So this comes from the OAUTH two V one token end point, copy that and let’s paste that in. And we wanna use the client ID and client key from the front end application. So the front end application had this ID here, and we want the secret for that application, which is here. Paste that in, and let’s try get that authentication token. Now you can see here, I’m currently logged in as mat at cyber labs, which is the administrator for this Azure ID domain and we’ve been given the option to authorize API front end, to access back end up, and sign it and read your profile. So this is what we talked about originally, with the OAUTH flow, and we can see in particular the permissions that does want to access. So we gonna accept that, and we can see the reply URL does not match what’s configured. So when we configured the application, we didn’t add the URL for Postman. So that’s fair that that won’t respond. So in this case, we can close this down, we can see there’s the callback URL we want to allow. So let’s copy that and return to our Azure ID applications, Azure ID application registrations, and we wanna look for API front end under labs. </p>
<p>In the front end app we wanna change the settings and the reply URL. So we can see we enabled the cloud demo portal sign in page, but we haven’t allowed Postman. So if we add the Postman URL to this, we can then save that information. Let’s return to Postman and try to request token again, refresh request, and here we have a token. So we can see we’ve got an APP token, and the token information, what type is it bare, is a bunch of information. We also have the refresh token, so that’s great. </p>
<p>So to review what we’ve done, in the Azure ID, we’ve set up two API applications, a front end and a back end application, we’ve created a secret key on the front end application and we’ve delegated permission to access the back end APP. We’ve also captured the end points for that, and put that information into Postman, which has allowed us to now get a new token from that end point. We also approved access for the API APP to access My Data from the Cyber Labs domain.</p>
<h1 id="Front-and-Back-Channels"><a href="#Front-and-Back-Channels" class="headerlink" title="Front and Back Channels"></a>Front and Back Channels</h1><p>You might be wondering the reason we <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/oauth-prerequisites/">create two applications</a>. Let’s look at the OAuth diagram again. When talking about OAuth, there is the concept of front channel and back channel. The front channel could be a browser on a user’s computer. A browser is very good at interacting with users. For example, presenting the user with a login screen and asking for user approvals. However, we don’t control the browser, and we can’t trust it with sensitive information. The back channel is considered servers or code we control or, more importantly, we can trust with sensitive information. </p>
<p>This is why we get an access token in two phases. First, we get an authorization token through the browser or front channel. We can then exchange this <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/oauth-grants/">authorization token</a> over the back channel using the client ID and secret we have already configured. OAuth utilizes the best things about the front channel and the best things about the back channel in order to obtain the access token or bearer token securely.</p>
<h1 id="Registering-the-Client-Application"><a href="#Registering-the-Client-Application" class="headerlink" title="Registering the Client Application"></a>Registering the Client Application</h1><p>Before a client application can present a token to an authorization server to gain access to privileged information on behalf of a user that application must be registered with an authentication server. To do this the application owner must provide a name, a callback or reply URL to represent the application. We can use this information in Azure AD to create a registered application. When we create the application we get a Client ID which is a public and unique identifier and we create a Client Secret. We give this Client ID and Client Secret back to the client application. With this combination, Azure AD knows who is sending the request and has a list of valid reply URLs stored for that application and will direct the OAuth request to the requested URL as long as it is valid. We saw this earlier with Postman when we tried to get an access token, the request failed because Postman’s callback URL was not on the list of valid reply URLs stored with the Azure AD application.</p>
<h1 id="Decoding-the-Token"><a href="#Decoding-the-Token" class="headerlink" title="Decoding the Token"></a>Decoding the Token</h1><p>Tokens are encoded data, and if we decode that data, we can see that a token is made up of a header, a payload, and a signature. Decoding the data we retrieved from Postman can help us validate we have set up the AAD applications and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/what-is-oauth/">OAuth</a> and Postman correctly. </p>
<p>We can use jwt.io to decode the token and take a look at the payload. If you’d like to do this yourself, copy the token out of Postman, go to jwt.io, and paste it into the encoded field. And you can take a look at the payload yourself. In this case, we can see in the image the aud is the audience for this token, which is the back end application. And we can see the app which is in the application requesting the token is the ID of the front end application. Using this tool, we can see we have validated that our application and OAuth flow are configured correctly. Next, let’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/configuring-oauth-authentication-service/">configure this in our APIM service</a>.</p>
<h1 id="Configuring-OAuth-Authentication-Service"><a href="#Configuring-OAuth-Authentication-Service" class="headerlink" title="Configuring OAuth Authentication Service"></a>Configuring OAuth Authentication Service</h1><p>For our example we’re going to be using OAuth 2.0, so let’s configure the appropriate endpoints. Under the management API service we go to security, OAuth 2.0, and we can see there’s no results here, we click add. I’ve already pre-populated this page here so we’re just going to talk through what the results are. So we have the CyberLabs for a display name. We have a client registration URL. I’ve just made up this URL. The type of grant is the authorization code. The authorization endpoint is the same authorization endpoint we used in Postman. </p>
<p>So if we go back to our document here, we can see that this was the code we used. The next piece of information we need is the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/decoding-the-token/">token</a> URL, again, this is the same as we’ve already used and the token endpoint is here. If we keep scrolling down we can see we need the client credentials, front-end client ID, and the secret. Which we can see here is that same secret key that we’ve put in the text file. And if we click create, we can see that OAuth service is added. </p>
<p>The next step is to use this auth service with our API. So let’s go to the APIs, Demo Conference, and we look at the settings for the Demo Conference API. If we scroll down, we can see security. So let’s select OAuth and we will get a list of all the configured OAuth 2.0 servers. So we’ve only got one, that’s fine, we’ll click save. We’ve now connected this API to the OAuth server. </p>
<p>Next step is we wanna try and view this authorization code. What we’re going to do is launch an incognito browser just so that we make sure we end up with the correct user. I’m gonna go log into portal.azure, and I’m going to use a user that I’ve already configured in the Azure AD. Which is in the onmicrosoft and keep Jessica signed in, yes. So now we’re signed in as a user in the CyberLabs domain. And we want to take the developer portal and log in here. So I’m gonna use my other user. This would probably be Jessica as well, but this is the way we’ve set it up for now. And if we go to the Demo Conference API, and let’s go to the GetSessions, and click try it. </p>
<p>We can see now we’ve got the subscription key, it’s already picked up the primary subscription. But we have a CyberLabs authorization. So if I select authorization code, we’re getting a request here from CyberLabs for the app API to get access to the backend app and read the profile. So we’re gonna accept that. And what we can see here is expected, this is saying that again, the reply URL isn’t valid. </p>
<p>So I wanted to show you a way you can grab this information to try and understand what it’s doing. If you select this header here to Notepad, we’ll just do a quick replace here to help make this readable. 3a becomes a colon and the percent 2f becomes a forward slash. </p>
<p>We can now see that this application is looking for a redirect to cloud portal docs authorize callback. So this is the URL now that we need to authorize again against our application. We go to Reply URLs, we’ve already got it loaded. Paste that in there and save. cloud portal demo docs CyberLabs console, which is the complete URL for us to get to this developer portal. So let’s just give this a hard refresh. </p>
<p>Let’s go to the get authorization token again, and we can see that Bearer Token’s come through. So if we just show that token, let’s just validate what we’ve got there. Copy that token, we’ll go to the JWT.io. And we’ll paste that into our debugger, and we can see we’ve got the backend application, the front-end application, and we’re logged in as Jessica. Oh if we try and execute our request, we’re getting the response 200 back, which is great. Successfully set up the OAuth server. We have successfully connected that OAuth server to our API, collected an authorization code through the browser. </p>
<p>Let’s just try this through Postman, see what we get. So if we put this in, now we don’t have any token here, but we’ve still got the data back. So what we actually need to do is apply a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/api-policies/">policy to check for valid token</a>, which we will do in the next section.</p>
<h1 id="API-Policies"><a href="#API-Policies" class="headerlink" title="API Policies"></a>API Policies</h1><p>A key strength of APIM is that it allows you to apply policies to change the behavior of the API. The policies can be applied on different attributes, like the subscription or data types returned and much more. The policies allow publishers to control or manipulate the requests or the various data at different stages. This screenshot is from the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> Portal and shows us where we can add policies. The Frontend, Inbound, Backend, or Outbound again. </p>
<p>The policy definition is a simple XML document that describes the order that the policies are executed in. This policy can be added directly in the Azure Portal. The portal offers a range of code snippets that you can add to each area to perform a range of functions to a request. Here we can see the XML document with the inbound, backend, outbound, and on-error sections.</p>
<p>Some examples of policies are securing your API by requiring an OAuth token, converting XML to JSON or JSON to XML, rate limiting the number of requests based on the specific subscription, or simply changing header values and callback URLs. Many of these policies can be applied through the UI experience by filling in the form and applying the policy in the right area. You can also code these policies by hand. The solution is very extensible. </p>
<p>Policies can be configured at different levels. You can set an API policy globally or at the scope of a product, a specific API, or individual operation. Before creating a policy, you should decide at what level you want to apply the policy. Policy scopes are evaluated in the following order: Global scope, which is all APIs, product scopes, like starter, API scope, which is like the Demo Conference API or all operations, and operation scope, which is an individual operation. </p>
<p>The statements within the policies are evaluated according to the placement of the base element if it is present. Global policy has no parent and using the base has no effect. We will take a look at what tools we can use to help us understand effective policies and troubleshooting policies during execution.</p>
<h1 id="Adding-API-Policies"><a href="#Adding-API-Policies" class="headerlink" title="Adding API Policies"></a>Adding API Policies</h1><p>Let’s look at configuring <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/api-policies/">policies</a> against the API requests. First thing let’s look for an existing policy. So as we’ve said we’ve got different scopes. If we go to the products and we go to starter, we can see those are policies listed here. We can see there’s an inbound policy which limits the number of calls and renewal period. If we go to Postman and we just run this one, two, three, four, five, this time should fail and indeed it does. So we see the rate is limited, try again in 54 seconds with the 429 request and 47 seconds. So that’s counting down for us. That was an easy way for us to see how this policy has been applied to our particular subscription. </p>
<p>Next thing we do is we want to look at perhaps changing some other policies, maybe an outbound policy. So let’s go back here and look at the API and we want to change the Demo Conference API. This is specific to this API. We want to change all operations, and we want to add some outbound processing. We’re going to try to use the UI here to change some headers. We’ve got the outbound policy and we want to choose set header. So let’s go find a header to change. </p>
<p>If we rerun this request here, and look at our headers, let’s say we don’t want anyone to know what the version of AspNet is. So let’s grab that, there. And we want to delete it. We also want to delete the powered by ASP NET. Add header, delete, delete, and save. Cannot have values, sometimes these get populated with a value. You just need to delete it. If we go and write our query again that’s already saved, we can see those headers have disappeared. So that was very easy to manipulate or control the data coming back from the API. </p>
<p>Let’s say we want to try something a little different. We want to go and edit this policy manually. So rather than choosing this we can choose this button here, choose expand, and we want to do a find and replace. We want to basically replace all the URL CORS that reference this conference API website and send them back to our website. If we scroll down here we can see all the different types of policies we have. In our case we wanna do the find and replace string. So what do we want to find? We want to find anything that says conference, API, azurewebsites, and we want to replace it with our URL. We’ll click save.</p>
<p>So if we go and run the Postman call again, we can see that’s now changed. So we’ve applied two policies, three policies, to the outbound processing of the API request and we’ve applied this to all operations. So let’s say we want to change one particular operation. If we go to get sessions and we want to add a new policy, you can see here we can choose other policies. We want to add an outbound policy here and we’re going to look for JSON TO XML. So we’d like to convert the JSON output to XML for this particular function. So if we click save and go to Postman, let’s try to run that again. </p>
<p>We’re still getting back the JSON version of the code. If you wanted to troubleshoot this, there’s a method for doing that. If we go over to the test, select get sessions, and send the query, we can then click the trace button here. So as much as we’ve got this response, we want to know why that policy hasn’t applied. So we can see the total response time, and we have different sections we can jump to.</p>
<p>So let’s look at the outbound section. The reason that we can see that here, is the content type. It’s not applied. We can see the other policies that we did apply worked. All we need to do in this case is go to the design for that item, and we’re going to change these two values to false, and save. Now if we try this operation and test, click send, we will look at the trace again and we’re hoping to see that the JSON to XML has been applied. Outbound, and we can see that it was set to XML which is exactly what we want. We can validate this by resending the request, and we can see we’ve got a different style of return. </p>
<p>If we save this query, and let’s duplicate it. We’re going to call this one speakers. Change the COR there to speakers. We can see we’re getting JSON from the speakers still, and we’re getting XML from sessions. Effectively applied policy at different levels to manipulate the API request in different ways. The very next thing we want to do is apply the policy to look for the correct token. We’ve seen that we can validate the token, but we’re not applying that to our session. </p>
<p>So again on the Demo Conference API, all operations, I would like to add a new policy. We’re going to go into the code editor for this one and expand. On the inbound policy I would like to validate the JWT token. We need to delete some of this code. We’re going to delete the issuers, audience, the claim, the particular claim we’re going to match as audience and the audience value is the backend application. In the token it will decode it, and we’re looking for this value. We’re going to call this auth, and let’s just change the message here so we know that it’s us, and we need the endpoint that we’re going to validate that token against. We captured this earlier from Microsoft here. </p>
<p>Now there’s only one problem with the endpoint that we got, and that’s it’s version two. We just need to remove the version two and you may also know that you can swap out these values here. If it wants to be more readable, instead of the tenant ID, you can put in your cyberlab’s name there. So let’s grab this openid connect inpoint for validation and put it in here. Don’t forget to leave the html closed, and save. </p>
<p>Now we’ve applied a lot of policies here and we’re maybe not sure exactly what order they’re happening in. What we can do is calculate effective policy. If we choose a particular product, you can see the effective policy view. Here we can see the rate call limited, which was on the product. Different versions are there. If we go and check this against the sessions and we edit this one we should see that particular policy for the JSON to XML call as well. So there’s our oauth, check, jwt token, check, the rate limit, and outbound policy. We’re doing the final replace JSON to XML and removing the headers, so this helps you view all the different policies in one place. </p>
<p>Now let’s test if our policies worked. We’ll try the developer portal first. Jessica let’s give it a refresh. We’re in the get sessions authorization code. Let’s have a look at the token just to make sure we’ve got the right user. So we have Jessica@mycyberlabs, and we’re going for the backend application. Let’s click send. We get a 200 response okay. So we’ve successfully applied that validation code there. If we turn auth off we get the authorization failure, you are not allowed in. Which is good. </p>
<p>Let’s go to the Postman application, and we’ve got our speakers and sessions. We’re gonna say get new access token. We’re gonna call this Jessica, and request a token. Let’s grab this token and prove that we are Jessica, no slight of hand going on. Jessica@cyberlabs on <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a> and our audience is the backend application. </p>
<p>If we go back to Postman, we can then choose the token Jessica and preview the header. We’ve then added this token to this header here and we click send so we get a result. Let’s take this to the sessions header. We’re gonna send as well. You’re not allowed in. So make sure we’ve got the latest Jessica token and send, and we get our result. So if we were to remove this token from the header, and send, you are not allowed in. So we’ve successfully secured our API with a validation policy and we’ve tested that and validated that token for that user works. </p>
<p>This concludes the course, and the demos. I hope you’ve found this useful. I’ve tried to include steps here that help with troubleshooting. The oauth token flow is definitely difficult and without some of these tools it’s difficult to troubleshoot.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/introduction/">Azure API Management</a> provides a rich set of features to manage, control, and publish your content. During this presentation, we have published our own API using an existing API from Microsoft. We have focused on using <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/what-is-oauth/">OAuth</a> as a method to protect your API. Using Postman has allowed us to set up and consume this service external to the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> portal tooling. And finally, we used Azure API policies to manipulate responses. </p>
<p>There are many other areas worth investigating, from using your own custom domains, using revisions and a Git repository to version and control the release of API functionality, using application insights to help track and troubleshoot performance, also creating alerts. I hope you found this content useful and it helps you create and consume your own APIs.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32/" class="post-title-link" itemprop="url">AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 11:52:52 / Modified: 11:52:54" itemprop="dateCreated datePublished" datetime="2022-11-14T11:52:52-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Designing-for-Azure-Operations-31/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Designing-for-Azure-Operations-31/" class="post-title-link" itemprop="url">AZ-204-Designing-for-Azure-Operations-31</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:51:25" itemprop="dateCreated datePublished" datetime="2022-11-14T11:51:25-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 09:48:10" itemprop="dateModified" datetime="2022-11-15T09:48:10-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Designing-for-Azure-Operations-31/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Designing-for-Azure-Operations-31/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Greetings! Welcome to Design for Azure Operations with Cloud Academy! I am delighted to have you join me on what is bound to be an educational and delightful adventure into the world of Microsoft Azure.</p>
<p>First I will let you know a bit about myself before I get into the course outline. My name is Jonathan. I am one of the course developers with Cloud Academy. I work professionally as a technical consultant specializing in DevOps, data engineering, and security. Long ago in another life I was a public school teacher, so I love educating people and I am thrilled to be doing it again only now with technology.</p>
<p>So enough about me, let’s get into this course. Who is this course for exactly? This course is for anyone looking to improve their infrastructure engineering abilities with Microsoft Azure. If you are a DevOps engineer, sysadmin, or security specialist and plan to work with Microsoft Azure at your next job, then this course will be very helpful to you.</p>
<p>So what exactly are the prerequisites for this course then - what do I expect you to know in order to understand the material? Well, not much actually. This is not a programming intensive subject. You do not need any deep knowledge of computer science or software development. The course will focus mostly on explaining Microsoft Azure systems and how to use the Azure user interface. You should know some basic concepts, like what a virtual machine is, or what software application logs are. You should also know some basic networking concepts, like SSL and TCP. If these sort of rudimentary cloud and software concepts are new to you, then you probably don’t need this course anyway.</p>
<p>The course will cover a lot of information given its short length. We are going to go into detail on a number of Azure services and practices. You will learn all about Azure monitoring and automation systems - the kinds of things DevOps engineers would need to worry about in their day to day work. We are going to talk about log aggregation, software application instrumentation, and network security.</p>
<p>There are three core learning objectives for this course. Number one is learning how to use Azure for application monitoring. Number two is how monitor Azure resources and infrastructure. Number three finally, is about task automation in Azure, including instance autoscaling. If you finish the course with a solid understanding of these three things, you will have gotten your money’s worth.</p>
<p>Lastly I want to encourage everyone to leave feedback. Email <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a> if you have any questions, comments, suggestions, or concerns. We always appreciate people taking the time. Now without further ado, let’s get started.</p>
<h1 id="The-Big-Four-Priorities-of-Microsoft-Azure"><a href="#The-Big-Four-Priorities-of-Microsoft-Azure" class="headerlink" title="The Big Four Priorities of Microsoft Azure"></a>The Big Four Priorities of Microsoft Azure</h1><p>For section 1 of this course we have four priorities: System monitoring, application monitoring, log monitoring, and alerting. System monitoring refers to monitoring of cloud resources and hardware with a focus on things like CPU, memory, and network. Application monitoring refers to instrumentation of your own service code - anything you deploy on top of your servers. Log monitoring, as you can probably guess, is focused on analyzing logs generated by your system. Finally alerting is the process by which we automate a variety of alarms triggered by your application getting into an unhealthy state. The fourth priority, alerting, is made possible by the first three - system and application monitoring along with log analysis.</p>
<p>For system monitoring you will need to learn about the Azure Monitor service. For logging you will get acquainted with Azure Log Analytics. For application monitoring Azure offers its Application Insights service, which we will also be using for alerting in the last part of the section. So if you’re ready, we’ll get started now in the next lesson with an introduction to Azure Monitor.</p>
<h1 id="Monitoring"><a href="#Monitoring" class="headerlink" title="Monitoring"></a>Monitoring</h1><p>One of the nice things about Azure is that there are a lot of default metrics automatically reported for different services. For Azure VM’s, system level metrics are enabled by default and viewable in the dashboard. You can see a lot of these metrics right from the Azure compute interface by just clicking on the relevant VMs.</p>
<p>Azure Monitor is sort of your ‘base camp’ for metrics in Microsoft Azure. Azure Monitor, ‘provides base level infrastructure metrics and logs for most services in Microsoft Azure. The service has evolved over time, gradually subsuming more and more types of metrics from other Azure services. We are going to focus on Azure Monitor as our solution for system level monitoring.</p>
<p>In the Azure Monitor interface we can casually browse different system metrics. By default all Azure resources report basic information about network and system state. It is analogous to Amazon’s Cloudwatch. Azure Monitor is meant to be used primarily with Azure resources, however individual components can be used with non-Azure servers. For example the Application Insights component, which we will address in more detail later, can be installed on on-premise servers or virtual instances in another cloud. You could then use Azure Monitor to collect metrics about your Google Cloud or Amazon servers. This is not a very common use case though.</p>
<p>Azure also has a diagnostics extension that can be used for application performance monitoring. For this course we will be using Application Insights for this sort of monitoring, but it is cool to know that Monitor is also getting into this use case. In the future the two systems may become more tightly integrated, so it’s good to be aware of it.</p>
<p>By default Azure Monitor will store metrics for 30 days. If you need to keep metrics for longer than that you will need to store them somewhere. You can easily import metrics into Azure storage by using the console. If you wish to store metric data elsewhere, you can also export everything to some other system.</p>
<p>Now that we have a good understanding of Azure Monitor’s capabilities and how to get started, our next priority is looking at log aggregation. In the next lesson we’ll talk about Azure Log Analytics and learn how it can be your one-stop shop for logs. Let’s get to it.</p>
<h1 id="Log-Analytics"><a href="#Log-Analytics" class="headerlink" title="Log Analytics"></a>Log Analytics</h1><p>Having application and system level metrics is a minimum requirement for a proper monitoring system. However log aggregation is a similarly important but often overlooked part of an overall monitoring strategy. Many companies do not even think about proper log management until some disaster comes along and they find they cannot properly identify the root of the problem. Being able to collect and quickly analyze large numbers of logs is extremely helpful for any forensic investigation.</p>
<p>Companies spend large amounts of money and development on solutions like Splunk or ELK. With Azure, you get a baked in solution with Azure Log Analytics. It gives you an easy way to search a variety of types of event logs and has simple quickstart guides for Linux, Windows, and Azure VM server types.</p>
<p>The setup for Azure VM’s is easiest. All you will have to do is enable to log analytics extension from the console. With just a few clicks you can immediately start collecting event data for analysis. For Linux and Windows servers you will need to obtain a set of credentials - specifically a workspace ID and key. These will be used to set up the log analytics agent that will run on your server. The actual agent installation is pretty straightforward. You can do it with a few terminal commands in Linux. For Windows, you can download the agent from Azure directly and set it up with a few clicks on the relevant server. In both cases, you will need to configure the agent with the workspace ID and key so that the log data is sent to your Azure portal.</p>
<p>From the Log Analytics portal you will do most of your setup using the ‘Advanced Settings’ tab. There you can type in the name of the relevant logs to set as event logs. You can enable OS performance data for Linux or Windows with a separate option and configure severity levels WARN and ERROR for isolating potentially serious events. Once you are done with configuration, you can freely search and view log data by clicking on ‘Log Search.’ There you can type in any arbitrary pattern and find matches among all of your events.</p>
<p>One final cool feature to note about Azure Log Analytics is the ecosystem of additional plugins, known as ‘management solutions’ that you can add to your workspace. Management solutions are additional data acquisition rules and visualizations that let you really customize your log analysis needs to your specific use case. There are dozens of them available. Just to name a few examples, there is a management solution specifically for container monitoring, a solution for tracking specific events in your activity log, and a solution for automated real-time server mapping and graphing. If you want to really get the most out of your log data then it is definitely worth your time to browse these additional features for Azure Log Analytics.</p>
<p>In the alerting section we will discuss how to use Log Analytics for automatically catching dangerous conditions in your system. For now, you should have a basic understanding of how to set up Log Analytics and use it for investigating your systems. Next, we move on to application monitoring with Application Insights. See you there.</p>
<h1 id="App-Monitoring"><a href="#App-Monitoring" class="headerlink" title="App Monitoring"></a>App Monitoring</h1><p>Now that we have a solid understanding of log analysis and system monitoring in Azure, we can proceed to the final and most critical component of our instrumentation: Application monitoring. This is a deeper level of monitoring that goes beyond just tracking the state of the hardware. When we talk about application monitoring, we really mean monitoring everything we actually put into our infrastructure - all of our own unique business logic, internally developed software, and external libraries.</p>
<p>The general way to do this is to use a monitoring library with your code. There are many such libraries as frameworks for different languages, such as dropwizard metrics or ERMA for Java. Application Insights is similar in that you will need to add it to your code base before you can start getting metrics. Like many such frameworks the library is pretty lightweight and should not cause much performance overhead. Tracking calls are non-blocking, batched, and sent in a separate thread.</p>
<p>Application Insights can be used to monitor applications running <em>anywhere</em>. You can use it to monitor applications hosted in another provider like AWS or Digital Ocean. You can use it to monitor applications hosted on premise or even on your personal computer. All that Azure needs is for your application to have the Insights library installed and sending metrics to an endpoint in Azure.</p>
<p>Now, the Azure Portal has some great quickstart guides for a few languages including Java, Node.js, and .Net. It starts by having you create the Application Insights resource in the portal. You will need to set an app name, a region, an application type (usually just the language or framework name), and a resource group name, which is just the name for the resource actually hosting the metric data.</p>
<p>Once you have the Application Insights resource defined, step two is installing the library in your app. The quickstart guide shows how to do this very quickly using an IDE like Eclipse. It can also be done manually if you carefully follow the Azure documentation. There are some useful code examples that show how to actually get your application code to send data.</p>
<p>Once you have solid application and system monitoring in place, you need to make use of all that data. You need to empower your systems to send you actionable alerts when metrics suggest that something is wrong. In the next lesson we will discuss how to create meaningful alerts using application and system metrics.</p>
<h1 id="App-Alerting"><a href="#App-Alerting" class="headerlink" title="App Alerting"></a>App Alerting</h1><p>A key principle with alerting is ensuring that alerts are actionable and relevant. If you set up a large number of irrelevant alerts that fire constantly, you will train your team to ignore all alerts. Maintaining a good signal to noise ratio is critical with alerts that may require human intervention. It is similarly important that you try to make sure all alerts are actionable. This is not always possible - sometimes you may have to configure an alert for a situation that is not easily resolved. To the extent possible, you want to try to have documented responses to alerts so that the majority of your alerts are actionable.</p>
<p>For system level alerts - things like low disk space or high cpu load - we can use Azure Monitor. In the Azure Monitor portal we can configure notifications to fire when specific metric thresholds are met. From the monitoring dashboard click on the ‘Add metric alert’ button and create a name for your alert. You will then pick a relevant metric and set a condition such as ‘greater than’ or ‘less than’ some specific value.</p>
<p>You also will have to set a time period for the condition such as ‘5 minutes’. This would mean that the alert condition must be sustained for five minutes in order for the alert to trigger. It is crucial to think very carefully about the time period parameter. Configuring it incorrectly can lead to false positives or false negatives. For example, let’s say we set an alert for CPU load. We set it to alert whenever load is above 2.0 for more than 3 minutes. This may be too sensitive, as perhaps your application regularly has short periods of high load that are expected. In such case the alert would just end up being noise and training your response team to not take alerts seriously.</p>
<p>For Azure metric alerts be sure to add the right email address under the ‘Additional administrator email(s)’ section. This way you can ensure that the right people are notified when an alert is triggered.</p>
<p>Application Insights alerts are similarly easy to set up for your application performance metrics. From the Insights dashboard just click on ‘Alerts’ and then ‘Add alert’ to get the setup menu. From there you will define the alert rules in much the same way as we did with system metrics. You will pick a metric, a time period, a threshold, and a condition. You can set contact emails or a webhook address if you wish to integrate your Insights alerts with another system.</p>
<p>Finally it is possible to set up alerts based on queries run by Azure Log Analytics. From the Analytics dashboard you can create the alert rules by defining a time window and query. If the query returns the expected result within the time window, and alert can be generated. This can be used for example to catch serious ERROR messages that were output to an event log within some time frame.</p>
<p>And that about wraps it up for alerting using Azure Monitor and Application Insights. As we have seen, we can create a variety of alerts based on system metrics and application performance stats. Keep in mind the importance of minimizing noise with your alerts - make sure that when an alert is triggered it really means something. With this in mind, let’s move on to the next major section of course.</p>
<h1 id="Network-Security-and-Access-Management-with-Azure"><a href="#Network-Security-and-Access-Management-with-Azure" class="headerlink" title="Network Security and Access Management with Azure"></a>Network Security and Access Management with Azure</h1><p>Now that we have a solid understanding of application monitoring and alerting with Azure, we need to think about how to properly monitor Azure resources at a higher level. While Azure Monitor is a pretty flexible system for getting basic metrics about Azure VM’s, we need to think about how to monitor other Azure components. We also need to think about Azure network security and access management.</p>
<p>Section two will address these priorities in three parts. In part one, we’ll look at how to actually monitor all of the different Azure components using Azure Health, Azure Advisor, and the Activity Log. In part two we will focus on network security the Network Watcher Service and Azure Log Analytics. Finally in part three take a detailed look at the Azure Security Center and see how it can help ensure our Azure infrastructure is not compromised.</p>
<p>So without further ado, let’s begin.</p>
<h1 id="Monitoring-Platform-Resources"><a href="#Monitoring-Platform-Resources" class="headerlink" title="Monitoring Platform Resources"></a>Monitoring Platform Resources</h1><p>Out first monitoring priority is just tracking the health of Azure itself. Azure Health is your first line of defense for identifying problems with Azure platform resources. It is the most high level view of your cloud system and is generally the best place to start if you are experiencing problems and have no other leads.</p>
<p>Azure Health offers three basic levels of information about your infrastructure. At the highest level is Azure Status, which is simply a dashboard with information about the health of all of Azure’s different components. This information is not specific to your account; rather it will tell you if there is a global issue with a particular Azure service, such as virtual machines or storage. A quick check of the Azure Status dashboard is the fastest way to rule provider level problems when debugging failures.</p>
<p>The next level is Azure Service Health. It is similar to Azure Status but focused only on Azure resources in your account. Like Azure Status it is a dashboard only this one is customizable. You can arrange elements to focus on specific Azure products and regions.  Also like Azure Status, it will give you a general health check for each product category and inform you of issues that need your attention. Azure Service Health will notify you of planned maintenance that may affect your system. It will also warn you if you are approaching a resource quota or if a feature you use is about to become deprecated. After a quick check of the Azure Status dashboard, Azure Service Health is often the next best place to quickly examine when you are in the middle of responding to some kind of system failure.</p>
<p>Finally you have Azure Resource Health, the most granular level of inspection in the Azure Health suite. With Azure Resource Health you can get the status of specific instances of Azure resources, such as a single VM. It will let you know if a given resource is unavailable and it keeps a very useful log of platform events. You can see if an Azure platform SLA was violated at any point. With its very simple status messages and historical data, Azure Resource Health is the simplest way to monitor individual resources from the Azure platform’s perspective.</p>
<p>The Azure Health set of services gives us a lot of information to track our system’s health over time. However we often need to more than just data; we need some analysis and a more granular view of system events. To address these two issues we will use Azure Advisor and Azure Activity Log respectively.</p>
<p>Azure Advisor, as the name implies, is a personalized cloud consultant. It automatically examines all of your Azure resources and identifies ways to optimize them. It will spit out tons of recommendations automatically focusing on security, availability, performance, and cost. The nice thing about Advisor is that it’s really simple to use. Literally all you do is click “Advisor” in the left pane menu and you’ll get a summary of recommendations. You can then drill down to one of the four categories I just mentioned. So for example, you might get a cost recommendation telling you to scale down your storage provisioning if you are not actually using much of it.</p>
<p>So Azure Health has given us copious amounts of information about our system and Advisor continually helps us optimize. The final component is tracking system changes over time. For this we have Azure Activity Log.</p>
<p>Azure Activity Log is a subscription log that records events using event data from Azure Resource Manager. It records eight specific types of events: Administrative, Service Health, Security, Alert, Autoscale, Recommendation, Policy, and Resource Health.</p>
<p>Now, Azure Activity Log is accessible from a wide range of tools. You can get event data from the console, Powershell, CLI tools, and the Azure Monitor REST API. You can do a lot of useful things aside from just viewing system event data in the dashboard. You can store the data offline and query it programmatically with scripts. You can set alerts against specific types of event. You can also stream Activity Log data to external event hubs such as a third party analytics tool or monitoring system.</p>
<p>Activity Log is a very flexible tool and is very simple to use. That said, it is important to understand its limitations. It is not a replacement for proper application logging and monitoring. Activity Log is primarily concerned with Azure Resource Manager events. Some of the older “classic” type resources will not by default send events to Activity Log. You will need proxy resource providers to make the operations appear in Activity Log.</p>
<p>So now we are at the end of our dive into platform resource monitoring. You should have a basic understanding now of how Azure can monitor its own assets, track events over time, and automatically help us use resources most efficiently. So next we move onto all of that space in between our Azure resources: the network. In the next lesson we will learn how to properly monitor our network infrastructure in Azure.</p>
<p>Let’s get to it.</p>
<h1 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h1><p>We have spent a good deal of time covering how to monitor the physical infrastructure of our system. We have covered application level monitoring and Azure resources from the smallest levels up to the entire set of Azure datacenters. Our priority now is to fill in the gaps - to track what happens in between all of those resources at the network level. Our main tool to accomplish this will be the Azure Network Watcher service. We will also revisit Azure Log Analytics as it plays a role here too.</p>
<p>Network Watcher is a comprehensive network topology monitoring and analytics solution. It is comprised of several features. A full list is presented here in the slides. I will not dive deeply into every single one so it is a good idea to pause the lesson and read through each description. I will cover three of the more important Network Watcher tools so that you know how to handle basic network level monitoring.</p>
<p>It starts with the Topology app. This gives you a network level view showing the various interconnections between network resources within a given resource group. This will be your go-to tool when you need to get a clear picture of your network infrastructure.</p>
<p>Next up is the Variable Packet Capture tool. This lets you capture packets flowing in and out of virtual machines, much as you might do with tcpdump or wireshark. You can filter the capture tool to set size and time constraints and then store the packets in the Azure blob store or on the VM disk. This is a really useful surgical tool for analyzing very low level network events.</p>
<p>Thirdly there is the Next Hop tool. This is a personal favorite because it can identify unexpected behavior. Basically it just determines the next hop for packets routed in the Azure Network Fabric. It is great for identifying problems with user-defined routes.</p>
<p>There are eight other great tools to look at in Network Watcher. It’s worth giving a quick mention to the NSG Flow Logging, Security Group View, and IP Flow Verify tools, all of which are really great for identifying where exactly packets are permitted to go and not go. Again, be sure to take a deeper look at the documentation to learn about the other Network Watcher tools.</p>
<p>Azure Log Analytics adds a few useful supplemental feature  to your overall network monitoring system. They are activated through the Log Analytics UI and so need to be addressed separately. Most are just additional levels of instrumentation. For example there are the DNS Analytics and Traffic Analytics components. The former is for DNS administrators and aggregates DNS logs. The latter is for aggregating and visualizing public internet traffic against Azure systems.</p>
<p>Two larger pieces of the Log Analytics network monitoring feature set, are the Network Performance Monitor and the Application Gateway analytics solution. We’ll start with the Network Performance Monitor. At a high level, all it is meant to do is track performance between various parts of your infrastructure. The power comes from the versatility and the web interface. Network Performance Monitor can track loss and latency across  various subnets and set alerts. It can track connectivity between user locations, multiple data centers, on-premise locations, and other endpoints, all while visualizing everything in an intuitive UI.</p>
<p>The Application Gateway analytics solution will provide you with an additional level of network logging, specifically firewall logs, performance logs, and access logs for application gateways. It is quick to set up too. Simply enable the Azure Application Gateway analytics solution from Azure Marketplace and then enable diagnostics logging for the desired application gateways.</p>
<p>Whew! So this was pretty thorough. As you can see, Azure gives you A LOT of tools for monitoring your network infrastructure. If you are the type that likes to be able to audit every single packet, then Azure is going to be a lot of fun for you.</p>
<p>Our final priority in this section is going to be security. We have covered in depth how to track everything that happens in our system both in transit and at rest, so now we need to think about how to harden the system from threats. We’ll dive in in the next lesson. See you there space cowboy!</p>
<h1 id="Securing"><a href="#Securing" class="headerlink" title="Securing"></a>Securing</h1><p>Properly securing your cloud infrastructure is a multi-faceted effort. It includes a lot more than just using the tools provided by your hosting solution. It takes employee training, secure coding practices, properly maintained facilities, regular auditing, and a number of other important practices. That said, Microsoft Azure does of good job of simplifying the task of securing its own resources. Thanks to the Azure Security Center service you have one full-featured centralized solution for hardening your entire Azure infrastructure.</p>
<p>Security Center is automatically included with your Azure account at no additional charge. By default it can only be used with your Azure systems. If you upgrade from the free tier to the ‘standard’ tier, you can have Security Center work with non-Azure resources in a sort of hybrid infrastructure model. The upgraded ‘standard’ tier also adds a number of useful features not available to the free tier. These include advanced threat detection systems for Azure systems, customizable alerting, security event collection and search, and a threat intelligence module.</p>
<p>Security Center’s core functionality, available in both the free and standard tiers, is its security policy system. Security policies let you defined the configuration of your workloads such that they satisfy specific company or regulatory security requirements. When you access the Security Center UI you will discover that there are default policies for all Azure subscriptions. These policies include recommendations that can be turned on or off. A good place to start looking is at your computer resources. On the Security Center dashboard, click ‘Overview,’ and then select ‘Computer.’ It will display a color-coded list of recommendations for your entire computer infrastructure.</p>
<p>The security policy and recommendation services are the bulk of what the free tier of Azure Security Center does. It might seem simple, but it is actually quite powerful, particularly if you are <em>only</em> using Azure for your cloud environment. You get tons of free recommendations and a central location for auditing and adjusting security policies to suit company compliance requirements. When combined with all of the other monitoring, event logging, and alerting systems in Azure that we have already covered, you have all the tools you need to maintain a hardened, transparent, self-optimizing infrastructure.</p>
<p>We strongly recommend digging into the Security Center documentation to learn about some of the additional features at the standard tier. In particular VM access management and customizable alert systems can be very helpful for complex cloud systems. One cool thing is you can actually use the standard tier with all of its additional features completely free for 60 days. It’s a great way to see if you actually need any of its advanced capabilities.</p>
<p>So with that, we come to the end of section two. We have thoroughly covered platform monitoring, network monitoring, and security for your Azure systems. Congratulations on making it this far. You’re ready to really do some great operational work for any Azure environment now. Our final section will focus on operation automation. See you there!</p>
<h1 id="Automation-Overview"><a href="#Automation-Overview" class="headerlink" title="Automation Overview"></a>Automation Overview</h1><p>This is a very broad topic that could easily be its own course. For our purposes we will focus on Azure-specific technologies and introduce a few third-party tools that integrate well with the platform.</p>
<p>We will again divide our subject into three parts. We will start by just introducing the relevant automation technologies, namely, Chef, Puppet, PowerShell, Desired State Configuration, Event Grid, and Azure Logic Apps. The next two sections will be about using these technologies to address the challenges mentioned above: Autoscaling, and task automation. By the end of this unit you should have a solid understanding of how to automate operations in Azure.</p>
<p>So without further ado, let’s get started.</p>
<h1 id="Automation-Technologies"><a href="#Automation-Technologies" class="headerlink" title="Automation Technologies"></a>Automation Technologies</h1><p>When it comes to automation with Azure we have a lot of different options. The three basic categories are Azure web console tools, PowerShell scripts with Azure SDK, or a third party tool like Chef. Which approach we take will be a function of our expertise and the nature of the work we want to automate.</p>
<p>We will start by focusing on Azure’s built-in tool set. Azure Automation is comprised of two core pieces: Runbooks and Configurations, both built on top of PowerShell. Before you do anything you will need to set up an Azure Automation  account in the UI. Once done you are ready to start writing PowerShell runbooks and PowerShell Desired State Configurations (DSC). A runbook is a simply a collection of scripts. These scripts use the Azure SDK API to execute changes to your Azure system. It takes some programming knowledge to use it properly. The upside is that Powershell is far more flexible than simply using the web gui.</p>
<p>Desired State Configurations are special methods within PowerShell that let you predefine a configuration state for your servers. For example you can enforce that specific ports are open or that only a specific set of software is installed. DSC greatly simplifies the process of writing scripts by letting you work from the end state. The Azure documentation and console make it very easy for non-programmers to generate and import basic PowerShell DSC scripts in their Azure Automation account. It lets you define a specific end state for your Azure systems and let Azure do the work of getting things there. Be warned that DSC Configurations sometimes do tasks in a manner or order you don’t expect. If you have very delicate requirements regarding how and when things change in your system it may be better to write more explicit PowerShell code instead of relying on DSC.</p>
<p>Azure also has a service for intelligent event routing. It is called Azure Event Grid and it lets you automate responses to relevant events across both Azure and non-Azure services. Event Grid uses a publish-subscribe model and is configurable in the portal or by using Azure CLI or Powershell scripts. To use Event Grid you need to create an event subscription. This is done by selecting ‘Add Event Grid subscription’ to the relevant app in the Azure portal. The Azure documentation includes a number of handy examples of how you can make use of this. In one it shows how you can use Event Grid to automatically resize images uploaded to your Azure storage. It can be done in minutes and save you a great deal of time and money that would be spent on manually fixing images.</p>
<p>Let’s turn our attention to some non-Azure tools. Chef and Puppet are two cloud infrastructure automation tools. Both have open source offerings that have integrations with not only Azure, but other providers like Google Cloud and AWS. Chef and Puppet have different names for their different pieces. For example in Chef, modules are described as ‘cookbooks’ with scripts called ‘recipes.’ In Puppet these things are called ‘manifests’ and ‘modules.’ One thing to note is that both are fairly complex tools. If your automation needs are very simple, then it is likely not a great idea to try to set up Chef or Puppet; better to just stick with Azure’s built-in tools such as PowerShell with DSC or Event Grid.</p>
<p>So we he have discussed Chef, Puppet, Powershell with DSC, Runbooks, and Event Grid. As you can see, we have a lot of options when it comes to automating work in Azure. In our next lesson we will focus in on a specific use case: autoscaling. Let’s get started.</p>
<h1 id="Autoscaling"><a href="#Autoscaling" class="headerlink" title="Autoscaling"></a>Autoscaling</h1><p>Azure has multiple systems for automatically scaling computer resources. Our focus will be on horizontal scaling - namely, adding additional compute resources instead of trying to switch to a larger instance.</p>
<p>The simplest approach with Azure is to use Azure Monitor’s built-in autoscale feature. This lets you automatically scale up and down compute resources based on metrics.</p>
<p>Azure VM’s also have a concept known as ‘Scale Sets.’ A Scale Set is simply a group of VM’s that can be given autoscaling rules. They are similar to AWS autoscale groups and make for a handy way to organize and think about your VM’s in terms of large groups instead of individual machines. Scale Sets can also be configured through Azure Service Fabric. Each node type in a Service Fabric cluster can be a separate VM scale set, thus allowing each node type to scale up or down independently.</p>
<p>Azure autoscaling is also available for the Azure App Service. Autoscaling is actually built right in as an app-level setting. It will allow you to scale based on a designated metric. You select a value and also use a slider to set your maximum and minimum number of instances. Similarly, Azure Cloud Services have a setting for autoscaling. The difference here is that scaling is based on number of cores being used. Depending on your subscription you may have a limit for a maximum number of cores for autoscaling. You can set this up in the portal by clicking on the scale tab in the portal and setting it to ‘automatic.’</p>
<p>Finally, probably the most bleeding-edge approach to autoscaling, would be to cut out VM’s and containers entirely and just use Azure Functions. If you can adopt a serverless paradigm wherein your app logic is defined using Azure Functions, then you won’t need to think about autoscaling at all. The Azure platform automatically allocates computer resources as necessary to any code running as an Azure Function in your account.</p>
<p>We won’t focus much on non-Azure autoscaling systems. I’ll instead just take a quick second to remind you that such systems exist. Kubernetes, for example, has support for horizontal scaling of ‘pods’ based on metrics. You can also integrate your configuration management tools like Chef with your monitoring to create autoscaling logic.</p>
<p>So now that we have a good understanding of what autoscaling looks like in Azure, it is time to broaden our automation scope. In the next lesson we will discuss how to automate arbitrary tasks in Azure using a variety of different approaches. See you there.</p>
<h1 id="Task-Automation"><a href="#Task-Automation" class="headerlink" title="Task Automation"></a>Task Automation</h1><p>Azure is very flexible when it comes to arbitrary task automation. In this short lesson we will introduce a few common maintenance tasks and explain how we can fully automate the work using different tools.</p>
<p>As we have seen in earlier lessons, Azure integrates well with management tools such as Chef and Puppet. If, for example, you are already very comfortable with Chef, then it trivial to automate any task defined in your Chef code on subsets of your servers. There is an easy to use cron Chef cookbook that lets you define cronjobs. One common use-case is to automate the chef-client run itself to run every few minutes. This ensures that configuration changes are automatically propagated quickly.</p>
<p>Another common need is automated resource deletion and re-creation. For example a business may want to save money by not running Azure VM’s during non-work hours. Automating this safely requires ensuring you have a reliable way of preserving the environment’s state and then recreating and deleting resources easily. This is do-able using Chef and Puppet if you have your infrastructure well-defined in your config management code. A perhaps easier approach, however, is to use a runbook with a Powershell Workflow.</p>
<p>As mentioned in the previous lesson, runbooks are just collections of Powershell scripts. An Azure Powershell Workflow uses runbooks to execute a series of tasks. Workflows add a number of useful features to your Runbooks. For one, they can be scheduled, and they can include automated failure recovery and retry logic. Workflows can help automate many simple maintenance tasks. For example, you can create workflows that save your environment state every day at 8 pm and then delete unneeded resources. Then you can have another workflow that executes a runbook to recreate everything the next day at 8 am. This would cut your Azure hourly costs in half.</p>
<p>You might need several different scripts to do all of the work of snapshotting your environment, deleting everything safely, and then recreating everything in the right order with proper tests to ensure environment health. You could combine the scripts into multiple runbooks and multiple workflows.</p>
<p>Powershell workflows are great for people comfortable writing scripts. For people that prefer to focus on GUI tools, Azure has its Logic Apps system. Azure Logic Apps let you automate and schedule workflows. Logic Apps are similar to Powershell scripts in that they can include conditional statements, switches, loops, and branches. All of this is definable in the GUI, so if you have ever done any coding using a GUI you will have a sense of what to expect.  You can define a logic app in the Azure portal. You will have to define a resource group to let the logic app know what Azure components it will access, and then you define a schedule trigger, which lets you set the exact time interval for when to execute the app.</p>
<p>So that’s basically all you need to know about task automation in Azure. You have your third party services like Chef and Puppet. These integrate well so if you’re familiar with them you can continue to lean on them with Azure. If you prefer writing scripts perhaps because you like checking them into version control and being more transparent, Powershell works great with Azure runbooks and workflows. If you are not as confident about writing scripts, you’ve got Azure Logic Apps, and that will let you automate pretty much anything involving Azure resources.</p>
<p>So keep those core three approaches in mind and congrats on making it through this final section of the course. We will finish up with a final course summary in the next lesson. See you there.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Congratulations on completing the Microsoft Azure Design for Operations course. For a relatively short course there is a lot of material crammed in here, and you made it through, so kudos. We covered a lot of ground.</p>
<p>We started by talking about application monitoring and alerting. We learned how to thoroughly instrument applications using Azure Application Insights and we learned how to aggregate log data using Azure Log Analytics. We explored the numerous features in the Azure Monitor system.</p>
<p>We then learned all about how to monitor the Azure platform itself. We went over how to use Azure Status and Azure Health to quickly assess the state of both our own Azure resources and the wider Azure platform. We learned about how to optimize our resource usage with Azure Advisor. We covered how to use the Activity Log for forensic investigations and resource tracking. We also covered the Azure Network Watcher service and Azure Security Center to handle network and platform security respectively.</p>
<p>Finally we did a deep dive on Azure automation. We learned how to autoscale resources using Azure Autoscale, and we learned how to automate various tasks by using Powershell and Runbooks. We also reviewed configuration management technologies like Chef and Puppet to see how they integrate with our Azure systems.</p>
<p>By combining all of this knowledge we have a skill set for thoroughly modernizing our cloud infrastructure. We can instrument, monitor, configure, automate, and secure our Azure systems as well as a professional DevOps engineer. That’s pretty darn cool for a class like this. Of course remember that practice makes perfect. We have described a lot of technology in this course. It is up to you to actually play around with things in Azure and develop some intuition.</p>
<p>Now that you are done I’d like to invite you to send any feedback you have about the course to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. We greatly appreciate your comments, questions, and suggestions. Congratulations again on fighting through the whole course and good luck in your future endeavors.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30/" class="post-title-link" itemprop="url">AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:49:44" itemprop="dateCreated datePublished" datetime="2022-11-14T11:49:44-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 09:38:44" itemprop="dateModified" datetime="2022-11-15T09:38:44-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>- [Thomas] Welcome to Integrating Redis Cache and CDN on Azure. My name is Thomas Mitchell and I’ll be taking you through this course on key caching and content delivery concepts. I’m an Azure content author at Cloud Academy and I have over 25 years of deep IT experience, several of those with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn or send an email to <a href="mailto:&#x73;&#117;&#112;&#x70;&#x6f;&#x72;&#x74;&#x40;&#x63;&#108;&#x6f;&#117;&#100;&#97;&#x63;&#x61;&#100;&#101;&#109;&#x79;&#46;&#99;&#x6f;&#x6d;">&#x73;&#117;&#112;&#x70;&#x6f;&#x72;&#x74;&#x40;&#x63;&#108;&#x6f;&#117;&#100;&#97;&#x63;&#x61;&#100;&#101;&#109;&#x79;&#46;&#99;&#x6f;&#x6d;</a>. </p>
<p>This course is intended for IT professionals who are interested in earning Azure certification and those who need to incorporate Redis Cache or CDN with their solutions. To get the most from this course, you should have at least a moderate understanding of what caching is and why it’s used. We’ll kick off the course with an overview Redis Cache, and then we’ll create a Redis Cache instance in Azure. With Redis Cache deployed in Azure, we’ll then connect an application to the cache. Next, we’ll walk through the process of storing and retrieving data in Redis Cache. After covering Redis Cache, we’ll walk through an overview of what CDN is and what it’s used for. We’ll then develop some code for leveraging CDN. As we wrap up the course, we’ll cover the process for invalidating date in both Redis Cache and in a CDN. </p>
<p>By the end of this course, you should have a good understanding of what Redis Cache and what CDN are and what purposes they serve. You’ll also know how to connect to each from applications and how to purge or invalidate data in both. We’d love to get your feedback on this course, so please give it a rating when you’re finished. </p>
<p>If you’re ready to start learning about integrating Redis Cache and CDN on Azure, let’s get started!</p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>- [Instructor] Azure Cache for Redis is usually used to improve performance and scalability of systems and applications that rely on back end data-stores. Leveraging Redis cache improves performance by temporarily copying frequently accessed data to fast storage that’s located close to the application that’s being run. Azure Cache for Redis provides the storage and memory instead of loading data from disc via a database. </p>
<p>In addition to providing caching services, Azure Cache for Redis can also be used for other purposes. For example, it can be used as an in-memory data structure store or even a distributed non-relational database. By taking advantage of the Redis engines high throughput and low latency, application performance is improved. </p>
<p>Leveraging Azure Cache for Redis provides organizations with access to a cache that’s managed by Microsoft. Because it’s hosted in Azure, Azure Cache for Redis is accessible to all applications, whether they reside within Azure or outside of it. </p>
<p>There are several typical patterns where Azure Cache for Redis comes in handy for supporting application architecture or to improve application performance. </p>
<p>Common patterns include things such as cache-aside, content caching, user session caching, job and message queuing and distributed transactions. </p>
<p>Because databases can be quite large, they should never be loaded in their entirety into a cache. That said, a common strategy would be to use the cache-aside pattern to load data items into the cache only as needed. When the back end data is updated by the system, the cache can also be updated. Such updates are then distributed with other clients. Through expiration settings or by using an eviction policy, the system can cause data updates to be reloaded into the cache. </p>
<p>Because most web pages are generated from templates that contain static headers, footers, toolbars, et cetera, they don’t change all that often, as such, generating them dynamically isn’t recommended. By using an in-memory cache like Azure Cache for Redis, you can speed up access to web content by providing your web servers with quicker access to this type of static content when compared to back end data-stores. The content caching pattern reduces processing time and server load that would otherwise be necessary to generate content dynamically. What this does, is allow web servers to be more responsive. As such, this results in the ability to actually reduce the number of servers that are needed to handle similar loads. Azure Cache for Redis provides the Redis output cache provider to help support this pattern with asp.net. </p>
<p>User session caching is typically used with shopping carts. It’s also used in other applications that deal with user-history types of information that make use of cookies. Because storing too much in a cookie can negatively affect performance, you can instead use the cookie as a key to query the data that’s stored in a back end database. Using Azure Cache for Redis to associate information with a user is far faster than interacting with a full relational database. </p>
<p>Any time an application receives a request, there’s a chance that the operations that are associated with that request, might take additional time to execute. A common way to deal with these types of longer running operations is to add them to a queue, which is then processed later and maybe even by a different server altogether. This type of deferment strategy is called task queuing and Azure Cache for Redis serves this purpose well by acting as a distributed queue. </p>
<p>An application will often need to be able to execute multiple commands against a back end data-store in a single operation. If all commands don’t succeed, then they must all be rolled back to the initial state. </p>
<p>Azure Cache for Redis provides support for executing a batch of commands in a single operation. It does so in the form of transactions. Azure Cache for Redis is available in three different tiers. These tiers include basic, standard and premium. The basic tier offers a single node cache. It supports multiple memory sizes from 250 megabytes all the way up to 53 gigabytes. </p>
<p>The basic tier is a good fit for development environments, testing and non-critical workloads. It’s important to note that the basic tier offers no service-level agreement. The standard tier offers a replicated cache in a two-node, or primary, secondary configuration that’s managed by Microsoft. </p>
<p>The standard tier offers a high-availability SLA of 99.99% or four nines. </p>
<p>The premium tier is enterprise ready. Caches in the premium tier offer more features, higher throughputs, and lower latencies than standard or basic. Premier tier caches are deployed on more powerful hardware than the other tiers, which in turn obviously offers better performance than basic or standard. </p>
<p>It’s important to note that a cache can be scaled to a higher tier after it’s already been created, but it can’t be scaled down to a lower tier. So with that in mind, when you’re deploying a cache make sure that you don’t over-provision, because if you do, you may find yourself in a spot where you can’t go backwards. It’s always better to slightly under-provision and then scale higher if necessary.</p>
<h1 id="Create-a-Redis-Cache-Instance"><a href="#Create-a-Redis-Cache-Instance" class="headerlink" title="Create a Redis Cache Instance"></a>Create a Redis Cache Instance</h1><p>- [Instructor] In this demonstration, we’re going to create an Azure Cache for Redis on Azure. To do so, I’ve logged in to my Azure portal, as you can see on your screen. </p>
<p>To create our Azure Cache for Redis, I browse over to the left pane and click Create a resource. From here, I can browse to Databases, and then, in the list of featured services, I can scroll down to Redis Cache and select it. I need to provide a globally unique name for my Redis Cache. Now, basically, what that means is the name that I give my cache needs to be unique across the entire Azure landscape. So, I’ll call it myredis9878. The green check box tells me that my name is valid. Then, of course, I need to select a subscription, so I’ll select the Microsoft Azure Sponsorship subscription that I have, and then, I need to specify a resource group. </p>
<p>I don’t have an existing resource group, so I’ll create a new one. And I’ll just call it Redis and okay it. I typically deploy my resources in the east region, so I’ll go East US, and for this demonstration, I’m going to select the basic pricing tier. </p>
<p>Now, if I click on View full pricing details, I can see all of the different options that are available to me for my Redis Cache pricing. If we scroll back up here, we can see Premium. We scroll down, we see the standard. And then, at the bottom, we can see our basic tiers. I’m using the C0 Basic tier. You can see further down here that some features or options, I should say, are not available because I’m not using a premium tier. </p>
<p>So, now, what I’ll do is I’ll create my cache, and this can sometimes take a few minutes to complete. We can see up here we get the Deployment in progress status. And what I’ll do is I’ll switch over to my resource group here, and if I select my cache here, we can see that the status is creating. This status will change to running once it’s completed. </p>
<p>We’ll refresh it here. And we can see it’s still creating. And while we’re waiting for this to create, what I’m going to do is switch over to my dashboard and create a new one for my Redis Cache lab here. And then, I’ll switch back to my resource group, and then, I’ll pin my Redis to my dashboard here. And if we select my cache, we can see it’s still creating. And let’s give it one more refresh. </p>
<p>So, we can see now that our cache is in the running state. So, in the next demonstration, we’re going to retrieve our access keys and connect a Python app to our cache.</p>
<h1 id="Installing-Redis-PY"><a href="#Installing-Redis-PY" class="headerlink" title="Installing Redis PY"></a>Installing Redis PY</h1><p>- [Narrator] In this lesson, we’re going to create a Python application and connect it to our Redis cache. However, before doing so we need to install redis-py, which is a Python interface to the Azure cache for Redis. I’m goin to install redis-py through Microsoft Visual Studio, which you see on your screen. To perform the installation I simply click on tools and then Python. From here I go to Python Environments. In my packages search I can search for Redis. In my list of commands that are returned I can see install redis here installs redis-py. So we’ll go ahead and click this command, and we need to run it in an elevated prompt, so we’ll go ahead and elevate it, and you can see on the bottom here that it was successfully installed. In the next demonstration we will test the read and write access to our cache from Python.</p>
<h1 id="Test-Read-and-Write"><a href="#Test-Read-and-Write" class="headerlink" title="Test Read and Write"></a>Test Read and Write</h1><p>- [Instructor] What we are going to do in this demonstration is connect to our Redis cache via Python through an interactive window in Microsoft Visual Studio. Once we connect to our cache, we are going to use the set command to store some data in the cache and then use the get command to pull that data out and display it. It’s a basic demonstration, but it shows how to connect to the ready cache and how to store and retrieve data. </p>
<p>Before connection to our cache, we need to import the readis-py package. And what I am going to do is copy and paste some of these commands and explain them as we go. </p>
<p>So on the screen we have my Python interactive window open and what I am going to do is paste in this import command and essentially what this does is pull in that ready cache package, so we can use it to connect to our ready cache. We’ll hit enter here, doesn’t give us any feed back, but it doesn’t give us an error either. So we know we are good. </p>
<p>And what we are going to do here is connect to our cache. So this is the connection string we are going to use to connect to our cache. We are storing this in a variable. You can see here that we have to specify the complete host name for our cache. And this is our host name that we give it when we deployed it earlier on. We need to specify the port we are going to connect over. And sixty-three eighty, by the way, is the default port number. The Db equals zero command here tells us that we are connecting to the zero data base. Remember, there are sixteen databases that comprise the data cache. So we are just specifying which database we are working with. The password here that we are specifying is actually the access key that we copy from our cache after we deployed it in Azure. And then lastly, we are just telling the command that we are going to use SSL to connect. </p>
<p>So with this command we hit enter and again there is no real feedback to tell us anything. What we are going to do now is perform a set command to store some data in the cache. So essentially performing this set against our variable. And we are put in some data in our cache and we can hit enter. So finally, we get some feedback true tell us that our storage set was successful. So now, what I am going to do here is to perform a get against our variable to pull the data back out. And on the screen here we can see that the get was successful. </p>
<p>What we will do on our next demonstration is create an actual Python script that goes out and communicates with our ready cache.</p>
<h1 id="Test-Read-and-Write-Access-to-Cache"><a href="#Test-Read-and-Write-Access-to-Cache" class="headerlink" title="Test Read and Write Access to Cache"></a>Test Read and Write Access to Cache</h1><p>- What we’re going to do here is create a basic Python script or application in Visual Studio. What this script is going to do is connect to the cache, set a message into the cache, and then retrieve it and display it. </p>
<p>To create our new project in Visual Studio, you can go up here and click file and then new project. We’re going to select a Python application and we’ll call it my Python app. We’ll leave it in the default location and what this does is open an editor window. Now what I’m going to do is I’m going to copy some of the lines for this code into the window rather than just type everything out. Essentially what we’re going to do is import the redis and then we’re going to set two variables. The redis host name and the access key. The host name is the FQDN of the cache that we configured in Azure and the access key is the access key to access it. </p>
<p>What we’ll do is we’ll open a connection to the cache we’ll ping it to confirm it’s accessible and then we’ll set a message, confirm that the message was set and then we’ll access and display that message. I’m going to start here by importing redis and then I’m going to pull in my two variables the redis host name is the FQDN of my cache and the access key is the key to access that cache. What I’m going to do now is open up the connection to the cache on port 6380 and then what I’m going to here is ping the cache we’ll do the ping store it in result and then print the result so we can see it. What we’ll then do is set a message in our cache we’re essentially setting a string here in a message that says hi Tom. </p>
<p>Python can access the cache and then what we’re going to do is we’ll print that result out and then what we’ll do here I have one more command or two more commands I wanna paste in here and after we’ve set that message, what we’re going to do is retrieve that message and display it. </p>
<p>So what this simple little Python script does is verify that we can connect to the cache that we can ping the cache, that we can set data to the cache, and that we can retrieve data from the cache. So to run our little test Python application here, we can simply click debug and then start without debugging. And the basic feedback we get is that the ping returns a true statement so we were in fact able to ping the cache. We were able to set the message in the cache which means we can store data in it, and then we were able to retrieve that data which is represented by the message that’s returned, Hi Tom, Python can access the cache. So we’ll hit enter to continue and exit back out. </p>
<p>So what we’ve done with 10 lines of code is confirm that we can connect to our cache and at the same time we’ve also demonstrated that we can store data in that cache as well as retrieve that data.</p>
<h1 id="Flushing-Redis-Cache"><a href="#Flushing-Redis-Cache" class="headerlink" title="Flushing Redis Cache"></a>Flushing Redis Cache</h1><p>- [Instructor] You will sometimes find yourself in a spot where you need to invalidate the data in your Redis cache. Doing so is pretty straightforward right from the Azure Portal. So, what I wanted to do in this really, really brief demonstration is show you how to open the console for the Redis cache in Azure Portal and issue a flushall command to empty out the Redis cache. On the screen here, you see that I’m in my Redis resource group and I have my Redis cache here. What I’m going to do is open my Redis cache and then click on Console. From here, I can simply flush my cache by issuing a flushall command. And that’s it. It’s a rather straightforward process that you can do right from the Azure Portal.</p>
<h1 id="Azure-CDN-Overview"><a href="#Azure-CDN-Overview" class="headerlink" title="Azure CDN Overview"></a>Azure CDN Overview</h1><p>- [Narrator] A content delivery network, which is also known as a CDN, is a network of distributed servers that’s used to more efficiently deliver content to end users. What CDNs do is store cached content on what are called edge servers that are located in specific point-of-presence locations that are near the end users who are consuming the content. What this does is minimize latency. </p>
<p>The Azure Content Delivery Network provides a global solution for organizations and developers that need to deliver high-bandwidth content to end users by caching that content on strategically-placed nodes all over the world. While a CDN is useful for delivering static content, Azure CDN can even accelerate delivery of non-cacheable, dynamic content by leveraging many different network optimizations using CDN POPs, or points of presence. </p>
<p>Using Azure CDN to deliver web content offers better performance and an improved end user experience for those who are consuming the content. This is especially true when the end users are using applications that require multiple round-trips to load that content. </p>
<p>Azure CDN also offers large scaling. What this does is allow it to better handle high loads, which is something that you would expect to see maybe during a product launch. </p>
<p>By distributing user requests and serving content directly from the edge servers, Azure CDN ensures that less traffic is actually sent to the origin server, which further improves performance and responsiveness of the origin server.</p>
<h1 id="How-Azure-CDN-Works"><a href="#How-Azure-CDN-Works" class="headerlink" title="How Azure CDN Works"></a>How Azure CDN Works</h1><p>- [Narrator] On the screen here, you can see a diagram of exactly how CDN works. Let’s put a little context behind it. In step one, User A requests a file or an asset via a URL with a special domain name. Such a domain name might be mydomain.azureedge.net. The domain name can actually be an endpoint hostname or even a custom domain. DNS then routes that request to the best performing point-of-presence, or PoP, which is often the point-of-presence that is geographically closest to the user requesting the content. </p>
<p>Now, if there are no edge servers in the point-of-presence that have the requested file in their cache, the POP, or point-of-presence, requests the file from the originating server. The originating server could be an Azure Web App, an Azure Cloud Service, an Azure Storage Account, or essentially any other publicly accessible web server. Next, the originating server returns the requested file to one of the edge servers in the PoP. The edge server in the PoP then caches the file and returns it to the original requester, which is User A in this case. The file will then remain cached on that edge server in the PoP until the time to live, or TTL, that’s specified by its HTTP headers, expires. The default TTL is seven days, unless the origin server provides a specific TTL. Other users can then request the same file by using the same URL that User A used, and can also be directed to the same PoP. If the TTL for the file hasn’t expired, the PoP edge server returns the file directly from the cache instead of going back to the originating server. What this does is result in a far faster, more responsive end user experience.</p>
<h1 id="Adding-Azure-CDN-to-an-Azure-Web-App"><a href="#Adding-Azure-CDN-to-an-Azure-Web-App" class="headerlink" title="Adding Azure CDN to an Azure Web App"></a>Adding Azure CDN to an Azure Web App</h1><p>- [Instructor] In this demonstration, we’re going to add an Azure CDN to an existing Azure web app. What we’re going to do is deploy a CDN profile in Azure, along with an endpoint for our web app. The web app that we’re going to use is a basic static HTML page that we’re going to use to demonstrate the functionality of the CDN and how to purge CDN content. </p>
<p>On the screen, you can see my dashboard for my CDNLab. We already have a basic web app deployed. It’s a static HTML page, and it’s essentially a picture of a cat, because I like cats, and a little bit of text at the bottom. The website in its starting form displays a sentence called “This is a cat!!” in red text. We’re going to use the color of this text to demonstrate how a CDN caches content from a web application. So let’s bounce back over into my dashboard here. </p>
<p>The first thing I need to do is create a CDN profile and an endpoint. So let’s go ahead and click Create a resource here, and search for CDN. We’ll deploy a CDN, and create it. And we’ll call it mycdnlabdemo. And we’ll put this in our CDNLab Resource group. And for the Pricing tier, we’re going to use the Standard Akamai. This is because we need to be able to configure custom rules later on. </p>
<p>Now to create our CDN endpoint, which points to our application, we’ll click the checkbox, and then give our CDN endpoint a name. This needs to be unique across the entire Azure landscape. So I’ll just call it mycatendpoint.azureedge.net. And what we’re going to do is specify an Origin type of Web App, since it’s a web app we’re pointing to. And we’ll browse to the Origin hostname, which is themywebapp1973, which you saw up here. So we’ll go ahead and create that CDN profile and endpoint. </p>
<p>So now that we have our CDN profile created, what we can do is browse to our CDN and see that our endpoint is running. If we click on our endpoint here, we can get the hostname. So we’ll copy this and paste it into a new tab. Now the name of our file here, our HTML page, is CDNDemo.htm. So we’ll append that to our cache. So as you can see, our CDN cache is the same as our application, our web app. So now that we’ve confirmed that our cache and our live site both match, what we’re going to do is make a change to the website itself. So to do this, I’m going to drop down into my FTP client here, which is already connected to my web app. If I open up my CDNDemo page on my live site, I can see that I’m specifying a red color for the text. We’re going to go ahead and change this to blue, and we’ll save it. </p>
<p>Now if I bounce back up to my web app itself, which is denoted by mywebapp1973.azurewebsites.net, if I refresh my page here, I now have blue text. However, if I go to my endpoint in my CDN, which is denoted by my endpoint name with an azureedge.net attached to it, and refresh, the text is still red. This is because the cache content hasn’t been updated yet. Now the CDN, in and of itself, will periodically refresh its content from the origin webpage. This is based on the TTL configuration. That being said, the default TTL is seven days. </p>
<p>So there will be times when content is updated on a website that we may wish to purge the cached content from our CDN. This is one of those cases. So what we’re going to do is purge the content from our CDN by browsing over, back into our Azure portal, and into our endpoint here. If we roll back out into our demo here, we can see our endpoint listed. What we can do is click Purge at the top here. And I’m going to purge the CDNDemo. And we’ll purge it. Now this takes a minute or so to do, but once this happens, we’ll go back up and refresh our endpoint here to see if it’s updated. So let’s bounce back up into our endpoint here and do a refresh. </p>
<p>And there you have it. So by purging the CDN cache, we’ve allowed it to recache the new content from the source website. So now you know a little bit about how to deploy your CDN profile, how to create that endpoint that references the production website, and how to purge your CDN content to ensure it pulls down the latest version of the content so that it can serve it up properly.</p>
<h1 id="Using-Query-Strings-to-Version-Content"><a href="#Using-Query-Strings-to-Version-Content" class="headerlink" title="Using Query Strings to Version Content"></a>Using Query Strings to Version Content</h1><p>- [Instructor] In this demonstration we’re going to see how the cache in an Azure CDN can be manipulated using query strings. On your screen you can see I’m in here with my CDN in Azure. On your screen here you can see I’m in my CDN. If I click on my end point that we created in our previous demonstration, I can browse over to caching rules to see what rules are set up for this end point. We can see that we have global caching rules and custom rules. What we’re going to do here in this demonstration is change the query string caching behavior. If I select this drop-down you can see there’s three options. We have ignore query strings, bypass caching for query strings and cache every unique URL. What we’re going to do here is change the default caching behavior to cache every unique URL. And then we’ll save it. While this is saving, we’ll go out to our web app and we’ll refresh here and see that our text is blue. If we go into our cache, we can also see that our text is blue. Now what I’m going to do here is copy my end point URL and open a new tab. I’ll paste this URL in, but I’ll specify a query string. So we can see here even with a query string of one we still have blue text, which makes sense, we haven’t made any changes yet. And I’ll just refresh this to make sure it gets committed to cache. And now what I’m going to do is go down into my ftp client and I’m going to edit my web app and I’ll change the color to green. So on my production web app this text is now green. So what I’ll do next is open up my end point again this time with a query of two. We can see my query two shows green text, my query one shows blue. If I refresh, I still have blue text. So what this demonstrates is how each query string is treated differently based on the fact that I have the query string caching behavior set to cache every unique URL. If we bounce back down to my editor here, and change it to black, I can then open another tab, so another query and now I get black text. So as you can see, you can control what content is cached and how, based on how you configure your caching rules, and how you access the content itself.</p>
<h1 id="Invalidating-CDN-Cache-With-a-Custom-Rule"><a href="#Invalidating-CDN-Cache-With-a-Custom-Rule" class="headerlink" title="Invalidating CDN Cache With a Custom Rule"></a>Invalidating CDN Cache With a Custom Rule</h1><p>- While we’re in here looking at caching rules for our CDN cache, let’s take a look at a custom caching rule. What we’re going to do in this demonstration is define a custom caching rule that invalidates our CDN cache after a specified amount of time. What we’re going to do in this demonstration is use a custom caching rule to set a cache duration of one second on our cdndemo.htm file. What this will do is override any cache control or expires http headers that are sent by the originating server. </p>
<p>So to create our custom caching rule, we’ll browse down here, down to the custom caching rule section. So to define our custom caching rule, we’ll go down to the bottom here where it says custom caching rules. So to create our custom caching rule, what we’re going to do is go down to the bottom here where it says custom caching rules. What we’re going to do for the match condition field is set it to path. The value we’re going to match on is our cdndemo.htm file. The caching behavior we’re going to set is override and we’re going to tell it that we want a cache duration of one second. We can go ahead and save our new rule. </p>
<p>With our new rule in place, what we’ll do is go up to our web app and we’ll refresh it. And we can see we have black text. If we switch over to our end point, we can refresh and we see we have black text. Now what I’m going to do is go into my FTP client again and I’m going to edit the text color back to red. Now if I go back up to my application and refresh, we can see I get red text. Now what I would expect in my end point is that a refresh also displays red text. This is because the custom rule down here should override the default cache expiration of seven days because I’m focused on the cdndemo.htm match. So let’s go up here and do a refresh and as you can see here, the text is in fact red. So what this demonstrates is that I can control individual caching with custom caching rules. Our custom rule here that matches on the cdndemo.htm file overrides the default caching expiration duration of seven days. And if you read closely under the custom caching rule section, Microsoft will tell you that these rules override the default settings above and that they’re evaluated from top to bottom. That being said, rules that are lower in this list can override rules that are further above it. So keep that in mind when you start creating custom caching rules.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>- [Instructor] I hope you’ve enjoyed learning about integrating Redis Cache and CDN on Azure. Let’s review what you’ve learned. </p>
<p>Early on in this course, you learned about Azure Cache for Redis and what it offers. You learned about several patterns where Azule Cache for Redis comes in handy and about different service tiers. After learning what Azure Cache for Redis is, you learned how to create a cache instance in Azure and how to access it. You then learned how to test, read, and write access to the cache and how to access the cache with a Python application via Visual Studio. We then moved on to the Azure Content Delivery Network or Azure CDN where you learned what it is, what it offers, and how it works. Later in the course, you learned how to add an Azure CDN to an Azure App Service web app and how to invalidate CDN content as well as Redis Cache content. </p>
<p>To learn more about integrating Redis Cache and CDN on Azure, you can and should read Microsoft’s published documentation. Be sure to also watch for new Microsoft Azure courses on Cloud Academy because we’re always publishing new ones. Please give this course a rating and if you have any questions or comments, please let us know. As always, thanks for watching and happy learning.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Lab-Azure-Key-Vault-and-Disk-Encryption-29/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Lab-Azure-Key-Vault-and-Disk-Encryption-29/" class="post-title-link" itemprop="url">AZ-204-Lab-Azure-Key-Vault-and-Disk-Encryption-29</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 11:44:00 / Modified: 11:44:02" itemprop="dateCreated datePublished" datetime="2022-11-14T11:44:00-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Lab-Azure-Key-Vault-and-Disk-Encryption-29/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Lab-Azure-Key-Vault-and-Disk-Encryption-29/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Designing-for-Azure-Identity-Management-28/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Designing-for-Azure-Identity-Management-28/" class="post-title-link" itemprop="url">AZ-204-Designing-for-Azure-Identity-Management-28</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:30:51" itemprop="dateCreated datePublished" datetime="2022-11-14T11:30:51-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 09:31:52" itemprop="dateModified" datetime="2022-11-15T09:31:52-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Designing-for-Azure-Identity-Management-28/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Designing-for-Azure-Identity-Management-28/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to Designing for Azure Identity Management. My name is Thomas Mitchell and I’ll be taking you through this course on the key technologies to consider when designing an identity management solution. I’m an Azure Content Author at Cloud Academy and I have over 25 years of deep IT experience, several of those with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn, or send an email to <a href="mailto:&#115;&#x75;&#112;&#x70;&#x6f;&#x72;&#x74;&#x40;&#x63;&#108;&#111;&#117;&#x64;&#x61;&#x63;&#97;&#x64;&#101;&#109;&#121;&#x2e;&#99;&#x6f;&#109;">&#115;&#x75;&#112;&#x70;&#x6f;&#x72;&#x74;&#x40;&#x63;&#108;&#111;&#117;&#x64;&#x61;&#x63;&#97;&#x64;&#101;&#109;&#121;&#x2e;&#99;&#x6f;&#109;</a>. This course is intended for IT professionals who are interested in earning Azure certification, those who wish to become Azure architects, and those who are tasked with designing an Azure identity management solution. To get the most from this course, you should have at least a moderate understanding of Microsoft Azure, and of identity management concepts. We’ll kick off the course by discussing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a> and what it offers. We will then talk a bit about hybrid identities and what purpose they serve. Next, we’ll cover Azure AD Domain Services and how to deploy this feature. </p>
<p>After covering Azure AD Domain Services, we’ll get into <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/single-sign-on-overview/">single sign-on</a>, and how to configure it for a web application. Azure MFA or multi-factor authentication is another cool feature that we will discuss. We’ll cover what it is, what it offers, and how to enable it. After covering MFA, we will get into Azure AD B2B and Azure AD B2C. These are Azure AD Business to Business and Azure AD Business to Consumer. You will learn what they are, what they offer, and how to deploy them. We’ll then move into Privileged Identity Management, otherwise known as PIM. Rounding out the course are topics on <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/self-service-password-reset/">self-service password reset</a>, self-service group management, and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/overview-of-managed-identities-for-azure-resources/">managed identities for Azure resources</a>. There are demonstrations sprinkled throughout the course. These demos will show you how to deploy and use the technologies covered. By the end of this course, you should have a good understanding of all key technologies and features as they relate to designing for Azure identity management. You should also be able to deploy each feature with an understanding of what it offers and how it fits into any identity management solution. We’d love to get your feedback on this course, so please give it a rating when you’re finished. If you’re ready to learn about Designing for Azure Identity Management, let’s get started.</p>
<h1 id="Introduction-to-Azure-AD"><a href="#Introduction-to-Azure-AD" class="headerlink" title="Introduction to Azure AD"></a>Introduction to Azure AD</h1><p>Microsoft’s Azure Active Directory is a cloud-based identity and access management service. With it, users can sign in and access external resources such as Office 365, the Azure portal, and other software as a service applications. Azure AD, of course, also allows users to access internal resources as well. Such resources include applications inside the corporate network and on the internet along with cloud applications that have been developed and deployed by your organization. Azure AD is used to control access to applications and resources according to business requirements. For example, Azure AD can be configured to require multi-factor authentication or MFA when a user needs access to important company resources. In addition, Azure AD can be used to automate user provisioning between an existing on-prem Windows server AD and corporate cloud applications like Office 365. With Azure AD, organizations have access to tools that can used to automatically help protect user identities and credentials which allows them to meet access governance requirements. Microsoft Online services like Office 365 and Microsoft Azure leverage Azure AD for sign-in and for identity protection. As such, an organization that subscribes to any of the Microsoft Online business services automatically gets at least the free version of Azure AD along with those services. </p>
<p>Adding paid services to a tenant can enhance an Azure AD implementation. Such paid services include Azure Active Directory Basic, Azure Active Directory Premium 1, and Azure Active Directory Premium 2. These Azure AD paid licenses ride on top of an existing free directory, and they can provide additional services such as self-service, security reporting, enhanced monitoring, and secure access for mobile users. One thing to note, however, is that while all of these added features can add cool functionality and security, Azure Active Directory Basic, Azure Active Directory Premium 1, and Azure Active Directory Premium 2 are not currently supported in China. The free version of Azure Active Directory offers basic user and group management functionality and on-prem directory synchronization. It also offers basic reporting and single sign-on or SSO across Office 365, Microsoft Azure, and many popular SaaS applications. In addition to the free features available in the Azure AD Free version, Azure AD Basic provides cloud-centric application access as well as group-based access management. Other features included with the Basic version include self-service password reset for cloud apps and Azure AD Application Proxy which is a feature that allows you to publish on-prem web applications using Azure AD. Azure Active Directory Premium P1 offers quite a bit more than either Free or Basic. In addition to what those versions offer, Azure AD Premium P1 offers hybrid users access to both on-prem and cloud resources. Premium P1 also supports advanced administration tasks like self-service group management, dynamic groups, and it even integrates with Microsoft Identity Manager or MIM. Microsoft Identity Manager is an advanced, on-prem identity and access management solution. </p>
<p>Azure AD Premium P1 also offers cloud write-back capabilities which are used to allow self-service password reset for your on-prem users. Azure Active Directory Premium P2 builds upon what is offered in the P1 edition by offering everything included in the Free, Basic, and P1 versions plus Azure Active Directory Identity Protection which helps provide risk-based conditional access to applications and critical company data. Azure AD Premium P2 also offers Privileged Identity Management or PIM which is useful for discovering, restricting, and monitoring administrators as well as their access to corporate resources. Privileged Identity Management also provides just-in-time access when it’s needed, meaning access to resources can be limited to only those times when it’s required and then be taken away automatically when the access is no longer needed. Other pay-as-you-go feature licenses such as Azure AD Business-to-Consumer are also available to assist with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity management</a>. Azure AD B2C as it’s called helps provide identity and access management solutions for customer-facing applications.</p>
<h1 id="Create-Directory-and-Add-Custom-Domain"><a href="#Create-Directory-and-Add-Custom-Domain" class="headerlink" title="Create Directory and Add Custom Domain"></a>Create Directory and Add Custom Domain</h1><p>To create a new directory and add a custom domain for it, log into the Azure portal. While in the portal, open <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a> and click on the create a directory link. Provide an Organization name along with the domain to use for the directory. Select a country or region and then click create. Once the directory has been provisioned, click the link to manage the new directory and sign in if required to do so. From within Azure Active Directory click custom domain names and then add your custom domain name. Provide and internet routable custom domain name and then click add domain. </p>
<p>At this point you’re provided with the option to verify the domain via either a text record or an MX record. My preference is to typically use the text record. Copy the record value and then visit your domain’s DNS management console. Create a text record and supply the value that you were provided. Save your new text record and switch back over to Azure. Click the verify button to verify the domain using the DNS record that you’ve just created. After verifying the domain, set its primary. And then click yes to confirm.</p>
<h1 id="Azure-AD-Domain-Services-Overview"><a href="#Azure-AD-Domain-Services-Overview" class="headerlink" title="Azure AD Domain Services Overview"></a>Azure AD Domain Services Overview</h1><p>Azure AD Domain Services is a Microsoft cloud-based offering that provides managed domain services, such as domain join, group policy, LDAP, and Kerberos and NTLM authentication. The domain services provided are fully compatible with traditional on-prem Active Directory and they can be deployed without any need for deployment or management of domain controllers in the cloud. Azure AD Domain Services integrates with the existing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> tenant and makes it possible for users to log in with their corporate credentials. Existing user accounts and groups can be leveraged to secure access to resources. As such, this offers a smoother transition of on-prem resources to Microsoft Azure. Companies leveraging a hybrid IT infrastructure will typically synchronize their <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity</a> information from their on-prem directories to the Azure AD tenant. As more of their on-prem applications are migrated to Azure, Azure AD Domain Services can become more useful. An important caveat to consider when deciding if Azure AD Domain services are the right solution is that password sync is mandatory for a hybrid organization to use Azure AD Domain Services. </p>
<p>This is required because users’ credentials are needed for authentication via NTLM and Kerberos in the managed domain that is provided by Azure AD Domain Services. When considering Azure AD Domain Services, keep in mind that the managed domain is actually a stand-alone domain. It is not, and I repeat, it is not an extension of the on-prem AD domain. This is a common misconception among IT professionals. Also, because the domain is managed, the IT administrator does not need to, nor can he, manage, patch, or monitor the domain controllers for the managed domain. Likewise, there is no need to manage or even monitor AD replication within the managed domain. Quite frankly, there really isn’t much for the administrator to do in the managed domain, especially since the administrator doesn’t even have Domain Admin or Enterprise Admin privileges on the managed domain.</p>
<h1 id="Deploy-Azure-AD-Domain-Services"><a href="#Deploy-Azure-AD-Domain-Services" class="headerlink" title="Deploy Azure AD Domain Services"></a>Deploy Azure AD Domain Services</h1><p>To deploy <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/azure-ad-domain-services-overview/">Azure AD Domain Services</a> log into the Azure portal. Once in the portal click on Create a Resource and then search for Domain Services. Select Azure AD Domain Services from the search results and then click Create. Provide the basic information for the domain, including the DNS name for the domain as well as the Subscription you are deploying to, along with a Resource group. You’ll also need to supply a Location. Click Okay to move onto the next step. At this point you’re prompted to create a Virtual network for the managed domain that you are setting up. Provide a name for the network along with an address space that works for your environment. You will also need to define a Subnet and a Subnet address range that you’d like to use for the managed domain. </p>
<p>The managed domain controllers and associated infrastructure that gets deployed by <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure</a> as part of the Manage Domain setup will reside on this network and on this subnet. Click Okay and then Okay again. Next you are advised that the AAD DC Administrators group has been created. This group is used to manage the domain. It’s similar to but not quite like Domain Admins in an On-Prem Active Directory Domain. Click on the group to add members to it. When you’re done adding members that need to manage the domain go back and click Okay. This synchronization step has nothing to do with Azure AD Connect or with On-Prem AD if one exists. Instead, this synchronization step is meant to sync users and groups from Azure AD into Domain Services. You have a choice of syncing all users or scoping the sync to just certain groups. In this demonstration I’m just going to sync all users and groups from Azure AD to Domain Services. Clicking Okay takes you to the next step where you can review your options. Click Okay to commence the deployment of Azure AD Domain Services. </p>
<p>The actual deployment can take the better part of an hour because it’s deploying lots of stuff in the background. It’s deploying the network infrastructure that you’ve defined as well as two managed domain controllers. It’s also setting up the managed domain itself. After enabling Azure Active Directory Domain Services you need to enable computers within the Virtual Network to connect to and consume these services. To do so you need to update the DNS Server Settings for your Virtual Network so that it points to the two IP addresses where Azure Active Directory Domain Services are available. To update the DNS Server settings for the Virtual Network hosting your Azure Active Directory Domain Services browse to the Azure portal and open up your instance of Azure AD Domain Services. The Overview tab will list a set of required configuration steps. One of those is to update the DNS Server settings for the Virtual Network. You will be presented with two different IP addresses. These are the IP addresses where Azure AD Domain Services is available. These are essentially the managed domain controllers that were stood up as part of the deployment of Azure AD Domain Services. After making a note of these IP addresses, click the Configure button and update the DNS Server settings for the Virtual Network. With Azure AD Domain Services provisioned and your DNS updated you can now move on and enable password hash synchronization using Azure AD Connect.</p>
<h1 id="A-Word-About-Personas"><a href="#A-Word-About-Personas" class="headerlink" title="A Word About Personas"></a>A Word About Personas</h1><p>Personas can be an important tool that drives adoption and business value realization. What happens quite often is that organizations deploy technology solutions without a full understanding of the users that those solutions are intended for. When this happens, the deployed solutions do not get used, and the value of those solutions goes unrealized.</p>
<p>If an organization deploys an Azure solution, but nobody uses it, the organization doesn’t realize the value – and it becomes a waste. In order to generate value from an Azure solution, an organization must determine what users should START doing or STOP doing, in order to realize the value of the solution.</p>
<p>Essentially, its user behavior change that becomes the yardstick for evaluation, adoption, and use of solutions deployed in Azure. Personas can be useful when trying to drive adoption of new Azure solutions.</p>
<p>A persona is really just a fictitious character that represents a certain user type. Personas refer to the “who” when discussing an organization. The use of personas helps organizations characterize different sets of users, and to capture details about what a typical day looks like to those users. Personas can be used to capture the pains, needs, and desired outcomes that users have as they perform their daily tasks. </p>
<p>To build personas that reflect the workforce, organizations need to communicate with end users. Organizations need to know how work currently gets done in order to deploy Azure solutions that help users get that work done. Defining personas for each user type can help organizations accomplish this. More specifically, from an Azure perspective, an organization can build personas to assist with the creation of roles. By defining different personas, the organization has better visibility into what roles are necessary – and if custom roles are needed.</p>
<p>As a result, organizations can realize more value when deploying Azure solutions, because the solutions that are deployed can then be tailored to the users for whom the solutions are intended. Management of those solutions can be streamlined via built-roles that match the defined personas, or via custom roles, when the built-in roles are not sufficient.</p>
<h1 id="Hybrid-Identities"><a href="#Hybrid-Identities" class="headerlink" title="Hybrid Identities"></a>Hybrid Identities</h1><p>As the move to the cloud gathers steam, corporations are finding themselves supporting a mixture of on-prem and cloud applications. Users obviously are finding themselves requiring access to those applications as well. This, of course, becomes a challenge to implement. The <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity</a> solutions we previously discussed are solutions that span on-prem and cloud-based capabilities. Leveraging these solutions allows an organization to create a common user identity for authentication and authorization to all resources, regardless of whether they are on-prem or in the cloud. This concept is called hybrid identity. Achieving hybrid identity requires the development of one of three authentication methods. The authentication method that is deployed is dependent on the specific scenario being addressed. The three authentication methods include Password Hash Synchronization, Pass-Through Authentication, and Federation. Password Hash Synchronization is also referred to as PHS, while Pass-Through Authentication is referred to as PTA. Federation is referred to as, well, Federation. Password hash synchronization is a sign-in method used as part of a hybrid identity solution. This is accomplished with Azure AD Connect by synchronizing a hash, of the hash, of a user’s on-prem AD password to a cloud-based <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> instance. This feature is useful for signing in to Azure AD services like Office 365 with the same password as an on-prem AD account, which reduces end-user impact. The password hash synchronization strategy reduces, to just one, the number of passwords that an organization’s users need to maintain. As such, password hash synchronization can improve user productivity and reduce helpdesk costs. Password hash synchronization, which is the most common hybrid identity solution, requires an organization to install Azure AD Connect. </p>
<p>Once Azure AD Connect is installed, directory synchronization between the on-prem Active Directory instance and the Azure Active Directory instance is configured. As part of the synchronization configuration, password hash synchronization is enabled. Azure AD Pass-through Authentication, or PTA, much like Password Hash Synchronization, allows users to sign in to both on-prem and cloud-based apps with the same password. And much like password hash synchronization, this option offers a better end user experience. However, pass-through authentication validates user passwords directly against the on-prem Active Directory, instead of using a synced password hash. A key benefit of pass-through authentication over password hash synchronization is that it affords organizations the ability to enforce their on-prem AD security and password policies, since pass-through authentication is actually leveraging the on-prem credentials. By combining Pass-through Authentication with Seamless Single Sign-On, organizations can allow users to access applications on corporate machines inside the network without the need to type in their passwords again. Azure AD Pass-through Authentication provides an improved end-user experience because it offers end users the ability to complete self-service password management tasks in the cloud. Deployment and administration are easy because Pass-Through Authentication only requires a lightweight agent to be installed on-prem. Since the agent automatically receives updates, there is no management overhead. Pass-Through Authentication offers improved security over Password Hash Synchronization because on-prem passwords are never stored in the cloud. </p>
<p>Because it works with Azure AD Conditional Access policies, including MFA, Pass-Through Authentication offers additional account protection. Another benefit of Pass-Through Authentication is the fact that the agent only makes outbound connections from the network, removing all requirements for a DMZ as part of a solution. Communication between the on-prem agent and Azure AD is secured via cert-based authentication, which adds another layer of security. Further, the certificates that are used are automatically renewed every few months by Azure AD, removing the requirement to manually maintain them. In addition to high security, Azure AD Pass-Through Authentication offers high availability by allowing the installation of additional agents on multiple on-prem servers. Federation is a bit different from the other two solutions. It is a collection of domains with an established trust, which typically includes authentication, and almost always includes authorization. In a common configuration, a federation might include multiple organizations that have established trust for shared access to a specific set of resources. Federating an on-prem environment with Azure AD allows and organization to use the federation for authentication and authorization. Federation ensures that all user authentication happens on-prem and it provides administrators with the ability to implement more rigorous levels of access control. Federation with ADFS and PingFederate is available. To protect against a failure of the ADFS infrastructure when using federation with ADFS, organizations can set up password hash synchronization, or PHS, as a backup. Doing so allows authentication to continue, despite an ADFS infrastructure failure. All three of these authentication methods including PHS, PTA, and Federation provide single-sign on capabilities, which automatically signs users in when they are on their corporate devices inside the corporate network.</p>
<h1 id="DEMO-Managing-Users-Groups-and-Devices-in-Azure-AD"><a href="#DEMO-Managing-Users-Groups-and-Devices-in-Azure-AD" class="headerlink" title="DEMO: Managing Users, Groups, and Devices in Azure AD"></a>DEMO: Managing Users, Groups, and Devices in Azure AD</h1><p>Hello and welcome back! In this brief demonstration, I just wanted to walk you through the process of managing users and groups within Azure Active Directory. Now on the screen here, you can see I’m logged into my Azure Portal for the directory called Test9878.org. This is the custom domain I’m using for my Azure AD here.</p>
<p>Now to get to this screen from Azure, what I’ll do here is I’ll bounce back out to my homepage and here’s the homepage. To get into Azure AD, I can simply select Azure Active Directory from the top here, or I can go to the hamburger and select Azure Active Directory.</p>
<p>So from this overview page, I can browse to lots of different pieces of Azure AD. Under the manage section is where I’ll manage my users and groups along with devices, app registrations, all of this fun stuff where you’ll do your day to day management of your Azure Active Directory. Down the bottom is where you’ll perform your monitoring. And then down at the very bottom, you’ll do your troubleshooting and support.</p>
<p>So from this page, let’s go ahead and create a user in Azure Active Directory. And to do that, it’s pretty straight forward. We simply select users here. And from this screen, we can see all of the existing users in our AD.</p>
<p>We can see, we have two accounts here. One is an admin in the actual Azure Active Directory as shown here under source. The ThomasMitchell.net account is actually an external Azure Active Directory account from another directory.</p>
<p>What we’re going to do here is create a new user and we’ll just call this Dave. And in this dropdown we can select the actual domain name we want to use, we’re using the custom domain, so we’ll leave it at Test9878.org and we’ll give our username. And then we have the option to auto-generate a password or create one, we’ll leave the auto-generate here. And this will show us what the password is.</p>
<p>We can then provide that password to the new user. I would not send this out via any kind of electronic methods when possible. That’s obviously a security risk. As we create our user, we can then select a group to add our user to. So we’ll go ahead and make him a user within our box users group.</p>
<p>This is actually a group I created earlier for some other demonstration. So we’ll go ahead and we’ll select him. So now what we’re doing here is creating our <a href="mailto:&#x44;&#97;&#118;&#101;&#x40;&#84;&#x65;&#x73;&#x74;&#x39;&#x38;&#x37;&#x38;&#46;&#x6f;&#x72;&#103;">&#x44;&#97;&#118;&#101;&#x40;&#84;&#x65;&#x73;&#x74;&#x39;&#x38;&#x37;&#x38;&#46;&#x6f;&#x72;&#103;</a>, we’re auto generating a password and we’re placing this new user in the box users group.</p>
<p>The block sign in is pretty self explanatory. We can either block sign in by selecting yes or allow sign-ins by leaving the no option selected here. And then we have some additional info we can add. We can add a job title in a department.</p>
<p>We can also specify the usage location. So we’ll go ahead and we’ll select United States down here. And we’ll go ahead and create the user. And at this point, we now have a new user in our directory. If we select our user from our list, we can then look at the user’s profile, which includes his identity, his job information, any kind of special settings, contact info. This is where we manage this information as far as the profile goes.</p>
<p>We can then go into assigned roles where we can actually look at any roles that have been assigned to this user. And we can add assignments. You can see all of the different directory roles here that are included by default.</p>
<p>Now we can also see, we can assign custom roles, but if you look at the little icon up here, it tells us that if we want to assign custom roles to a user, the organization needs Azure AD Premium P1 or P2. I’m using the free Azure edition right now. But if he wanted to make, you know, Dave an application administrator, we simply check the box and add the role. And now we can see under assigned roles for Dave, we have application administrator, and of course the description tells us what an application administrator can do.</p>
<p>If we want to remove this assignment for this user, we select the assignment and remove it. Now, if we go back out to our directory, let’s take a look at groups and how we can manage groups here. By selecting groups, we can look at what groups are currently defined within our Azure AD.</p>
<p>If we want to create a new group, we simply select a new group and we can choose whether it’s a security group or an office 365 group. We’ll leave this at security and we’ll just call this marketing. And we’ll give it a description. We can see, we currently have no owners or members defined for this group.</p>
<p>So we’ll go ahead and select an owner. We’ll just make myself an owner here. And then we’ll add a new member. Let’s go ahead and add Dave. And then we create it. So now we have a new group called marketing. It’s a security group and the membership type here is assigned, which means we’re going to manually add and remove users from this group. So we’ll go ahead and select marketing here. And from here, we can look at the different properties of this group.</p>
<p>We can see when it was created, the membership type, whether it’s a cloud sourced group and what type of group it is. We can see the different direct members and any kind of group memberships. We look at properties here. We can see here, we have the name and we can actually change it here. And the description, and then members and owners will tell us who the members are and who the owners are.</p>
<p>If we select group memberships here, we can see that the marketing group is not a member of any other groups. So this is where you could see group nesting. Now in this applications area, we can see what applications are assigned to our group. So if we have a group of users that needs access to a specific application, we can create that group, assign the application to that group, and then add users to that group.</p>
<p>Any users that get added to that group are the ones that will get access to the application. Same thing with licensing. We can assign licenses to specific groups. So whatever users get added to that group also get those licenses. And same thing for Azure roleassignments.</p>
<p>So that’s the quick and dirty on how to create users and groups and how to manage them through the Azure Portal for Azure Active Directory. And before we run away here, let’s just take a look at devices.</p>
<p>Now, this devices page is where you manage any devices that are joined to your Azure AD. We can see here, I have a workstation that has been joined. And if I select that workstation, I can take a look at its device ID, its object ID, and all kinds of information about this specific device. I can then even disable the device so it’s no longer able to access Azure AD. We’re not going to do that here, but we will bounce back to our directory.</p>
<p>Now from this Azure Active Directory overview page, you can also manage password resets, manage Azure AD connect. You can take a look at the provisioning status. You can manage your custom domain names, even managed company branding. So there’s a lot you can do from your Azure Active Directory page here. And this is where all of your management will happen.</p>
<p>All of your users, all of your groups, all of your devices, all of your branding, all of your domains, all this stuff is done right here from this Azure Active Directory page. So I really recommend that you go in and you play around in here and kind of learn what you can do and do some experimentation because you really want to try to get some stick time to get a real good understanding of all of the different features in Azure Active Directory.</p>
<h1 id="Deploy-Azure-AD-Connect"><a href="#Deploy-Azure-AD-Connect" class="headerlink" title="Deploy Azure AD Connect"></a>Deploy Azure AD Connect</h1><p>In this demonstration, we’re going to deploy Azure AD Connect so we can sync our on-prem active directory users to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a>. We are also going to need to ensure that we synchronize NTLM and Kerberos credential hashes to Azure AD, since this isn’t done by default. To get started, login to the server that will run Azure AD Connect and download the Azure AD Connect software. Launch the Azure AD Connect installer that you downloaded. Because our lab environment in a single forest with an internet routable domain name, we can use the express option. </p>
<p>When prompted, we’ll connect to Azure AD by providing our global admin <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">credentials</a>. And then, we can then connect to the on-prem AD by providing an enterprise admin credential. Clicking install begins the setup of Azure AD Connect. When the installation completes, click Exit. Because Azure AD Connect does not by default synchronize NTLM and Kerberos credential hashes to Azure AD, we must ensure that these hashes get synchronized if we want to use Azure AD Domain Services. To enable synchronization of the required credential hashes from your on-premises directory to the Azure AD tenant, run the script that you see on your screen:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$adConnector = &quot;&lt;CASE SENSITIVE AD DS CONNECTOR NAME&gt;&quot;</span><br><span class="line">$azureadConnector = &quot;&lt;CASE SENSITIVE AZURE AD CONNECTOR NAME&gt;&quot;</span><br><span class="line">Import-Module -Name &quot;C:\Program Files\Microsoft Azure AD Sync\Bin\ADSync&quot;</span><br><span class="line">$c = Get-ADSyncConnector -Name $adConnector</span><br><span class="line">$p = New-Object Microsoft.IdentityManagement.PowerShell.ObjectModel.ConfigurationParameter &quot;Microsoft.Synchronize.ForceFullPasswordSync&quot;, String, ConnectorGlobal, $null, $null, $null</span><br><span class="line">$p.Value = 1</span><br><span class="line">$c.GlobalParameters.Remove($p.Name)</span><br><span class="line">$c.GlobalParameters.Add($p)</span><br><span class="line">$c = Add-ADSyncConnector -Connector $c</span><br><span class="line">Set-ADSyncAADPasswordSyncConfiguration -SourceConnector $adConnector -TargetConnector $azureadConnector -Enable $false</span><br><span class="line">Set-ADSyncAADPasswordSyncConfiguration -SourceConnector $adConnector -TargetConnector $azureadConnector -Enable $true</span><br></pre></td></tr></table></figure>

<p>What this script will do is enable all on-premises users’ NTLM and Kerberos password hashes to be synchronized to the Azure AD tenant. This script will also initiate a full synchronization in Azure AD Connect. </p>
<p>The values for $adconnector and $azureadconnector variables can be found in the Azure AD Connect synchronization service manager. What I’ve done is create a PowerShell script called NTLMSync.ps1. This script includes all of these commands. I just need to open PowerShell on the Azure AD Connect server to run the script. The output tells me that the password hash sync configuration has been updated.</p>
<h1 id="Azure-Role-Based-Access-Control"><a href="#Azure-Role-Based-Access-Control" class="headerlink" title="Azure Role-Based Access Control"></a>Azure Role-Based Access Control</h1><p>Hello and welcome back. A tool that goes hand-in-hand with Azure active directory is Azure role-based access control, or RBAC. Azure RBAC is used to manage who has access to what resources and to manage what those users can do with those resources. It’s an authorization system that is built upon Azure resource manager, and it offers fine-grained access management to your Azure resources.</p>
<p>Azure RBAC relies on role assignments for access control. Each role assignment consists of three parts, a security principal, a role definition, and a scope.</p>
<p>The Security principal is essentially an object that represents either a user, a group, a service principal, or a managed identity that requires access to resources in Microsoft Azure. </p>
<p>The role definition is essentially a collection of permissions. Role definitions are usually referred to simply as roles. A specific role will list the operations that can be performed by someone with that role. These operations include things like read, write, and delete.</p>
<p>Although there are many built-in roles in Azure that you can use, there are four fundamental roles available. These fundamental roles include owner, contributor, reader, and user access administrator. A person assigned the owner role has full access to all resources, including the rights to delegate access to others. A person assigned the contributor role can create and manage all kinds of Azure resources. However, a contributor cannot grant access to those resources to other users. The reader role allows you to view existing Azure resources, while the user access administrator role allows you to manage user access to your Azure resources.</p>
<p>In addition to the built-in roles you can also create custom roles. This allows you to tailor access to your resources in a way that best suits your organization.</p>
<p>A scope is a set of resources that the access you are setting up applies to. For example, you may provide access to a scope that includes a subscription or maybe a resource group or even a specific resource. A scope in Microsoft Azure can be specified at the management group level, the subscription level, the resource group level, or to specific resources. Because scopes are structured in parent-child relationship, access that is granted at the parent scope level will be inherited by the child scopes.</p>
<p>The process that Azure RBAC uses to determine if a user has access to a specific resource is pretty straightforward. First, the user requesting the access acquires a token from Azure resource manager. This token includes any group memberships for the user. </p>
<p>Next, the user makes a rest API call to Azure resource manager with the attached token.</p>
<p>What Azure resource manager will do next is retrieve all the role assignments and deny assignments for the resource that the user is trying to access. Azure resource manager will then narrow those role assignments down to only those that apply to the user or to groups that the user is a member of. It will also determine which roles have been assigned to the user for the resource being accessed.</p>
<p>Next, Azure resource manager will determine whether or not the requested action in the API call is allowed by the role that the user has for the specific resource being accessed.</p>
<p>Assuming the user is assigned a role that allows the action being requested at the requested scope, access is granted. Otherwise, access is blocked.</p>
<p>Azure RBAC is free and is included with all Azure subscriptions.</p>
<p>To learn more about Azure RBAC, visit the <a target="_blank" rel="noopener" href="https://docs.microsoft.com/azure/role-based-access-control/overview">URL</a> that you see on your screen.</p>
<h1 id="Single-Sign-On-Overview"><a href="#Single-Sign-On-Overview" class="headerlink" title="Single Sign-On Overview"></a>Single Sign-On Overview</h1><p>Unless an organization deploys a single sign-on solution, its users will be required to remember multiple usernames and passwords, one for each different application in use. Additionally, the IT department needs to maintain all of these different accounts and passwords manually. Single sign-on allows users to sign in once with one account in order to access domain-joined devices, corporate resources, SAS applications, and even web apps. After signing in, users can then launch apps right from the O365 portal or via the MyApps access panel. With single sign-on, IT administrators can centralize user account management, allowing them to automatically add or remove user access to applications based on group membership. In this lecture, we are going to discuss the various single sign-on options that are available when designing an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity management</a> solution that incorporates single sign-on. </p>
<p>Choosing a single sign-on solution for an application will largely depend on how the application is configured for authentication. Of all the single sign-on methods we are about to discuss, disabled is the only one that does not automatically sign users into applications without requiring a second sign-on to occur. When deciding on a single sign-on solution, it’s important to know that cloud apps can use SAML, password-based, linked, and disabled methods for single sign-on. Of the bunch, SAML is the most secure method. On-prem apps, when configured for Application Proxy, can use password-based, Integrated Windows Authentication, or IAW, header-based, linked, or the disabled methods for single sign-on. The table that you see on your screen provides a summary of the single sign-on methods that are available. Use SAML for single sign-on whenever possible. </p>
<p>This method works when applications are configured to use a SAML protocol. Use password-based single sign-on when an application authenticates with a username and password. Using password-based single sign-on offers secure application password storage and replay via a web browser extension or via mobile application. Password-based single sign-on uses the existing sign-in process that’s provided by the application while allowing an administrator to manage the passwords for it. The linked single sign-on method is useful when an application is configured for SSO in another identity provider service. This SSO option doesn’t add single sign-on to the application. Use disabled single sign-on when an application isn’t ready for single sign-on. Users of the application will need to provide their username and password each time they launch the application.</p>
<p> Use IWA SSO for applications that use Integrated Windows Authentication or for claims-aware applications. When using this method for SSO, Application Proxy connectors use Kerberos Constrained Delegation to authenticate users to the application. Header-based single sign-on should be used when an application uses headers for authentication. It should be noted that header-based single sign-on requires PingAccess for Azure AD. When using header-based SSO, Application Proxy uses <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> to authenticate the user and then passes traffic through the connector service.</p>
<h1 id="Enable-Single-Sign-On-for-Dropbox"><a href="#Enable-Single-Sign-On-for-Dropbox" class="headerlink" title="Enable Single Sign-On for Dropbox"></a>Enable Single Sign-On for Dropbox</h1><p>In this demonstration, we’re going to walk through the process of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">enabling</a> single sign-on for an application. We’re going to enable single sign-on for Steven Davis so that he can access his Dropbox for Business account. To configure single sign-on for Dropbox, browse to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a>. From here, click on Enterprise applications, and then click New application. Find the Dropbox application in the gallery, and then select the application and click Add. After adding the application to Azure, click Single sign-on located under Manage. Select SAML to open the SAML configuration screen. Retrieve the sign on URL from the application vendor and provide that URL in the Sign on URL field for the application in Azure. Provide an identifier value. In this case, we’ll just use the word Dropbox. And then next, download the SAML signing certificate from Azure. This certificate needs to be provided to the application vendor. After downloading the certificate, switch over to the application vendor’s configuration dashboard and provide the certificate you downloaded. </p>
<p>The type of certificate you download will be largely dependent on the application itself so you’ll need to refer to the vendor’s documentation for setting up single sign-on. Retrieve the login URL for the application from Azure and provide it to the application. Save the application configuration, and then after the configuration is complete in both Azure and the app vendor’s portal, you can go ahead and test the login. To test single sign-on, assign a user to the application in Azure by clicking Users and groups within the application’s Azure dashboard. Find a user and then click Assign. Ensure that there is a user account for the assigned user also configured in the application itself. Next, open an incognito window and launch the application panel and login as the user to whom the application was assigned. Launch the application from the application panel and confirm that single sign-on works.</p>
<h1 id="MFA-Overview"><a href="#MFA-Overview" class="headerlink" title="MFA Overview"></a>MFA Overview</h1><p>Two-step verification provides a layered approach to security. Even the most enterprising attacker would have problems compromising multiple authentication factors, because, even if the attacker obtains a user’s password, the password would be useless without also being in possession of the additional authentication method, a mobile phone, for example. Multi-factor authentication works by requiring two or more authentication methods, which typically include something like a password that the user knows, something the user owns, typically a mobile phone, and something the user is, biometrics, for example. Azure MFA offers the ability to safeguard access to apps and data while maintaining a simple end-user experience. By providing additional security via a second form of authentication, MFA provides much sought after security for end-user authentication, and it does so via a range of easy to use authentication methods, including passwords, security questions, email address, application, OATH hardware token, SMS, voice call, and app passwords. Multi-Factor Authentication comes as part of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> Premium.</p>
<p> A subset of MFA capabilities is also available as part of an Office 365 subscription and as a means to protect Global Administrator accounts. As part of Azure AD Premium, Azure MFA is offered in two flavors, including the Azure Multi-Factor Authentication Service, which is cloud-based, and the Azure MFA Server option, which is a good option for organizations who have deployed ADFS and that want to or need to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">manage</a> MFA on-prem. Because most users are used to using only passwords to authenticate to applications and services, it’s critical that an organization communicate with the user base when rolling out an MFA solution. Doing so will invariably reduce the number of helpdesk calls that come in during any MFA rollout. Now, despite the best laid plans and deployments, there will be times when you may need to disable MFA in a one-off scenario. For example, if a user can’t sign in because he has lost access to his authentication methods, a lost phone, for example, in such a case, you could use a conditional access policy for Azure MFA. </p>
<p>With a conditional access policy in place, you can create a user group that is excluded from the policy that requires MFA. Placing the user in the excluded group would temporarily allow access until MFA functionality or access can be restored. A way to temporarily bypass MFA for Azure MFA Server users is to allow them to authenticate without two-step verification. Such a bypass can be configured but it expires after a specified number of seconds. Two-step verification prompts can be minimized for users that are on the local network. This can be accomplished with trusted IPs or named locations. By leveraging this features, an administrator for a managed or federated tenant can bypass two-step verification for users that are signing in from a trusted network location.</p>
<h1 id="Enable-MFA-for-O365-User"><a href="#Enable-MFA-for-O365-User" class="headerlink" title="Enable MFA for O365 User"></a>Enable MFA for O365 User</h1><p>In this demonstration, we’re going to enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">Multi-Factor Authentication</a> for an Office 365 user, so you can see how the process works and have a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">log in</a> process works once it’s been enabled. To enable Multi-Factor Authentication for an Office 365 user, open the Office 365 admin portal as a global administrator. Click on Users, and then Active Users. Find the user in the list for whom you wish to enable MFA and double click that entry. On the user’s property page, down at the bottom, click “manage multi-factor authentication”. Select the user in the multi-factor authentication screen and click Enable. Confirm that you want to enable multi-factor authentication by clicking the enable multi-factor auth button, and then close the box out. You’ll notice that the multi-factor auth status now shows enabled for this particular user. Open an incognito browser window and launch the Office 365 portal. Login as the user for whom you just enabled MFA. If you’ve configured MFA properly, the user, Steve in this case, will be prompted for more information before being allowed to login. Continue the login process by providing the information requested. Be sure to save the application password, so that it can be used for other applications if necessary, and then go ahead and click Done. After providing the MFA info, you’re prompted to log back in. Log back in, and be sure to supply the proper MFA info. As you can see on your screen, MFA is now working for Steve.</p>
<h1 id="Azure-AD-B2B"><a href="#Azure-AD-B2B" class="headerlink" title="Azure AD B2B"></a>Azure AD B2B</h1><p>Azure Active Directory Business-to-Business collaboration, also known as Azure AD B2B, allows an organization to securely share company applications and company services with guest users from other organizations while retaining control over company data. With Azure AD B2B, an organization can work with external partners, even if they don’t use Azure AD. The invitation and redemption process of Azure AD B2B allows users in a partner organization to use their own credentials to access a company’s resources. Because the partner organization uses its own <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity management</a> solution, external administrative overhead for the sharing organization is essentially non-existent. There’s no requirement to manage external accounts or passwords, nor is there a need to synchronize accounts or manage account lifecycles. When guest users are invited to access resources in a partner organization, they sign into the shared applications and services with their own identities. Guest users without a Microsoft account or Azure AD account have one created for them when they redeem their invitations. Inviting a guest user to access an app or service, using AD B2B, is as simple as sending an invite to the guest user, using the guest user’s email address.</p>
<p>The guest user then follows a few easy redemption steps to sign in. Azure AD B2B offers the ability to use authorization policies to protect corporate content. Conditional access policies like <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">MFA</a> can be used to protect corporate applications and data. Such policies can be enforced at the tenant level, the application level, and even for specific guest users. With Azure AD B2B, administrators can add guest users to the organization right from the Azure portal. When the administrator creates the new guest user, which is done in a similar fashion to adding a new internal user, the guest user receives an invitation that allows him to sign into the Access Panel for that user. Guest users can be assigned to apps and even groups. By delegating guest user management to application owners, you can reduce the workload of the Azure administrators in your organization. Delegating user management allows application owners to add guest users to any application that they want. By delegating guest user management to application owners, you can reduce the workload of the Azure administrators in your organization. Delegating user management allows application owners to add guest users to any application that they want to share, even if it’s not a Microsoft application. To make this work, an administrator needs to set up self-service app and group management. Once this has been configured, non-admins can use their Access Panel to add guest users to applications or to groups.</p>
<h1 id="Add-Guest-Users-to-the-Directory"><a href="#Add-Guest-Users-to-the-Directory" class="headerlink" title="Add Guest Users to the Directory"></a>Add Guest Users to the Directory</h1><p>In this demonstration, we’re going to add a guest user to our Azure AD. To add a guest user, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">log in</a> to the Azure portal and browse to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a>. Click users and then click new guest user. Provide the new guest users email address and then click Invite. The user you’ve invited receives an invite email. Upon clicking the get started button in the invite email, the guest user is prompted to accept the invite. After accepting the invite, the guest user is taken to the applications pane, where he will be able to access applications that ultimately get assigned to him.</p>
<h1 id="Azure-AD-B2C"><a href="#Azure-AD-B2C" class="headerlink" title="Azure AD B2C"></a>Azure AD B2C</h1><p>Azure Active Directory Business-to-Consumer, also known as Azure AD B2C, is an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">identity management</a> service that offers organizations the ability to customize and control how customers interact with corporate applications. It allows organizations to control how users sign up, sign in, and how they manage their profiles when using the applications. Azure AD Business-to-Consumer enables this functionality while also protecting customer identities. Applications registered with Azure AD B2C can be configured to handle many identity management tasks. </p>
<p>For example, you can allow users to sign up to use a registered application, you can enable a signed-up user to edit his profile, and you can even enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">MFA</a> in the application. Other identity management tasks that can be handled include allowing users to sign up and sign in with specific identity providers, such as Facebook, for example. You can even customize the look and feel of the signup experience for users, as well as the sign-in experience. Azure AD B2C completes identity tasks by interacting in sequence with identity providers, also known as IdPs. It also interacts with users, other systems, and with the local directory. The Identity Experience Framework establishes multi-party trust and completes these steps. Along with a Trust Framework policy, this framework defines the actors, actions, protocols, and sequence of steps that need to be completed in order to make things work. Azure AD B2C makes use of SYN cookies and rate and connection limits to protect against denial-of-service and password attacks against applications. It also includes mitigation for brute-force password attacks, as well as dictionary password attacks. </p>
<p>A service that authenticates customer identities and issues security tokens is called an identity provider. Azure AD B2C offers the ability to configure several different identity providers in the tenant. Common identity providers include Microsoft accounts, Facebook, and even Amazon. Before configuring an identity provider in an Azure AD B2C tenant, the application identifier, client identifier, password secret, and client secret, or a combination of each, depending on the identity provider itself, must be recorded from the identity provider application that is created. This identifier information is then used to configure the application that will be accessed via the identity provider being configured. Every Azure AD B2C tenant is distinct and separate from other Azure AD B2C tenants. To leverage the features of AD B2C, you must deploy a B2C tenant, and link it to your Azure subscription. If you wish to allow users to sign in to an application using Facebook, Amazon, or some other identity provider, you must first register the application in the Azure AD B2C tenant.</p>
<h1 id="Create-a-Link-and-Azure-AD-B2C-Tenant"><a href="#Create-a-Link-and-Azure-AD-B2C-Tenant" class="headerlink" title="Create a Link and Azure AD B2C Tenant"></a>Create a Link and Azure AD B2C Tenant</h1><p>In this demonstration, we are going to create a new <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/azure-ad-b2c/">Azure B2C</a> tenant and then, we’re going to link the new B2C tenant to our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure subscription</a>. To get started, login to the Azure portal and make sure you’re in the directory that contains the Azure subscription. We only have one subscription here, so we’re good on that front. Click create a resource and then search for Azure Active Directory B2C. Click on Azure Active Directory B2C in the search results and then click create. Choose the option to create a new Azure AD B2C tenant. Provide an organization name and a domain name. Select a region and then click create. After creating the Azure AD B2C tenant, you now have to link it to your Azure subscription. While, again, ensuring you’re in the directory that contains your Azure subscription, create a new resource and search for Azure AD B2C, just as you did the first time. Click on Azure SD B2C in the results and click create. This time, however, choose the second option to link an existing Azure AD B2C tenant. In the Azure AD B2C tenant dropdown, choose the B2C tenant that you created earlier. Leave the subscription where it’s at and then select a resource group. Click create to complete the linking process. When the process completes, click Go to resource to manage the newly created B2C tenant.</p>
<h1 id="Privileged-Identity-Management"><a href="#Privileged-Identity-Management" class="headerlink" title="Privileged Identity Management"></a>Privileged Identity Management</h1><p>Azure Active Directory Privileged Identity Management, otherwise known as PIM, is an Azure offering that allows you to manage and control access to resources within <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure</a> and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a>, as well as within other services, such as Intune and Office 365. A valid Azure AD Premium P2 license is required for all users that will interact with or benefit from Privileged Identity Management before enabling the service on a tenant. Alternatively, you can assign an Enterprise Mobility + Security E5 license for each user that interacts with Privileged Identity Management. Generally speaking, licensing is required for users that are assigned to the Privileged Identity Role Administrator role or who are assigned as eligible to other directory roles that are manageable through Privileged Identity Management. If a user can approve or reject requests in Privileged Identity Management, that user also requires a license. Users assigned to a role with time-based assignments, such as Just in time or Direct, or those assigned to an access review role, also require licensing. With Azure AD Privileged Identity Management, an organization can see which users are assigned privileged roles that are used to manage Azure resources. Organizations can also see which users are assigned administrative roles within Azure Active Directory. </p>
<p>Privileged Identity Management also offers the ability to enable on-demand, or just in time, administrative access to services such as Office 365 and Intune, as well as to Azure subscriptions, resource groups, and even individual Azure resources, like virtual machines and such. Azure AD Privileged Identity Management offers the ability to view a history of administrator activation, along with a history of changes that administrators have made to Azure resources. Alerts can also be configured to notify you about changes in administrator assignments. Privileged Identity Management also allows you to require approval for activation of Azure AD privileged admin roles, to review membership of such administrative roles, and to force users to provide justification for ongoing membership in these roles. In Azure Active Directory, Privileged Identity Management can be used to manage users that are assigned to built-in Azure AD roles, such as Global Admin. In Azure itself, Privileged Identity Management can manage users and groups assigned via Azure RBAC roles, such as the Owner and Contributor roles.</p>
<h1 id="Enable-PIM-and-Manage-Subscriptions"><a href="#Enable-PIM-and-Manage-Subscriptions" class="headerlink" title="Enable PIM and Manage Subscriptions"></a>Enable PIM and Manage Subscriptions</h1><p>In this demonstration, we’re going to enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/privileged-identity-management/">Privileged Identity Management</a>, and we’re going to set up a subscription to be managed by Privileged Identity Management. To enable Privileged Identity Management or PIM for short, Login to the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure</a> portal, and then click on All services and search for privileged identity management. Click on the Azure AD privileged identity management in the search results. Next, click on “consent to PIM” and then verify your identity when prompted to do so. Provide the additional security verification info that is requested and then click Next. Click Verify to verify your information. At this point you’re taken back to the PIM consent screen. To complete the consent process, click the “consent” link and then click Yes to confirm. With PIM enabled, you can now sign up for PIM for Azure AD role management. To do so, click on Azure AD roles, under Manage. Click sign up for PIM in the left pane and then click the sign-up link at the top. When prompted to confirm, click Yes. After setting up PIM to manage AD roles, you need to discover resources in the subscription, so they, too, can be managed with PIM as well. To do this, go back to the quick start page and click Azure Resources. In this demo, here, we’re going to manage all resources in the subscription. Click Discover Resources and then select the subscription. Click Manage Resource to onboard the resource for management, and then click Yes to confirm. At this point, you’ve deployed PIM and configured Azure AD roles and Azure resources to be managed by it.</p>
<h1 id="Self-Service-Password-Reset"><a href="#Self-Service-Password-Reset" class="headerlink" title="Self-Service Password Reset"></a>Self-Service Password Reset</h1><p>Self-service password, or SSPR, is pretty self-explanatory. This feature allows end users to reset forgotten passwords without the need for a call to the help desk. It’s a feature that many organizations request, as it helps provide a more streamlined and pleasant end-user experience. Depending on the SSPR functionality that is required, license requirements may vary. For example, Self-Service Password Change functionality for cloud users is included in all editions of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a>. In these cases, we are talking about cloud-only users who wish to change their passwords to something new. Self-Service Password Reset functionality for cloud users is only included in Azure AD Basic and higher. It’s not offered in the free version of Azure AD. This functionality applies to cloud-only users who wish to reset their passwords to something they know. Self-Service Password Reset, Password Change, and Password Unlock, leveraging on-premises write-back, requires either Azure AD Premium P1 or Premium P2. This functionality applies to hybrid users that are synced to Azure AD from an on-prem AD. So, when considering Self-Service Password Reset, it’s important to understand the user base and how users are <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">managed</a> and provisioned.</p>
<h1 id="Configure-Self-Service-Password-Reset"><a href="#Configure-Self-Service-Password-Reset" class="headerlink" title="Configure Self-Service Password Reset"></a>Configure Self-Service Password Reset</h1><p>Enabling <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/self-service-password-reset/">self-service password</a> for end users take a huge burden off of the shoulders of the help desk. In this demonstration, we will enable self-service password reset, and test that it’s working with a test account. Before enabling self-service password reset, make sure that password writeback is turned on in Azure AD Connect. To do this, launch Azure AD Connect on the server running it. Click configure and then view the current configuration. If its disabled, relaunch Azure AD Connect, click configure, and then select customize synchronization options. Provide the global admin account to connect to Azure AD. Click next to leave the directories and domain and ou filtering options unchanged. Under optional features, check the password writeback box and click Next. Click Configure to update the configuration and then click Exit. After turning on password writeback, switch over to the Azure portal and then browse to Azure active directory. From here, click Password Reset. For this demonstration, I’m going to enable password reset for all of my users so I’m going to click All, and then save. After enabling password reset, click on Authentication methods and select the authentication methods you wish to make available, along with how many are required to set a password. </p>
<p>This is obviously going to be different for every environment. If you select the security questions option, you’ll be presented with more info to supply. We aren’t using security questions here, so I’ll turn this off. For this demonstration, I’m going to make mobile phone available as the only option. After clicking Save, I’m going to click on registration. I’m asked if I want to require users to register when <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">signing in</a>. I’m going to leave the default value set to yes. I’m also going to leave the window set to the default of 180 days. Clicking notifications allows me to set the notification options for when a user resets a password. I’m going to set both options here to yes. this ensures users receive a notification when they reset their passwords, but it also ensures that all administrators are notified when another administrator resets his password. In the customization pane, I can provide a customized helpdesk link for users to visit if they need assistance. I don’t have helpdesk here in the lab, so I’m going to leave this off for this demonstration. When I click on the on-premises integration link, Azure confirms that the on-prem writeback client is running and allows me to determine if I want passwords to writeback to on-prem AD. I need to leave this set to yes. The second option designates whether or not users should be given the option to unlock their accounts without resetting their passwords. </p>
<p>I’m going to leave this set to no for this demonstration. With password reset enabled, we can now test it. To test self-service password reset, open an incognito browser window and launch the single sign on setup process with a test account. In my case here, we previously enabled <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">MFA</a> so let me get through the authentication process here first. As you can see here, I’m prompted to to work through the process of setting up self service password reset for my account. Once I’ve completed the self service password reset setup, I’m presented with my application dashboard. To reset my password, I need to open the password reset URL in my browser. The password reset URL is <a target="_blank" rel="noopener" href="https://aka.ms/sspr">https://aka.ms/sspr</a>. On the next screen, I’m prompted to begin the reset process. I just have to provide my user ID and I need to complete the captcha. Clicking Next takes me to the verification screen, where I can request a code via mobile phone. After I click the Text button, I receive a code on my phone that I need to enter. After providing my verification code and clicking Next, I’m then prompted to create a new password. Clicking Finish completes the process.</p>
<h1 id="Self-Service-Group-Management"><a href="#Self-Service-Group-Management" class="headerlink" title="Self-Service Group Management"></a>Self-Service Group Management</h1><p>To further improve the end user experience, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure AD</a> offers the ability for users to create and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">manage</a> their own security groups and Office 365 groups. In addition, users can also request security group memberships as well as Office 365 group memberships. In such cases, the owner of these groups can approve or deny their membership requests. By delegating group membership control, organizations can ensure that the people who best understand the business context for such memberships are the ones controlling group membership. It’s important to note, however, that this feature applies only to security groups and Office 365 groups. It does not apply to mail-enabled security groups nor does it apply to distribution lists. There are essentially two flavors of self-service group management currently available. These include delegated group management and self-service group management. An example of delegated group management would be a scenario where an organization uses a SaaS application, whose access is managed by an administrator. As the company grows, access management becomes a bit cumbersome for the administrator to handle. To ease the burden of granting access and revoking access to the application, the administrator requests that the application owner create a new group. </p>
<p>After the group has been created, the administrator assigns access to the application for the new group. He also adds all users who need access to the application to this group. Because the application owner created the group, he has he ability to add and remove users from it. Users added to the group are automatically granted access to the application, while users that are removed from the group have their access to the application revoked when the leave the group. By delegating group membership management to the application owner, the application owner no longer needs to wait on the administrator to provide and revoke access to the application. Of course, however, the administrator would still be able to see who has access to the application, and he could block access as necessary. A self-service group management example would be a scenario where an app owner manages an application. In order to grant a group of business users access to the application, the app owner creates a group in Azure AD, grants the group access to the application, and then enables self-service group management on the group. When a user in the organization needs access to the application, the user simply requests access to it from the Access Panel. When the request is approved, the user receives access to the application.</p>
<h1 id="Demo-Self-Service-Group-Management"><a href="#Demo-Self-Service-Group-Management" class="headerlink" title="Demo: Self-Service Group Management"></a>Demo: Self-Service Group Management</h1><p>In this demonstration we are going to enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/self-service-group-management/">Self Service group management</a>, by allowing users to create their own security groups and to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">manage</a> them. To enable Self Service group management, sign into the Azure portal and browse to Azure Active Directory. You’ll need to do this with a Global Admin account for the directory. From here select groups, and then go into the general settings for groups. Set the option for owners can manage group membership requests to yes. And then set the option for users can create security groups to yes as well. With these settings enabled users in the directory are allowed to create new security groups and to add members to those groups. These new groups will also show up in the access panel for all other users. In addition, if the policy settings on the group allow it, other users can create requests to join these groups as well.</p>
<h1 id="Overview-of-Managed-Identities-for-Azure-Resources"><a href="#Overview-of-Managed-Identities-for-Azure-Resources" class="headerlink" title="Overview of Managed Identities for Azure Resources"></a>Overview of Managed Identities for Azure Resources</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Managed Identities</a> for Azure Resources is a feature of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a>. There are several Azure services that support Managed Identities for Azure Resources. For those who build cloud applications, management of credentials within a code for authenticating to cloud services is often a common challenge. It’s critical to ensure credentials are kept secure. As a matter of fact, preferably, credentials should never appear on a developer’s workstation, nor should credentials ever be checked into source control. With Azure Key Vault, administrators have a way to securely store credentials. However, to be effective, the application code needs to authenticate to Key Vault to retrieve those credentials that are stored. Enter Managed Identities for Azure Resources. Using the Managed Identities for Azure Resources feature in Azure AD solves this problem. This solution provides supported Azure services with an automatically managed identity in Azure AD that can be used to authenticate to any service that supports Azure AD authentication without the need to store any credentials in code. Key Vault is one of the Azure services that is supported. Managed Identities for Azure Resources is a free feature that comes with all Azure AD editions. There are two types of managed identities to choose from. </p>
<p>They include a system-assigned managed identity and a user-assigned managed identity. A system-assigned managed identity is enabled directly on an Azure service instance. Once the identity has been enabled, Azure will create an identity for the instance in the Azure AD tenant that’s trusted by the subscription of the instance. The credentials for the identity are provisioned onto the instance after the identity had been created. System-assigned identities are tied to the Azure service instances that they are enabled on. Deleting an instance with a system-assigned managed identity attached to it will cause Azure to automatically clean up the credentials, along with the identity in Azure AD. A user-assigned managed identity is essentially a standalone Azure resource. Via a creation process, Azure creates the identity in the Azure AD tenant. The subscription in use, in turn, trusts the identity. An identity, once created, can be assigned to one or more Azure service instances. Unlike a system-assigned managed identity, the lifecycle of a user-assigned identity is managed separately from that of the Azure service instance, or instances, to which it’s been assigned. Application code can use managed identities to request access tokens for services that support Azure AD authentication. Azure will handle the rolling of the credentials that are used by the service instance.</p>
<h1 id="Enable-a-Systems-Designed-Management-Identity-on-a-VM"><a href="#Enable-a-Systems-Designed-Management-Identity-on-a-VM" class="headerlink" title="Enable a Systems Designed Management Identity on a VM"></a>Enable a Systems Designed Management Identity on a VM</h1><p>To enable <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/overview-of-managed-identities-for-azure-resources/">System Assigned Managed Identity</a> on a VM that was originally provisioned without it your account needs at least the Virtual Machine Contributor Role assignment. In the case of our demo here I’m using a global admin so that’s a non-issue. To complete this task sign into the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">Azure</a> portal, navigate to the Resource Group that contains the VM that you wish to configure. Clock on the desired Virtual Machine and then select Identity. Under System Assigned Status select On and then click Save. Once the System Assigned Managed Identity is enabled the VM will be registered with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a>. After being registered you can then control its access to other services like Storage Accounts and the like.</p>
<h1 id="DEMO-Azure-AD-Reporting-and-Monitoring"><a href="#DEMO-Azure-AD-Reporting-and-Monitoring" class="headerlink" title="DEMO: Azure AD Reporting and Monitoring"></a>DEMO: Azure AD Reporting and Monitoring</h1><p>Hello and welcome back. In this brief demonstration here, what I wanna do is give you a tour, so to speak, of some of the Azure Active Directory Reporting and Monitoring options that are available.</p>
<p>Now, on the screen here, you can see I’m logged in to my Azure Portal, and I’m at the Overview page for my Azure Active Directory. We are working in the test9878.org directory. Now, the Azure Active Directory Reports that are available provide you with a view of the different activities that are going on in your environment.</p>
<p>You can use reports to determine how applications and services are utilized by your users, and you can detect potential risks that affect the health of your environments. You can use reports to also troubleshoot issues.</p>
<p>With Azure Active Directory Monitoring, you can route your Azure AD activity logs to different endpoints. You can then view this data to see what’s going on within your Active Directory.</p>
<p>Let’s take a look at some audit logs and some sign-in activities. Now, to take a look at the audit log for Azure Active Directory, what you do here is scroll down in the left pane from the Overview page of your directory and you select Audit logs under Monitoring. Now, what this Audit Log Report does is provide you with a record of the different system activities that have occurred.</p>
<p>For example, we can take a look and see who had access to an admin group and who gave them that access. We can also see information regarding password resets and the like. Now, in this dashboard here for our audit logs, we can see a few different activities that have occurred. We’ve seen some Add user activities. We’ve seen some Add member activities. We’ve also seen some activities revolving around roles.</p>
<p>If we select an activity here, so for example, we’ll choose this Add owner to group, what this tells us is what happened, when it happened, and what the status was. It also tells us who performed this action. Selecting the target gives us more information about the activity that occurred. And if we select Modified Properties, we can see what properties were actually modified.</p>
<p>So when you need to look at information for compliance, for example, the Audit logs report would be the report to go to. Now, if we click over to Sign-ins, we can see what was going on regarding sign-ins to our Azure Active Directory. Typically, you’d use the Sign-ins Report to find the sign-in pattern of specific users, or to see how many users have logged in in the last week, or what the sign-in status is.</p>
<p>On the screen here, we can actually see two different sign-ins that occurred. One was interrupted and one was successful. If we select the one here that was interrupted, we can see information about that specific sign-in. We can see when it happened, what happened, what the error code was, and what the failure reason was for the interrupted sign-in. We can see which user generated the alert and even the application where the sign-in occurred.</p>
<p>Along this top tab, we have lots of other different information we can look at. We can look at the location where this occurred. The Device Info. We can see that this failed login occurred on a Windows 10 machine from the Chrome browser. If we look at the Authentication Details, we can see that was a CloudOnlyPassword and that it was false. We can see any Conditional Access information that applied here.</p>
<p>In this case, there were no policies applied. And any Additional Details. Now, to configure monitoring for Azure Active Directory, what you can do is go into Diagnostic settings here below Monitoring, and we can see we have no diagnostic settings configured yet. So what we’ll do is add a diagnostic setting.</p>
<p>So we’ll go ahead and call this MyDiags. Now, what we can do here is we can collect audit logs or sign-in logs. And then when we do that, we can send them to either Log Analytics or to a storage account, or we can stream them to an event hub. For this demonstration here, what we’ll do is we’ll gather our audit logs and send them to a storage account.</p>
<p>Now, if we leave Retention here set to zero, if you look down here, you can see that setting it to zero does not apply a retention policy. This means the data that you collect is retained forever. I’ll just retain this for one day for this demonstration.</p>
<p>Now, when we select our storage account, we need to choose what storage account we want to archive to. So I already have a test9878 storage account here, so that’s what’s selected here. But I could change this to a different storage account if I wanted to. So what we’re doing here is collecting our audit logs with a retention of one day and sending them to our storage account, and then we’ll go ahead and save this.</p>
<p>Now, what we could also do here is instead of sending to a storage account, we can send to Log Analytics. Now, to send to Log Analytics, you’ll need to have a Log Analytics workspace already created. We have a default workspace here. We actually have a couple. So what we’ll do here is we’ll send to Log Analytics, and we’ll save it, and we can see we get the success here.</p>
<p>Now, to take a look at our logs, what we can do is go back out to our directory and then go into Logs here under Monitoring. Now, from the Log Analytics page here, what I can do is run different queries to track down the information I’m looking for as it relates to my Azure Active Directory. So that will call it a wrap.</p>
<p>Just keep in mind that you can run reports to track down specific information that’s reported in the Sign-ins Report and in the Audit logs report. And you can use Monitoring to send your information through logs into the Azure Monitor and&#x2F;or Log Analytics workspace.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>We’ve covered quite a bit of ground in <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction/">this course</a>. With so many terms and features to keep track of, it’s critical to be able to distinguish them from one another and understand what each does. By understanding what each identity management piece does, it becomes far easier to design an identity management solution. With that said, let’s walk through a high-level recap of all of the key players in the identity management space and what each offers. Microsoft’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/introduction-to-azure-ad/">Azure Active Directory</a> is a cloud-based identity and access management service. With it, users can sign in and access external resources, such as Office 365, the Azure portal, and other SaaS applications. Azure AD is used to control access to applications and resources according to business requirements. A hybrid identity is an identity that spans on-prem and cloud-based capabilities. Leveraging hybrid identities allows an organization to create a common user identity for authentication and authorization to all resources, regardless of whether they are on-prem or in the cloud. Azure AD Domain Services is a Microsoft cloud-based offering that provides managed domain services, such as domain join, group policy, LDAP, and Kerberos and NTLM authentication. These services are fully compatible with traditional on-prem Active Directory and they can be deployed without any need for deployment or management of domain controllers in the cloud. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/single-sign-on-overview/">Single sign-on</a>, also referred to as SSO, allows users to sign in once with one account in order to access domain-joined devices, corporate resources, software as a service apps, and even web applications. </p>
<p>After signing in, users can then launch apps right from the O365 portal or via the MyApps access panel. With single sign-on, IT administrators can centralize user account management, allowing them to automatically add or remove user access to applications, based on group membership. Also known as MFA, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/mfa-overview/">multi-factor authentication</a> works by requiring two or more authentication methods, which typically include something like a password that the user knows, something the user owns, which is typically a mobile phone, and&#x2F;or something the user is, biometrics would be a good example. Azure MFA offers the ability to safeguard access to applications and data while maintaining a simple end-user experience. Azure Active Directory Business-to-Business collaboration, also known as AD B2B, allows an organization to securely share company applications and services with guest users from other organizations, while retaining control over company data. Azure Active Directory Business-to-Consumer, also known as Azure AD B2C, is an identity management service that offers organizations the ability to customize and control how customers interact with corporate applications. It allows organizations to control how users sign up, sign in, and how they manage their profiles when using the applications. Azure AD B2C enables this functionality while also protecting customer identities. Azure Active Directory Privileged Identity Management, also known as PIM, is an Azure offering that allows you to manage and control access to resources within Azure and Azure AD, as well as within other services such as Intune and Office 365. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/self-service-password-reset/">Self-Service Password Reset</a>, also known an SSPR, allows end users to reset forgotten passwords without the need for a call to the helpdesk. It’s a feature that many organizations request, as it helps provide a more streamlined and pleasant end-user experience.</p>
<p>Depending on the SSPR functionality that is required, license requirements may vary. Through self-service group membership, Azure AD offers the ability for users to create and manage their own security groups and Office 365 groups. In addition, users can also request security group memberships as well as Office 365 group memberships. In such cases, the owner of such groups can approve or deny their membership. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-azure-identity-management/overview-of-managed-identities-for-azure-resources/">Managed Identities for Azure Resources</a> provides supported Azure services with an automatically managed identity in Azure AD that can be used to authenticate to any service that supports Azure AD authentication without the need to store any credentials in code. Key Vault is one of the Azure services that is supported. Managed Identities for Azure Resources is a free feature that comes with all Azure AD editions. So, like I said, lots of terms. To learn more about each feature, you can, and should, read Microsoft’s published documentation on each. Be sure to also watch for new Microsoft Azure courses on Cloud Academy, because we’re always publishing new ones. Please give this course a rating, and if you have any questions or comments, please let us know. Thanks for watching and happy learning!</p>
<h1 id="10Azure-Role-Based-Access-Control"><a href="#10Azure-Role-Based-Access-Control" class="headerlink" title="10Azure Role-Based Access Control"></a>10<strong>Azure Role-Based Access Control</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.microsoft.com/azure/role-based-access-control/overview">Azure RBAC overview</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Lab-Azure-Resource-Manager-Templates-In-Depth-27/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Lab-Azure-Resource-Manager-Templates-In-Depth-27/" class="post-title-link" itemprop="url">AZ-204-Lab-Azure-Resource-Manager-Templates-In-Depth-27</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 11:30:11 / Modified: 11:30:12" itemprop="dateCreated datePublished" datetime="2022-11-14T11:30:11-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Lab-Azure-Resource-Manager-Templates-In-Depth-27/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Lab-Azure-Resource-Manager-Templates-In-Depth-27/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Knowledge-Check-Introduction-to-Azure-Resource-Manager-26/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Knowledge-Check-Introduction-to-Azure-Resource-Manager-26/" class="post-title-link" itemprop="url">AZ-204-Knowledge-Check-Introduction-to-Azure-Resource-Manager-26</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 11:29:29 / Modified: 19:31:36" itemprop="dateCreated datePublished" datetime="2022-11-14T11:29:29-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Knowledge-Check-Introduction-to-Azure-Resource-Manager-26/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Knowledge-Check-Introduction-to-Azure-Resource-Manager-26/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><object data="3.pdf" type="application/pdf" width="100%" height="600"></object></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Introduction-to-Azure-Resource-Manager-25/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Introduction-to-Azure-Resource-Manager-25/" class="post-title-link" itemprop="url">AZ-204-Introduction-to-Azure-Resource-Manager-25</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:24:40" itemprop="dateCreated datePublished" datetime="2022-11-14T11:24:40-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 00:48:56" itemprop="dateModified" datetime="2022-11-15T00:48:56-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Introduction-to-Azure-Resource-Manager-25/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Introduction-to-Azure-Resource-Manager-25/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Course-Introduction"><a href="#Course-Introduction" class="headerlink" title="Course Introduction"></a>Course Introduction</h1><p>Hi, and welcome to this introduction to this Azure Resource Manager course. My name is Hallam Webber and I will be your instructor for this course. This is a beginner’s course that’s aimed at those who want to know more about managing and configuring their Azure environment. So whether you’re in DevOps, IT support, or a developer that wants to get a better understanding of fast-tracking deployments, there is something in this course for you.</p>
<p>In this course, we will start with an overview of what Azure Resource Manager is and where it fits into the overall Azure picture. Then, we’ll get an understanding of why it’s important. and then, we will delve into some hands-on demonstrations of how you can use it to simplify what would otherwise be quite labor-intensive tasks. </p>
<p>As an introductory course, we will be learning by doing, to give you a basic “how-to” foundation in ARM templates. When we’re not in the Azure portal I’ll be using Visual Code with the ARM template extension which provides IntelliSense for Azure Resource Manager syntax. This is a very helpful tool if you’re not familiar with ARM instructions.</p>
<p>We welcome all comments and feedback, so please feel free to reach out to us at <a href="mailto:&#115;&#x75;&#x70;&#x70;&#x6f;&#x72;&#x74;&#64;&#x63;&#108;&#x6f;&#x75;&#100;&#x61;&#99;&#x61;&#x64;&#x65;&#109;&#x79;&#46;&#99;&#x6f;&#x6d;">&#115;&#x75;&#x70;&#x70;&#x6f;&#x72;&#x74;&#64;&#x63;&#108;&#x6f;&#x75;&#100;&#x61;&#99;&#x61;&#x64;&#x65;&#109;&#x79;&#46;&#99;&#x6f;&#x6d;</a> with any questions or comments. Let’s get started.</p>
<h1 id="Azure-ARM-Intro-Overview"><a href="#Azure-ARM-Intro-Overview" class="headerlink" title="Azure ARM Intro Overview"></a>Azure ARM Intro Overview</h1><p>So, what is Azure resource manager? Well, it is what it says it is. For a lot of people when they think of Azure they think of the complete Microsoft cloud product and all that it entails. But in reality, Azure is a collection of services or resources. When you sign up to Azure for the very first time as an organization with a new subscription and you log in to the portal there is nothing there. As you require services whether that’s a virtual machine, a web app, or database server you create instances of those resources. Azure resource manager is the glue behind-the-scenes that makes it substantially easier for you to deploy and manage all those different resources. </p>
<p>ARM in Context</p>
<p>You might think that the portal is Azure, but the portal is one of several interfaces to Azure resource manager. The portal is merely a graphical interface over the resource manager, which in itself is an interface to the various resources, especially in terms of deployment, and managing the order and dependencies involved in deploying various resources. Apart from the portal, there is also an API interface to Azure resource manager and more importantly for us, an SDK interface.</p>
<p>Command Line Interface</p>
<p>PowerShell for Windows and the Azure command-line interface are the preferred methods for interacting with Azure resource manager when it comes to large, complex, and repeated deployments. One thing I want you to take notice of on the slide is where authentication fits into the scheme. Because there are multiple ways to interact with resource manager authentication is handled directly by it. This is demonstrated by the fact that when you log into Azure through PowerShell or the Azure CLI a browser window will pop up and you can authenticate through that when using two-step authentication or a Microsoft account.</p>
<h2 id="Scope"><a href="#Scope" class="headerlink" title="Scope"></a>Scope</h2><p>As we can see here Azure resource manager is mostly used when managing resources within a resource group. All resources are created within a group even if they are spread over multiple geographical regions. By grouping resources, you can perform actions on all the resources in that group at one time. A simple example would be creating a database server with databases and a web app service for some testing and then deleting all of them at one time by deleting the resource group that contains them. Having said that depending on the type of billing account you have with Microsoft you can also create subscriptions and management groups through resource manager.</p>
<p>Why You Need to Know ARM</p>
<p>But why do you need to know about Azure resource manager? After all, the portal works just fine and is easy enough to use. Infrastructure as code is the reason. In the cloud, hardware does not exist; everything is virtual and can be defined by code. It’s fine for you to deploy a simple resource or even a couple of simple resources using the portal in a one-off situation. But having to set up by hand multiple and complex resources, perhaps several times for different environments, like development test and production, would not only be tedious and time-consuming but also prone to error. You can create resource deployments with scripts and run them through the Azure CLI or PowerShell. As resource creation and deployment are so important Azure has developed templates for defining your resources.</p>
<p>A template is a JSON formatted text specification of a resource. The JSON template file contains all the information about a resource necessary for Azure to create it. It contains vital information like the type of resource, for example, virtual machine, database or storage, and the resource’s name. What resource group, and where the resource should be deployed, as in the geographic region are other configurable attributes in the JSON definition. The template specifies the size of the resource, whether that is disk space for a database or compute power for a virtual machine. As I said, every detail about the resource you want to create, including other resources that the target resource will depend on. A template won’t be that useful if it just specifies exactly the same resource. What I mean by that, is you can’t have resources with identical names. The template architecture allows you to use input parameters to reuse a template to deploy the same type of resource, with a different name and attributes. We will see that all the attributes we choose from drop-down lists, radio buttons, and checkboxes as well as text we enter during the resource creation process in the portal become template parameters.</p>
<p>I’m going to introduce you to templates by creating a virtual machine resource in the portal and then saving the template. We will look at the elements of the template like how a resource is defined and how parameters are used to modify a resource deployment. Creating a VM will also demonstrate how one resource is dependent on other resources. A virtual machine doesn’t exist in isolation, it requires a network and storage in the form of a disk. Don’t worry if you don’t get resource templates after the first demonstration. I will examine the different elements of a template in more detail later. The first demo is to show you the relationship between a resource created in the portal and the corresponding template that gets produced.</p>
<h1 id="DEMO-Modifying-Existing-Templates"><a href="#DEMO-Modifying-Existing-Templates" class="headerlink" title="DEMO:Modifying Existing Templates"></a>DEMO:Modifying Existing Templates</h1><p>Without a doubt, the easiest way to get started with templates is to go to a current resource and download the deployment as an ARM template. This process can be likened to recording an Excel macro and then inspecting the code to see how it works. </p>
<p>I’ll start by creating a virtual machine resource. Let’s just fast forward through the portal process by going with most of the defaults. It’s not important what we choose here as template creation will work for any resource. I’ll go with premium SSD and the standard networking setup. I will turn on OS guest diagnostics, take the advanced defaults, and not bother with tags. We can see before we hit the create button, we have the opportunity to download the template before getting the portal to deploy the VM. I’m going to download the template now for use later on.</p>
<p>Having a look at the template we can see it is made up of 22 input parameters that can be changed or substituted to alter how the resources are created. The parameters have a name and a data type. There are 3 variables that are used within the template, and of course, there are the 6 resources being created in the deployment. The parameters file contains the values that are currently used for the resource deployments. These are default values, or values manually entered in the portal when creating the VM resource, like location, machine name, and resource group. Scripts just links you to Azure documentation. The same information is accessible while the deployment is happening. For an existing resource, you can download the template or deploy from the Export Template page. Some of you might be thinking, “hang on, now there are only 3 parameters and 1 resource”. That’s because this template is just the virtual machine component and doesn’t include the supporting network infrastructure resources. If you need to get the templates for all resources in a deployment after the fact, you can go to the resource group and select the resources and click export template.</p>
<p>Back at our VM resource, Azure lets you save templates to an online library, which is what I’ll do now by giving the template a name and simple description. You can view templates saved to the library through More Services, then All Services, and then select Templates. With a template, you can redeploy the resource or make a similar resource with different attributes by changing some of the input parameters.</p>
<p>We’ve got the template what now? The usual method for deploying resources using templates is to use a command-line interface, either PowerShell or Azure CLI. We will look at both of these later, but initially let’s create the VM resource through the portal using the downloaded template.</p>
<p>Search for deploy on the home page of the portal and select Deploy a custom template. Under common templates, there are templates for creating common resources that you can adapt and modify. We want to build our own template in the editor. Here we have a blank boilerplate template, which I’m going to replace with the template I previously downloaded. I’ll upload the file and save it. Once that’s been loaded, we can see that there are 6 resources in our template – correct. Now we have an interface for entering the parameters for the resource creation. Typing in all those values does seem a bit painful, but if I click edit parameters, I can upload the associated parameters.json file with all the values in it and click save. Boom, and there we go, the values that are entered as part of the resource creation wizard are filled in as parameters. We can do a side by side comparison of the parameters as they relate to the manual portal process Resource Group, virtual machine name, region, VM size, user name, disk type, and networking. I’ll fill in the password and agree to the terms and conditions. The purchase button is a bit misleading, and I assume I won’t be charged for my own template. Anyway, the template validates correctly as I would expect, and the deployment successfully completes.</p>
<p>As with most things Azure, there is a marketplace for templates where you can browse or search for a template that meets, or closely meets your requirements at Azure quick-start templates. I’ll search for something a little bit interesting involving Cosmos, like Create an Azure Cosmos account for MongoDB API autoscale. Clicking on the link takes us to a description of the template and its parameters, along with instructions on how to deploy the template using either PowerShell or Azure command-line interface. Browse on GitHub will take you to the template’s repo where you can download the template JSON files.</p>
<p>Clicking Deploy to Azure takes back to the same Deploy Custom Template page where you can enter the missing parameters using the GUI interface.</p>
<h1 id="ARM-Templates"><a href="#ARM-Templates" class="headerlink" title="ARM Templates"></a>ARM Templates</h1><p>An ARM template is a JSON file describing the resources or services that you want to deploy and it has many advantages. Templates are idempotent. This means changes are applied only once, which is exactly what we want. Associated with this is repeatability, and that each time we apply the template we get the same result. Unlike a procedural script where the order of commands is crucial, the template is submitted as one object and Azure Resource Manager works out the order that resources should be created in. So dependency management and orchestration of deployment operations are carried out correctly. That JSON format also allows for nested and hierarchical resources and you can divide up a deployment into multiple linked files to make complex deployments modular and easier to manage. Azure Resource Manager includes commands for testing templates, and Azure DevOps has a task for including ARM templates in pipelines.</p>
<p>A template file is made up of five sections. There are parameters that can be passed into the template. A parameter has a name and a type, for example, string or int for integer, so like programming data types. There is a functions section, this is where you define your own functions. This is in addition to the ARM template built-in functions. Any values you want to use within the template are defined in the variables section. So not variables in the traditional programming sense, but more like constants. Of course, we have a resources section which is obviously the most important part of the template as this is where we define the resources or services we want to deploy. Finally, we have an outputs section that could be used for displaying information or daisy-chaining templates. Also at the root of the template, we have the JSON schema, which we shall see is very important when building a template and also the content version.</p>
<p>Parameters allow you to pass variables into the template to make its functionality more dynamic. Each parameter object starts with its name. A parameter has a type that can be an int, bool, array, object, string, secure object, or secure string. You can also define a default value, allowed values and minimum and maximum lengths or values. Within the metadata section, you can give your parameter a description.</p>
<p>Before I move on to the function section, I just briefly want to touch on the built-in functions that are available within ARM templates. As you can see from this table, there are quite an extensive array of built-in functions, ranging from array functions through to string, although not all of the string functions have been listed here. Many of the functions are what you would expect to find in most programming languages and definitely in the .NET environment. Resource functions are there to provide access to your Azure resources and account settings, while the deployment value functions allow you to access different sections of the template.</p>
<p>User-defined functions are more like formulas or expressions rather than functions that you might find in a procedural programming language. They do take parameters that are defined with a name and a data type and the return type called output also has a defined data type. Template variables and parameters are global and can be used within user-defined functions. While you can use built-in logical functions within your user-defined function, there is no facility for iterations or for-loops. Essentially user-defined functions are a way of separating out complex or compound functionality that you want to use more than once into a separate piece of template code.</p>
<p>Variables are key-value pairs that are defined once and can be used throughout the template. As I said earlier, they are more like constant values as they can’t be assigned to once defined. Variables don’t have to be simple data types, they can be nested and complex JSON objects. The resource section is the main event, if you will. This is where we define the resources or services that we want to deploy. For obvious reasons, different resources will have different properties but there are some properties that all resources must contain. Every resource needs a name and every resource is of a type and is located somewhere. The resource shown here is an app service and depends on another resource of the type app service plan.</p>
<p>Output values are essentially the inverse of parameters. They enable you to output values from your template for either informational purposes or as inputs to linked templates, that we shall look at later, or to be used in scripts that executing the template.</p>
<h1 id="DEMO-Virtual-Machine-Template"><a href="#DEMO-Virtual-Machine-Template" class="headerlink" title="DEMO: Virtual Machine Template"></a>DEMO: Virtual Machine Template</h1><p>Let’s look at how the template structure relates to the virtual machine template we previously downloaded. I’m using Visual Studio Code to view the JSON files. Here we have those 22 parameters, followed by the three variables, and then the 6 resources. A virtual machine deployment involves more than just the machine. There is all the supporting network and security infrastructure that allows you to safely connect to and use the VM. Here we have a resource name which is one of the parameters that we input to this template. That’s the parameter definition specifying its data type. If I go over to parameters.json I can see the value that is being inserted for network interface name. Going back to template.json we can see each resource has a type, that is what resource is created. This is a network interface which is defined in the region specified by the location parameter. We have a security group name, virtual network resource, a public IP address resource, the actual virtual machine itself with the various nested properties that define that machine like its size, which is also retrieved from the machine size parameter. Here we have the virtual machine’s dependsOn section specifying that the VM requires the network interface and storage resources.</p>
<h1 id="DEMO-Simple-Template"><a href="#DEMO-Simple-Template" class="headerlink" title="DEMO: Simple Template"></a>DEMO: Simple Template</h1><p>I know what you’re thinking, this is very complex, and where do I start? Well, as luck would have it, Visual Studio has some fantastic features for creating and editing ARM templates. To access the ARM template intellisense, you need to have the Azure Resource Manager Tools extension installed in VS Code.</p>
<p>First thing I’m going to do is create a new file, and save it with the JSON extension. Straightaway, we can see that VS Code recognizes this as a JSON file. This is where the magic starts, or more correctly intellisense, when I type ARM for Azure Resource Management. We can see I have code auto-complete here with some prompts. I’m just going to select the top one, which is a resource group template and there we have all the sections that we have talked about earlier. So if I want to create a simple web app deployment, all I have to do is go into resources and once again type ARM, and we can see here we have a lot of resources to choose from.</p>
<p>Now this is all context-based, and I’m going to select web app, and there we have all the properties that we need to create a web app deployment. Obviously, I don’t want my app to be called webApp1. So I’m going to create a parameter of type string, called appname. We can see here with the yellow squiggly line that part of the template functionality is that it recognizes that I haven’t used that parameter yet. So, I’ll go down here and type open square bracket P and you see the auto-complete prompts with parameters. I’ll pick parameters and type open bracket and I’m prompted with the parameter appname. I can then go and I can just replace all the instances of webApp1 with my appname parameter. Every resource has a type and in this case it’s a web site and it’s already put in the ARM tags and properties for us.</p>
<p>In the dependsOn section, we can see a service plan. But before I define that I’m going to show you how we can test our template before deploying it. If I go to my PowerShell window, which I’ve already logged into Azure and enter Test AzResourceGroupDeployment, I’m prompted for the parameter appname, which I’ll supply, called howdeploywebapp. It’s returned with an invalid template error. It’s complaining that it doesn’t have an appServicePlan1.</p>
<p>Okay, so I need to back in the resources section and I will add a service plan and I will also add another parameter called planname. I can use that parameter everywhere I’ve got appServicePlan1, and that is even within the app service itself, like in this concat function. As you can see, functions, parameters and variables are used within square brackets. The error in the concat function indicates a missing comma. Right, so I’ll save that. Just notice here that the location is picked up from the resource group.</p>
<p>So when we are testing, we are testing it with AzResourceGroupDeployment, and that relies on the fact that it belongs to an existing resource group as opposed to using the Test-AzDeployment command. I’ll go back here and re-run this, howdeploywebbapp and the plan name is howdeployplan and we can see that has been successful. So let’s go ahead and deploy that. I’ll just go back here and change my test to new. Now we can go over to the portal and see what’s happening. If I refresh deployments, we can see we’ve got a deployment happening. Let’s click on that and go into it, and it’s complete. I’ll navigate back to the resource group home page so we can see the newly created resources.</p>
<p>Right, so here we have the plan and the app, and as you would expect. Clicking on the app service resource takes us to the app service, where we can click on the app service URL to see it deployed.</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;$schema&quot;: &quot;https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#&quot;,</span><br><span class="line">  &quot;contentVersion&quot;: &quot;1.0.0.0&quot;,</span><br><span class="line">  &quot;parameters&quot;: &#123;</span><br><span class="line">    &quot;appname&quot;: &#123;</span><br><span class="line">      &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;description&quot;: &quot;description&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;planname&quot;: &#123;</span><br><span class="line">      &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;description&quot;: &quot;description&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;    </span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;functions&quot;: [],</span><br><span class="line">  &quot;variables&quot;: &#123;&#125;,</span><br><span class="line">  &quot;resources&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;[parameters(&#x27;planname&#x27;)]&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;Microsoft.Web/serverfarms&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;2018-02-01&quot;,</span><br><span class="line">      &quot;location&quot;: &quot;[resourceGroup().location]&quot;,</span><br><span class="line">      &quot;sku&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;F1&quot;,</span><br><span class="line">        &quot;capacity&quot;: 1</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;tags&quot;: &#123;</span><br><span class="line">        &quot;displayName&quot;: &quot;[parameters(&#x27;planname&#x27;)]&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;[parameters(&#x27;planname&#x27;)]&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;[parameters(&#x27;appname&#x27;)]&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;Microsoft.Web/sites&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;2018-11-01&quot;,</span><br><span class="line">      &quot;location&quot;: &quot;[resourceGroup().location]&quot;,</span><br><span class="line">      &quot;tags&quot;: &#123;</span><br><span class="line">        &quot;[concat(&#x27;hidden-related:&#x27;, resourceGroup().id, &#x27;/providers/Microsoft.Web/serverfarms/&#x27;, parameters(&#x27;planname&#x27;))]&quot;: &quot;Resource&quot;,</span><br><span class="line">        &quot;displayName&quot;: &quot;[parameters(&#x27;appname&#x27;)]&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;dependsOn&quot;: [</span><br><span class="line">        &quot;[resourceId(&#x27;Microsoft.Web/serverfarms&#x27;, parameters(&#x27;planname&#x27;))]&quot;</span><br><span class="line">      ],</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;[parameters(&#x27;appname&#x27;)]&quot;,</span><br><span class="line">        &quot;serverFarmId&quot;: &quot;[resourceId(&#x27;Microsoft.Web/serverfarms&#x27;, parameters(&#x27;planname&#x27;))]&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;outputs&quot;: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
</blockquote>
<h1 id="DEMO-Linked-Template"><a href="#DEMO-Linked-Template" class="headerlink" title="DEMO: Linked Template"></a>DEMO: Linked Template</h1><p>In this demonstration, I want to show you how to use linked templates. That’s how you can separate resources into separate template files to make management easier and to reuse resources and deployments. This is a little bit of a contrived example but what I’m going to do is separate out the app plan resource from the app service deployment. </p>
<p>First of all, create a new file that I will save as appsplandeploy.json and start with the ARM template boilerplate structure. Then move the plan name parameter along with the plan resource from the existing template file to the new one. </p>
<p>In the appsplandeploy template, I will need to define an output parameter that will pass the planname to the parent or calling template. That output parameter will be the plan name and will be of type String and the value is simply going to be the parameter planname that is being passed in. </p>
<p>I’m going to create a new file for my web app deployment called websitedeploy. This will be the parent or master template. It will just be the content from the original template, so yes I could have just renamed the file.</p>
<p>We can see here that we already have some issues with our missing parameter and service plan, so I will need to add a link to the appsplandeploy template, and I will do that by creating a nested resource. </p>
<p>While link and nested might not be intuitive, I guess that is exactly what we are doing; we are nesting this linked resource within our main resource template. One thing to be aware of is that the template file cannot be accessed locally, you must have that file accessible by HTTP, which means storing it somewhere on the Internet, and in my case, I’ve created container storage where I will upload that template file to. I’ll just upload that file to my storage container templates inside the howarmtemplate storage account. I’ll grab the link to the file and I will paste it into the URI property of the template link section. Obviously the other issue we need to address is the now redundant planname parameter and we do that by using a reference function to reference the output value from our linked template. So the reference name is the name of my linked template resource. I’ll just change the name of that resource from nested deployment to linkedTemplate. </p>
<p>We reference our outputs with the word outputs, then it picks up the name of the output, which is planname, and then we want to use the keyword value to get its value.</p>
<p>We no longer need the dependsOn section, so I will get rid of that. Another thing you need to be aware of is that the reference function does not work as a parameter within another function, that is, you cannot nest it with another function. Replacing the planname parameters within the linked template reference inside the concat function will throw a template error.</p>
<p>One thing I forgot to mention was that in the app service plan template as it is being linked from our website deploy template we will not be prompted for our plan name parameter. Just for the purposes of demonstration, and it is definitely not best practice, I will use the default parameter to specify a plan name. Later on we will look at a much better option. I’ll just save appsplandeploy and refresh it to my blob storage. Before we continue I’ll demonstrate how that reference function within the concat function will give an invalid template error by running a Test-Az- ResourceGroupDeployment. Here we have the invalid template error’s telling us there is a problem at line 30 column 9 and the function reference is not expected at this location. Line 30 column 9 isn’t really accurate but the closest reference we have to that is within the tags property, but I know this to be the case and I will change it and we will retest. Having changed that tag property it passes the test deployment so I can now deploy for real using the new-azresourcegroupdeployment command. Going back to the portal and into deployments of the resource group, we can see the link template and the website deploy are both in action. If we go and have a look at the link template deployment and in outputs we can see the plan name output value and obviously that is also the input for the website deploy deployment.</p>
<p>Let’s recap what’s gone on here. We started with a resource template that had an app service plan and a website. Then we took the app service plan and we put it in another template file; this is called a linked or nested template. The app service plan template file is linked to the master template using a deployments resource. Values are passed from the master into the linked template with parameters, and values generated in the linked template can be passed back to the master with outputs. Input parameters take the same format as we’ve already seen, while outputs are analogous to return values of a programming function. Linked or nested templates must be stored on-line and referenced with a URL. Template deployments can be tested with the Azure CLI test-azresourcegroupdeployment command, taking the resource group and template file as parameters. Once successfully tested a template can be deployed to Azure with the new-azresourcegroupdeployment command.</p>
<h1 id="DEMO-Parameter-Template"><a href="#DEMO-Parameter-Template" class="headerlink" title="DEMO: Parameter Template"></a>DEMO: Parameter Template</h1><p>Obviously, using a default parameter in our linked template, which is essentially the same as hard coding, the value is completely unacceptable and almost pointless. Before I show you how to use a parameter file to dynamically change parameters, I’ll just delete the web app and plan. Let’s go back to visual studio code and create a new JSON file called deploy parameters, and from the autocomplete, I will choose the parameter template. We just need the app name and plan name parameters with values inside the parameter template and add the plan name parameter to the website deploy template. </p>
<p>With the parameters set up I’ll save and close the the template file, and go back to appsplandeploy.json and add the plan name parameter to the website deploy template. The plan name parameter in this template, website deploy is where the plan name comes in from externally. Then we will pass it to the linked or nested template via a parameter within the linked template resource below.</p>
<p>Now in the parameters section of the linked template resource I will just add the plan name parameter and pass it the parameters planname value. This is a completely ridiculous and circular scenario in reality as the plan name parameter is being passed to the link template and then subsequently retrieved through the outputs value. But this is just to give you an idea of how to use parameters in linked templates using the previous example. Now, to deploy the resources, we’ve got the parameters in a file. That file will be passed as a parameter to the new-azresourcegroupdeployment command. The parameter values get pulled out of the JSON file and matched by name to the parameters defined in the ARM template file. Those parameters, can in turn be passed to linked or nested templates, by matching on name.</p>
<p>Let’s switch over to the PowerShell command prompt. First I’ll test the deployment, specifying the resource group name, the ARM template file, and the parameters file. Okay having successfully tested that I will now redeploy by executing the new resource group deployment command with the template parameter. We can see in the PowerShell CLI and the portal that it has successfully executed.</p>
<h1 id="DEMO-Database-Deployment"><a href="#DEMO-Database-Deployment" class="headerlink" title="DEMO: Database Deployment"></a>DEMO: Database Deployment</h1><p>As I’ve said the demos so far have been a little contrived. Now I want to show you a few of the more advanced features of ARM templates like the use of user-defined functions and how to create multiple instances of a resource type using something that could be called a looping mechanism. We will then deploy that template via a PowerShell script which will involve creating a new resource group and then submitting the template parameters using a template object. Let’s begin by creating a new template. I’m going to call it arm deploy and once again that will be a resource group template. In terms of resources, we are going to need a database server and then obviously some databases to run on that server. From the ARM template autocomplete I’ll select arm-sql-server and then arm-sql-db for my resources.</p>
<p>For parameters, I will need a server name and because I am creating more than one database I’m going to need a parameter that lets me tell the template how I databases I want. I will call that dbcount. Because we are accessing Azure SQL I will also need to provide an IP address for the database firewall. That will be startip and endip to define the IP address range. In terms of naming the databases, I’m going to call them test_db and that name will have a number appended to it, and also define an admin name and password. I’m defining these as variables to demonstrate the variable use, but you could just as well pass them in as parameters. I’ll replace SqlServer1 with the servername parameter, which will have to be changed in several places. I’ll also replace the administrator login and password with my variables. Next, I’ll replace the firewall start IP and end IP addresses with the corresponding parameters.</p>
<p>When it comes to the database name this is where it all gets a little bit interesting. So the database name is made up of the server name&#x2F;followed by the database name so the first thing I’m going to have to do is concatenate my server name parameter with the database name. But of course, the database name is a compound of the DB prefix variable plus the database number. To make up this compound name I’m going to define a function that will return the name. Let’s go into the functions section and we’ll look for arm-user, which is for user-defined function. I’ll give my function a name of databasename, and like all functions it takes parameters. This is where the auto complete doesn’t fully meet expectations. The function section has to have a namespace property and all functions have to be defined within a members section of the functions section. I’ll need a parameter for my database name prefix and I will need an integer parameter for the number that will be appended to the name. The return value or output is a string and it is a concatenation of name prefix and index, which I’ll join together with the built-in conact function. Going back to the database name I will use the databasename function firstly by starting with the namespace and the function name. Then I will use the DB prefix variable as my first parameter and then a built-in function called copy index. I guess you could say copyindex is a little bit like the index of a for loop, although we have yet to tell the database template to make copies. I’ll just replace the SqlServer1 text with the server name parameter in the depends on section for my database, as obviously, a database does depend on a database server. Now I’ll add the copy section. So it has a name and it has a count and that count is the number of copies to make and I will get that from my dbcount parameter. I’ll just replace the display name and tags with my compound database name.</p>
<p>Now that we are done with the template let’s move on to the PowerShell script. So this is going to be called dbarmdeploy.ps1 and Visual Studio Code recognizes the file extension and that I’m working with a PowerShell script and it is doing a nice job of syntax highlighting for me. So I’ll start by declaring a resource group variable and I will give it a name and a location. The location is the Azure abbreviation for the West US region. Next, I want to issue the command to create a new resource group. So that’s New-AzResourceGroup with a name and the location, which is the location element of the resource group variable. Next, I’m going to create a compound template variable which will have the name of my template as file name and nested within it the parameters that I want to submit. So that will be server name dbcount, startip and endip. I’ll create a new deployment with New-AzResourceGroupDeployment and use the resource group variable to get the ResourceGroupName parameter. Then the template variable to get the file name for -TemplateFile and then the template parameters object will be for the -TemplateParameterObject parameter, my word that’s a mouthful of parameters. Just in case that wasn’t clear, the TemplateParameterObject is a compound parameter, whereas the other parameters are strings. Right, let’s save that and go to the PowerShell command prompt, and run the script. Straightaway we can see the resource group has been created so that’s a good start, and if we pop over to the portal we can see that the deployment is running. If I open up an Azure SDK command prompt I can issue a deployment group list command to see which deployments are running for my resource group. At the top, I can see the name of the deployment is armdeploy so using that I can issue and az deployment group show command with my resource group and then the name of the deployment. This will also return all the details of the deployment plus the provisioning state at the bottom which is currently showing it as running.</p>
<p>Okay, the server has been deployed and Azure resource manager has accepted the database deployments. Going back to the PowerShell window we can see that the whole deployment has finished successfully and it returns our input parameters. I’ll just open up SQL Server management and log into the database server and check out my to test databases. Finally, I will remove the resource group with the force parameter so I’m not prompted.</p>
<h1 id="Deploying-with-a-Script"><a href="#Deploying-with-a-Script" class="headerlink" title="Deploying with a Script"></a>Deploying with a Script</h1><p>As I said at the beginning of this course in the architecture section, Azure Resource Manager accepts commands from PowerShell and the Azure CLI. In a way, templates are a little bit like the portal in terms of providing an alternative interface. Everything that you can do with a template you can do with a script. Here is an example of what a script might look like for creating a resource group in an Azure SQL server with firewall rules and a database. In some ways, this does seem more concise and easy to understand what exactly is going on here, but in one crucial respect, templates have an advantage over scripts when it comes to deployment mode.</p>
<p>Azure Resource Manager has two deployment modes; the default, which is incremental, means that whatever is in your deployment is added to your resource group, whereas complete says the resource group will become whatever is in your deployment. This essentially means that the resource group is cleaned out before the deployment is applied or all resources that are not in your deployment are removed from the resource group.</p>
<h1 id="Course-Summary"><a href="#Course-Summary" class="headerlink" title="Course Summary"></a>Course Summary</h1><p>Let’s recap what we have learned about Azure Resource Manager. It’s not the Azure portal. It’s the behind-the-scenes process that’s mostly involved with managing the deployment of resources in the Azure cloud. There are multiple interfaces for interacting with Azure Resource Manager apart from the graphical interface of the portal.</p>
<p>You can issue commands through PowerShell and the Azure CLI, but the preferred method is to use ARM templates. Azure Resource Manager templates are JSON files with sections that allow you to specify parameters, variables, functions, and resources. There is also an outputs section so you can pass values from one template to another.</p>
<p>A template can specify multiple resources, and multiple resources can be specified in multiple template files that are linked to a master template deployment file. Visual Studio Code has an IntelliSense extension for creating ARM templates. This extension has auto-complete and syntax checking and greatly simplifies the creation of templates.</p>
<p>As well as defining your own functions, there are many built-in functions to work with strings, arrays, logical comparisons, and Azure resources. Once a template has been defined, it can be tested with the Test-AzResourceGroupDeployment command. The template can then be deployed to Azure using the New-AzResourceGroupDeployment command. Both of these commands can be actioned either through PowerShell or the Azure CLI.</p>
<p>When a deployment is in progress you can monitor it through the portal or by using the Az group deployment list and show commands. You don’t have to create your template from scratch. You can download deployments as templates that you have created previously through the portal. This reaffirms the architecture of the portal as an interface to the Azure Resource Manager.</p>
<p>There is also a marketplace of Quickstart templates that you can use as-is, or download and modify. ARM templates simplify deployment by taking care of dependency management and orchestration. Unlike deploying resources with a script, you don’t have to worry about the order you define your resources in. Testing a deployment will let you know if dependencies are missing, and if you deploy without testing either the whole template is successful or none of it succeeds. You won’t end up in a situation with half of your resources deployed due to missing dependencies.</p>
<p>When a new resource or service becomes available on Azure often deploying an instance is only available using ARM templates and commands. Quite often a resource is released and there may be some time before the portal is updated to support it. But the main reason to become familiar and experienced with Azure Resource Manager is that it is by far the easiest method to ensure that your deployments are consistent and repeatable. This is of particular importance when deploying infrastructure as code through a DevOps pipeline.</p>
<h1 id="Course-Introduction-1"><a href="#Course-Introduction-1" class="headerlink" title="Course Introduction"></a><strong>Course Introduction</strong></h1><p><a target="_blank" rel="noopener" href="https://github.com/cloudacademy/intro-to-arm">Github Repo</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Lab-Developing-with-the-Cosmos-DB-Core-API-and-Change-Feed-24/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Lab-Developing-with-the-Cosmos-DB-Core-API-and-Change-Feed-24/" class="post-title-link" itemprop="url">AZ-204-Lab-Developing-with-the-Cosmos-DB-Core-API-and-Change-Feed-24</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 11:24:10 / Modified: 11:24:12" itemprop="dateCreated datePublished" datetime="2022-11-14T11:24:10-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Lab-Developing-with-the-Cosmos-DB-Core-API-and-Change-Feed-24/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Lab-Developing-with-the-Cosmos-DB-Core-API-and-Change-Feed-24/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/64/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/64/">64</a><span class="page-number current">65</span><a class="page-number" href="/page/66/">66</a><span class="space">&hellip;</span><a class="page-number" href="/page/199/">199</a><a class="extend next" rel="next" href="/page/66/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">1986</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
