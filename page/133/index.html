<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hang&#39;s Blog">
<meta property="og:url" content="https://example.com/page/133/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/page/133/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Hang's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-Intrusion-Detection-and-Prevention-on-Amazon-Web-Services-43/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-Intrusion-Detection-and-Prevention-on-Amazon-Web-Services-43/" class="post-title-link" itemprop="url">AWS-Security-Specialty-Intrusion-Detection-and-Prevention-on-Amazon-Web-Services-43</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:54" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:54-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 23:03:16" itemprop="dateModified" datetime="2022-11-19T23:03:16-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-Intrusion-Detection-and-Prevention-on-Amazon-Web-Services-43/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-Intrusion-Detection-and-Prevention-on-Amazon-Web-Services-43/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-Lab-Query-Encrypted-Amazon-S3-Data-with-Amazon-Athena-42/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-Lab-Query-Encrypted-Amazon-S3-Data-with-Amazon-Athena-42/" class="post-title-link" itemprop="url">AWS-Security-Specialty-Lab-Query-Encrypted-Amazon-S3-Data-with-Amazon-Athena-42</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:52" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:52-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 23:02:54" itemprop="dateModified" datetime="2022-11-19T23:02:54-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-Lab-Query-Encrypted-Amazon-S3-Data-with-Amazon-Athena-42/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-Lab-Query-Encrypted-Amazon-S3-Data-with-Amazon-Athena-42/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-Lab-Using-S3-Bucket-Policies-and-Conditions-to-Restrict-Specific-Permissions-41/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-Lab-Using-S3-Bucket-Policies-and-Conditions-to-Restrict-Specific-Permissions-41/" class="post-title-link" itemprop="url">AWS-Security-Specialty-Lab-Using-S3-Bucket-Policies-and-Conditions-to-Restrict-Specific-Permissions-41</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:50" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:50-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 23:04:04" itemprop="dateModified" datetime="2022-11-19T23:04:04-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-Lab-Using-S3-Bucket-Policies-and-Conditions-to-Restrict-Specific-Permissions-41/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-Lab-Using-S3-Bucket-Policies-and-Conditions-to-Restrict-Specific-Permissions-41/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-AWS-Security-Best-Practices-Abstract-and-Container-Services-40/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-AWS-Security-Best-Practices-Abstract-and-Container-Services-40/" class="post-title-link" itemprop="url">AWS-Security-Specialty-AWS-Security-Best-Practices:-Abstract-and-Container-Services-40</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:49" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:49-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 22:54:02" itemprop="dateModified" datetime="2022-11-19T22:54:02-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-AWS-Security-Best-Practices-Abstract-and-Container-Services-40/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-AWS-Security-Best-Practices-Abstract-and-Container-Services-40/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hello and welcome to this course where we shall be looking at two different classifications of AWS services, these being Abstract and container services.</p>
<p>This course focuses on the security best practices that surround the most common services that fall into each of these classifications. To help you adopt and implement the correct level of security within your infrastructure.</p>
<p>Before we start, I would like to introduce myself. My name is Stuart Scott. I’m one of the trainers here at Cloud Academy, specializing in AWS Amazon Web Services. Feel free to connect with me with any questions using the details shown on the screen. Alternatively, you can always get in touch with us here at Cloud Academy using the community forum where one of our Cloud experts will respond to your question.</p>
<p>This course has been designed to help those who implement or manage cloud security, such as a cloud solutions architect, cloud security specialist, or similar. This course will also be useful for anyone looking to enhance their AWS security skills across a number of different services.</p>
<p>This course will cover a range of topics, including:</p>
<p>What are AWS Abstract and container services? This lecture provides you with a clear understanding of what Abstract and container services are within AWS.There is a clear divide between the two which be understood as responsibilities around security is a key difference between them.</p>
<p>Security controls, data at rest and in transit. Here we will take a look at some of the available options and best practices to help you maintain integrity and protection around your data when at rest, in transit, and held within a number of container and Abstract services.</p>
<p>Security controls, network segmentation. In this lecture, we’ll look at how we can use the network infrastructure and architecture to connect and restrict access to our container and Abstract services to increase security through a number of different controls.</p>
<p>Identity and access management. IAM is heavily used for both container and Abstract services and plays a key part in authorization and authentication for access and management. This lecture looks at how IAM can be used to help protect access across your services.</p>
<p>Built-in service security controls. This lecture will briefly look at some of the service specific security controls that may not have been covered in the previous lectures that you can leverage to help secure your data and environment.</p>
<p>As a student of this course, you will obtain the following:</p>
<p>An understanding of the difference between both container and Abstract services within AWS and how security is managed differently between the two.</p>
<p>An awareness of how data can be protected at rest and in transit for different services.</p>
<p>A comprehension of the importance of network design in increasing the security of Abstract and container based services.</p>
<p>The ability to apply the correct level of security to your services depending on their classification, container or Abstract using security features from other AWS services as well as the services own built-in protection.</p>
<p>During this course I will cover some of the common services under container and Abstract services. As it is discussed, it will help to have a basic level of understanding of these services but it’s not imperative to understand the details. With container services, we’ll be looking at RDS, EMR, and Elastic Beanstalk. For Abstract services, we’ll be looking at S3, DynamoDB, and SQS. In addition to these services, a basic understanding of the following is also recommended, VPCs and IAM.</p>
<p>As this course is focused on best practices rather than a detailed instructional how to course, there may be terms and phrases that are unfamiliar to you that you may want additional information and clarity on. Therefore, I will attach a glossary to this course which you can find on the course’s landing page.</p>
<p>Feedback on our courses here at Cloud Academy are valuable to both us as trainers and any students looking to take the same course in the future. If you have any feedback, positive or negative, it would be greatly appreciated if you could use the comments section found on the landing page of this course.</p>
<p>That brings us to the end of this lecture. Coming up next, we will take a look at what container and Abstract services are and the differences between them.</p>
<h1 id="AWS-Abstract-and-Container-Services"><a href="#AWS-Abstract-and-Container-Services" class="headerlink" title="AWS Abstract and Container Services"></a>AWS Abstract and Container Services</h1><p>Hello, and welcome to this lecture, where we shall look at what AWS abstract and container services are, as well as the differences between them.</p>
<p>So, before we get into the nitty gritty of security contact, it’s important that we understand what AWS defines as these abstract and container services. There was a chance that when I mentioned container services, you may immediately been thinking of <a target="_blank" rel="noopener" href="https://cloudacademy.com/blog/aws-ec2-instance-types-explained/">AWS EC2 Container Service</a>, knows as ECS, and its association with Docker; however, this is something completely different, as I already explained during this lecture, but I just wanted to clarify that point straightaway.</p>
<p>Both container and abstract services can be seen as different service classifications. We are aware of AWS service categories which can be seen from the AWS Management Console such as Compute, Storage, and Database, but the classifications that are referred to are not listed or defined within the Management Console. So, what are they?</p>
<p>Let’s start by looking at what is defined by AWS Container Services.</p>
<p>Services that fall under container services have the following characteristics:</p>
<ul>
<li>the service itself runs on separate infrastructure instances, such as EC2.</li>
<li>AWS is responsible for managing the operating system and the platform.</li>
<li>A managed service is provided by AWS, which is typically the service itself for the actual application which are seen as containers.</li>
<li>As a user of these container services, you have a number of management and security responsibilities, including managing network access security, such as network access control list rules and any firewalls.</li>
<li>Also, platform-level identity and access management where it exists.</li>
<li>Examples of AWS container services include Relational Database Service, Elastic Mapreduce, and Elastic Beanstalk.</li>
</ul>
<p>Now, if we take a lot of the characteristics of abstract services to see how these compare …</p>
<ul>
<li>These services are removed, abstracted, from the platform or management layer which cloud applications are built on.</li>
<li>The services are accessed via endpoints using AWS application programming interfaces, APIs.</li>
<li>The underlying infrastructure, operating system, and platform is managed by AWS.</li>
<li>The abstracted services provide a multi-tenancy platform on which the underlying infrastructure is shared.</li>
<li>Data is isolated via security mechanisms.</li>
<li>Abstract services have a strong integration with IAM, and examples of abstract services include S3, DynamoDB, Amazon Glacier, and SQS.</li>
</ul>
<p>So, as you can see, the main differences between the two relate to responsibilities, control, and the level of administration and customization you have over the chosen service. Container services provide you with a greater level of control and responsibility than those of abstracted services, largely due to the fact they are not providing shared tenancy of the underlying service infrastructure, whereas abstract services do. Also, abstract services are not typically deployed within specific availability zones, as they are accessed via endpoints and so are abstracted from your VPC infrastructure.</p>
<p>As listed within these two definitions, there are some boundaries between responsibilities of security between you and AWS, and this is an important point. So let’s look at this in greater detail, as it will help you understand and define the differences between the two.</p>
<p>One of the main principles of AWS security is that it operates its security processes via a model called the AWS shared responsibility model. This dictates which security controls are AWS’s responsibility and which are yours. Now, depending on the service being used and deployed within AWS, the boundaries of responsibilities will vary. When planning and architecting your security policies, it’s essential you have a clear understanding of where these boundaries lay for difference services.</p>
<p>There are three main models that AWS uses to define these responsibilities, these being:</p>
<ol>
<li>the shared responsibility model for infrastructure services</li>
<li>the shared responsibility model for container services and</li>
<li>the shared responsibility model for abstract services.</li>
</ol>
<p>By taking a look at each of these models, we will be able to clearly see the differences. So let’s start by looking at the first model, based upon infrastructure, which includes services such as EC2. We will see how the level of responsibility shifts as we move onto container and then abstract services.</p>
<p>Although this course does not cover infrastructure services, I just want to graphically show you the change of responsibility as we go through the different models.</p>
<p>As we can see from this model, it’s down to you to decide how secure you want your resources to sit in the cloud while AWS guarantees the global security of the cloud.</p>
<p>Looking at AWS responsibilities first, this covers the global infrastructure elements: regions, availability zones, and edge locations, and also the foundation of their services, covering compute, storage, database, and network.</p>
<p>AWS owns and controls access to their data centers, where your data resides. This covers physical access to all hardware and networking components, and any additional data center facilities, including generators, UPS, power distribution units, computer room air conditioning, and fire suppression systems. Essentially, AWS is responsible for the components that make up the cloud. Any data put into the cloud then becomes your responsibility.</p>
<p>So moving onto your responsibility, and as I’ve just mentioned, securing what goes into the cloud falls upon you. This covers both client and server encryption and network traffic protection. All the way up to the security of the operating system, network, and firewall configuration, followed by application security and identity and access management.</p>
<p>How much of this additional security you wish to implement is entirely your decision. What you choose may depend on the nature of the business or on existing controls you may already have in place. For example, it’s up to you if you want to implement network access control lists, or NACLs, or encrypt your data.</p>
<p>The important point to remember is that while AWS provides many powerful security controls, how and when to apply them is not AWS’s responsibility.</p>
<p>Now, we’ve covered this first model. Let’s see the shift of responsibility as we start to look at container services.</p>
<p>Straightaway, we can see that both platform and application management, along with any operating system and system and network configuration, has shifted to being the responsibility of AWS, and is no longer down to us as the customer to manage. This is a huge difference from that of infrastructure-based services. However, not all responsibility has shifted. Note that firewall configuration remains the responsibility of the end user, which integrates at the platform and application management level. For example, RDS uses security groups of which you would be responsible for configuring and implementing.</p>
<p>Now, let’s look at the shared responsibility model for abstract services.</p>
<p>You will notice that even more responsibility has been shifted to AWS; specifically, network traffic protection, which AWS will manage via the platform, protecting all data in transit using AWS’s own network. You are responsible for using IAM tools to apply the correct permissions, both at the platform such as S3 bucket policies, and IAM user and group level.</p>
<p>As we progress through each of these models, it’s clear to see that the level of control and responsibility shifts more towards AWS than that of the customer. So how does that affect how we apply security around these services that fall into the container and abstract classifications? How can we ensure that when we use these services, tight integration of security controls are applied? Coming up in the next lecture, we will address these questions.</p>
<p>Lectures:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/introduction-70/">AWS Security Best Practices</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/aws-abstract-and-container-services/">AWS Abstract and Container Services</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-data-at-rest-and-in-transit/">AWS Encryption at rest and in transit</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-network-segmentation/">Network segmentation</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/indentity-and-access-management/">Identity and Access Management</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/built-in-service-security-controls/">Built-in Service Security Controls</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/summary-14/">Summary</a></li>
</ul>
<h1 id="Security-Controls-Data-at-Rest-and-In-Transit"><a href="#Security-Controls-Data-at-Rest-and-In-Transit" class="headerlink" title="Security Controls: Data at Rest and In Transit"></a>Security Controls: Data at Rest and In Transit</h1><h3 id="Referenced-Resources"><a href="#Referenced-Resources" class="headerlink" title="Referenced Resources"></a><strong>Referenced Resources</strong></h3><p><strong>AWS Links:</strong></p>
<p><a target="_blank" rel="noopener" href="https://aws.amazon.com/blogs/big-data/process-encrypted-data-in-amazon-emr-with-amazon-s3-and-aws-kms/">Implementing SSE and CSE with EMR</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/awslabs/aws-dynamodb-encryption-java">AWS Labs GitHub Repository</a></p>
<p><a target="_blank" rel="noopener" href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html">Using SSL to encrypt a connection to a Database</a></p>
<p><a target="_blank" rel="noopener" href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.Oracle.Options.NetworkEncryption.html">Oracle Native Network Encryption</a></p>
<p><a target="_blank" rel="noopener" href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/configuring-https-endtoend.html">Configuring end-to-end encryption in a load-balanced Elastic Beanstalk envrionment</a></p>
<h3 id="Lecture-Transcript"><a href="#Lecture-Transcript" class="headerlink" title="Lecture Transcript"></a><strong>Lecture Transcript</strong></h3><p>Hello and welcome to this lecture where we sure look at the different security controls that can be used to help you architect and implement a secure solution around your container and abstract services.</p>
<p>From this point onwards within this course I will provide some best practice controls for the following services, for both container and abstract classifications.</p>
<p>So for container services we’ll be looking at:</p>
<ul>
<li>RDS</li>
<li>EMR, and</li>
<li>Elastic Beanstalk</li>
</ul>
<p>And for the abstract services we’ll be looking at:</p>
<ul>
<li>S3</li>
<li>DynamoDB</li>
<li>SQS and</li>
<li>Glacier</li>
</ul>
<p>These services have been selected as they’re some of the most common services utilized within each classification. However, if you’re using container or abstract services other than the ones listed here, then the principles that I cover throughout this course will enable you to look into those services with the same approach and at least be aware of what to look out and architect for when planning and applying your security policies.</p>
<p>Okay, let’s get started by looking at some of these security controls that you can implement to increase the security around these different services. Starting with the protection of your data, but more specifically on how to protect your data at rest.</p>
<p>EMR is a managed service by AWS and is comprised of a cluster of EC2 instances. That’s a highly scalable to process and run big data frameworks such as Apache Hadoop and Spark.</p>
<p>A key point to make it is that by default EMR instances do not encrypt data at rest. The instances used with EMR are created from pre-configured AMIs, Amazon Machine Images, that have been published and released by AWS. You are not able to use your own custom AMIs in an EMR cluster. Similarly, the same applies to EBS volumes for a persistent storage within the cluster which are again supplied by AWS.</p>
<p>EMR can also use DynomoDB or S3 for its persistent data store which you can either access directly or copy the data from these services to its own persistent data store on to HDFS, Hadoop Distributed File System.</p>
<p>Although EMR does not encrypt data at rest by default there are a number of mechanisms you can use if your data is sensitive enough or perhaps you’re required to do so for compliance reasons.</p>
<p>If you decide to use persistent storage rather than S3 or DynamoDB, then there’re a number of options available that can work together, if you enable local disk encryption in your EMR security configuration. Once enabled the following features are available.</p>
<ul>
<li>Linux Unified Key Setup, which allows EBS cluster volumes to be encrypted</li>
<li>Also Open-Source HDFS Encryption, which provides two Hadoop encryption options: Secure Hadoop RPC and Data encryption of HDFS Block Transfer.</li>
</ul>
<p>As mentioned previously, we could use S3 as our persistent data store for EMR. If this was the case then you could use S3’s very own encryption tools. As we know S3 is an abstract service and as a result you could apply server-side encryption SSE-S3, to encrypt the data that is stored at rest. To help with this configuration EMR allows you to apply security configuration that specifies security settings on how you can encrypt your data. You can either encrypt data at rest, data in transit, or, if required, both together. The great thing about these security configurations is that they’re not actually a part of the cluster itself. They exist within EMR and therefore you can reuse the same security configuration for existing clusters or others you plan to use in the future.</p>
<p>As a part of this security configuration you have the choice of AWS managing your encryption keys for you on S3, using the SSE-KMS, Server-Side Encryption with Key Management Service, or by using the SSE-S3 method. Alternatively, you could choose to manage your own encryption keys with client-side encryption. If we refer back to the shared responsibility model for abstract services, we can see this difference of responsibility clearly here.</p>
<p>For those unfamiliar with SSE it’s an encryption method used in Amazon S3 to encrypt any object at rest. It’s completely managed by AWS along with the encryption keys which themselves are also automatically encrypted and rotated regularly by S3. SSE-S3 uses the 256-bit Advanced Encryption Standard, AES-256, algorithm for its encryption. When using SSE-KMS AWS will configure and create a KMS customer muster key, CMK, and associate all relevant policies to work with your EMR cluster. More information on KMS can be found here.</p>
<p>In addition to SSE, S3 offers Client-Side Encryption with KMS or a customer key provider. Alternatively you could encrypt your data using your application before storing it on S3 where it would remain stored in an encrypted form, for example, using a serializer&#x2F;deserializer with Hive.</p>
<p>More information on implementing SSE and CSE with EMR can be found <a target="_blank" rel="noopener" href="https://aws.amazon.com/blogs/big-data/process-encrypted-data-in-amazon-emr-with-amazon-s3-and-aws-kms/">here</a>.</p>
<p>Another option is to apply encryption at the application level by encrypting the entire file. Alternatively and again at the application level you could encrypt individual fields within your data by using a standard serializer&#x2F;deserializer such as JSON for Hadoop.</p>
<p>So at a fairly high level there’re just a few mechanisms that you can choose to apply encryption at rest on EMR which, remember, is not provided by default. For more information on how to set up these different methods of encryption in detail I recommend you visit the relevant AWS documentation pages on EMR.</p>
<p>Let’s now take a look at another container service: RDS.</p>
<p>RDS allows you to set up a relational database using a number of different frameworks, such as MySQL, MS SQL Server, and Oracle, at cetera.</p>
<p>During the creation of your RDS database instance you have the opportunity to enable encryption on the Configure Advanced Settings screen under Database Options, Enable Encryption. By enabling encryption here you’re enabling encryption at rest for your storage, snapshots, read replicas, and your backups. Keys for all of this encryption can be managed by the AWS Key Management Service.</p>
<p>KMS utilizes the AES-256 encryption algorithm which is the same used in S3 for its server-side encryption. This encryption mechanism is completely transparent to any applications reading and writing data to the database.</p>
<p>In addition to encryption offered by RDS itself at the application level, there’re additional platform level encryption mechanisms that could be used for protecting data at rest, including Oracle and SQL Server Transparent Data Encryption, TDE. This could be used in conjunction with the method already discussed, but it would impact the performance of the database. Also, MySQL cryptographic functions. More information on this can be found <a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/8.0/en/encryption-functions.html">here</a>. And lastly, Microsoft SQL Transact-SQL cryptographic functions. And again, you can find more information on this using the <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/sql/t-sql/functions/cryptographic-functions-transact-sql?redirectedfrom=MSDN&view=sql-server-ver15">link</a> on the screen.</p>
<p>In comparison to EMR, encryption at rest for RDS is simplified, thanks to the built-in application level encryption option, which EMR does not have.</p>
<p>We have looked at a couple of examples for how data can be encrypted at rest with container services. Now let’s visit the abstract services. We have already covered elements of S3 when we discussed Elastic MapReduce, but there’re additional protection mechanisms offered by S3 other than server-side and client-side encryption that helps to protect your data when at rest.</p>
<p>Securing and protecting your data at rest is not always about encryption, it’s also about availability and reliability of being able to access your data. By default, S3 replicates your objects across all availability zones within the region where your data was uploaded. On a side note, S3 also supports cross-region replication, but this has to be configured manually. The automatic replication between availability zones ensures that you will still be able to access your data in the event of an availability zone outage, therefore protecting your data when at rest. It doesn’t, however, protect the data against accidental or malicious deletion. To help protect against this, S3 allows you to implement versioning on your buckets. By default this is not enabled, but once enable it cannot be disabled, only suspended.</p>
<p>S3 versioning, as the name implies, allows you to version control objects within your bucket. This allows you to recover from unintended user changes and actions, including deletions, that might occur through misuse or corruption. Enabling versioning on the bucket will keep multiple copies of the object. Each time the object changes a new version of the object is created and access the new current version. One thing to be aware of with versioning is the additional storage cost applied in S3. Storing multiple copies of the same object will use additional space and increase your storage cost.</p>
<p>Now let’s take a quick look at Glacier and DynamoDB.</p>
<p>By default, AWS Glacier encrypts data at rest using server-side encryption. For each archive created with Glacier, a new key is generated and the data is encrypted using AES-256 algorithm. AWS manages these keys, all key rotations, and the keys themselves are encrypted with a master key which is also stored and managed by AWS.</p>
<p>If you want to add another layer of protection for your data on Glacier, then you should simply encrypt the data before sending it to Glacier.</p>
<p>DynamoDB does not currently have support for any server-side encryption. This means any encryption for data at rest falls upon you to implement. It is possible to encrypt your data if you’re using Java by using an AWS client-side library for encrypting. This can be found from the AWS Labs GitHub repository.</p>
<p>Another option is to encrypt your data with an application development framework before saving and storing your data with DynamoDB.</p>
<p>As we have looked at securing data at rest for a couple of container and abstract services, let’s turn our attention now to see how we can secure data when in transit.</p>
<p>Let’s start by looking at RDS, a container service. When communicating with the RDS instance, for example from the application, then you can secure that communication using SSL&#x2F;TLS, Secure Sockets Layer&#x2F;Transport Layer Security, which will encrypt that data whilst in transit.</p>
<p>This is recommended if you have to abide by specific compliance and governance controls or when the data being sent to RDS is highly sensitive, perhaps containing customer information.</p>
<p>The method in which this process is carried out varies depending on which database type you have. For more information on the implementation of the encryption please visit the <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html">link</a> on the screen.</p>
<p>If you’re using Oracle with RDS, then instead of using SSL encryption between the client and the database, you could use Oracle’s Native Network Encryption, NNE, which will encrypt all connections to and from the database. It is, however, not possible to use both SSL and NNE together for encryption, one of them must be switched off to then use the other. More information on NNE can be found <a target="_blank" rel="noopener" href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.Oracle.Options.NetworkEncryption.html">here</a>.</p>
<p>When using EMR, there’re again a number of options. Similar to when we looked at EMR for securing data at rest on the ABS, we mentioned the following when local disk encryption was enabled in the security configuration.</p>
<p>These encryption features are also used for encrypting data in transit for Hadoop along with Hadoop MapReduce Encrypted Shuffle which uses SSL&#x2F;TLS.</p>
<p>For this course I won’t go into the full range of other in-transit encrypting methods for other big data frameworks running on EMR, but realize others do exist for Spark and Tez. And so for information on what these are and how to configure them, please refer to the relevant AWS documentation.</p>
<p>When EMR communicates with S3 or DynamoDB to transport data then this communication will be sent over an encrypted HTTPS protocol.</p>
<p>When users connect to the EMR cluster for admin purposes then it’s recommended that this is conducted over a Secure Shell, SSH, a cryptographic network protocol, encrypted connection.</p>
<p>Next, if we take a quick look at data protection for Elastic Beanstalk, it can be achieved using HTTP over SSL with signed certificates. This would allow clients to access your website and application where data will be encrypted in both directions, from the client to your Elastic Beanstalk environment. When doing so, by default, the encryption in transit will exist between the client requesting access and your Elastic Load Balancer for Elastic Beanstalk. From the ELB to your backend instances the data will then be unencrypted.</p>
<p>If you need end-to-end encryption for compliance or sensitivity reasons, then this level is possible but it will require additional configuration and implementation. For detailed instructions on how to implement this, please see the following <a target="_blank" rel="noopener" href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/configuring-https-endtoend.html">link</a>.</p>
<p>Let’s now take a look at how encryption in transit is handled for some of the abstract services starting with S3.</p>
<p>With S3 being a managed abstract service encryption in transit is managed by AWS, and so all communication with S3, whether it be from the AWS Management Console over an API, or from the AWS CLI, it will be encrypted. S3 uses HTTPS and SSL connections to encrypt any communication into and out of S3 automatically.</p>
<p>When accessing DynamoDB over the internet the only connections that should be allowed and permitted are those that use HTTPS to ensure the data is encrypted.</p>
<p>Taking a step back from container and abstract services for a moment, I want to briefly mention how data in transit is secured when using the AWS Management Console. The console uses SSL between your browser and the AWS service endpoints in addition to an X.509 certificate to authenticate the identity of the console service endpoint.</p>
<p>If using an SDK, the AWS CLI, or an AWS API call not from the AWS Management Console, then these are RESTful APIs over HTTPS. When the SSL connection is made between the two endpoints all traffic is then encrypted and protected.</p>
<p>That brings us to the end of this lecture. And I know we only covered a handful of services. I hope you can see that between both container-based and abstract services there’re security features that can be used to protect your data both when in transit and at rest. There’re differences between the amount of configuration and control that you have between the different classifications, and again, this comes down to the different shared responsibility models that they operate between.</p>
<p>Coming up next we’re going to look at how the configuration of your network infrastructure can actively be used as a security layer.</p>
<p>Lectures:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/introduction-70/">AWS Security Best Practices</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/aws-abstract-and-container-services/">AWS Abstract and Container Services</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-data-at-rest-and-in-transit/">AWS Encryption at rest and in transit</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-network-segmentation/">Network segmentation</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/indentity-and-access-management/">Identity and Access Management</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/built-in-service-security-controls/">Built-in Service Security Controls</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/summary-14/">Summary</a></li>
</ul>
<h1 id="Security-Controls-Network-Segmentation"><a href="#Security-Controls-Network-Segmentation" class="headerlink" title="Security Controls: Network Segmentation"></a>Security Controls: Network Segmentation</h1><p>Hello, and welcome to this lecture where we are going to discuss how the configuration of your network infrastructure can help you increase security specifically for your container services. If we remember back to the lecture entitled AWS abstract and container services, where we looked at the different responsibility models, we can see that the responsibility for network traffic control lays firmly in the hands of us, the customers. As a result, we must look at the best ways to architect and secure our services and data, utilizing different network features and controls.</p>
<p>Within this lecture, we’re going to cover the following topics and how each one can help you secure container services. So we’ll be looking at subnets, both public and private, routing tables, network access control lists, known as NACLs, security groups, network address translation and bastion hosts. Let’s start out by looking at a high level at what each of these controls are, starting with public and private subnets within your VPC.</p>
<p>Firstly, what is a subnet, and what makes us subnet public or private? Subnets allow you to segment your VPC into different networks with different IP ranges, which is important both from a deployment and design perspective and also for security. Segmentation allows you to refine your security profile as appropriate for each of the services operating within each subnet. A subnet is the distinct network segment with its own IP address range within the larger VPC CIDR block. So let’s have a quick look at how these subnets look and their network diagram.</p>
<p>So we have a VPC with a network range of 10.0.0.0&#x2F;16, so that’s our VPC CIDR block. And then we have a private subnet within this with 10.0.1.0&#x2F;24 and another private subnet with an IP address range of 10.0.2.0&#x2F;24. And each subnet is in a different availability zone. It’s important to point out here that subnets cannot cross availability zones. So what is the difference between a public and a private subnet? Well, you can only have a public subnet when the following two conditions are true. Firstly, you need to have an internet gateway attached to your VPC. And secondly, you need to have a route from your subnet pointing to the outside world via the internet gateway. If both of these conditions are met, then that subnet is considered to be a public subnet. If your subnet does not meet this criteria, then you have a private subnet.</p>
<p>So if we take a look at our network diagram again to see how these controls fit in. Without an internet gateway attached to your VPC, then your VPC is at that point an isolated network, only accessible via the Management Console or the AWS CLI. By attaching an internet gateway to your VPC, it provides your VPC a gateway to the outside world. And this internet gateway is provided and managed by AWS. All we need to do is to create it and attach it to our VPC. When the internet gateway is attached, a subnet still doesn’t know it exists, as there are no routes to that internet gateway to the outside world.</p>
<p>At this point, your subnet and other subnets are still classed as private. That is why it is only when point two from the conditions I mentioned previous is true, that the subnet is then classed as a public subnet. There has to be a route. So here we can see that there’s now a route from subnet 10.0.1.0&#x2F;24 to the internet gateway via a public route table. And between the two subnets, we just have a private route. So when this public subnet is configured, traffic can then traverse in and out of your VPC public subnet and potentially beyond depending on security controls you have set up between other private subnets.</p>
<p>As we briefly mentioned, when you have more than one subnet, you can implement routing between the two network segments using route tables which are attached to the subnet itself. These route tables define which subnets can talk to which other subnets. This helps you isolate traffic between specific subnets to help increase security and by only allowing communication between subnets that needs to talk to each other. You may have submits where instances never need to send traffic to instances or services in another subnet. If so, then it’s best practice to ensure no route between these two subnets exist. Also attached to each subnet is something called a network address control list, a NACL.</p>
<p>NACLs provide a rule-based tool for controlling ingress and egress network traffic at the protocol and subnet level. In other words, NACLs monitor and filter traffic moving in and out of a network. You can attach a NACL to one or more subnets within your VPC. If you haven’t created a custom NACL, then your subnets will automatically be associated with your VPC’s default NACL, which allows all traffic to float in and out of every subnet. One point to mention is that NACLs are stateless in their design, meaning that any response traffic generated from a request will have to be specified in either the inbound or outbound rule set depending on the direction of response expected.</p>
<p>So again, if we go back to our network diagram, we can see that we have two NACLs, both a public and a private NACL, that control ingress and egress network traffic at the subnet level. Security groups are very similar to NACLs, but they work at the instance level rather than the network subnet level. AWS security groups are associated with instances and provide security at the protocol and port access level. Each security group, working much the same as a firewall, contains a set of rules that filter traffic coming into and out of an EC2 instance. There are no deny rules like there are with NACLs. Rather, if there is no rule that explicitly permits a particular data packet, it will be dropped. Whereas NACLs are stateless by design, AWS security groups are stateful, meaning that response traffic does not need to be specified in the inbound&#x2F;outbound rule set. So if we have a quick look at our network diagram just to see the placement of our security groups, and there you can see, within our security groups, we’ve have instances that are protected by the conditions within those security groups.</p>
<p>Now let’s look at what a NAT is. From a security stance, a NAT, network address translation, essentially allows your private instances to have outgoing connectivity to the internet while at the same time blocking inbound traffic from the internet, therefore protecting your private instances. Your NAT resides within the public subnet. This is useful for allowing your private instances to access the internet for important operating system updates that may be required.</p>
<p>Lastly, at a high level, a bastion host sits within your public subnet, which should only be accessible by authorized personnel via a secure connection using SSH or RDP. Once remote connectivity is established with the bastion host, the host then acts as a jump server, allowing you to SSH or RDP to log into other instances within private subnets deeper within your network. When properly configured for the use of security groups and network ACLs, the bastion essentially acts as a bridge to your private instances via the internet. If you require remote connectivity with your private instances over the public internet, then a bastion host would be a great solution. There are many ways to secure your bastion host, and it should be locked down as much as possible, such as hardening your chosen operating system. If this is not locked down sufficiently and gets breached by a malicious user, then they could potentially gain access to your internal instances, too. Again, looking at our network diagram, we can see that our NAT instance sits within our public subnet along with our bastion host.</p>
<p>Okay. Thus far, we have looked at some of the network security controls that are available within the VPC. I now want to talk about some of the container services and how they can leverage these features to implement additional security. As before, let’s run through some of the container services mentioned previously to see the best placement within a VPC, starting with RDS.</p>
<p>As we know, RDS is a database service and as such, will often store sensitive customer data for some application. This application could be a web app which will be accessible from the internet by the general public. In this scenario, we would only want internet users to interact with the web server and not the back end infrastructure, such as the application servers, or more importantly, the database where the customer data may be stored. As a result for security concerns and possibly governance controls, your RDS instances should be located within a private subnet within your VPC, removing the exposure to the internet like we have with the public subnet. This essentially creates multiple layers within your infrastructure through the use of multiple subnets. From a network architecture perspective, a best practice approach would be to use different subnets carrying out similar functions to create different layers within your infrastructure. For example, you would have a public subnet which would act as a public internet layer. Here you may have an Elastic Load Balancer receiving incoming traffic from your web application. Next, you will have a threat protection layer where network level security appliances can intercept and analyze traffic before being sent to the next layer.</p>
<p>Next, we’ll have a web server layer. This is where your web servers will be located to manage the web communications from your users. Following this, an application layer. This is where your application will process the requests from the web servers. And finally, your database layer. And this is where your RDS instances will be located to store any data from the application processing. As you can see, by placing your RDS instances in the fifth level behind the other four layers, the likelihood of malicious users and traffic getting access to your RDS instance is significantly reduced, especially when you begin to couple this with other security features we have discussed, such as NACLs, security groups and route tables.</p>
<p>The route tables for these subnets can be configured to only allow communications with the subnets both above and below its current layer. For example, the subnet for layer three only needs to be able to communicate with layer two and four subnets. Routes to subnet one and five can be removed from the route table. For Elastic Beanstalk, we can use the same approach. Again, we are responsible for implementing the correct level of security for environments that are deployed via the Elastic Beanstalk service, which, often by design, have a multi-layered approach of web, app and database infrastructure components.</p>
<p>Grouping similar elements and spitting others into different subnets enhances the overall security of the deployment. This grouping allows you to implement other security features, such as NACLs and security groups more effectively, as the number of protocols and ports being used will be kept to a minimum, thus narrowing any room for error or malicious access. For example, an incoming NACL applied at level five subnet, the database layer, using the layered example previously discussed, may look like the following. This keeps the network firewall restricted to only those ports expected by the instances within that subnet, which, in this case, would be MySQL running on RDS.</p>
<p>In addition to this network-level security, it would be advisable to also implement security groups to add another level of security protection at the instance level. In this example, we would use VPC security groups to control this access. One security group would contain all the application servers, and another security group would contain the database instances. This would ensure that the only communication between the application servers and the database servers will be between the instances included within the respective security groups over specific ports that are defined inside the security group. It’s recommended that you define the specific ports here instead of opening up access to communicate over all TCP ports for example.</p>
<p>With RDS being a container service, platform and application management is taken care of. As a result, the need to patch the instance and perform updates on the database itself falls under the responsibility of AWS. Therefore, the need for NAT implementation is not required to perform these actions. I briefly mentioned the Elastic Beanstalk earlier, where I referenced the resources caught up to deploy your environment to run your application. Depending on your configuration, you will likely be using a number of resources between your public and private subnets. And so it’s imperative to make use of the range of network security features throughout the VPC that we’ve already mentioned.</p>
<p>Again, AWS offers the ability for Elastic Beanstalk to manage updates to your underlying platform, run a new application, such as PHP, Java, et cetera, the OS as well as the web and application server updates. By design, Elastic MapReduce automatically uses some of these VPC security features, in particular, security groups. During an EMR job flow, EMR will launch and create two different EC2 security groups. One that sets the security for the master node and the secondary security group for the slaves. This secondary security group only allows communication between the slaves and the master. The master security group allows communication between itself and the AMR service and resources, such as S3 for pulling data. As these are security groups, we have the ability to modify and change these groups as necessary. So we still have full control over security from this perspective. </p>
<p>Again, the EC2 instances used by EMR within its cluster should be located within a private subnet, especially, if the data is sensitive. This subnet would also have its own NACL. Always protect your data and services where possible within private subnets. If the data or service does not need to be access over the internet, then they should be within private subnets behind NACLs, behind route tables and not made accessible via the public subnet. If we take a quick look at our abstract services, the network security is largely taken care of by AWS as the shared responsibility model dictates. </p>
<p>Firstly, DynamoDB. DynamoDB is an abstract database service, whereas RDS is a container database service. There are some fundamental differences between the two as expected. More of DynamoDB security, operational controls and underlined maintenance falls under the responsibility of AWS. For example, DynamoDB hardware failover and data replication is taken care of by AWS automatically and does not have to be configured like it does in RDS by setting multi-AZ failover. Also with DynamoDB, you do not place a database yourself within a particular AZ or network segment, being an abstracted service. And as such, network inspections around security for DynamoDB are also managed by AWS. This approach remains the same for both S3 and SQS.</p>
<p>Network security controls and management for these services are managed by AWS and are governed by the security mechanisms impose on AWS’s own network. However, controlling who has access to these services does require you to set up the necessary authorized permissions. This is largely related to identity and access management, IAM, and this is what we will be discussing in the next lecture. So to summarize this lecture quickly, we can clearly see that there’s clear distinction between the amount of network security control we have over container services to those of abstract services. Detail, care and attention should be taken to ensure the correct level of network security is used to protect your data when using these container services. Genuinely speaking, container services offer more control, along with that is an increased effort to secure them however. Conversely, abstract services are easy to set up, as AWS is responsible for the lion’s share, but also offer less control. </p>
<p>Lectures:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/introduction-70/">AWS Security Best Practices</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/aws-abstract-and-container-services/">AWS Abstract and Container Services</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-data-at-rest-and-in-transit/">AWS Encryption at rest and in transit</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-network-segmentation/">Network segmentation</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/indentity-and-access-management/">Identity and Access Management</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/built-in-service-security-controls/">Built-in Service Security Controls</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/summary-14/">Summary</a></li>
</ul>
<h1 id="Identity-and-Access-Management"><a href="#Identity-and-Access-Management" class="headerlink" title="Identity and Access Management"></a>Identity and Access Management</h1><p>Hello, and welcome to this lecture, where we will look at how the IAM service is used to help implement security across both container and abstract services.</p>
<p>IAM is tightly integrated with both of the shared responsibility models, and both of them require you to understand the different methods of using IAM to implement the different security controls around these services.</p>
<p>This lecture will not cover how to create and setup these controls. More information on how to do this can be found within our existing courses and labs, Introduction to IAM, and Advanced Roles and Groups Management Using IAM.</p>
<p>Regardless of the service, you must be familiar with AWS IAM. This will allow you to control who has access to which services and also under which conditions. IAM policies allow you to configure conditional access. For example, configuring access only during set time periods or from a specific IP address.</p>
<p>IAM enforces multiple methods of authentication and authorization against resources within your AWS environment. Detailed information on this subject can be found in our existing course entitled Understanding of AWS Authentication, Authorization, and Accounting.</p>
<p>So let’s take a look at how IAM can help to control access to our container services, looking firstly at RDS.</p>
<p>An authenticated identity whether that be a user within your AWS account, a user from another account, another service, or even a federated user from your on-premise Microsoft active directory environment, the identity can access your RDS instance providing they have authorized permissions to do so. Using the correct permissions and access control, you are able to grant or restrict access on a granular level within RDS. For example, you can specify who can create an RDS database, who can access it, and who can run snapshots, et cetera, all through using IAM policies attached to the user, group, or role. As I said earlier, these permissions can even be based on specific conditions. For example, only to allow access at a specific time of day or from a specific IP address.</p>
<p>IAM policies are JSON formatted files. The following policy example only allows the user to create an RDS instance using the MySQL as the database engine type using the Condition parameter.</p>
<p>RDS permissions can only be given through IAM policies. There are no resource based policies that can be applied like it’s possible within S3, such as bucket policies or S3 ACL’s.</p>
<p>You must review who should have access to your database along with the correct level of permissions. Be as granular as possible when looking at data security across your databases. For improved management, create groups and roles, and apply permissions to these rather than individual users.</p>
<p>EMR also uses IAM to control access to its resources, such as the clusters and the data itself, again with policies, groups, and roles that we have already discussed. To understand the full level of access that can be granted or denied, see the EMR documentation provided by AWS.</p>
<p>By default, when an IAM user launches a new cluster, it is restricted to only that user. No other IAM users are ever to see the clusters; however, there is an option to make the cluster visible to all IAM users if required.</p>
<p>To help you manage permissions for EMR within IAM, you could always implement the AWS managed policies and assign them to users, groups, or roles. If they do not fully fit your requirements, then you can copy, edit, and customize these policies as required, which saves a lot of time and effort. And this applies to all services discussed within this lecture, and these AWS managed policies are a good source to base your permissions upon.</p>
<p>Looking at our abstract services, we can apply all of the same IAM security controls that we have already discussed; however, there are some differences worth noting. For example, when we look at S3, we can implement additional resource based access control methods, such as bucket policies and access controllers, which can specify permissions at an object level given granular access. When there are conflicting access permissions between IAM and resource based permissions, then access will be granted on a least privileged basis.</p>
<p>So, for example, the user John may have access of our IAM policy that grants access to delete objects within bucket CA-Lecture. In addition to this, there is a bucket policy attached to a bucket CA-Lecture that explicitly denies the principle John to delete objects. If John tried to delete an object within this bucket, he would be denied as access is granted based on least privileged and a denial will always take precedence over an allow.</p>
<p>As we are already aware, IAM allows you to create very specific permissions against different services for access. DynamoDB is no exception, and, in fact, with IAM, you can even grant access to specific rows within a DynamoDB table for specific users given a fine grained access control on the database itself.</p>
<p>As you can see, there isn’t a huge amount of difference between how IAM is used to manage authentication, authorization, and access control to both container and abstract services. IAM is fundamental in granting users and services access to resources within AWS.</p>
<p>This access control centers around the following components of IAM:</p>
<ul>
<li>Users</li>
<li>Groups</li>
<li>Roles, and</li>
<li>Permissions</li>
</ul>
<p>Understanding how these interact with each other is imperative in applying an effective security policy from an access control perspective. Like I mentioned earlier, we have courses on IAM that go into these details in great detail, and I highly recommend you take these courses.</p>
<p>In addition to these IAM components, other services such as S3 may have their own resource level permissions, which you should invest time into understanding in order to help you add another layer of security to your data, and this may be required for specific governance controls depending on the data being used.</p>
<p>That brings us to the end of this lecture, and coming up next, we take a brief look at how some of the services have built-in functionality to help you secure your data. Understanding the services you’re working with is just as important as understanding the security features offered by other AWS services such as IAM.</p>
<p>Lectures:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/introduction-70/">AWS Security Best Practices</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/aws-abstract-and-container-services/">AWS Abstract and Container Services</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-data-at-rest-and-in-transit/">AWS Encryption at rest and in transit</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-network-segmentation/">Network segmentation</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/indentity-and-access-management/">Identity and Access Management</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/built-in-service-security-controls/">Built-in Service Security Controls</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/summary-14/">Summary</a></li>
</ul>
<h1 id="Built-in-Service-Security-Controls"><a href="#Built-in-Service-Security-Controls" class="headerlink" title="Built-in Service Security Controls"></a>Built-in Service Security Controls</h1><p>Hello, and welcome to this short lecture, where we are going to take a look at a couple of the security controls that are built into different services and are available for you to configure and implement.</p>
<p>When using the service, you should look at how to correctly architect and implement the service using all of the features that are available to you, and helpful to meet your requirements. Many of the services within AWS have specialized components that can greatly enhance the security of your data. And as such, they should be explored.</p>
<p>Security of your data isn’t always about encryption or preventing people from accessing it. For example, data security also ensures that the data is available when you need to access it. This durability of your data enhances your data security.</p>
<p>RDS is able to offer durability and availability of your data. For a feature that allows you to set up your database in readiness for a failover to take place. This is an optional element to configure when you create your database, and it is called Multi-AZ, Multiple Availability Zones. By enabling Multi-AZ, RDS will automatically configure a secondary database of your primary database in a different availability zone to that of your primary. In the event of the primary database becoming unavailable, RDS will automatically update any DNS entries, and redirect database traffic to the secondary database, which will then become the primary. This significantly enhances the reliability of your data within the database, securing its availability and durability.</p>
<p>With RDS being a managed service, it also has automatic backups and snapshots. Automatic backups enables point-in-time recovery, in allowing you to specify exactly what time you want to recover from within specific customizable parameters. In addition to these automatic backups, you can also create a snapshot of your entire database, which have to be initiated by a user. Once you have a snapshot, you can move and copy this between regions and, if required, create a new database from your snapshot.</p>
<p>S3 also has a number of built-in functionalities to help protect your data, including Multi-Factor Authentication Delete, known as MFA Delete. MFA Delete enforces additional security measures to be used when an object within a bucket is set for deletion. If a user wants to delete an object, then not only does that identity have to have the required delete object access for that object or bucket, but they also have to use an additional MFA device, virtual or physical, to obtain a six-digit code to confirm the deletion.</p>
<p>In this short lecture, I just wanted to give a couple of examples of how different services, whether they are container-based, or abstract, provide additional level of security. Among all of the other security features within AWS to help protect you, remember there are also features and components that you can use within each of the services to help you add additional levels of security to your environment.</p>
<p>Understand what your services are truly capable of, and what each of their features are. The likelihood is that there are unused features that would be of benefit to your AWS infrastructure.</p>
<p>That brings us to the end of this lecture. Coming up next, we will take a look at our previous lectures to summarize what we’ve learned.</p>
<p>Lectures:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/introduction-70/">AWS Security Best Practices</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/aws-abstract-and-container-services/">AWS Abstract and Container Services</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-data-at-rest-and-in-transit/">AWS Encryption at rest and in transit</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/security-controls-network-segmentation/">Network segmentation</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/indentity-and-access-management/">Identity and Access Management</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/built-in-service-security-controls/">Built-in Service Security Controls</a></li>
<li><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-security-best-practices-abstract-and-container-services/summary-14/">Summary</a></li>
</ul>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Hello and welcome to this lecture, where we shall briefly summarize what we have covered.</p>
<p>By now, you should understand that there are clear differences between AWS container services and Abstract services. These two classifications fall under two different shared responsibility models that offer various levels of AWS and customer management roles. It’s important to understand which model your service falls under, whether that be infrastructure, container or Abstract, as this dictates how much of a responsibility you have to manage and architect the correct level of security for your environment.</p>
<p>As a general rule, when using container based services you will have more control and operational management of the service then those of Abstract services. You’ll also have greater manipulation as to where the container service physically resides, such as within the private or public subnet, enabling you to utilize network security controls. Whereas your Abstract services will be abstracted from this environment and will be accessed over a service endpoint instead, such as S3, SQS, Glacier and DynamoDB.</p>
<p>With these Abstract services, you’ll not need to maintain the underlying network architecture, as this is a shared multi-tenancy infrastructure that AWS maintains where they enforce their own network security controls on their own managed AWS network.</p>
<p>Throughout both container and Abstract services, there are multiple ways, depending on the service, to apply security at numerous different levels. For example, ensuring security exists for data at rest, in transit, via access controls, at a network level, for data durability and reliability and many more. Much of this access can be implemented at a deep and granular level depending on the sensitivity required on the data you’re using. Some of this may be dictated by security governance and controls that may be required in your environment.</p>
<p>So to reiterate some key points:</p>
<ul>
<li>Container services provide you with more control, operational management and security responsibility than that of Abstract services</li>
<li>Abstract services are managed and maintained by AWS more so than that of any other service classification, container or infrastructure</li>
<li>Roles and responsibilities for customer differ when implementing security controls between the two classifications</li>
<li>Understand the services that your are using and ensure that you are implementing its own security features as an additional layer within your security policies</li>
<li>Whenever necessary and possible implement encryption when data is at rest and in transit</li>
<li>Use the network security features offered by the VPCs, such as NACLs, Security Groups, Route Tables, NATs, Bastion Hosts, to restrict traffic between your different network segments and to enhance the security around your container services</li>
<li>Implement a structured and managed IAM process using groups and roles to manage permissions across your AWS infrastructure ensuring access for users is restricted to only what is necessary</li>
</ul>
<p>If you have any feedback on this course, positive or negative, please do leave a comment on the course landing page. We do look at the comments in our list and your feedback is greatly appreciated.</p>
<p>So that brings us to the end of this lecture and the end of the course. I hope it has given you a better understanding of AWS, Abstract and container services and that you have found it useful. Thank you for your time and good luck with your continued learning of cloud computing. Thank you.</p>
<h1 id="3Security-Controls-Data-at-Rest-and-In-Transit"><a href="#3Security-Controls-Data-at-Rest-and-In-Transit" class="headerlink" title="3Security Controls: Data at Rest and In Transit"></a>3<strong>Security Controls: Data at Rest and In Transit</strong></h1><p><a target="_blank" rel="noopener" href="https://aws.amazon.com/blogs/big-data/process-encrypted-data-in-amazon-emr-with-amazon-s3-and-aws-kms/">Blog: Implementing SSE and CSE with EMR</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/awslabs/aws-dynamodb-encryption-java">AWS Labs GitHub Repository</a></p>
<p><a target="_blank" rel="noopener" href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html">Using SSL to encrypt a connection to a Database</a></p>
<p><a target="_blank" rel="noopener" href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.Oracle.Options.NetworkEncryption.html">Oracle Native Network Encryption</a></p>
<p><a target="_blank" rel="noopener" href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/configuring-https-endtoend.html">Configuring end-to-end encryption in a load-balanced Elastic Beanstalk envrionment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-Lab-Securing-your-VPC-using-Public-and-Private-Subnets-39/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-Lab-Securing-your-VPC-using-Public-and-Private-Subnets-39/" class="post-title-link" itemprop="url">AWS-Security-Specialty-Lab-Securing-your-VPC-using-Public-and-Private-Subnets-39</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:47" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:47-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 23:03:06" itemprop="dateModified" datetime="2022-11-19T23:03:06-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-Lab-Securing-your-VPC-using-Public-and-Private-Subnets-39/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-Lab-Securing-your-VPC-using-Public-and-Private-Subnets-39/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-AWS-Virtual-Private-Cloud-Subnets-and-Routing-38/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-AWS-Virtual-Private-Cloud-Subnets-and-Routing-38/" class="post-title-link" itemprop="url">AWS-Security-Specialty-AWS-Virtual-Private-Cloud:-Subnets-and-Routing-38</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:45" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:45-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 22:52:32" itemprop="dateModified" datetime="2022-11-19T22:52:32-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-AWS-Virtual-Private-Cloud-Subnets-and-Routing-38/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-AWS-Virtual-Private-Cloud-Subnets-and-Routing-38/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hello, and welcome to this advanced course covering AWS subnets and routing within a VPC, a virtual private cloud. Throughout this course, I shall deep dive on both topics, looking at how each are used within a single and multiple VPC configuration, and also in conjunction with on-premise connectivity across a VPN.</p>
<p>Before we start, I would like to introduce myself. My name is Stuart Scott. I’m one of the trainers here at Cloud Academy, specializing in AWS, Amazon Web Services. Feel free to connect with me with any questions using the details shown on screen. Alternatively, you can always get in touch with us here at Cloud Academy using the community forum, where one of our cloud experts will reply to your question.</p>
<p>This course has been designed for engineers who are responsible for designing, configuring, and implementing AWS virtual private clouds, also for any one performing network configuration within AWS and on-premise solutions, also if you are connecting and configuring a hybrid cloud solution using AWS.</p>
<p>And it’s also for those who are network administrators and network architects, and those wishing to take the Certified Advanced Networking Specialty Certification. Throughout this course, I shall be focusing on VPC subnets and routing, and breaking each of these components down into the following lectures, starting with VPC CIDR blocks.This lecture focuses on the effects of subnetting your VPC CIDR block.</p>
<p>Then I’ll look at why you should subnet your VPC. Here we’ll look at some of the reasons that you might want to do this by looking at the advantages and benefits.</p>
<p>Then we’ll look at VPC subnets, and this lecture dives into what a VPC subnet looks like within the management console, and its associated components, such as network access controllers.</p>
<p>Next we’ll look at VPC peering and its subnet considerations. This lecture focuses on some of the considerations when architecting your subnets in different VPC peering configurations.</p>
<p>Following this, we’ll look at flow logs, and here we’ll take a look at how to monitor the ingress and egress network traffic of each of your VPC subnets using flow logs.</p>
<p>And to wrap up the subnet section, I’ll create a VPC and a number of subnets via a demonstration.</p>
<p>Following those lectures covering subnets, I will then look into AWS routing, and here I’ll cover routing fundamentals and route tables, and this lecture introduces AWS routing and its routing tables by breaking down all the components within it.</p>
<p>Next we’ll look at routing priorities, and here I will explain how the routing priorities are defined for overlapping routes within the same route table.</p>
<p>Next we’ll look at a number of routing configurations, starting with VPC peering, and this lecture looks at the different routing configs for multiple VPC peering scenarios.</p>
<p>And then we’ll do the same for VPN connectivity via a virtual private gateway.</p>
<p>And then following this, we’ll look at some more routing configurations that are used by internet gateways and NAT gateways, and the different dependencies involved here.</p>
<p>And then, lastly with regards to routing configurations, we’ll look at VPC endpoints, and this lecture looks at the automatic route configuration when creating a VPC endpoint.</p>
<p>Once you have completed this course, you will be able to design and implement an effective subnet structure within your VPCs, ensuring they meet specific requirements for your solutions. You’ll understand the differences between public and private subnets. And you will have the ability to architect successful routing configurations for your different VPC designs for both internal and external connectivity options. And you will have an awareness of different VPC gateways for external connectivity.</p>
<p>There are a number of pre-requisites for this course, and as this course is not a beginner’s course to AWS, it’s assumed you have a basic understanding of some of the AWS services specifically to do with a VPC. You should also have a basic understanding of network infrastructure and AWS connectivity, including a basic-level understanding of IPv4 and VPNs. You should also have a basic awareness of common protocols and IP addressing, and a basic awareness of VPC peering and VPC endpoints.</p>
<p>Feedback on our courses here at Cloud Academy are valuable to both us as trainers and any students looking to take the same course in the future. If you have any feedback, positive or negative, it would be greatly appreciated if you could use the comment section found in the landing page of this course.</p>
<p>That brings us to the end of this lecture. Coming up next, we start off by looking at VPC CIDR block ranges.</p>
<h1 id="VPC-CIDR-Blocks"><a href="#VPC-CIDR-Blocks" class="headerlink" title="VPC CIDR Blocks"></a>VPC CIDR Blocks</h1><p>Hello and welcome to this lecture. We’ll actually be talking about subnetting and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-subnets/">VPC subnets</a> in detail.</p>
<p>Let me start by quickly talking about what is meant by subnetting. Subnetting is the process of splitting a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">CIDR block</a> into smaller CIDR blocks within the same range by using different subnet masks.</p>
<p>There are many reasons why you would want to do this and I’ll come on to these later in this lecture. Subnetting enables you to create smaller networks using a smaller CIDR range from your larger network IP address space. For example let’s say you had a CIDR block range of 10.0.0.0&#x2F;16. Which as itself gives you the following network details.</p>
<p>This is a large IP range to have as a single network as it allows for up to 65,534 hosts. To make better use of this range and to create smaller networks allowing segmentation within your network you could subnet the CIDR block into smaller CIDR ranges using a different subnet mask, such as &#x2F;17 for each subnet.</p>
<p>This would provide you with two different subnets with CIDR block ranges of 10.0.0.0&#x2F;17 and black 10.0.128.0&#x2F;17 providing the same range of host addresses minus the network and broadcast addresses for each subnet of course. You can see this by comparing the HostMin and HostMax entries between the three CIDR blocks.</p>
<p>Should you require more than just the two subnets which is likely than you can obviously split the original CIDR block further giving you more than just the two subnets I listed. For example, if I wanted 16 different subnets than I could subnet the CIDR block 10.0.0.0&#x2F;16 by using a subnet mask of &#x2F;20 for each subnet which would provide me with the following subnets.</p>
<p>Again this will provide the same range of host addresses minus the network and broadcast addresses for each subnet. Let’s now look at how the subnetting relates to your AWS VPC. When you create a VPC you are required to enter your VPC CIDR block range. This CIDR block range will encompass the entire IP address space that you can use within that VPC.</p>
<p>So you need to be sure that you set the correct mask allowing you to subnet the RP space into different networks should it be required. Whilst at the same time ensuring there are enough host IP addresses for your instances available within each subnet. As a result consideration must be put to your VPC CIDR block.</p>
<p>At this point it’s important to point out that the maximum and minimum masks for your VPC CIDR block are &#x2F;16 to &#x2F;28. A &#x2F;16 can provide you with 65,531 usable host addresses as one single subnet. A &#x2F;28 will provide you with just 11 host addresses as one single subnet. In addition to the network and broadcast address of the subnet which can’t be used for host addresses AWS reserves the first three host IP addresses of each subnet for internal AWS usage.</p>
<p>The first host address used is for the VPC router. The second address is reserved for AWS DNS and the third address is reserved for future use. Let’s look at this as an example. Sticking with the AWS VPC CIDR block of 10.0.0.0&#x2F;16 let’s imagine we want to create 16 subnets. We would use a &#x2F;20 mask for each subnet as previously mentioned.</p>
<p>In this scenario one of the 16 subnets would be detailed as follows. For this subnet the AWS reservations would be reserved as 10.0.32.1. And this would be for the VPC router as this is the first host address available in the subnet. 10.0.32.2 would be for the AWS DNS being the second available address. And thirdly 10.0.32.3 which would be reserved for any future use service or feature that may be used by AWS.</p>
<p>Which means your available host addresses for any instances would be from 10.0.32.4 through to 10.0.47.254 giving you a total of 4,091 usable host addresses. When allocating your VPC CIDR block range for your VPC it is mandatory to specify an IPv4 range, but you also choose to associate an IPv6 range to your VPC as well.</p>
<p>However when selecting an IPv6 you are not able to specify the range yourself but AWS will provide a &#x2F;56 IPv6 CIDR block for you from their pool of IPv6 addresses. Once you have allocated a CIDR block range for your VPC you are then ready to begin creating different subnets within your VPC. If you need help with your IP addressing and subnet calculations there are a number of free IP and subnet calculators available on the internet that will quickly help you define your requirements.</p>
<p>We have now come to the end of this lecture. Next I will focus on why we should consider adding subnets to a VPC.</p>
<h1 id="Why-Subnet-your-VPC"><a href="#Why-Subnet-your-VPC" class="headerlink" title="Why Subnet your VPC?"></a>Why Subnet your VPC?</h1><p>Hello and welcome to this lecture, where I try to answer the question of why we may want to Subnet our VPCs and what the benefits are by doing so.</p>
<p>Starting with logical network division. Creating multiple Subnets allows you to create logical network divisions between your resources. By doing so, you could have a Subnet for database instances, another for application servers, and another for web infrastructure.</p>
<p>By splitting up your Subnets this way, helps to enforce a greater level of security. Logical grouping of similar resources also helps you to maintain an ease of management across your infrastructure.</p>
<p>On this point, I remember being in a meeting with a network engineer many years ago. And someone around the table asked, “Why do we need to Subnet?” He responded with a question. “Does your house have more than one room? “ He then continued by saying, “It’s a similar thought process, your house has more than one room, as each room serves a different purpose, A kitchen, a lounge, a dining room, etc. Think of these as Subnets. The space in your house, your <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">CIDR block</a>, has been divided into smaller more manageable purpose specific rooms rather than one large room in which you can cook, clean and sleep in, which would soon become very disjointed.”</p>
<p>Security. By having multiple Subnets with similar resources grouped together, as per the previous point, it allows for greater security management. By implementing network level virtual firewalls, called network access control lists, or NACLs, it’s possible to filter traffic on specific ports from both an ingress and egress point at the Subnet level.</p>
<p>For example, if you had a Subnet that only held my SQL RTS databases within it, you could allow communication between your application service Subnet to talk to your database Subnet on port 1443 for my SQL. And then block and drop all other packets that do not meet this criteria. If you had web servers and application servers within the same Subnet as your RTS instances, you would have to open up a lot of other ports, reducing the level of security within that Subnet.</p>
<p>Having multiple Subnets allows you to create both private and public Subnets. Public Subnets allows the resources within it to access and connect to the internet, and the outside world to connect to those resources, depending on certain security controls. Private Subnets are not directly accessible from the internet. And so <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/public-and-private-subnets/">private Subnets</a> are protected from the outside world, providing a greater level of security by its very nature.</p>
<p>You may want some of your Subnets to route out to the internet, some to remain private, and some to communicate back to your corporate on premise network over a VPN link. Through the use of routing tables associated to each specific Subnet, you can route traffic as required to cater for these communication paths.</p>
<p>A Subnet can only belong to one route table at any time. Therefore, by creating multiple Subnets, you can restrict some resources in those Subnets to specific routes. If your solution requires a level of high availability, and it most likely will, then it’s best practice to deploy services across multiple availability zones within a region.</p>
<p>Here becomes a restriction of VPC Subnets in that a single Subnet cannot span across two availability zones. As a result, this best practice forces you to create an additional Subnet in the second availability zone. So if you want high availability within your environment, you’ll need Subnets in at least two availability zones in any region.</p>
<p>As we go through this course, you’ll see the benefits that this provides. As you can see, there are many advantages over creating multiple Subnets within your VPC. And as you design, architect and secure your infrastructure, you will quickly see how multiple Subnets enables ease of network management, rooting and security.</p>
<p>In the next lecture, I want to look at what a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-subnets/">VPC Subnet</a> actually looks like and what its configurable components are.</p>
<h1 id="VPC-Subnets"><a href="#VPC-Subnets" class="headerlink" title="VPC Subnets"></a>VPC Subnets</h1><p>Hello, and welcome to this lecture covering AWS VPC Subnets.</p>
<p>So what does a subnet look like with an AWS, and what information does it contain? Well when the subnet is configured and created within the management console, it contains the data around the following components. Summary, Route Table, Network ACL, Flow Logs, and Tags.</p>
<p>Let’s look at the summary. The summary is just that, a summary of all the elements and metadata associated with the subnet. The Subnet-ID shows the automatically generated ID of the subnet along with its tag name. The Subnet-ID is a unique identifier for that subnet. You can use this value when configuring AWS through a command line interface, such as the AWS CLI.</p>
<p>For example, you could issue a following command to run an EC2 instance in this particular subnet. The IPv4 CIDR section shows the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">CIDR Block</a> associated to that subnet using IPv4. And the same applies for the IPv6 CIDR Block section too. The state of the subnet will either show as pending or available.</p>
<p>The VPC section shows the VPC that the subnet belongs to using its VPC ID, which again, is a unique identifier of the VPC, similar to that of the Subnet-ID. The available IPs list how many IP available addresses you have for your resources left within that subnet. If you try to launch an EC2 instance in your subnet, and it does not have enough free addresses, then you’ll get the following error.</p>
<p>Remember, in addition to the network and broadcast address of the subnet, three other IP addresses are reserved within the subnet for AWS purposes. The Availability Zone shows which AZ the subnet belongs in. And again, subnets cannot span more than one Availability Zone. The Route Table shows which Route Table the subnet is using and is shown by its Route Table ID and Tag name. More on AWS routing will be covered in an upcoming lecture.</p>
<p>The Network ACL, or NACLs, as I refer to, shows the subnet’s associated NACL. And again, by using its NACL ID. During the creation of a new VPC, the default Route Table and the default NACL are also created. These defaults are then associated to any subnet that did not have a custom Route Table or NACL associated.</p>
<p>The Default Subnet section identifies if the subnet was created by default from the default VPC that comes with your AWS account. The Auto-assign Public IP value can either be set to as yes or no, but I’ll talk more about this setting later in this lecture. And finally, the Auto-assign-IPv6 addresses again can be either set to yes or no.</p>
<p>The Route Table tab shows the Route Table that the subnet is using along with the route’s destinations and targets for that route. Further details on configuration of routes will be provided in an upcoming lecture so I won’t go into detail on this section right now.</p>
<p>The Network ACL, or NACL, shows the current NACL associated to the subnet and it will display both inbound and outbound rule sets.</p>
<p>If you haven’t created a custom NACL, then your subnet will automatically be associated with your VPC’s default NACL, which allows all traffic to flow in and out which, by default, provides no level of security, and so I highly recommend you either modify your default NACL or even better, create a custom NACL for each subnet.</p>
<p>NACLs provide a rule-based tool for controlling ingress and egress network traffic at the protocol and subnet level. In other words, NACLs monitor and filter traffic moving in and out of your subnet. NACLs are stateless by their design, meaning that any response traffic generated from a request will have to be specified in either the inbound or outbound rule set depending on the direction of response expected.</p>
<p>The rule set itself is very simple, and has both inbound and outbound list of rules, and these rules are comprised of just six different fields. These being, Rule Number, ACL rules are read in the ascending order, and as soon as a network packet is received, it reads each rule in ascending order until a match is found.</p>
<p>For this reason, you’ll want to carefully sequence your rules with an organized numbering system. I would suggest that you leave a gap of at least 50 between each of your rules to allow you to more easily add new rules in sequence later if it becomes necessary. Type, this dropdown list allows you to select from a list of common protocol types, including SSH, RDP, HTTP, and POP3.</p>
<p>You can alternatively specify custom protocols such as varieties of ICMP. Protocol, based on your choice for type, the protocol option might be grayed out. For custom rules like TCP&#x2F;UDP, however, you should provide a value. Port Range, if you do create a custom rule, you’ll need to specify the port range for the protocol to use.</p>
<p>Source, this can be a network subnet range, a specific IP address, or even left open to traffic from anywhere using the value of 0.0.0.0&#x2F;0.</p>
<p>Allow&#x2F;Deny, each rule must include an action, specifying whether the traffic will be permitted to either enter or leave the associated subnet or not.</p>
<p>The Flow Logs tab shows you any Flow Logs that you have set up and created for the subnet to capture IP traffic flow information. More information on Flow Logs will be covered in a later lecture.</p>
<p>Finally, the Tags tab allows you to add custom key value pairs to help with the tagging of your subnet. In this example, I added a Key of Name with a Value of Subnet A.</p>
<p>That brings us to the end of this lecture. Following this, I shall be talking about the differences between a public and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/public-and-private-subnets/">private subnet</a>.</p>
<h1 id="Public-amp-Private-Subnets"><a href="#Public-amp-Private-Subnets" class="headerlink" title="Public &amp; Private Subnets"></a>Public &amp; Private Subnets</h1><p>Hello, and welcome to this lecture. Where I want to discuss the differences between public and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/public-and-private-subnets/">private subnets</a>, and how they are defined. Now we have seen what a subnet looks like, I want to talk to you about both public and private subnets. In a nutshell, public subnets have direct access to the Internet, whereas your private instances do not.</p>
<p>So what makes a subnet public? There are essentially 2 components required to make any one of your subnets classed as a public subnet. Firstly, you need to create and attach an Internet gateway to your VPC. This Internet gateway is a managed service, controlled, configured, and maintained by AWS. It scales horizontally automatically, and is classified as a highly valuable component of your VPC infrastructure.</p>
<p>Once your Internet gateway is attached to your VPC, you have a gateway to the Internet. However, at this point, your instances have no idea how to get out to the Internet. As a result, you need to add a default route to the route table associated with your subnet. The route could have a destination value of 0.0. 0. 0&#x2F;0, and the target value will be set as your Internet gateway ID.</p>
<p>The destination value of 0.0.0.0&#x2F;0 essentially says for any destinations not already known to the route table, then use this route, which points to the target of the Internet gateway. With an Internet gateway attached, and a route in place, the subnet is now considered to be a public subnet.</p>
<p>There are, however, additional elements required before your instances within that public subnet can access the outside world. Any instance that you’re required to communicate with external resources on the Internet and beyond, will require a public IP address. Also, you’ll need to ensure that your public subnet NACL is not restricting or blocking expected ingress and egress traffic.</p>
<p>For example, if you are using http, and the NACL denied all traffic going over port 80, then you would run into problems very quickly. So to quickly recap, to enable the instances to communicate with the Internet, the following conditions must be true. The VPC must have an Internet gateway attached. The subnet must have a route, for example, 0.0.0.0&#x2F;0, with a target of the attached Internet gateway. The instances must have a public IP address assigned. And the associated NACL must allow ingress and egress traffic. Before moving on from this section, I just want to revisit a point I made about the public IP address allocation for the instances.</p>
<p>Depending on the IP addressing behavior of the subnet, these can either be automatically assigned to new instances launched within the subnet, or you must manually choose to have a public IP address for your instance. By default, all subnets have the automatic assigned of public IP addresses turned off.</p>
<p>Even when a subnet is considered a public subnet. The assignment remains as a manual process for instances. To modify the subnet IP addressing behavior from within the management console, you must first select the subnet within the VPC service, select subnet actions, then select Modify Auto Assign IP Settings.</p>
<p>Select the Tick box to enable auto assign public IPV4 addresses, and then click Save. The subnet will then automatically assign a public IP address to any instances that are launched within that subnet. Do be aware that for each instance created, you can overrule this decision. As you can see, although the default is Enable, it’s possible to select Disable for the instance.</p>
<p>Any public IP address assigned by this method is not directly associated to your AWS account. Instead it’s taken from a pull of addresses owned by AWS, and when the instance is no longer required, the IP address is released back into the AWS pull. You can’t request the same public IP address if you need to use it again.</p>
<p>If you acquire this functionality of being able to reuse, and reassign a public IP address, then you would need to use an elastic IP address, an EIP. Using an EIP is another option we have to give instances public IP addresses. So far, we have looked at VPC <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">CIDR Block</a> Ranges, and subnetting of these blocks into smaller side blocks for subnets, Subnet IP reservation addresses, why you would want and need to subnet your VPC, Public and private subnets within your VPC and subnet IP addressing behavior. However, does any of this change if you have multiple VPCs? What considerations need to be made if you are looking to peer multiple VPCs together?</p>
<p>In the next lecture, we will take a look at VPC peering subnet considerations.</p>
<h1 id="VPC-Peering-Subnet-Considerations"><a href="#VPC-Peering-Subnet-Considerations" class="headerlink" title="VPC Peering: Subnet Considerations"></a>VPC Peering: Subnet Considerations</h1><p>Hello, and welcome to this lecture, where I shall be discussing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-subnets/">subnets</a> when used for VPC peering.</p>
<p>Let me start by explaining what VPC peering is at a high level. VPC peering allows you to connect two or more VPCs together, using IPV4 or IPV6, as if they were a part of the same network.</p>
<p>Once the peer connectivity is established, resources in one VPC can access resources in the other. The connectivity between the VPCs is implemented through the existing AWS network infrastructure, and so it is highly available with no bandwidth bottleneck. As peered connections operate as if they were part of the same network, there are restrictions when it comes to your <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">CIDR block</a> ranges that can be used.</p>
<p>If you have overlapping or duplicate CIDR ranges for your VPC, then you’ll not be able to peer the VPCs together. So this is a design consideration if you plan on setting up multiple VPCs that you want to peer. Also from a design perspective, you are not able to daisy-chain VPCs together expecting them all to talk across one large network.</p>
<p>Each AWS VPC will only communicate with its peer. As an example, if you have a peering connection between VPC 1 and VPC 2, and another connection between VPC 2 and VPC 3 as shown, then VPC 1 and 2 could communicate with each other directly, as can VPC 2 and VPC 3, however, VPC 1 and VPC 3 could not. You can’t route through one VPC to get to another.</p>
<p>To allow VPC 1 and VPC 3 to talk directly, you would have to implement a separate peering connection, between VPC 1 and VPC 3 as shown. Interestingly, the daisy-chain diagram allows the possibility of having two of the VPCs to have overlapping or even identical VPC CIDR blocks.</p>
<p>Let’s say VPC 1 and VPC 3 have exactly the same CIDR block, which both connect to VPC 2. As the peer does not exist between VPC 1 and VPC 3, this is allowed without causing an issue. You may be wondering how this works from a routing perspective, if VPC 2 has two VPCs with the same CIDR block range, where does it know where to send traffic? I shall be covering VPC routing in an upcoming lecture, where this scenario will be discussed and explained.</p>
<p>Now, if we applied the same CIDR block settings in this example to the second scenario, where VPC 1 and VPC 3 were also peered, we would encounter configuration issues, and the peer connection would not be allowed due to overlapping CIDR blocks. We have now come to the end of this lecture covering VPC peering subnet considerations,</p>
<p>in the next lecture I shall be discussing flow logs, and how these can be used to monitor network traffic in and out of your subnets.</p>
<h1 id="Flow-Logs-VPC-Subnets"><a href="#Flow-Logs-VPC-Subnets" class="headerlink" title="Flow Logs: VPC Subnets"></a>Flow Logs: VPC Subnets</h1><p>Hello, and welcome to this short lecture examining flow logs for <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-subnets/">VPC subnets</a>. As you create more and more subnets within your VPC, each with their own network access controls and route table, it won’t be long before you start to encounter communication issues with certain subnets not being able to talk to others over specific ports, or traffic is not being routed as expected.</p>
<p>When you start to troubleshoot these kinds of problems, you’re going to wish you have a helping hand. Within AWS, that comes in the form of VPC flow logs. These flow logs capture IP traffic going in and out of your network interfaces. And these flow logs can be created for subnets, your entire VPC, or even a single interface.</p>
<p>Once activated, the login information is sent to a CloudWatch log group, where you are able to filter information and monitor specific metrics. To set up flow logs for your subnet, first select Subnets within the VPC service in the management console. Select your subnet, select Subnet actions, select Create Flow Log.</p>
<p>You will then be prompted to enter a number of details to complete the setup. Let’s take a look at these.<br>- The filter. This allows you to specify the type of traffic to log. Available options are, all, accept, or reject.<br>- The role. As flow logs need to be able to publish data to a CloudWatch log group, permission is required in the form of a role. This role has five actions in the policy, and will look like the following. You must remember to ensure that the flow log service also has permission to assume the role itself, which can be added by modifying the trust relationship of the role to include the following policy.<br>- The destination log group name. Here you must enter the name of a CloudWatch log in which the data will be published to.</p>
<p>Once your subnet flow logs are set up, you will then be able to configure CloudWatch to monitor specific metrics with filters and use SNS to configure notifications for specific events. For more information on CloudWatch, please see our existing course here.</p>
<p>Coming up in the next lecture, I will be providing a demonstration on how to create a new VPC and configure both public and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/public-and-private-subnets/">private subnets</a>.</p>
<h1 id="Demonstration-Creating-a-VPC-amp-Subnets"><a href="#Demonstration-Creating-a-VPC-amp-Subnets" class="headerlink" title="Demonstration: Creating a VPC &amp; Subnets"></a>Demonstration: Creating a VPC &amp; Subnets</h1><p>Hello and welcome to this demonstration lecture on the creation of a VPC and different subnets. Now we understand the concepts of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-subnets/">subnets</a>, why we subnet, and the different types of subnets, public and private, I want to demonstrate how to create a VPC and a couple of the associated subnets.</p>
<p>In this demonstration, I will carry out the following steps:<br>- I’ll create a new VPC with a &#x2F;16 <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">CIDR Block</a>.<br>- I’ll then create and attach an Internet Gateway to the VPC<br>- I’ll then create and configure two subnets whilst allowing for the possibility of creating up to thirty two in total by using a &#x2F;21 twenty one mask<br>- and I’ll then configure one subnet as a public subnet.</p>
<p>Let’s take a look. Okay, so I’ve logged into the AWS management console and the first thing I want to do is go to the VPC. So I have a shortcut here and once that is loaded, I then want to look at creating a new VPC. Over on the left-hand side here, we can see my existing virtual private clouds. And it gives me opportunity here to create a new VPC.</p>
<p>So let’s create this VPC. I’ll give it a name, I’ll call it “Networking Demo”. And then here we can enter the IPv4 CIDR Block for the VPC and I want to use 10.0.0.0&#x2F;16 and we’re not going to use a IPv6 and keep it at default tenancy and then click create. That has now created our new VPC so now we have the new VPC and want to start creating some subnets.</p>
<p>So let’s go down to subnets, click on create subnet. Give it a name, we’ll call this “Public Subnet”. I’m going to have this within our new VPC that we just created so our networking demo VPC. And the availability zone, I don’t mind which AZ that’s in so I have no preference but I can select on availabilities in there if I want to.</p>
<p>So now I can enter the CIDR Block for this subnet and as I explained before I started this demo, I’m going to use a different mask than the VPC mask with &#x2F;16 so I want to allow for up to thirty two potential subnets so I’ll use this &#x2F;21. And so the first available subnet for me to use with the &#x2F;21 is 10.0.0.0&#x2F;21.</p>
<p>And then I shall create. And now we can see, we have our public subnet within our networking demo VPC. With this subnet mask of a &#x2F;21, we can see that we have 2043 host addresses available. I now have a public subnet, but at the moment there’s nothing public about it because we don’t have an Internet Gateway attached to our VPC, and we don’t have a route to Internet Gateway either.</p>
<p>So lets create another subnet, and we’ll call that “Private”. Let’s call that our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/public-and-private-subnets/">private subnet</a>. Again, we’ll select the right VPC, networking demo, and again no preference for availability zone. For this subnet I’m going to use the last available subnet within that range, which is 10.0.248.0&#x2F;21, create.</p>
<p>Now I could have used any one of the 32 subnets, but for this demonstration I just thought I’d use the first subnet and the last available subnet. So now we have our private subnet within our networking demo VPC and again we have 2043 addresses available. So now what we need to do, we have our VPC set up, we have two subnets, one named “Public” and one named “Private” but now we need to make that public subnet to act as a public subnet.</p>
<p>For that we’ll need to create an Internet Gateway. Go down to Internet Gateways, click on create Internet Gateway. Give this a name, we’ll say networking demo, yes, create. And we have our Internet Gateway here and at the moment it’s detached, so we need to attach this Internet Gateway to our new VPC. So click on attach to VPC, select the appropriate VPC, which is networking demo and say yes, attach.</p>
<p>Now we have an Internet Gateway attached to our networking demo VPC. Now all I’ll want to do is create a new <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-fundamentals-and-route-tables/">route table</a> for the VPC with a route pointing to the Internet Gateway. If I go across to Route Tables, create Route Table, call this “Public Route Networking” and associate that to the networking VPC, create.</p>
<p>Here we have our new route, Public Route Networking. Go down to routes, we have our route table. We can see that we have this local route and what that does, it allows all subnets within this VPC to communicate with each other. But I want to edit this route table to add another route pointing to anywhere with a 0.0.0.0&#x2F;0 using our new Internet Gateway that we just created here.</p>
<p>Save that, and I now want to associate this route table to our public subnet. If we click on subnet associations, come across to edit, and select our public subnet, click save. We now have a public subnet within our new VPC, because what we’ve done, we’ve created our new VPC, we created two subnets, a public subnet and a private subnet. I then created and attached an Internet Gateway to our VPC. I then created a new route that pointed to the Internet Gateway for Internet traffic and I then associated that route table to our public subnet. Now any instances that I might launch in that public subnet can communicate with the Internet.</p>
<p>However, the private subnet cannot because if we look at our private subnet here and look at the route table we can see that it doesn’t have any route to the Internet Gateway. It can only talk internally to the other subnets but not any further, whereas our public subnet that we just associated a new route table with, we can see that it now has a route out to the Internet via the Internet Gateway. And that’s it.</p>
<p>Before I finish this lecture on VPC subnets, I just want to highlight a few more points around them.</p>
<p>When architecting and designing your VPC subnets across different availability zones, specifically for resiliency, I recommend you replicate the same configurations in both availability settings. This includes any public and private subnets. This ensures you maintain a mirror image of your network infrastructure should one AZ go down.</p>
<p>You should name your subnet something meaningful during creation, allowing you to quickly identify its use or other distinct information about that sublet. For example, web tier or database tier. Think about the amount of network and hosts required across your VPC, ensuring you have allocated a large enough CIDR Block.</p>
<p>Allow for future capacity growth for the number of subnets that you may need. Do not make the host IP addresses availability in your subnet too small unless you have a very specific reason. For example, by using a &#x2F;28 mask, if you run out of IP addresses for your instances within the subnet then you can’t make the subnet bigger.</p>
<p>The only option would be to make a bigger subnet and then migrate your resources across to the new subnet. This now brings us to the end of this lecture. Coming up next, I will be discussing VPC routing using the information we have just covered from these past few lectures.</p>
<h1 id="Routing-Fundamentals-amp-Route-Tables"><a href="#Routing-Fundamentals-amp-Route-Tables" class="headerlink" title="Routing Fundamentals &amp; Route Tables"></a>Routing Fundamentals &amp; Route Tables</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-resilient-architectures/designing-for-disaster-recovery-1/">Hello and welcome</a> to this lecture, where I shall explain the fundamentals of AWS routing and take a look at the route tables themselves. Routing provides a mechanism to allow network packets to be forwarded to the correct destination. Within a VPC, this is all configured via routing tables associated to your subnets which use virtual routers that are fully managed by AWS.</p>
<p>This means you do not need to provision or configure any routers. When you create a new VPC an implicit router will be linked to your VPC as a part of your VPC creation process. If you remember from a previous lecture regarding <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-subnets/">VPC subnets</a>, the first host IP address available within each subnet is always reserved to enable routing functionality for that subnet.</p>
<p>In addition to the implicit router linked to your VPC a default route table, known as the Main Route Table, is also created for your VPC. This Main Route Table cannot be deleted, however it can be customized by adding or removing routes to it. When you create a new subnet, this Main Route Table will be implicitly associated to it, unless you specify an alternate custom route table.</p>
<p>Remember, there has to be an associated route table for all subnets and a subnet can only have one route table association at any one time, although multiple subnets can all use the same root table. The Main Route Table will therefore act as the route table for any subnet that does not have a custom route table associated.</p>
<p>Let me now show you what a route table looks like and how to configure it. I’ll start by looking at an example of a default Main Route Table from within the Management Console. When any new route table is created it will contain data around five components, these being a summary, routes, subnet associations, route propagation and tags.</p>
<p>The summary pane shows just a few details, unlike the summary pane for the subnets which contained a lot more information.</p>
<p>The route table ID is issued automatically which is prefixed with rtb, which stands for route table. In this example, it’s been set to rtb-31bc7256. Similarly with the subnet ID, VPC ID and NACL ID, they’re all referenced when using the CLI tools to perform specific programmatic commands.</p>
<p>The explicitly associated with section shows how many subnets are explicitly associated with this route table. Subnets can either be explicitly or implicitly associated to a route table, and we’ll cover more on this when I come to subnet associations.</p>
<p>The main defines if this route table is the Main Route Table for the subnet and it will either be set to yes or no.</p>
<p>As we know, the Main Route Table will act as the route table for any subnet that does not have an explicit associated route table. The Main Route Table of a VPC can be updated and customized, but another route table can also take over as the Main Route Table. For example, you may have your Main Route Table set with a specific configuration which acts as an implicit association to many subnets within your VPC.</p>
<p>However, you want to change the routing of the Main Route Table without causing disruption and potential issues. So how would you achieve this? To start with, you would leave your Main Route Table serving implicit associations to those subnets using it. Next you would create a custom route table. You would then add the relevant routes that you need for the new Main Route Table to this newly created custom route table. Next you would explicitly associate that route table to a single subnet. And this subnet would then be using the new route table and not the Main Route Table. After this you would then test and confirm the routing would work as expected. And then from within the Management Console select route tables from the VPC Dashboard, select the newly created custom route table and then click on Set as Main Route Table and confirm the message.</p>
<p>This would then successfully act as the new Main Route Table for your VPC. You could then delete the old route table if it was no longer required.</p>
<p>Remember, you always have to have a Main Route Table within your VPC, but it doesn’t always have to be the same one that was created when the VPC was.</p>
<p>Lastly within the summary the VPC section simply shows which VPC this route table resides in, which is defined by the VPC ID and tag name.</p>
<p>Let’s now take a look at the routes tab. The routing pane shows the actual routing decisions that are made and this is where the routing of the network is defined. The table itself is comprised of four columns.</p>
<p>Destination, the destination field shows the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">CIDR block</a> ranges for any network that you need to route to, outside of your current subnet.</p>
<p>Target, the target field provides the gateway to allow you to get to that destination. For example, if you wanted to route back to your own on-premise network, you could have a destination field of 192.168.0.0&#x2F;16 with a target pointing to your virtual gateway, your VGW. This <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-vpn-connection-via-vgw/">virtual private gateway</a> is the gateway between your AWS VPC and a VPN connection back to your corporate network.</p>
<p>The status field will show you the status of your routes within the table, for example, Active. Propagated, the propagated field will define which routes within the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-fundamentals-and-route-tables/">route table</a> are propagated. I will cover more on route propagation later in this lecture. So, to reiterate, the destination points to the network you need to route to and the target provides the gateway for doing so.</p>
<p>You may have noticed that from this example Main Route Table that it comes with a pre-configured route. This route will have a destination value the same as your VPC CIDR block, with a target set to local. This is an important route and one that exists for every route table that is created. What this route does is to allow all subnets within your VPC to route to each other.</p>
<p>It provides a path from every subnet to every other subnet. The route does not have to be created manually, it is automatically created when you create any route table and it cannot be deleted. As by default and by design, AWS allow routes to and from all of your subnets within your VPC.</p>
<p>Now just because you have this local route that enables a known route and pathway between all subnets does not mean that a subnet that does not have an Internet gateway attached can access the Internet by knowing the route to a subnet that does.</p>
<p>The subnet has to have its own route to a gateway to be able to use it. If you have a lot of rules within your route table you can perform some basic level filtering by using the drop down list above the routes in the table. Here you can filter on all rules within the table, just IPv4 rules or just IPv6 rules.</p>
<p>To modify the routes within the table you must edit the route table using the Edit button. Here you can then add another route by entering the destination and target fields. The status and propagation fields are automatically determined. You can also remove any routes that you no longer need by selecting the cross in the remove field, but notice that you cannot delete the local route.</p>
<p>Like I mentioned previously, when a subnet is created it has to have an associated route table, and by default the Main Route Table will be associated implicitly to that subnet. If then a custom route table is associated to that subnet, replacing the implicit association of the Main Route Table, then that route table will become an explicit association to that subnet.</p>
<p>From this example we can see that there are no explicit subnet associations to this route table, as it states: ‘You do not have any subnet associations’. And you’ll generally find that when looking at the Main Route Table, simply because of the implicit nature that the Main Route Table has. We can also see any subnets that do not have any explicit associations, which are listed at the bottom of the route table.</p>
<p>If we compare this example to another route table that is not the Main Route Table, we can see a difference. This route table does have explicit subnet associations and these are listed as subnet B and subnet S. This means that these two subnets are not using the Main Route Table, instead they are explicitly connected to this route table.</p>
<p>However, again, like the Main Route Table, we can see the subnets that are implicitly associated to the Main Route Table, and you will always see any subnets associated to the Main Route Table and all root table subnet associations. The IPv4 CIDR and IPv6 CIDR fields will simply show the corresponding CIDR blocks for each subnet listed.</p>
<p>The route propagation pane allows you to enable propagation against any virtual private gateways that you have attached to your VPC. Once you enable route propagation with a selected virtual private gateway then routes representing your VPN connection will be added to your route table automatically and will be identifiable by being listed as Yes in the propagated field of the routing table.</p>
<p>Lastly, the tags tab provides the same function as it did with subnets, it allows you to add any custom key value pairs to help with the tagging of your route table. In this example, I added a name of Main Route Table.</p>
<p>That brings us to the end of this lecture. Next I want to talk to you about routing priorities and how these are managed.</p>
<h1 id="Routing-Priorities"><a href="#Routing-Priorities" class="headerlink" title="Routing Priorities"></a>Routing Priorities</h1><p>Hello and welcome to this lecture, where I want to discuss how <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-fundamentals-and-route-tables/">AWS route tables</a> manage routing priorities for overlapping routes.</p>
<p>A key point of understanding AWS routing, especially when it comes to troubleshooting, is to know how AWS route tables prioritizes these routes. For example, if there are overlapping destinations from a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">CIDR block</a> perspective, which target should AWS use to send the traffic to?</p>
<p>Remember, the destination points to the network you need to route to and the target provides the gateway for doing so. The rule of thumb is that AWS will use the most precise route available within the table to route traffic to a specific destination. This is also known as the Longest Prefix Match.</p>
<p>For example, let’s say you had four routes in your route table associated to a subnet as shown.</p>
<p>This subnet has its local route, like every subnet has, enabling all subnets within the VPC to route to each other. It also has an Internet gateway with a destination value of 0.0.0.0&#x2F;0. Then it has two routes on the 192.168 network. So if traffic from within your subnet needed to be routed to 192.168.1.1, which route would it use?</p>
<p>Like I said before, the rule of thumb will be the most specific, in this instance, the last route in the table with a destination of 192.168.1.0&#x2F;24 as this route has the Longest Prefix Match, even though it also falls within the boundaries of the third route. Let’s look at some more examples.</p>
<p>So the first column shows a number of IP addresses in this example that we are trying to reach. The second column shows the potential routes that those IP addresses could use, if looked at individually. Almost all of the IP addresses could use more than one route in the table. The third and fourth columns show the example root table entries used previously. The fourth column shows the selected route for the corresponding IP address. And the final column explains the reason why that particular IP address used that route. Feel free to pause the video and take a review of this table for a few minutes.</p>
<p>Now there are some circumstances where the Longest Prefix Match of a route is not selected within the route table and these are important to be aware of, as they could aid with any routing troubleshooting issues that may arise.</p>
<p>If you have any virtual gateways attached to your VPC and have enabled propagation for those virtual gateways and these propagated routes have overlapping destinations with your VPC’s local route, then your VPC local route will have precedence, even if your propagated routes across your VPN link have the Longest Prefix Match.</p>
<p>Also, again, if you have any propagated routes that have the same destination specified as any of your other existing static routes within your route table, then the rule of Longest Prefix Match will not be applied. Instead, the following priority is executed against any static routes that have the following gateways as their target first, the Internet Gateway, a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-vpn-connection-via-vgw/">Virtual Private Gateway</a>, a Network Interface, an Instance ID, a VPC Peering connection, a NAT Gateway, or a VPC Endpoint.</p>
<p>Let me take a look at a couple of examples where these may come into play. This route table contains two routes, one is the local route for all <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-subnets/">VPC subnets</a> and a second overlapping route that has been added through propagation via a Virtual Private Gateway. Any traffic destined to the 10.0.1.0&#x2F;24 network will be routed using the local VPC route over any propagated route, even though it has the Longest Prefix Match.</p>
<p>Another example, in this example the root table has three routes, one that is the local VPC route, a route to the Internet Gateway, and a propagated route to the same destination as the Internet Gateway route. Just to clarify, the Internet Gateway does not always have to point to 0.0.0. 0&#x2F;0 as it has done previously in this course. In some circumstances, you may only want to route to specific networks out to your Internet connection, rather than to everywhere. Any traffic that is destined for the 172.31.0.0&#x2F;16 network would have the potential of using two routes. However, in this scenario, all traffic to that network would use the Internet Gateway route, as that is a static route and has precedence over any propagated route. When managing route tables, including your static and any propagated routes.</p>
<p>Do be aware that there are limitations on the number of routes within a VPC in any one table. Currently, there is a default limit of 200 routes per VPC, however, you can request an increase if required. For each route table you have a default of 50 non-propagated routes, with a maximum increased limit of 100.</p>
<p>However, if you do increase the amount of routes you may notice some degradation to your network performance. This limit is separate for both IPv4 and IPv6 addressing, meaning you can potentially have up to 100 IPv4 routes and 100 IPv6 routes. The maximum propagated route limit is fixed at 100 per route table, and this limit cannot be increased.</p>
<p>So far, we have looked at AWS routing, covering what routing is, the route tables themselves, subnet associations, route propagation, routing priority and limitations. In the next few lectures I want to run through some examples of how routing is configured across a range of different designs and configurations, including routing to a VPC Peered Connection, a Virtual Private Gateway, a NAT Gateway, an Internet Gateway and a VPC Endpoint.</p>
<h1 id="Routing-VPC-Peering"><a href="#Routing-VPC-Peering" class="headerlink" title="Routing: VPC Peering"></a>Routing: VPC Peering</h1><p>Hello, and welcome to this lecture. We’re on to cover some example scenarios of routine configurations in different VPC peering solutions.</p>
<p>For connectivity to exist between VPCs over a peered connection, abbreviated as a pcx, then specific routing must be set up on each side of the peer in the relevant subnets of the VPC to allow each VPC to know where to route traffic to.</p>
<p>Setting up routing on peered VPCs can only exist if the IP CIDR blocks do not overlap in any way. In each peered subnet that you want to communicate with, you must ensure that the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-fundamentals-and-route-tables/">route table</a> being used in that subnet has a static route to either the peered VPC CIDR block or the CIDR block of the subnet in the peered VPC.</p>
<p>From this diagram, you can see that we have two subnets in each VPC. In VPC 1, we have a subnet A and B, and in VPC 2, subnet C and D. Subnet A in this VPC 1 has a static route in the table with a destination of the CIDR block of VPC 2 and a target of pcx-abcd1234, which is the peered gateway between the two VPCs.</p>
<p>Subnet B in the same VPC does not have a route pointing to the pcx. Similarly, in VPC 2, subnet C also has a route to VPC 1’s CIDR block by the pcx, and subnet D does not. In this scenario, subnet A and VPC 1 has a route to the entire IP address space of VPC 2, and subnet C and VPC 2 has a route to the entire IP address space of VPC 1.</p>
<p>Therefore, these two subnets have a route to each other to enable connectivity. Although VPC 1 can route to the entire IP address space of VPC 2, which would include subnet D, subnet D does not have a route in its routing table to enable traffic to route to VPC 1. This is also true for VPC 2 communicating with subnet B.</p>
<p>For every subnet that requires connectivity to a peered VPC, a route must exist in the route table for that subnet pointing to the pcx. Let’s now look at another example configuration of peering connections between VPCs. This time between three VPCs.</p>
<p>The peering connection between these VPCs offers connectivity to all VPCs from every other VPC. VPC 1 can communicate with 2 and 3, VPC 2 can communicate with 1 and 3, and VPC 3 can communicate with 1 and 2. In this scenario, three different peering connections are in place. As such, different pcx’s are used to connect the same VPC from every other VPC. For example, the route table in VPC 3 uses pcx-wxyz6789 to communicate with VPC 1, whereas VPC 2 uses pcx-abcd1234 to communicate with VPC 1.</p>
<p>Care must be taken when configuring your route tables to ensure you use the correct pcx to route your traffic to peered VPCs in a multiple VPC peering scenario such as this. One final example of VPC peering. Again with three VPCs, but this time, not all the VPCs can communicate with all others plus two of the VPCs have identical <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">CIDR blocks</a>.</p>
<p>So, let’s take a look at the routing in this scenario. Both VPC 1 and 3 have a peering with VPC 2. You will notice that VPC 1 and VPC 3 have identical VPC CIDR blocks as well as the same subnet CIDR range. The route table for the subnet in VPC 1 is set up correctly to point to VPC 2 via the correct target of the pcx.</p>
<p>However, the route table of the subnet in VPC 2 poses a problem. It states that for any traffic destined for the 10.0.0.0&#x2F;16 network, then use the pcx which points to VPC 3 only. So, if a request comes from VPC 1 and a response is required, the response will be sent to VPC 3. Currently, VPC peering does not support unicast reverse path forwarding, which checks the source IP of packets and routes response packets back to the correct source.</p>
<p>To resolve this, you could rely on the longest periphics match roll when looking at route priorities. The route table of the 192.168.1.0&#x2F;24 subnet could be changed to the following to include a new route. Now if any traffic from VPC 1 in the subnet 10.0.1.0&#x2F;24 was destined for VPC 2, VPC 2 would respond correctly using the correct pcx of pcx-abcd1234, as this route has the longest periphics match.</p>
<p>For any other traffic on the 10.0.0.0&#x2F;16 network, it will route to VPC 3. You could be more specific with your route table on VPC 2 to route to different subnets within VPC 1 and VPC 3 as shown on the route tables.</p>
<p>Coming up in the next lecture, I’m going to look at routing configuration when using a virtual product gateway for VPN connectivity.</p>
<h1 id="Routing-VPN-Connection-via-a-Virtual-Private-Gateway"><a href="#Routing-VPN-Connection-via-a-Virtual-Private-Gateway" class="headerlink" title="Routing: VPN Connection via a Virtual Private Gateway"></a>Routing: VPN Connection via a Virtual Private Gateway</h1><p>Hello, and welcome to this short lecture on Virtual Private Gateway routing for VPN connectivity.</p>
<p>The AWS side of the routing configuration for a VPN connection over a Virtual Private Gateway is a little less complicated than that of VPC Peering.</p>
<p>Before you can set up a route for a VPN over a Virtual Private Gateway, you need to create and attach a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-vpn-connection-via-vgw/">Virtual Gateway</a> to your VPC.</p>
<p>These Virtual Gateways are used to help create a VPN connection between your VPC and your corporate network outside of <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a>. There are many more points of configuration in setting up a VPN connection, which is outside the scope of this course. However, to simply configure the AWS routing, at this stage, all you require is the Virtual Gateway to be attached to your VPC.</p>
<p>Once your Virtual Gateway is created and added to your VPC, you can then update the route tables for any subnets that intend to route to your corporate date center network. However, to simply configure the AWS routing, at this stage, all you require is the Virtual Gateway to be attached to your VPC. Once your Virtual Gateway is created and added to your VPC you can then update the route tables for any subnets that intend to route to your corporate data center network.</p>
<p>In this diagram, we can see that an AWS subnet, 10.0.2.0&#x2F;24, has two static routes in its route table pointing to the two 172.16 subnets, which are located within the corporate data center outside of AWS. The destination networks have been added with a target pointing to the Virtual Gateway, listed as vgw1234abcd.</p>
<p>Any traffic destined for this network will then be directed to use this Virtual Gateway. You may remember from earlier, when I spoke about route propagation and the fact that it can be enabled when you have a Virtual Gateway attached to your VPC, by enabling propagation on this Virtual Private Gateway it will include the routes used in your VPN connection.</p>
<p>If you do not include propagation routing for your Virtual Gateway you will need to add static routes for all network used by the VPN connection that you want to route to, which is the case in this diagram. One point to mention is that AWS does not currently support IPv6 traffic across a VPN connection.</p>
<p>That brings us to the end of this short lecture, next up <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-internet-gateways-and-nat-gateways/">Routing for Internet Gateways and NAT Gateways</a>.</p>
<h1 id="Routing-Internet-Gateways-amp-NAT-Gateways"><a href="#Routing-Internet-Gateways-amp-NAT-Gateways" class="headerlink" title="Routing: Internet Gateways &amp; NAT Gateways"></a>Routing: Internet Gateways &amp; NAT Gateways</h1><p>Hello, and welcome to this lecture, where I want to look at how to configure routing for both internet gateways and NAT gateways. In a previous lecture, I talked about public and private subnets and how a public subnet is defined. A part of this public subnet definition is an association of an internet gateway.</p>
<p>This internet gateway, or IGW, as it’s known, provides a means of communicating out to the internet. This internet gateway is aservice, controlled, configured, and maintained by AWS. It scales horizontally automatically and is classified as a highly available component of your VPC infrastructure. Once your internet gateway’s attached to your VPC, you have a gateway to the internet.</p>
<p>Now you need to configure the subnet’s route table to point to this internet gateway, and therefore, makin’ it a public subnet. Often, the route is configured as follows. The destination value of 0.0.0. 0&#x2F;0 essentially implies that for any destinations that are not known by the route table, then use this route, which has a target pointing out to the internet gateway.</p>
<p>It’s essentially used as a catch-all, if no other route exists. However, the destination for the internet gateway doesn’t always have to point to all other destinations. You can have a destination pointing to a specific IP out on the internet, or to a specific range if required. You may need to do this for security and compliance reasons.</p>
<p>Any subnet which has a route table associated that points to an internet gateway is considered a public subnet, as it has connectivity out to the internet. Routing for a NAT gateway is slightly different, but also requires the use of a public subnet to be configured. To briefly explain, a NAT gateway allows instances within a private subnet access out to the internet; however, access to the instances within these private subnets cannot be initiated from the internet.</p>
<p>This diagram shows a VPC with two subnets, one public, 10.0.1.0&#x2F;24 and one private, 10.0.2.0&#x2F;24. The public subnet is configured with a route to the internet gateway and can access the internet as required. Instances in the private subnet, which are kept private for security reasons, but still need access to the internet for important operating system updates, and so need to be able to initiate a route to the internet.</p>
<p>The route table for the private subnet has a very similar route to the public subnet, in that they both have a destination route to 0.0.0.0&#x2F;0. The <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/public-and-private-subnets/">private subnet</a>, however, has a route to the NAT gateway instead, which is located within the public subnet. From here, the NAT gateway will provide internet connectivity.</p>
<p>From a design perspective, if you had multiple availability zones but only one NAT gateway configured, and the AZ went down which held the NAT gateway, all of your other private subnets across all AZs would not be able to connect to the internet. To resolve this, configure a public subnet in each AZ and update the route tables for all the private subnets in that availability zone to point to the new NAT gateway.</p>
<p>That way, if any AZ goes down, it will not affect the internet access for private instances within other AZs, as this will now be AZ-independent.</p>
<p>Coming up in the next lecture, routing configurations for <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-vpc-endpoints/">VPC endpoints</a>.</p>
<h1 id="Routing-VPC-Endpoints"><a href="#Routing-VPC-Endpoints" class="headerlink" title="Routing: VPC Endpoints"></a>Routing: VPC Endpoints</h1><p>Hello, and welcome to this lecture on the final routing configuration scenarios using VPC endpoints. A VPC endpoint is a virtual device which allows you to connect your VPC to another AWS service without traversing any gateway of any kind, such as an internet Gateway, a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/routing-vpn-connection-via-vgw/">virtual gateway</a> or a NAT gateway.</p>
<p>Currently, the only supported endpoint is for S3, and when using these endpoints it doesn’t impose risks of availability or bandwidth across your VPC network, as it uses horizontally scaled, highly available VPC components, which are all held on the AWS network. When communicating between the VPC endpoint and your VPC, the traffic remains inside the global AWS network.</p>
<p>So how is this routing managed between your VPC subnet and these VPC endpoints? Well, the routing is implemented automatically. To create a VPC endpoint, select “Endpoints” from the VPC dashboard. Then select “Create endpoint” Then select your VPC, service endpoint and access policy for the service. Then select “Next step.”</p>
<p>At this point, in step two, “Configure Route Tables” you must select which route tables will be used to route the AWS service, which in this case, is S3. It will add a new rule for the new destination, with a target of the VPC ID. I shall create the endpoint in this example by selecting the main route table to see which route to add.</p>
<p>To complete setup, select “Create endpoint” As you can see, by completing the configuration of the VPC endpoint, it has automatically added a new route to the main route table, which I had selected in the previous section. The destination values and target values have automatically been added. That now brings us to the end of this lecture covering AWS routing across VPC endpoints.</p>
<p>Coming up next, we shall summarize what we have learnt throughout each of the previous lectures.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Hello, and welcome to this final lecture. By now, you should have a solid understanding of how to architect your VPC subnets and configure routine appropriately for various different configurations and scenarios. However, in this last lecture, I just want to reiterate some of the key points that we made throughout the previous lectures.</p>
<p>We started off by looking at VPC CIDR blocks. Where this lecture focused on the effects of subnetting your VPC CIDR block and here were some of the key points.</p>
<p>- Subnetting is the process of splitting a CIDR block into smaller CIDR blocks within the same range of the larger block.<br>- Subnetting enables you to divide your VPC CIDR block into small networks.<br>- The VPC CIDR block range encompasses the entire IP address space that you can use within that VPC.<br>- The maximum and minimum masks for your VPC CIDR block are &#x2F;16 to &#x2F;28.<br>- AWS reserves the first three host IP addresses of each subnet for internal AWS usage. The first host is used for the VPC router. The second is for DNS and the third is reserved for future use.<br>- An IPv4 CIDR block range for your VPC is mandatory but you can also associate an IPv6 block as well.</p>
<p>Next we focused on the topic of why subnet your VPC? And here we looked at some of the reasons why you may want to subnet your VPC by looking at some of the advantages and benefits.</p>
<p>- Logical network division. When you create multiple networks it allows you to create logical network divisions between your resources.<br>- Security. By having multiple subnets with similar resources grouped together, as per the previous point it allows for greater security management.<br>- Accessibility. Having multiple subnets allows you to create both Private and Public subnets.<br>- Communication. You may want some of your subnets to route out the internet, some to remain private and some to communicate back to your corporate-on-premise network via VPN. Subnetting allows you to do this with the help of IWS routing.<br>- High availability. If your solution requires a level of high availability, it’s best practice to deploy services across multiple availability zones within a region. Remember, a single subnet cannot span across two availability zones.</p>
<p>Once we understood the reasoning of benefits behind VPC subnets I delved into what a VPC subnet looks like within the management console and its associated components such as the network access control list. Here we learned that the subnet itself has five components.</p>
<p>- The summary, and this summarizes all the elements and metadata associated with the subnet. Such as the IPv4 CIDR block, the VPC the Asian and route table associated exception.<br>- The Route Table. This defines which route table that the subnet is using along with its routes.<br>- The NACL. The network ACSL shows the current NACL associated to the subnet displaying both Inbound and Outbound rule sets.<br>- Flow Logs. Shows you any Flow Logs that you have set up and created for the subnet to capture IP traffic flow information.<br>- Tags. And this allows you to add any custom key value pairs to help with the tagging of your subnet.</p>
<p>Following the definitions made in this lecture I then discussed the different kinds of subnets, Private and Public. Key points of this lecture.<br>- Public subnets have direct access to the internet. Whereas your private subnets do not.<br>- There are 2 components required to make a public subnet. An attached Internet Gateway to your VPC and a route pointing to the target Internet Gateway.<br>- By default, all subnets have the automatic assigned of public IP addressing turned off<br>- You can modify IP addressing behavior of a subnet using the ‘modify auto-assign IP settings’ option within the Management Console for your subnet.</p>
<p>Next, I focused on what consideration should be made when peering VPCs together from a subnet point-of-view. The key points here were that:<br>- VPC peering allows you to connect two or more VPCs together using IPv4 or IPv6 as if they were a part of the same network.<br>- The connectivity between the VPCs is implemented through the AWS network, and so it is highly valuable with no bandwidth bottleneck.<br>- Overlapping or duplicate CIDR ranges between VPCs cannot be peered together. Each AWS VPC will only communicate with its peer.</p>
<p>Following this, I then covered how to monitor your subnets using Flow Logs.</p>
<p>-Subnet Flow Logs can help you troubleshoot networking problems.<br>- They can capture IP traffic going into and out of your network interfaces.<br>- The log data can be sent to a CloudWatch Logs log group where you are able to filter information and monitor specific metrics.</p>
<p>To end this section on subnets I then demonstrated how to set-up and configure a VPC with both public and private subnets.</p>
<p>Following this, I then spoke about AWS routing. Starting by looking at AWS routing fundamentals and route tables. Within this lecture, we learned that:</p>
<p>- Routing provides a mechanism to allow a network packets to be forwarded to the correct destination.<br>- Within the VPC, all routing is configured via routing tables associated to your subnets which use virtual routers that are fully managed by AWS.<br>- An implicit router will be linked to your VPC as a part of your VPC creation process.<br>- A default route table, known as the Main Route Table is also created for your VPC.<br>- The Main Route Table cannot be deleted.<br>- When you create a new subnet, this Main Route Table will be implicitly associated to it unless you specify an alternate custom route table.<br>- A subnet can only have one route table association at any one time. Although, multiple subnets can all use the same route table.<br>- Subnets can either be explicitly or implicitly associated to a route table.<br>- Any route table can take over as the Main Route Table.<br>- A route in the route table has values for destination, target, status and propagated fields.<br>- The destination field shows CIDR block ranges for any network that you need to route to outside of your current subnet.<br>- The target field provides the gateway to allow you to get to that destination.<br>- The status shows the states of your routes within the table.<br>- The propagated field will determine which routes within the route table are propagated via a virtual private gateway.<br>- The local route in every route table allows all subnets within your VPC to route to each other.<br>- Subnets can be explicitly associated to a route table.<br>- Route propagation via a private gateway will automatically add routes representing your VPN connection to the route table if propagation has been enabled for that virtual private gateway.</p>
<p>Next, routing priorities were discussed to understand how overlapping routes within the same route table were managed.</p>
<p>- The rule of thumb is that AWS will use the most precise route available within the table to route traffic to a specific target.<br>- This is also known as the longest prefix match.<br>- There are some circumstances where the longest prefix match route is not selected.<br>- When propagated routes have overlapping destinations with your VPCs local route, then your VPC local route will have precedence even if your propagated routes have the longest prefix match.<br>- If you have any propagated routes with the same destination as any existing static routes then the rule of longest prefix match will not be applied. Instead, the following priority is executed against any static routes that have the following gateways as the target first. Internet gateway, virtual private gateway network interface, an instance ID a VPC peering connection, a NAT gateway and, finally, a VPC endpoint.</p>
<p>Next I started to look at different routing configurations for different scenarios.</p>
<p>Starting off with VPC peering.</p>
<p>- A peered connection if pre-fixed with pcx in the target.<br>- Routing must be set up on each side of the peer to allow each VPC to know where to route traffic to.<br>- Peering can only exist if the IP CIDR blocks do not overlap in anyway.<br>- Every subnet that requires connectivity to a peered VPC, a route must exist in the route table for that subnet pointing to the pcx.<br>- VPC peering does not support unicast reverse path forwarding.<br>- Use the longest prefix-match rule for any VPC that is peered to multiple VPCs that have the same CIDR block ranges.</p>
<p>Next was the routing configuration for VPN connectivity via a virtual private gateway.</p>
<p>-Virtual private gateways are used to help create a VPN connection between your VPC and your corporate network outside of AWS.<br>- Before you can set up a route for a VPN over virtual private gateway you need to create and attach a virtual private gateway to your VPC.<br>- To route across your VPN, you must update the route tables for any subnets that intend to do so using the target of your virtual private gateway.<br>- By enabling propagation on this virtual private gateway your route table will automatically include the routes used by your VPN connection.<br>- If you do not enable propagation, you will need to add static routes for all the networks used by the VPN connection that you want to route to.<br>- AWS does not currently support IPv6 traffic across a VPN connection.</p>
<p>Following this, I then looked at routing for Internet gateways and NAT gateways.</p>
<p>-The Internet Gateway, or IGW, provides a means of communicating out to the Internet.<br>- Once your internet getway is attached to your VPC, you have a gateway to the internet.<br>- The destination value in a route table of 0.0.0.0&#x2F;0 essentially implies that for any destinations that are not known by the route table, then use this route.<br>- Any subnet which has a route table associated to that point is to an internet gateway is considered a public subnet.<br>- A NAT gateway allows instances within a private subnet access to the internet. However, access to the instances within these private subnets cannot be initiated from the internet.<br>- Instances in a private subnet must have a route to the NAT gateway which is located in the public subnet.<br>- Routing for a NAT gateway requires the use of a public subnet to be configured.</p>
<p>Then, finally, the last routing lecture I discussed was on VPC endpoints.</p>
<p>- A VPC endpoint is a virtual device which allows you to connect your VPC to another AWS service without traversing any gateway.<br>- Currently, the only supported endpoint is for S3.<br>- When communicating between the VPC endpoint and your VPC, the traffic remains inside the global AWS network.<br>- VPC endpoint routing is implemented automatically during the creation of the endpoint.<br>- The VPC endpoint creation will add a new rule with a new destination and a target value of the ‘vpce ID’ for the selected route table.</p>
<p>That has now brought me to the end of this lecture, and to the end of this course.</p>
<p>I hope it has given you a good understanding of some of the advanced AWS network concepts surrounding subnets and routing and has left you comfortable enough to start designing and architecting your own AWS network.</p>
<p>If you have any feedback on this course positive or negative, please do leave a comment on the course landing page. We do look at these comments, and your feedback is greatly appreciated.</p>
<p>Thank-you for your time and good luck with your continued learning of Cloud computing.</p>
<p>Thank-you.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-Protecting-Web-Apps-with-AWS-WAF-Shield-Firewall-Manager-37/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-Protecting-Web-Apps-with-AWS-WAF-Shield-Firewall-Manager-37/" class="post-title-link" itemprop="url">AWS-Security-Specialty-Protecting-Web-Apps-with-AWS-WAF-Shield-Firewall-Manager-37</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:44" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:44-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 22:52:50" itemprop="dateModified" datetime="2022-11-19T22:52:50-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-Protecting-Web-Apps-with-AWS-WAF-Shield-Firewall-Manager-37/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-Protecting-Web-Apps-with-AWS-WAF-Shield-Firewall-Manager-37/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hello and welcome to this course where I shall be discussing three AWS services which are designed to help protect your web applications from external malicious activity. Firstly, I shall focus on the Web Application Firewall service, or AWS WAF, as it’s more commonly known. And I’ll begin looking at the basics of the service before moving progressively into more technical and advanced configuration. Following WAF, I shall then explain how Firewall Manager can be used to help with WAF administration across multiple AWS accounts. And then finally, I will explain how AWS Shield is used in conjunction with WAF to help protect you from Distributed Denial of Service attacks, or DDoS. Before we start this course, I would like introduce myself. My name is Stuart Scott, I’m one of the trainers here at Cloud Academy, specializing in AWS, Amazon Web Services. Feel free to connect with me with any questions using the details shown on the screen. Alternatively you can also get in touch with us here at Cloud Academy by sending an e-mail to <a href="mailto:&#115;&#117;&#x70;&#112;&#x6f;&#114;&#116;&#x40;&#99;&#x6c;&#x6f;&#117;&#x64;&#x61;&#x63;&#97;&#100;&#101;&#x6d;&#121;&#x2e;&#x63;&#x6f;&#109;">&#115;&#117;&#x70;&#112;&#x6f;&#114;&#116;&#x40;&#99;&#x6c;&#x6f;&#117;&#x64;&#x61;&#x63;&#97;&#100;&#101;&#x6d;&#121;&#x2e;&#x63;&#x6f;&#109;</a>. </p>
<p>This course is intended for Security architects, technical engineers, and website administrators who have a responsibility for ensuring web applications and websites are not compromised or exploited within their environment. This course is also useful for anyone who requires a deeper understanding of the Web Application Firewall, Shield, and Firewall Manager service. This course is divided into four sections. Firstly I shall be looking at AWS WAF, as this is the key service that relates to the other sections that I’ll be discussing. And in the WAF section, I’ll be looking at the following points, what is WAF and what does it do? When and why should you use WAF? How to configure WAF? And here I’ll present a demonstration. WAF monitoring, WAF service limits, how WAF works with AWS CloudFront, and the pricing of WAF. By the end of these lectures, you will have a sound understanding of the AWS WAF service. This will then lead nicely onto the second section, which is focused on the AWS Firewall Manager. In this section of the course, I’ll be looking at an overview the of AWS Firewall Manager, the different components of the Firewall Manager, and also how to configure it as well. In the third section of the course, I will dive into the AWS Shield service which is used to help mitigate against DDoS attacks. And here I will explain what AWS Shield is, and how to configure AWS Shield Advanced. Finally, I’ll be summarizing the key points taken from each of the previous lectures within this course. By the end of this course, you’ll have a greater understanding of how AWS WAF, Firewall Manager and Shield can help you protect your web application infrastructure from malicious activity. </p>
<p>This course will provide you with the following, an understanding of what AWS WAF is and what it does, knowledge of how to configure and implement a WAF solution, you’ll understand how AWS WAF works closely with AWS CloudFront, you’ll gain an understanding of how AWS Firewall Manager can be used to help you control AWS WAF across multiple different accounts, and how AWS Shield is used to protect Distributed Denial of Service attacks. You’ll also gain an awareness of different types of DDoS attacks, and an understanding of the steps involved in configuring AWS Shield Advanced. There’s a number of prerequisites for this course, you should have an understanding of what Amazon CloudFront Distributions are, be aware of the AWS Application Load Balancer, have an understanding of AWS Organizations, and then awareness of the seven layers of the OSI model. Feedback on our courses here at Cloud Academy are valuable to both us as trainers and any students looking to take the same course in the future. If you have any feedback, positive or negative, it would be greatly appreciated if you could send an email to <a href="mailto:&#x73;&#x75;&#x70;&#112;&#111;&#x72;&#x74;&#64;&#x63;&#108;&#x6f;&#117;&#x64;&#97;&#x63;&#97;&#x64;&#x65;&#109;&#121;&#x2e;&#99;&#111;&#109;">&#x73;&#x75;&#x70;&#112;&#111;&#x72;&#x74;&#64;&#x63;&#108;&#x6f;&#117;&#x64;&#97;&#x63;&#97;&#x64;&#x65;&#109;&#121;&#x2e;&#99;&#111;&#109;</a>. That brings me to the end of this lecture. Coming up next, I will explain what exactly the Web Application Firewall service is, and what it can do for you.</p>
<h1 id="What-is-WAF-and-what-does-it-do"><a href="#What-is-WAF-and-what-does-it-do" class="headerlink" title="What is WAF and what does it do?"></a>What is WAF and what does it do?</h1><p>Hello and welcome to this lecture where I shall give an introduction to the WAF service. The AWS Web Application Firewall is a service that helps to prevent web sites and web applications from being maliciously attacked by common web attack patterns such as SQL injection and cross-site scripting. It is also used to identify how Amazon CloudFront distributions and application load balancers respond to web requests based upon specific conditions. The services work together to filter both HTTP and HTTPS by distinguishing between legitimate and harmful inbound requests that will then either be allowed or blocked with a HTTP 403 error code which is a Forbidden error. For clarity, a web application can be simply defined as a remote program that is accessed over the Internet via a web browser. Let me take a deeper look at what the WAF service is comprised of to allow you to understand how it works. So there are a number of essential components relating to WAF, these being: Conditions, Rules and Web access control lists, also known as Web ACLs. Let me explain each of these individually to see what part they play within the service, starting with the first building block of the configuration, that being Conditions. Conditions allow you to specify what elements of the incoming HTTP or HTTPS request you want WAF to be monitoring for. Currently these are defined as follows: Cross-site scripting. This threat are essentially scripts that have been written to maliciously gain access to client-side data from another user via a web application. This can be data such as stored cookie information and other sensitive client information. These scripts are embedded within web pages that are normally trusted and so the the client browser has no reason to suspect foul play and the script is then executed.</p>
<p> Cross site scripting is one of the largest vulnerabilities found in web applications today. Geo Match. This function allows you to specify which countries and geographic locations that you would like AWS WAF to filter on. This is a similar function that is provided with Amazon CloudFront. On this point it’s important to bear in mind that if you are using the Geo restriction functionality within CloudFront to block a certain country from accessing your web application then the traffic from that country will not reach AWS WAF. If you want to use the Geo Match function within WAF, then you must first disable the Geo restriction settings within your associated CloudFront distribution. IP addresses. Much like the Geo Match setting, this condition allows you to specify a single IP address or a range of IP addresses that you want to either allow or block as you configure the WAF rules. This can be used in conjunction with the Geo Match condition for granular access. For example, you might decide to block all originating requests from a specific country using Geo Match, but then allow specific IP addresses access to your web infrastructure from that country using the IP Address condition. Size constraints. This condition allows you to block traffic based on the size of parts of the request. These parts can include: Header, HTTP Method, Query String, Single query parameter. All query parameters. URI, Uniform Resource Identifier or the Body. </p>
<p>Once you have decided on which part of the request to define on size you can specify operators to define the size restriction, such as greater than, less than, equals et cetera. The size is then specified in Bytes. SQL injection attacks. If successful, these attacks can alter and read data within a database and spoof identities, some can even perform privileged functions on the database itself, such as a shutdown which is obviously an administrative level action and highly impactful to your service of operation. SQL attacks are performed by inserting a SQL query via a client into an entry field to a remote application database where it is then executed. Depending on the design of the attack it can cause serious damage as well as extract highly sensitive information for the attacker. String and Regex Matching. This allows you to identify web requests based on strings that are contained within the request itself, for example a string within the request header. Again, as applies with other conditions, when we create a web ACL we can select to either allow or block the request based on one of the strings identified. AWS Rules. You then need to add these conditions to a rule. A WAF rule allows you to compile one or more of these conditions into a list which acts as a rule where each condition is ANDed to form the complete rule. For example, if you had three conditions listed within a rule and an incoming request met only two of those conditions it would not be a match to the rule, it would have to meet all three conditions. The request will then continue to be processed by the associated Web ACL to see if it meets any other rule. This gives you fine grained control of very specific source targets. When creating your rule you will be asked to select a Rule Type, a Regular Rule or a Rate-Based Rule. </p>
<p>The only difference between a rate-based rule and a regular rule is that rate-based rules count the number of requests that are being received from a particular IP address over a time period of five minutes. When you select a rate-based rule option, and as you can see from the image you are asked to enter the maximum number of requests from a single IP within a five minute time frame. When the count limit is reached, all other requests from that same IP address is then blocked. If the request rate falls back below the rate limit specified the traffic is then allowed to pass through and is no longer blocked. When setting your rate limit it must be set to a value above 2000. Any request under this limit is considered a Regular Rule. You must also specify if the rule is associated to CloudFront or an application load balancer, and if so, in which region. When it comes to adding your conditions to the rule you must specify some parameters that the condition relates to, so the following options must be made for each request. Your rule is not limited to a single condition, it’s possible to add more as you see fit. And again to reiterate, every condition in the rule has to be met for the action of the rule to be carried out. The action associated with the rule is defined in the Web ACL the Access Control List. </p>
<p>Let’s take a look at that component in more detail. So once you’ve created these rules, they can then be added to Web Access Control Lists or the Web ACL. This forms the final component in the decision process as to whether the request traffic is blocked or allowed on through to the associated CloudFront distribution or application load balancer. Within the Web ACL, an action is applied to each rule, these actions can either be Allow, Block or Count. When a request is allowed, it is forwarded onto the relevant CloudFront distribution or Application Load Balancer. When a request is blocked, the request is terminated there and no further processing of that request is taken. A Count action will do exactly that, it will count the number of requests that meet the conditions within that rule. This is a really good option to select when testing the rules to ensure that the rule is picking up the requests as expected before setting it to either Allow or Block. If an incoming request does not meet any rule within the Web ACL then the request takes the action associated to a default action specified which can either be Allow or Block. An important point to make about these rules is that they are executed in the order that they are listed within a Web ACL. So be careful to architect this order correctly for your rule base, typically these are ordered as shown: Where you have your WhiteListed Ips as Allow. Your BlackListed IP addresses as Block and any Bad Signatures also as Block. WhiteListed IP addresses are a list of IP addresses that are allowed to access the resource. </p>
<p>If you are finding that a known customer is getting blocked within your rule base that shouldn’t be, then you could simply add their IP address to the WhiteList and they would then gain access. BlackListed IP addresses are a list of IP addresses that are explicitly blocked for known reasons. Bad Signatures would be rules that relate to attack patterns such as SQL injections and cross-site scripting vulnerabilities. When an incoming request comes into WAF it will be matched against a rule base in the order they appear, as soon as the request matches all the conditions within a rule it will be associated with that rule regardless of if there is another rule further down that would also be a match. So once your WAF Web ACL has been associated, then any request destined for CloudFront or your Application Load Balancer will first be governed by the conditions, rules and Web ACL you configured within WAF, providing an additional security barrier to your web applications. That brings me to the end of this lecture. Next I’ll take a look at when and why you should use AWS WAF.</p>
<h1 id="When-and-why-should-I-use-WAF"><a href="#When-and-why-should-I-use-WAF" class="headerlink" title="When and why should I use WAF?"></a>When and why should I use WAF?</h1><p>Hello and welcome to this lecture where I shall cover when and why you should use AWS WAF. If you are delivering web content via a CloudFront distribution or through an application load balancer, then I would recommend you implement the AWS Web Application Firewall service as an additional layer of security. Without using a Web Application Firewall, you could be exposing your websites and web apps to potentially harmful or malicious traffic, which could wreak havoc within your environment. This could have significant and detrimental impact on your business from a financial and reputation perspective. There are a number of security vulnerabilities that exist across web applications, and it’s important these risks of exposure are mitigated as early as possible. OWASP, the Open Web Applications Security Project, is a not-for-profit organization where it looks at improving the security in software. They provide a top 10 list of the most critical security risks facing organizations around application architecture. This list includes the following, and their website can be found <a target="_blank" rel="noopener" href="https://owasp.org/www-project-top-ten/">here</a>.</p>
<p>So the top 10 vulnerabilities and risks are as follows, injections, broken authentication and session management, cross-site scripting, insecure direct object references, security misconfiguration, sensitive data exposure, missing function level access control, cross-site request forgery, using known vulnerable components, and unvalidated redirects and forwards. If you can implement a WAF within your architecture to mitigate against some of these vulnerabilities, then that acts as a huge asset to your web application architecture and a great relief to the security officers within your organization. If you then compare the implementation and administration time needed to deploy AWS WAF to a standard WAF solution, then it’s by far quicker. Further, AWS WAF is far simpler and easier to manage as well. Another motivation for implementing a Web Application Firewall might be to achieve a higher level of security compliance.</p>
<p>If, for example, your web application handles credit card transactions, then your web solution may need to be PCI DSS compliant, which is Payment Card Industry Data Security Standard. As of April 2016, AWS WAF was PCI DSS 3.2 certified. You may have other security detection mechanisms within your organization that operate deeper within your infrastructure, perhaps at the web server layer to mitigate against some of the same risks that WAF does. And so you may be thinking, why should I implement WAF if I have this existing solution which is working perfectly fine? Well, if you have existing detection systems within your infrastructure, then that’s great. However, the closer they are logically implemented to your web application, the greater the risk of additional vulnerabilities occurring elsewhere within your infrastructure.</p>
<p>It’s best to mitigate vulnerability risks as close to the perimeter of your network environment as possible. By doing so, it reduces the chances of other infrastructure and systems being compromised. When using CloudFront, AWS WAF sits logically between the end user requesting access to your website or web app and your CloudFront distribution. Although logically AWS WAF is in front of CloudFront, the request will be received by the CloudFront distribution first, and then it’s immediately forwarded to your associated WAF Web ACL to either block or allow the request. So before it’s even traversed your CloudFront environment and network, you have the ability to detect, analyze, and either block or allow the incoming request. If the traffic is dropped, no more processing occurs, which saves valuable bandwidth across your internal network and prevents other internal systems potentially becoming compromised.</p>
<p>If the traffic is allowed, then AWS CloudFront continues to process the request as normal and forwards the traffic to the web resource. WAF is very easy to manage either via the AWS Management Console or via the API calls and offers integration with other AWS services, such as AWS CloudWatch for monitoring specific WAF metrics and AWS Lambda for automation. If you couple ease of use, built-in monitoring metrics, and automation possibilities with a low cost point compared to other WAF products, then you’ll realize AWS WAF offers an excellent secure solution for your web applications. That brings me to the end of this lecture. Following this, I shall be giving a demonstration on how to configure the WAF service itself.</p>
<h1 id="Demo-How-to-configure-WAF"><a href="#Demo-How-to-configure-WAF" class="headerlink" title="Demo - How to configure WAF"></a>Demo - How to configure WAF</h1><p>Hello and welcome to this lecture where I’ll provide a demonstration on how to configure the AWS WAF service. The key points in this demonstration will show you, where to find the WAF service, how to set up a Condition, and I’ll explain each of them with their corresponding filters, how to set up a Rule, how to set up a Web ACL, and how to associate a Web ACL to a CloudFront Distribution. So just opened up my AWS account and I’m at the main screen. So the first thing I need to do is go to the WAF service. Now you can find it under the security, identity, and compliance category. And you’ll see it’s down here, labeled as WAF &amp; Shield. So, if you go into that, and that will then load up this screen. And we can see here we have AWS WAF, AWS Shield and AWS Firewall Manager. Later in this course I’ll be talking about both AWS Firewall Manager and also AWS Shield. But for now, all I want to do is go to AWS WAF. So if you click on the blue button, and that takes us into the WAF Dashboard. Now I haven’t got any configuration in here at all. I kind of wanted to show you how to create this from scratch. So to start with, we need to configure a Web ACL. So, if you click on the blue button, we’ll then have a number of steps to complete. On the side here you can see step 1 through to step 4. So firstly, we have a concepts overview, and this is what we’ve already spoke about in the previous lectures. It talks about what conditions are, how rules contain conditions, and the fact that Web ACLs contain rules. So you can have a read through of that just to refresh your memory, and just get a bit more information. Once we’ve gone through that concepts, just click on the blue next button, and this is where you start to configure your web access control list or your Web ACL.</p>
<p> So to start with we need to give it name. Just call it CloudAcademy, and you’ll notice that whatever name I gave it, it’ll also automatically create a CloudWatch metric name. So you can view statistics about this web ACL from within CloudWatch under that metric. Now under the Region, we can either specify Global, if you want to use this web ACL with CloudFront, or we can specify a particular Region, if we want to apply it to an Application Load Balance for example. For this demonstration I want to create this web ACL for a CloudFront distribution. So if we click on next… Now this is where we can create our conditions. Now we have a number of conditions down the side here. We have our Cross-site scripting, Geo match, IP match, Size constraint, SQL injections, and String and regex matches. All of which I’ve discussed earlier. So let’s pick IP match conditions. So, we want to create and IP match condition that specifies and IP address or an IP address range, that you want to use to control access to our content. Click on Create Condition, then we can give this match condition a name. Just call it My IP. It’s associated with CloudFront. </p>
<p>Now we can select either an IPv4 or an IPv6 address, or just add in my IP address here. Then need to click on Add IP address, and we can see at the bottom here that’s it’s added our IP address to this condition. We then click on create, we can see here that an IP match condition has been created successfully. Let’s also create a GEO match condition as well. So again, create condition, server UK. Location type, country, location, type in United Kingdom, then select add location. And we can see here that it’s added it under the filter. Click on create, and we now have a GEO match condition as well. Once we’ve created all the conditions that we want for our web ACL, we can then scroll down to the bottom and click on next. Now here are your WAF rules. And remember the rules contain the conditions that you want to use to filter your web requests. So to start with, let’s create a rule, and give it a name. Just call it WAF. And again you’ll notice that any rules that you create, AWS WAF will automatically create another CloudWatch metric matching the name of all your rules as well. We have different rule types, regular or rate-based. For this demonstration I’ll select regular. Next we can then add our conditions to this rule. So, remember I created two conditions. I created one condition as a GEO match, and one as an IP address. </p>
<p>So, for this demonstration, let’s say that we want to block all requests that do not originate from the UK, which is one of the conditions I set up. And also to block any requests that do not originate from my IP address. So let’s say, when a request does not originate from a geographic location located in the UK, then add a condition, and, when it does not originate from an IP address from my IP. So at this stage, we don’t specify whether it allows or blocks it. So the rules simply contain the conditions that we created. And the variables of that condition, with regards to whether it does, or does not originate from that specific geographic location or the IP address. So to complete the rule, we then click on create. And we can see the rule we just created here. The rule name is WAF, and this is where we can specify the action. Either allow, block, or count. So this is the actual web access control list itself, which contains the rules. And, if you remember within our rule, we said if the geographic location does not originate from the UK, and does not come from my IP address, then we want that to block. So we are going to block all traffic that doesn’t come from the UK, and doesn’t come from my IP address. So that’s the action I’m going to elect for that rule. And then for any requests that do not match any rules within this web ACL, then we can either take a default action of allow all the requests, or block all the requests. For this demonstration, I’m going to block all the requests that don’t match any rules. At this point, click on review and create, and here’s the screen that just shows the Web ACL name, and the CloudWatch metric name, which is the same. It shows the rules that we have, the action of that rule, and also the default action of the Web ACL. The bottom it shows the AWS resources used in this Web ACL. </p>
<p>And at the minute we don’t have resources, we don’t have a CloudFront distribution list. So what we’ll do, we’ll then add this Web ACL to a CloudFront distribution. So to finish creating your Web ACL, simply click on confirm and create. And now you have your Web ACL created, with the name that we specified, CloudAcademy, and over here you can see the rules, etc. So what we can do now, is now add this Web ACL to an existing CloudFront distribution. So if I go across to CloudFront, and I have a distribution here, if I select it, and go to Distribution Settings, we can see here that next to AWS WAF Web ACL, there’s no entry. So what I need to do is click on edit, at the top here, there’s a drop down list for Web ACL’s, and we can now see the one that we created. So, if I select that, and then click on yes edit, to confirm our selection, we can now see that this CloudFront distribution has been associated with the newly created Web ACL that we stated. And that’s it. So just to clarify what we’ve done, we opened up the WAF service, we created two conditions. We created the GEO match condition, and an IP address condition. We then created a rule that contained both of those conditions. That rule was then added to the Web ACL, and we specified and action of block, and we also added a default action of block to the actual Web ACL itself for any requests that come through that didn’t match any rules. And then we associated that Web ACL to an existing CloudFront distribution.</p>
<h1 id="Monitoring-WAF"><a href="#Monitoring-WAF" class="headerlink" title="Monitoring WAF"></a>Monitoring WAF</h1><p>Hello and welcome to this lecture regarding monitoring your WAF service. As a prerequisite of this lecture you should have a basic understanding of AWS Simple Notification Service, and AWS CloudWatch. For more information on CloudWatch we have a lab which will guide you through an introduction to the service which can be found here. If you decide to monitor the activity of your WAF service and how it’s performing then are a rang of features that allow you to do this. However as with any monitoring you want to conduct, you need to make sure you know what you are monitoring for, what is the purpose of the monitoring, and also how often you intend to monitor and what elements of the service you want to monitor. Are you looking to perform monitoring to maintain the liability and operational performance? Or are you looking to understand trends allowing you to implement additional controls and making your infrastructure even more secure? Once you know what you’re monitoring for and why it becomes easier to select the best approach. And this is true for all monitoring. Let’s start with the service itself. From within the AWS WAF service dashboard in the management console you are able to view certain statistical information for the Web ACLs you have created. You can’t generate reports from here however the service dashboard does provide a graphical view of the requests that match each of your rules within each of your Web ACLS along with the total number of requests. For additional monitoring functionality and features you can use AWS CloudWatch. </p>
<p>As I mentioned in a previous lecture WAF integrates well with AWS CloudWatch allowing you to monitor set metrics for the service. WAF CloudWatch metrics are reported in one minute intervals by default and are kept for a two week period. The metrics monitored are AllowedRequests, BlockedRequests, CountedRequests, and PassedRequests. These are very much self explanatory, however these metrics provide a SUM count of web requests that hit a specific rule or Web ACL. The past request metric might throw you off but essentially this is a metric that lets you know how many requests didn’t match any rules within your Web ACL. You may have noticed during the demonstration I gave earlier that on the first step of the configuration of the WAF service you are asked to enter a name for the Web ACL. At the same time the service is automatically generating a CloudWatch metric name with the same name to allow you to report statistics against this Web ACL. For each Web ACL you have there will be an associated CloudWatch metric, and the same applies to WAF rules. From AWS CloudWatch you can perform all the same functions as with other services that you monitor such as alarm creation and viewing the history from the graphical interface. If you are creating a reactive policy within your Web ACL instead of a whole host of static pre-configurables that can get a little difficult to manage, then you could set a count action for a number of rules you have configured. From within CloudWatch you could then set an SNS notification to alert the security team to change the relevant rule action to either Allow or Block as required. By setting reactive rules it could help reduce a number of rules within your Web ACL and reduce the number of false positives that occur more often with larger rule sets. That brings me to the end of this lecture. Coming up next I’ll look at the limitations associated with AWS Web Application Firewall.</p>
<h1 id="Limitations-of-WAF"><a href="#Limitations-of-WAF" class="headerlink" title="Limitations of WAF"></a>Limitations of WAF</h1><p>Hello and welcome to this short lecture where I shall explain the limitations of the WAF service. Most AWS services have default service limits that can vary over time and from region to region. For AWS WAF, some of the default service limits can be increased by logging a request via the AWS Support Center, these conditions are as follows. You can have 100 conditions of each type, such as Geo Match or size constraints, however Regex is the exception to this rule where only 10 Regex conditions are allowed but this limit is possible to increase. You are able to have 100 rules and 50 Web ACLs per AWS account. You are limited to 5 rate-based-rules per account. Finally you can have 10,000 requests per second when using WAF within your application load balancer. For more limitations regarding specific WAF entries and to get the latest limitations please visit the following <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/waf/latest/developerguide/limits.html">link</a>. For small to medium solutions these limits will more than likely be more than adequate, especially as you can assign the same Web ACL to different CloudFront distributions without affecting these limits.</p>
<p>If however you are a large enterprise and find you are reaching these limitations then do be aware you can request an increase. Unfortunately not all the limits can be increased, and the following are static limitations that currently cannot be changed. These limitations also make a good reasons to implement a reactive rule policy to ensure you are only configuring rules and conditions that need to be configured. That brings me to the end of this lecture. Although it was short, it is important for you to understand the AWS WAF service limitations. Knowing these limitations can influence how you architect and design your Web ACLs.</p>
<h1 id="WAF-and-CloudFront"><a href="#WAF-and-CloudFront" class="headerlink" title="WAF and CloudFront"></a>WAF and CloudFront</h1><p>Hello and welcome to this lecture on how AWS WAF and AWS CloudFront can work together. As a prerequisite of this lecture, you should have a basic understanding of AWS CloudFront. More information on CloudFront can be found <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/cloudfront/overview-2/">here</a> from our existing course. AWS WAF relies heavily on AWS CloudFront distributions. However, it’s worth mentioning that this service dependency relationship is only one way, meaning that AWS CloudFront can operate and exist without AWS WAF being configured. AWS WAF also supports custom origins, allowing you to apply the same level of security to web infrastructure managed outside of AWS. As we saw in the demonstration earlier, the final step of configuring the service is to associate your Web ACL to an AWS CloudFront distribution. When this association between the two services takes place, it can take approximately 15 minutes for the Web ACL and associated rules to be propagated to all relevant Edge locations linked with your CloudFront distribution. This propagation is automatically instigated by CloudFront. </p>
<p>By propagating this configuration out to the Edge locations, it helps to ensure performance is maintained and latency kept low by not having to perform these WAF checks at another location in an availability zone somewhere else across the world. When a request is blocked by WAF, CloudFront is notified that the request was forbidden and CloudFront will return a 403 error to their browser. This is a standard error code when access to a HTTP resource is forbidden. Now this error doesn’t really provide much information to the end user, and offers no reason as to why the error was generated. All in all, it can be a bit frustrating for the end user. And so you can create your own custom 403 errors, and it’s far is more professional, and you can guide the user to other useful links and provide a polite reason as to why they may have experienced the error. </p>
<p>This creates a better user experience despite the user not being able to access the resource they were after. The next time a user is blocked by WAF, CloudFront would then display the custom error code instead. For more information on this customization, please see the following <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/custom-error-pages.html">link</a>. Before working on your Web ACLs, look at the CloudFront distribution that you intend on associating the Web ACL to. The reason being is that when you are creating your CloudFront distributions, you can select what HTTP methods that AWS CloudFront will respond to, and which ones it will not. Therefore, it would be inefficient to configure conditions that blocked against HTTP methods that would be dropped by CloudFront anyway. Instead, use a combination of the two, CloudFront configuration and WAF Web ACLs to process incoming requests effectively. When creating your CloudFront distributions, you have an option during step two, Create Distribution, to select an existing AWS WAF Web ACL so you don’t have to associate your Web ACLs through AWS WAF. You can also change your Web ACL from within the AWS CloudFront console as well by selecting your distribution and clicking on Edit under the General tab. From there, you can then select a different AWS WAF Web ACL. That brings me to the end of this lecture. Coming up next, I’ll be talking about the pricing options for this service.</p>
<h1 id="WAF-Pricing"><a href="#WAF-Pricing" class="headerlink" title="WAF Pricing"></a>WAF Pricing</h1><p>Hello and welcome to this lecture on pricing. This lecture will explain key points of AWS WAF pricing so there are no surprises. We know that pricing can can be a bit frustrating to understand at times. There are only three chargeable elements of AWS WAF, these being the number of incoming requests that WAF has to process, the number of Web ACLs that you have, and also the number of Rules within each of the Web ACLs. Do be aware however, that these costs are in addition to any AWS CloudFront costs that you have as they are an entirely different service with a different pricing structure and model. I briefly mentioned earlier within this course that you can use the same Web ACL on a number of different CloudFront distributions and that this doesn’t affect your limitations of WAF. Similarly, this is true for charging. You will not be charged extra for assigning the same Web ACL to multiple distributions. As you may be aware for some AWS services, pricing can change for the same service depending on which region you deploy that service in. However with AWS WAF, it is currently a flat charge regardless. With that in mind, the charges are as follows. For incoming requests, you are charged $0.60 per million web requests. For each Web ACL, you are charged $5 per Web ACL per month. </p>
<p>And with regards to your number of Rules per Web ACL, you are charged 1 per rule, per Web ACL per month. Note that there are no upfront costs to use WAF. It is charged purely on the three elements I just discussed so it can be quite easy to estimate how much this service is going to cost you across multiple CloudFront distributions. Let’s put an example around this pricing and see how easy it is to create pricing estimates. Let’s say you have five CloudFront distributions. Three distributions will have the same Web ACL and seven rules, and the other two will have their own Web ACL, each with five Rules. In total your CloudFront distributions have been calculated to have approximately five million requests per month. So the charge for the number of Web ACLs would be 3 x $5 which is $15 per month, because remember, three of the Web ACLs are the same. And the charge for the number of Rules per Web ACL would be 7 + 5 + 5, ‘cause remember three of the distributions owes in the same Web ACL with the same rules. Multiply that by 1 is 17 per month. And then the number of incoming requests would be 5 x 0.60 which is 3 per month. So the total per month for this solution would be 15 + 17 + 3 which is 35 per month. As you can see, it’s fairly easy to predict your spending with WAF as long as your have basic analytics of request rate for your distributions. That has now brought me to the end of this lecture on pricing. Coming up next I shall be discussing the AWS Firewall manager which works closely with AWS WAF.</p>
<h1 id="Overview-of-Firewall-Manager"><a href="#Overview-of-Firewall-Manager" class="headerlink" title="Overview of Firewall Manager"></a>Overview of Firewall Manager</h1><p>Hello and welcome to the first lecture covering AWS Firewall Manager. We now know and understand what the AWS WAF service is and what it’s used for. However, consider having multiple AWS accounts, all linked within an AWS Organization. If you have resources in these accounts that also need to be protected using WAF, perhaps when using CloudFront distributions, for example, it would be an administrative burden to repeat many of your configured rules across multiple accounts. Thankfully, AWS Firewall Manager has been designed to help you resolve this issue. Firewall Manager has been designed to help you manage WAF in a multi-account environment with simplicity and control. It allows you to protect your vulnerable resources across all of your AWS accounts within your AWS Organization. It can group and protect specific resources together, for example, all resources with a particular tag or all of your CloudFront distributions. One key benefit of Firewall Manager is that it automatically protects certain resources that are added to your account as they become active. Now, before using the Firewall Manager, there are a number of prerequisites that you need to meet, these being: you must ensure that your AWS Account is a part of an AWS Organization. </p>
<p>However, the Organization must have been configured with all features, not just consolidated billing, otherwise it will not work. For more information on AWS Organizations, please take a look at the following <a target="_blank" rel="noopener" href="https://aws.amazon.com/organizations/">link</a>. You must also define which AWS account will act as the Firewall Manager Admin account. And lastly, ensure you have AWS Config enabled. More information on AWS Config can be found on our existing course here. Let me now provide a quick demonstration on how to fulfill these three requirements. Okay, so for this demonstration we need to do three things. We need to setup an AWS Organization with all features enabled, not just the consolidated billing. We also need to decide which AWS account we’re gonna use as the Master account, and then also we need check to make sure we’ve got AWS Config enabled. So the first thing to do is to really understand which account you’re going to be using as the Master. So this account that I’ve logged into at the moment I’m going to be using as our Master account, and so from this account I’m going to also create an AWS Organization as well. Now, if you’ve already got AWS Organizations configured and setup, then you can skip this step. So let me start off by finding the Organization console, and, if you don’t have any Organizations setup at all, then you’ll be presented with this screen. So I’m gonna show you how to create it from scratch. So, from here, I can click on Create organization and this’ll just bring up a pop-up screen just to show you some of the benefits you get when creating organizations. Now the default is that you’ll create an organization with all features. If you just wanted to create an organization with consolidated billing features only, then you can click on this link down here, but remember we need all features enabled for the Firewall Manager to work. So, from here, I’ll click on Create organization, and then once your organization is created it’ll show it within this list here under the Account name and the start signifies that this is the Master account.</p>
<p> At this point when you setup a new organization, the account owner will receive an email to verify the new AWS Organization that you’ve setup. So, once you’ve verified that organization, what you can then do is invite your other member accounts that you want to be included under the Firewall Manager. Now to do that we simply go across to Invitations, and then across to Invite account. Now, if you have an existing account, you can use the Invite account option here, and then enter the account ID or, if you want you to create a new account and add it to this organization, then you can do so using this option here, but I’ve already got another account setup. So I’m just simply going to add the account ID, and then once I’ve entered the account ID I can add some Notes as well if I want to and then I simply click on Invite. And that shows that this account has been invited to join to this AWS Organization. Now what I need to do is go across to this member account and accept that invitation. So let’s do that now. So I’m now logged into that second account, and, if I go to AWS Organizations, I can see over on the left-hand side here I have an Invitation. So, if you click on Invitations, it shows you the Organization ID and the account name and the Requested controls and we enabled all features. So here we can simply Accept or Decline this invitation.</p>
<p> I’m going to click on Accept and then a splash screen just comes up just to let you know that you’re about to join the organization and want you to Confirm. And that’s it. It now says your account belongs to the following organization. So now we’ve completed the first step. We’ve setup the AWS Organization with the Master account, and also this member account. Now I want to define which of my accounts is going to be the administrative account for the AWS Firewall Manager, and, for this, I’m gonna go back to the account that’s setup the organization and I’m gonna use that as the administrative and Master account for the Firewall Manager. So let me switch back to that account. Okay, so I’m now back in my Master account where I setup the AWS Organization. So what I need to do to designate this account is the administrator account for the Firewall Manager. </p>
<p>I need to go the WAF service, and here on the right-hand side we can see AWS Firewall Manager. Now, if we go into the Firewall Manager console, we can see that we have our prerequisites here. Now it’s saying that we already have this AWS account in an organization as we have a tick, but we haven’t fulfilled this prerequisite here where we must designate an account as the AWS Firewall Manager administrator account. Now we know we haven’t done that, which is why we’re at this stage now, and to set this account as the administrator account we can click on Get started and all we need to simply do is add in the AWS account ID that we want to be the administrator. So, if I just paste that in and then simply click on Set administrator, and it gives you a confirmation message saying are you sure you want to proceed? And then once you’re sure just click on Set administrator and that’s it. Now, this AWS account will now act as the AWS Firewall Manager administrator account. So that’s the second prerequisite fulfilled. Lastly, we just need to make sure we’re running AWS Config. Now I already have AWS Config running on this account, so if I swap over to the member account in our AWS organization and I’ll show you just very quickly how to setup AWS Config on there. Type in config, and we can see here that we don’t have AWS Config enabled at the moment. So what we need to do is click on Get started. For the sake of this demonstration I’m just gonna accept all default options here about which resources to track and the Amazon S3 bucket et cetera and creating the AWS Config role. </p>
<p>If you need more information on AWS Config, then we do have a course dedicated to this, and it goes into to the configuration of it at quite some depth. So I’m gonna click on Next. I’m not gonna have any AWS Config rules at the moment, so I’ll skip this step and there’s just a Review screen at the end and I’m just gonna click on Confirm. And you wanna make sure that you have AWS Config enabled on all of your accounts that you want to use with AWS Firewall Manager. Okay, so that’s AWS Config setup. So now we have carried out all three prerequisites. We’ve decided on the Master account. We’ve setup an AWS organization and have added our member accounts as required and we’ve enabled AWS Config. So now if I go back to the Master account, and, if I go to the organizations, we can now see that the other account is a part of the same organization and we can see the date that they joined as well. So now if we go across to the AWS Firewall Manager, which is under the WAF Management Console, and we go across to the AWS Firewall Manager here we can see that we’ve met all the prerequisites that are required to begin creating our AWS Firewall Manager policies. And that’s it. That now brings me to the end of this lecture. Coming up next I will explain some of the components used by the Firewall Manager to enable you to manage and control your WAF rules across different accounts.</p>
<h1 id="Components-of-Firewall-Manager"><a href="#Components-of-Firewall-Manager" class="headerlink" title="Components of Firewall Manager"></a>Components of Firewall Manager</h1><p>Hello and welcome to this lecture where I shall introduce the components of the AWS Firewall Manager service. There are primarily three different components to Firewall Manager that allow you to control and manage walls across multiple AWS accounts within your AWS organization. These being, WAF rules, rule groups and Firewall Manager policies. I covered what AWS WAF rules are in a previous lecture so I won’t go over the same information again. So next we have rule groups. These simply allow you to group together one or more WAF rules that will all have the same action applied when the conditions are met within a rule. You have two options for your rule groups, you can create your own and add your own WAF rules or you can purchase existing rule groups pre-configured with set AWF WAF rules by the AWF Marketplace. By using the Marketplace rule groups it provides a number of benefits. For example they are all pre-configured and ready to deploy and are supplied by AWS and other AWS approved partner companies. Many of them allow protections against known vulnerabilities, specifically those highlighted within the open web application security project, the OWASP top 10 list, and they could help you to gain compliance to specific regulations such as PCI or HIPAA. Unlike web rules, rule groups can only contain one of two actions. </p>
<p>These being either block or count. And they have the same meaning as defined within the WAF section. There is no allow action for rule groups. Also you can only have 10 rules per rule group which can’t be increased. For other limitations of Firewall Manager please see the following <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/waf/latest/developerguide/fms-limits.html">link</a>. Once you have created your rule groups containing your rules, you then have to create an AWS Firewall Manager Policy. This policy simply contains the rule groups that you want to assign to your AWS resources. It’s important to point out that you can only have two rule groups per policy, one customer created rule group, and one AWS Marketplace rule group. This limit cannot be changed. So to recap, AWS WAF rules are created or selected first, which as we know contain conditions. WAF rules can then be added to a rule group which will have either a block or a count action associated. Finally, a rule group is then added to an AWS Firewall Manager Policy which is then associated to AWS resources, such as your cloud front distributions or application load balances. Do be aware that the cost of each policy is $100 per policy, per region, per month. That has brought me to the end of this short lecture. Coming up next I will provide a demonstration on how to use and create some of these components to add to our policy.</p>
<h1 id="Demo-Firewall-Manager"><a href="#Demo-Firewall-Manager" class="headerlink" title="Demo - Firewall Manager"></a>Demo - Firewall Manager</h1><p>Hello, and welcome to this lecture, where I shall demonstrate how to create an AWS Firewall Manager Policy, containing Rule Groups and WAF Rules. Okay, so I’m at the dashboard of my AWS Management Console, and I firstly need to go to the WAF &amp; Shield service. So if I go across, if I then scroll down to the bottom, where it says AWS FMS, which is the Firewall Management Service, click on security policies, and we can see here that I don’t have any security policies created at the moment. If I click on the blue button, create policy, it’s a similar setup to the demonstration I gave earlier when I showed you how to configure WAF, where on the left hand side it gave you a number of steps to complete, and it started off with a concept overview. So you can take a read through that concept overview if you wish. Then at the bottom you have two options, one to create an AWS Firewall Manager policy, and add existing rule groups that you may have already created, or to create an AWS Firewall Manager policy and add a new rule group. For this demonstration I’m going to select the second option, so I can show you how to create a new rule group. So once you’ve made that selection click on next. Now, here we have our conditions, and these conditions are exactly the same as we had in the WAF demonstration earlier, and if we scroll down we can still see that we have the same conditions from the demonstration we created earlier. So it picks up the same information that you’ve already created in WAF. So once you are happy with creating your conditions then you simply click on next. Now step two is where you need to create the rules, just like we did earlier in the previous demonstration when configuring WAF. So, to create a new rule it still has exactly the same options. </p>
<p>So I’m just going to leave that for this demonstration as we’ve done that in the previous one. And as we can see here, we have our previous rule that we created earlier. Click on next. Now we have our rule groups, and the rule groups contain multiple rules and define what actions to take when any of the rules match a request. So we don’t have any rule groups configured at the minute for Firewall Manager, so let’s set one up. Click on create rule group. And we’ll call this our FirewallRule. And again, we have a CloudWatch metric name, the region that we specified earlier. And if we go down to rules in this group, we can select our rules. Now we only have one rule, but if you have more than that, all will be listed here. Click on add rule, and here you can see that we can specify an action. Now remember, the Firewall Manager policies only allow other block or count actions, so we’re gonna leave this as block. And if you wanted more rules, you’d simply click on the dropdown list and add all the appropriate rules that you want. Click on create. And now we have our rule group created, and then we can see the name FirewallRules. Click on next. Now this is the first part of the policy itself, so those first three steps that we just carried out were, creating the conditions, the rules, and the rule group. So a lot of those elements are pulled from WAF, but you can create them from here as well. Now the next section is to do with creating the firewall policy. And the first part is to describe the policy and add rule groups. Just call it MyPolicy. </p>
<p>If you go down to the rule groups, now we can see the rule groups here, that we just created, and if we had more than one rule group then we’d see it in this dropdown list here, and we can add it to the same policy. Now the action has been specified by the rule group, or we can change it here to count. But we’re gonna use the action specified by the rule group, which was block. Now remember, if you did want to add more than one rule group to a policy, you can only have one customer rule group and one AWS Marketplace rule group. Click on next. This section defines the scope of the policy, and you can select accounts to either include or exclude from this policy, which is optional. Just gonna leave that as default. And we can select resource types that will be protected, and we want a CloudFront distribution, which is why we selected the global option in the region selector earlier. Now you can either use tags to include or exclude resources, so if you have tags with specific keys and values then you can add them in there. For this demonstration, I’m just gonna leave that blank. Now you have two options at the bottom here, you can either create and apply this policy to existing and new resources, or simply, just create the policy, but don’t apply to any resources at the minute. Now if you look at the first option, it explains that this option will create a web ACL in each account within the AWS Organization, and associate the web ACL with the resources in the accounts. The second option, it will simply create a web ACL in each account within the organization, but it will not apply that web ACL to any resources. </p>
<p>So for this demonstration, I’m simply just going to create the policy, but not apply it to any resources. Click on next. Then we have a final review screen, where it’ll just give you the name of the policy that you created and the region, whether you selected it for CloudFront or an application load balancer. The rule groups within your policy, and the associated action, and it states that all accounts in your AWS Organization will be protected by this policy. We haven’t applied any resource tags, and it shows that this policy is to be created but not be applied to any resources. And it will apply to all CloudFront distribution resources. At the bottom here, you have a message stating that you must enable Config for each member account in your AWS Organization, which we done earlier. And at the bottom here it also states that, in addition to your Firewall Manager charges, you’ll also incur charges for AWS Config. Before you can create your policy, you must click on the tick box, and then click create. Now I’m not going to click on create, because if I do then that’ll cost $100 for each policy. This is the end of the demonstration, but once you are happy with your configuration and your policy, you simply click create. And that’s the final stage.</p>
<h1 id="What-is-AWS-Shield"><a href="#What-is-AWS-Shield" class="headerlink" title="What is AWS Shield?"></a>What is AWS Shield?</h1><p>Hello and welcome to this section of the course focusing on the third and final service, AWS Shield. AWS Shield is closely related to both AWS WAF and also the AWS Firewall Manager. So what is it used for? Well, AWS Shield has been designed to help protect your infrastructure against distributed denial of service attacks, commonly known as DDoS. These attacks are very common, and the attack itself targets a host which might be running a website or web application, and it receives a huge number of requests simultaneously sent maliciously by an attacker from multiple distributed sources. This increase and flood of traffic aims to prevent legitimate requests getting through to host and being processed, while at the same time severely hindering the performance of the application or website. So much so in fact, that users often think the site is down. </p>
<p>There are a number of different types of DDoS takes that can take place, for example, a SYN Flood. In a Syn Flood attack, a large number of connections are made to the host under attack. The host will then respond accordingly with an SYN&#x2F;ACK packet, at which point the client sending the original connection request would normally respond with another SYN, completing the three-way handshake to allow communications to begin. However, this final SYN packet is not sent to the host, and this leaves a huge number of open connections on the host, resulting in diminished resources available to process legitimate requests. DNS Query Flood. By using multiple DNS queries an attacker can drain the resources against a DNS server, such as Route 53 in AWS. HTTP flood and cache-busting attacks. These attacks operate at layer seven, the application layer. And during an HTTP flood attack an attacker sends a large amount of HTTP requests, which may include POST and GET requests to a host, consuming the resources available. Cache-busting attacks are similar to HTTP floods, however, by using the HTTP request query string they are able to force content to be retrieved from the originating server, rather than from an edge location, which impacts the performance of the source servers available resources unnecessarily. AWS Shield itself is available at two different levels of features, AWS Shield Standard and AWS Shield Advanced, and AWS shield advanced has a lot more power and protection on offer than standard. AWS Shield Standard is free to everyone, well, at least anyone who has an AWS account, and it offers DDoS protection against some of the more common layer three, the network layer, and layer four, transport layer, DDoS attacks. This protection is integrated with both CloudFront and Route 53. </p>
<p>AWS Shield advanced offers a greater level of protection for DDoS attacks across a wider scope of AWS services for an additional cost. This advanced level offers protection against your web applications running on EC2, CloudFront, ELB and also Route 53. In addition to these additional resource types being protected, there are enhanced levels of DDoS protection offered compared to that of Standard. And you will also have access to a 24-by-seven specialized DDoS response team at AWS, known as DRT. With these additional features, the advanced level also provides an enhanced monitoring capability allowing you to view real-time metrics of any attacks against your resources. Whereas the Standard version of Shield offered protection against layer three and layer four, Advanced also offers protection against layer seven, application, attacks. Another great advantage is the fact that you also get cost protection as a part of the plan, whereby your resources may scale suddenly and unexpectedly to cope with the rise in traffic. From a cost perspective, if your decide to go with AWS Shield Advanced then you also get AWS WAF included in the same price, and this price is currently $3,000 a month, plus data transfer fees. As you can see from this image, there are a significant amount of advantages with the Advanced version of AWS Shield over Standard. That now brings me to the end of this lecture. Coming up next I shall provide an overview of how to set up and implement AWS Shield Advanced.</p>
<h1 id="Configuring-Shield"><a href="#Configuring-Shield" class="headerlink" title="Configuring Shield"></a>Configuring Shield</h1><p>Hello and welcome to this lecture where I want to cover how to configure and set up AWS Shield Advanced. There are a number of different steps involved if you want to make use of the benefits and features discussed in the previous lecture. Let’s take a look at them. Firstly, we need to activate AWS Shield advanced, which can be done via the Management Console using the WAF and Shield Service. When you go into the service, you are presented with the dashboard, you can simply select Summary from the AWS Shield menu on the left-hand side of the dashboard. This will then present you with a screen which we also saw in the previous lecture as shown. At the bottom of the screen, you can see in blue, a button that says Activate AWS Shield Advanced. It’s worth noting that AWS Shield is AWS account specific, so you will need to perform this step on each AWS account that you want to use it within. You must then accept a number of terms and conditions before you commit to activating the service. Once you have activated AWS Shield with your AWS account, you are then ready to define which resources you want to protect with the service. This is a manual process and is not done automatically. You may think Shield self-discovers resources, however, you need to manually select the resources needing protection. You can select the resources using ARNs providing the resource is within the same account, so simply select all supported resources from a dropdown list. If one of your resource is an EC2 instance, then you must first associate an EIP, an Elastic IP Address, to that instance for it to be protected as AWS Shield protects whatever resource is associated to that EIP. Once your resources are defined and selected, you must then add rate-based rules. Having these configured, it can be a primary indicator that a DDoS attack is in progress. </p>
<p>You may remember from a previous lecture in this course that a rate-based rule counts the number of requests that are being received from a particular IP address over a time period of five minutes. If there is a surge in requests from a particular IP address out of the ordinary, then these rate-based rules can alert you of this behavior. These rate-based rules are only associated with CloudFront distributions and application load balancers and so are not required or available for other resource types, such as EC2 instances. For each supported resource in the list, it is recommend you associate a Web ACL with a rate-based rule. If you have any resources already in the list being protected by a Web ACL, then you can’t change that Web ACL for that resource. If you want it, you must first remove it from the Web ACL within WAF before associating it to a new one. Following your rate-based rule configuration of your resources you then have the opportunity to pre-authorize the AWS DDoS Response team, the DRT, to have the ability to review, update and modify your Web ACLs and Shield configurations during an attack to help you resolve your issues quickly and effectively. If you are not happy to authorize the DRT team to access your resources, then you can select the option of Do not grant the DRT access to my account. If you decide you do want the assistance of the DRT team, you must be subscribed to either the business or enterprise support plans. The authorization process is governed by an IAM role where you can either create a new or select an existing role. </p>
<p>Creating a new role will set up all the relevant permissions automatically. If you wish to select an existing role, you must ensure that it has the AWSShieldDRTAccessPolicy managed policy attached and that you trust the service principal of drt.shield.amazonaws.com to use that role. If you need more information relating to IAM policies and permissions, please see our existing course <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/overview-of-aws-identity-and-access-management-iam/introduction-81/">here</a>. It’s also possible to allow the DRT team to access flow log information stored in an S3 bucket, you just need to supply the name of the bucket and the DRT team will be given permissions of GetBucketLocation, GetObject, and ListBucket to review the flow log information. Following this step, it’s recommended that you set up some CloudWatch alarms and use the SNS service to notify you about your resources. AWS Shield will configure the SNS topic for each region specified and it will also configure CloudWatch metrics to notify you of any potential DDoS activity. It’s also possible to configure a CloudWatch Dashboard of the data collected by Shield Advanced. To learn more about CloudWatch and Dashboards, please see our existing course <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-web-services-cloudwatch/introduction-39/">here</a>. Once this is done, then your configuration of AWS Shield Advanced is then complete. However, it’s also worth noting and viewing the Global Threat Environment Dashboard which can help provide an overview of the top attacks, and the number of attacks across the AWS landscape.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Hello and welcome to this final lecture where I shall be summarizing the key points from all of the previous theory lectures. I started off by explaining what the AWS WAF service was, and in this lecture I explained that AWS WAF is a service that helps to prevent websites and web applications from being maliciously attacked by common web attack patterns. It’s also used to identify how Amazon CloudFront distributions and application load balancers respond to web requests based upon specific conditions. It filters both HTTP and HTTPS request distinguishing between legitimate and harmful inbound requests. AWS WAF is comprised of conditions, WAF Rules, and web access control lists, which are also known as Web ACLs. Conditions allow you to specify what element of the incoming HTTP or HTTPS request you want WAF to be monitoring for. The condition used can be cross-site scripting, Geo Match, IP addresses, size constraints, SQL injection attacks, String and Regex Matching. These conditions are then added to AWS WAF Rules. And AWS Rules allow you to group one or more conditions into a list acting as the rule, where each condition is ANDed to form the complete rule. And there are two different rule types, Regular and Rate-Based. Every condition in the rule has to be met for the action of the rule to be carried out. And these actions within the rule are defined within the Web ACL Web ACLs form the final component in the decision process as to whether the request traffic is blocked or allowed on through to the associated CloudFront distribution or application load balancer. And the actions that are allowed are Allow, Block and Count. Incoming requests to WAF will be matched against a rule base in the order that they appear Following this lecture I answered the question, when and why should you use AWS WAF. The key points taken from this lecture were AWS WAF should be used if you are delivering web content via a CloudFront distribution or through an application load balancer. Without using a WAF you could be exposing your websites and web apps to potentially harmful and malicious traffic. Security vulnerabilities exist across web applications and its important that these risks of exposure are mitigated as early as possible. OWASP provide a top 10 list of the most critical security risks facing organizations around application architecture which you should aim to protect against. An AWS WAF might be able to achieve a higher level of security compliance. AWS WAF sits logically between the end user requesting access to your website or web app and your CloudFront distributions. </p>
<p>Before a request has traversed your CloudFront environment and network you have the ability to detect, analyze and either allow or block the incoming request. The Web Application Firewall is very easy to manage either via the AWS Management Console or via API calls supplied. It also integrates very well with Amazon CloudWatch for monitoring specific WAF metrics and AWS Lambda for automation Next I focused on Monitoring the AWS WAF service, and here we learnt that you can view certain statistical information for your Web ACLs that you have created within the WAF dashboard. And the service dashboard provides a graphical view of the requests that match each of your rules within each of your Web ACLs along with the total number of requests. Integration exists with Amazon CloudWatch allowing you to monitor set metrics for the service in one minute intervals by default. And these CloudWatch Metrics include AllowedRequests, BlockedRequests, CountedRequests, and PassedRequests. And Amazon CloudWatch automatically generates a CloudWatch metric with the same name of your Web ACLs and WAF Rules. I then gave a short lecture on some of the service limits for AWS WAF which were as follows. You can have 100 conditions of each type, such as Geo Match or size constraints, however, Regex is the exception to this rule where only 10 Regex conditions are allowed and this limit is possible to increase this limit. You are able to have 100 rules and 50 Web ACLs per AWS account. And you are also limited to five rate-based-rules per account. Finally you can have 10,000 requests per second when using WAF with your application load balancer. The lecture following this looked at how AWS WAF integrated and worked with Amazon CloudFront, and within this lecture I explained that AWS WAF relies heavily on AWS CloudFront distributions. And it also supports custom origins allowing you to apply the same level of security to web infrastructure managed outside of AWS. And this association between the Web ACL and a CloudFront distribution can take approximately 15 minutes for the Web ACL and associated rules to be propagated to all relevant edge locations linked with your CloudFront distribution When a request is blocked by WAF, CloudFront is notified that the request was forbidden, returning a 403 error. </p>
<p>But it’s also possible to create your own custom 403 errors to give greater information to the end user. You can use a combination of restrictions using CloudFront and your Web ACL to control inbound traffic requests. The last lectures to do with AWS WAF provided a rundown on pricing of the service. So the pricing summary looks as follows. There are three chargeable elements of AWS WAF. The number of incoming requests. The number of Web ACLs that you have. And the number of WAD Rules within each of the Web ACLs. You will not be charged extra for assigning the same Web ACL to multiple CloudFront distributions. And incoming requests are charged at 60 cents per million web requests. And the number of Web ACLs are charged at $5 per Web ACL per month. And the number of Rules per Web ACL are charged at $1 per rule, per Web ACL per month. Do bear in mind that these prices may change over time, so always refer back to the AWS documentation. And there are no upfront costs to use WAF. This then ended the section on WAF. And following this I then focused on the AWS Firewall Manager. </p>
<p>The first of these lectures introduced the service where I explained that AWS Firewall Manager was designed to help you manage and control AWS WAF across multiple AWS Accounts when using AWS Organizations. It can group and protect specific resources together, for example, all resources with a particular tag, or all of your CloudFront distributions. A key benefit of Firewall Manager is that it automatically protects certain resources that are added to your account To begin using AWS Firewall manager you have to meet three prerequisites, these being, ensuring that your AWS Account is a part of an organization with all features activated. You must define which AWS account will act as the Firewall Manager Admin account. And you need to have AWS Config enabled. I then looked at the components of the service and during this lecture I covered the following elements. WAF Rules which are the same rules used within AWS WAF. Rule Groups which allow you to group together one or more WAF rules that will all have the same action applied when the conditions a rule are met. And hese Rule Groups can either contain a Block or Count action. You can only have 10 rules per group, which is a fixed limitation. Firewall Manager Policies. This policy contains the rule groups that you want to assign to your AWS resources. You can only have two rule groups per policy, One customer created rule group, and one AWS Marketplace rule group. Again, this is a fixed limitation. So logically, AWS WAF rules are defined, which are then added to a Rule Group with either a Block or Count action associated, and this rule group is then added to an AWS Firewall Manager Policy, which is then associated to AWS resources. The cost of each policy is $100 per policy, per region, per month. I then performed a demonstration showing you how to configure an AWS Firewall Policy Manager. </p>
<p>The final service I looked at was the AWS Shield service. Within the first lecture covering this service I explained that AWS Shield is closely related to both AWS WAF and also the AWS Firewall Manager AWS Shield has been designed to help protect your infrastructure against DDoS attacks. And there are a number of different types of DDoS takes, for example, a SYN Flood, a DNS Query Flood, a HTTP flood or cache-busting attacks. AWS Shield comes in two variations, which is AWS Shield Standard and AWS Shield Advanced. AWS Shield Advanced has more power and protection than the Standard version. AWS Shield Standard is free to everyone and offers DDoS protection against some of the more common layer three and layer four DDoS attacks. AWS Shield Advanced offers the following on top of Standard. A greater level of protection for DDoS attacks across a wider scope for an additional cost. Protection against EC2, CloudFront, Elastic Load Balancing and also Route 53. It provides access to a 24-by-seven specialized DDoS response team at AWS, known as DRT. Provides an enhanced monitoring capability. Protection against layer three, four and seven DDoS attacks. It has added cost protection. And it costs $3,000 per month. The final lecture on AWS Shield provided a process on how to configure and set up AWS Shield Advanced. </p>
<p>This lecture covered the following points. AWS Shield Advanced is activated via the Management Console using the WAF and Shield Service. It’s AWS account specific, so you will need to activate the service on each account required. And you must manually define the resources you want to protect once the service is activated. To protect EC2 instances, you must first associate an Elastic IP first. You must then add Rate-based rules providing you with a primary indicator that a DDoS attack is in progress. You have the opportunity to pre-authorize the AWS DDoS Response team team to update and modify your Web ACLs and Shield configurations during an attack. But if you do not want AWS to have this access, then you can select the Do not grant the DRT access to my account. Access is provided via an IAM role. And it’s recommended you configure CloudWatch alarms with alerting via SNS service. By viewing the Global Threat Environment Dashboard it can provide an overview of the top attacks, and the number of attacks across the AWS landscape. That has now brought me to the end of this lecture and to the end of this course. You should now have a greater understanding of how AWS WAF, Firewall Manager and Shield can be used to help mitigate you against vulnerabilities and threats towards your web application infrastructure and resources. For further information on this topic you might want to take a look at the following AWS whitepaper. If you have any feedback on this course, positive or negative, please contact us by sending an email to <a href="mailto:&#x73;&#x75;&#112;&#112;&#111;&#114;&#x74;&#x40;&#x63;&#x6c;&#111;&#117;&#100;&#97;&#99;&#97;&#x64;&#x65;&#x6d;&#121;&#46;&#99;&#x6f;&#x6d;">&#x73;&#x75;&#112;&#112;&#111;&#114;&#x74;&#x40;&#x63;&#x6c;&#111;&#117;&#100;&#97;&#99;&#97;&#x64;&#x65;&#x6d;&#121;&#46;&#99;&#x6f;&#x6d;</a>. Your feedback is greatly appreciated. Thank you for your time and good luck with your continued learning of cloud computing. Thank you.</p>
<h1 id="3When-and-why-should-I-use-WAF"><a href="#3When-and-why-should-I-use-WAF" class="headerlink" title="3When and why should I use WAF?"></a>3<strong>When and why should I use WAF?</strong></h1><p><a target="_blank" rel="noopener" href="https://owasp.org/www-project-top-ten/">Top 10 List Critical Risks</a></p>
<h1 id="6Limitations-of-WAF"><a href="#6Limitations-of-WAF" class="headerlink" title="6Limitations of WAF"></a>6<strong>Limitations of WAF</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/waf/latest/developerguide/limits.html">Latest limitations of WAF</a></p>
<h1 id="7WAF-and-CloudFront"><a href="#7WAF-and-CloudFront" class="headerlink" title="7WAF and CloudFront"></a>7<strong>WAF and CloudFront</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/cloudfront/overview-2/">Course: Working with Amazon CloudFront</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/custom-error-pages.html">CloudFront Error page customisation</a></p>
<h1 id="9Overview-of-Firewall-Manager"><a href="#9Overview-of-Firewall-Manager" class="headerlink" title="9Overview of Firewall Manager"></a>9<strong>Overview of Firewall Manager</strong></h1><p><a target="_blank" rel="noopener" href="https://aws.amazon.com/organizations/">AWS Organizations</a></p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-to-aws-config/">Course: Introduction to AWS Config</a></p>
<h1 id="10Components-of-Firewall-Manager"><a href="#10Components-of-Firewall-Manager" class="headerlink" title="10Components of Firewall Manager"></a>10<strong>Components of Firewall Manager</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/waf/latest/developerguide/fms-limits.html">Limitations of Firewall Manager</a></p>
<h1 id="13Configuring-Shield"><a href="#13Configuring-Shield" class="headerlink" title="13Configuring Shield"></a>13<strong>Configuring Shield</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/overview-of-aws-identity-and-access-management-iam/introduction-81/">Course: AWS: Overview of AWS Identity &amp; Access Management (IAM)</a></p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-web-services-cloudwatch/introduction-39/">Course: Amazon Web Services CloudWatch</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36/" class="post-title-link" itemprop="url">AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:42" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:42-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 22:55:16" itemprop="dateModified" datetime="2022-11-19T22:55:16-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hello, and welcome to this course. I shall be looking at the different encryption mechanisms that can be utilized across a range of AWS services, that are commonly used for big data solutions, thereby enhancing security around the protection of your data. Before we start, I would like to introduce myself.</p>
<p>My name is Stuart Scott. I’m one of the trainers here at Cloud Academy, and I specialize in AWS, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">Amazon Web Services</a>. Feel free to connect with me with any questions using the detail shared on the screen. Alternatively, you can always get in touch with us here at Cloud Academy using the community forum where one of our Cloud experts will reply to your question.</p>
<p>This course has been designed for those who are responsible for implementing and managing security, architecting big data solutions, and anyone wanting to learn more about the encryption options available across different AWS services. This course will cover the following topics regarding services that can be used for big data encryption.</p>
<p>Starting with an overview of encryption, this lecture explains what encryption is, the difference between symmetric and asymmetric encryption options, and why you may want to implement encryption in the first place.</p>
<p>Then, I will talk about some of the encryption options for big data storage services, including S3 and Amazon Athena, and how it works with S3 encryption.</p>
<p>Then Elastic MapReduce, followed by RDS. Following these lectures, I will then look at encryption for the Amazon Kinesis platform, which will include Kinesis Firehose, and Kinesis Streams. Finally, I will then look at encryption mechanisms for big data warehousing, where I shall be focusing on Amazon Redshift.</p>
<p>At the very end of the course, there will be a summary lecture highlighting the main points taken from each of the previous lectures within the course. Almost like a cram session.</p>
<p>This course will provide you with an overview of what encryption is, and the differences between symmetric and asymmetric cryptography.<br>You will also gain the knowledge and understanding of available encryption mechanisms that can be used with big data solutions running on the following AWS services; S3, Athena, EMR, RDS, Kinesis Firehose, Kinesis Streams, and Redshift. As I have already mentioned, this course will be based on a number of different AWS services, and so it would be beneficial to have a basic understanding and awareness of each.</p>
<p>It is also recommended that you have an understanding of the Key Management Service, KMS, as this will be referenced throughout the course. If you are unfamiliar with KMS, then we do have an existing course that focuses on the service, which can be found here. Feedback on our courses here at Cloud Academy are valuable to both us as trainers, and any students looking to take the same course in the future.</p>
<p>If you have any feedback, positive or negative, it would be greatly appreciated if you could use the comment section found at the landing page of this course. That now brings us to the end of this lecture. Coming up next, we’re going to start off by looking at an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/overview-of-encryption-1/">overview of encryption</a>.</p>
<h1 id="Overview-of-Encryption"><a href="#Overview-of-Encryption" class="headerlink" title="Overview of Encryption"></a>Overview of Encryption</h1><p>Hello, and welcome to this lecture where I will be explaining what encryption is at a high level, and when and why you may want or need to use it.</p>
<p>Unencrypted data can read and seen by anyone who has access to it, whether this data is stored at rest or set between two locations in transit, it’s known as plaintext or clear text data.</p>
<p>The data is plain to see and can be seen and understood by any recipient. There is no problem with this, as long as the data is not sensitive in any way and doesn’t need to be restricted. However, on the other hand, if you do have data that is sensitive, and you need to ensure the contents of this data is only viewable by a particular recipient or recipients, then you need to add a level of encryption to that data.</p>
<p>But what is encryption? Data encryption is the mechanism in which information is altered, rendering the plaintext data unreadable through the use of mathematical algorithms and encryption keys. When encrypted, the original plaintext data is now known as ciphertext, which is unreadable. To decrypt the data, an encryption key is required to revert the ciphertext back into a readable format or plaintext.</p>
<p>A key is simply a string of characters used in conjunction with the encryption algorithm, and the longer the key, the most robust the encryption. This encryption involving keys can be categorized by either being symmetric cryptography or asymmetric cryptography. Let’s talk a look at both methods. I’ll start with symmetric cryptography first.</p>
<p>With symmetric encryption, a single key is used to both encrypt and also decrypt the data. So for example, if someone was using the symmetric encryption method, they would encrypt their data with a key, and then when that same person needed to access that data, they would use the same key that was used to encrypt the data to decrypt the data.</p>
<p>However, if the encrypted data was being read by a different person, that person would need to be issued the same key. Remember, the same key is needed to decrypt the data that was used to encrypt it. As a result, this key must be sent securely between two parties, and here exposes a weakness in this method.</p>
<p>If the key is intercepted by anyone during that transmission, then the third party could easily decrypt any data associated with that key.</p>
<p>Some common symmetric cryptography algorithms that are used are AES, advanced encryption standard, DES, digital encryption standard, Triple-DES, and Blowfish. Now let’s compare this to asymmetric encryption, which involves two separate keys.</p>
<p>One is used to encrypt the data, and another separate key is used to decrypt the data. These keys are both created at the same time and are linked through a mathematical algorithm. One key is considered the private key and should be kept by a single party, and should never be shared with anyone else. The other key is considered the public key, and this key can be given and shared with anyone.</p>
<p>Unlike with symmetric encryption, the public key does not have to be sent over secure transmission. It doesn’t matter who has access to this public key, as without the private key, any data encrypted with it cannot be accessed. Both the private and public key is required to decrypt the data when asymmetric encryption has been used.</p>
<p>So how does it work? If another party wanted to send you an encrypted message or data, they would encrypt the message using their own public key, which could be made freely available to them or anyone. It’s public for a reason. This message is then sent to you where you will use your own private key which has that mathematical relationship with your public key to decrypt the data.</p>
<p>This allows you to send encrypted data to anyone without the risk of exposing your private key, resolving the issue highlighted with symmetric encryption. The advantage that symmetric has over asymmetric is the speed of encryption and decryption. Symmetric is a lot faster from a performance perspective.</p>
<p>However, it does carry an additional risk, as highlighted. Some common examples of asymmetric cryptography algorithms are RSA, Diffie-Hellman, and Digital Signature Algorithm. So now we know what encryption is and are familiar with the differences between symmetric and asymmetric algorithms, when and why you may want to use encryption.</p>
<p>It may seem obvious. You want to protect your data, and that’s true. But do you want to protect it at rest or when it’s in transit, or both? And not forgetting other legal requirements, too. Any sensitive data that is stored at rest should be encrypted to protect both you and your customers. Should an untrusted entity gain access to the data, you can be assured that the information held within it cannot easily be accessed, safeguarding your business and your customer’s data from the intrusion.</p>
<p>In today’s world of virtualization and cloud technology, the physical location of stored data is often unknown. When you then couple this with replication, high availability, resiliency, or DR, where your data could be moved and replicated across a series of different AZs and regions automatically by design of some of the AWS services.</p>
<p>By encrypting your data, you be safe in the knowledge that any unexpected distribution of data by AWS would not be accessible by anyone unexpected. Be mindful that when your sensitive data is being moved and distributed, it should be done so via a secure mechanism, providing encryption in transit where possible.</p>
<p>Much of this can be done over HTTPS or SSL within AWS. If encryption in transit is not possible, then at the very least, the data should be encrypted prior to transmission. You may also have to apply encryption mechanisms against your data to adhere to specific compliance and legal controls that may be required to meet internal customer or external governing standards, such as PCI DSS or HIPAA.</p>
<p>By applying encryption to data bound by these standards and governance, it will help you achieve the required controls and compliance requirements. Big data solutions often hold very sensitive information, and so understanding how to apply and adopt encryption methods for different services that can be used for big data is crucial.</p>
<p>That now brings us to the end of this lecture. Coming up next, I’m going to start looking at encryption methods used for Amazon’s Simple Storage Service, known as S3.</p>
<h1 id="Amazon-S3-and-Amazon-Athena-Encryption"><a href="#Amazon-S3-and-Amazon-Athena-Encryption" class="headerlink" title="Amazon S3 and Amazon Athena Encryption"></a>Amazon S3 and Amazon Athena Encryption</h1><p>Hello and welcome to this lecture where I’m going to cover the different <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">encryption</a> mechanisms available for data being stored on S3 and when queried using Amazon Athena. S3 can be used to analyze large-scale data sets of information with the help of Amazon Athena which is an interactive query service that uses standard SQL.</p>
<p>Let me start by discussing the different encryption options available with S3. So, Amazon S3 offers both server-side encryption, SSE, and client-side encryption, CSE. I want to begin by looking at the different options available when using server-side encryption. Server-side encryption known as SSE is used for securing data at rest.</p>
<p>When SSE is applied, the data is encrypted at an object level before it is written to the physical disk that construct S3. If an object is encrypted with SSE, how you access the object remains the same as long as you have the relevant permissions to access the object. There are three different forms of SSE with S3, each providing a different method of encryption key management.</p>
<p>Firstly, SSE with Amazon S3-Managed Keys known as SSE-S3. Secondly, SSE with AWS KMS-Managed Keys known as SSE-KMS, and thirdly, SSE with Customer-Provided Keys known as SSE-C. Let’s take a look of each of these in more detail starting with SSE-S3. With SSE-S3 encryption, Amazon S3 uses a unique key to encrypt each data object and then this key itself is encrypted with a master key, providing a multifactor encryption mechanism.</p>
<p>The complete encryption and decryption cycle of the object is all managed by <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> and can be set by selecting the Amazon S3 master key encryption option when uploading an object in the management console or by using the AWS CLI. The objects are encrypted using one of the strongest algorithms, AES-256. As we know from the previous lecture, AES is a symmetric encryption algorithm.</p>
<p>In this case, symmetric cryptography works well as AWS will manage the encryption and decryption of the object when it is access by a user or service, therefore the key does not need to be sent to anyone else which may risk key exposure. To help enforce an encryption requirement on S3, SSE can work in conjunction with S3 bucket policies.</p>
<p>So, you could enforce conditions within a bucket policy to deny any object that is not uploaded with server-side encryption within the header during a PutObject request. For example, if you are an administrator of an S3 bucket which was being used as your storage layer, you could add the following bucket policy to ensure that only objects that had the SSE-S3 encryption specified were allowed to be uploaded.</p>
<p>This would deny any object that did not have the SSE-S3 server-side encryption enabled. If you are not using the management console to instigate the SSE encryption and instead you were using the AWS CLI, the user would have to add the server-side encryption AES256 parameter to enforce the encryption.</p>
<p>Let me now move on to SSE-KMS to show you how this method of encryption works. As you may have guessed, SSE-KMS uses the key management service to help with key management during encryption. If you are unfamiliar with KMS, then I recommend that you take our existing KMS course to help you understand how the service works and the different components within the service which can be found here.</p>
<p>If you select to use SSE-KMS for your object encryption, you have the opportunity to either select the default AWS S3 customer master key, CMK, which is managed by AWS or to set one of your existing customer-managed CMKs. This key will be used to encrypt the data keys generated by KMS which are then used to encrypt your object data on S3.</p>
<p>So, to be clear, the KMS CMK is used to encrypt the data keys not the actual object itself. With SSE-S3, a multifactor encryption process was used by first encrypting the object data with a data key and then this data key was encrypted with a master key. In the case of SSE-KMS, the master key puts on the same role as the KMS-CMK selected.</p>
<p>When you upload an object to S3 using SSE-KMS, a request is made by S3 to KMS which returns two versions of a randomly generated data encryption key. One version of this data key is plain text which S3 stores in memory and uses to perform the encryption of the object at which point it is removed from memory.</p>
<p>The second version is an encrypted version of the data key and is uploaded with the object. When S3 needs to decrypt the data, S3 sends AWS-KMS the encrypted data key associated with the object and KMS uses the CMK associated to decrypt the data key and responds with a plain text version of the key allowing you to decrypt the object.</p>
<p>Again, this key is stored in memory and will be deleted as soon as decryption has happened. If you don’t have a CMK configured, but you still want to use SSE-KMS, then S3 will automatically create the default AWS S3 CMK for you the first time you upload an object with this encryption type. It will then use the same CMK for all other uploads unless a customer-managed CMK is specified within that same region.</p>
<p>However, this AWS-managed CMK does not provide the same level of management that the customer-managed CMK does. By using your own customer-managed CMK, it gives you far greater flexibility of how your key is managed. For example, you are able to disable, rotate, and apply access controls to the CMK and audit it against their usage using AWS CloudTrail.</p>
<p>Similarly with SSE-S3, SSE-KMS also supports bucket policies. However, a different value needs to be configured for the server-side encryption parameter to indicate SSE-KMS encryption, So, the last option of SSE encryption is SSE-C, so let me now take a look at this option. So, SSE-C is server-side encryption for customer-provided keys.</p>
<p>So, here the encryption is provided to AWS S3 without using KMS and the S3 service itself performs the encryption. All we need to do is to supply the key. When you upload your data object, you must send your customer-provided key with the request. On this point, it’s worth mentioning that SSE-C only works with requests using HTTPS.</p>
<p>S3 will reject any request sent using HTTP. This helps to secure the data in transit, specifically for a customer-provided key. Once the encryption has taken place which will use AES-256, AWS deletes the key from memory, but instead stores a randomly salted hash message authentication code, a HMAC value, which is used for data integrity and authentication of the key to validate future requests.</p>
<p>When requesting to access the object from S3, you must again supply the same customer-provided key to decrypt the object. Remember, AES is symmetric, meaning you need the same key to decrypt as you use to encrypt. There are a number of request headers that you must use when using SSE-C as shown in the table below.</p>
<p>Now, I have covered server-side encryption, let me now talk to you about client-side encryption options within S3. This differs from server-side encryption in the fact that data is encrypted before it is sent to S3 for storage. S3 does not form any encryption itself when client-side encryption is used as the encryption mechanism.</p>
<p>There are two options that you can use, client-side encryption with KMS, CSE-KMS, and client-side encryption using a custom client-side master key, CSE-C. When using CSE-KMS with a CMK, you only need to supply the CMK-ID to the Amazon S3 encryption client. For example, the Amazon S3 encryption client in the AWS SDK for Java and the encryption is managed for you by AWS.</p>
<p>When you upload an object to S3 using this method, supplying the CMK-ID, a request is made by the client to KMS which returns two versions of a randomly generated data encryption key. One version of this data key is plain text which the client uses to perform the encryption of the object before it’s uploaded.</p>
<p>The second version is cipher blob of the data key and is uploaded with the object by the client as object metadata. When you retrieve the object on S3, the object is downloaded in an encrypted form along with the cipher blob data encryption key. Once downloaded, the client sends the ciphered blob to KMS to retrieve the matching plain text version of the data key to enable the decryption of the object.</p>
<p>It’s worth mentioning that for each object that is uploaded a different data encryption key is used. When using CSE-C using the client-side master key, your key is never sent to AWS like it is with CSE-KMS, so if you lose your client side master key, then you will lose access to your data. When performing an upload of an object, again, you need to provide the key to the client, for example, the Amazon S3 encryption client when using the AWS SDK for Java, but this time it will be your client-side master key. As this is the master key, it is only used to encrypt a randomly generated symmetric data encryption key generated by the client. This data key is then used to encrypt the object data.</p>
<p>Once the object is encrypted, the client-side master key is used to encrypt the data key. The encrypted data key is then made a part of the metadata of the object before both the encrypted object and the data key are uploaded to S3. When the encrypted object is retrieved, it is downloaded in an encrypted format along with its metadata including the encrypted data key.</p>
<p>The correct client-side master key is then identified to decrypt the data key which then in turn decrypts the object. So, we’ve now looked at the different encryption objects available when storing and sending data to S3. Let me now talk a little about how Amazon Athena handles encryption and encrypted S3 objects when performing queries against the data.</p>
<p>Amazon Athena is a serverless interactive query service which uses standard SQL and automatically execute queries in parallel, making it extremely fast. Amazon Athena supports the ability to query S3 data that is already encrypted and if configured to do so, Athena can also encrypt the results of the query which can then be stored in S3.</p>
<p>This encryption of results is independent of the underlying queried S3 data, meaning that even if the S3 data is not encrypted, the queried results can be encrypted. A couple of points to be aware of is that Amazon Athena only supports data that has been encrypted with the following S3 encryption methods, SSE-S3, SSE-KMS, and CSE-KMS.</p>
<p>SSE-C and CSE-E are not supported. In addition to this, it’s important to understand that Amazon Athena will only run queries against encrypted objects that are in the same region as the query itself. If you need to query S3 data that’s been encrypted using KMS, then specific permissions are required by the Athena user to enable them to perform the query.</p>
<p>You could simply add the users to the key policy of the CMK to provide the relevant access. However, if you wanted to just restrict the specific actions required for Athena to work, then you could simply grant access to the following actions, kms:Decrypt which is required for working with encrypted data sets and queries, and kms:GenerateDataKey which is required for working with encrypted queries only.</p>
<p>That now brings us to the end of this lecture of S3 and Athena encryption. Coming up next, I will be discussing encryption when using <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/elastic-mapreduce-emr-encryption-3/">Elastic MapReduce</a>, EMR.</p>
<h1 id="Elastic-MapReduce-EMR-Encryption"><a href="#Elastic-MapReduce-EMR-Encryption" class="headerlink" title="Elastic MapReduce (EMR) Encryption"></a>Elastic MapReduce (EMR) Encryption</h1><p>Hello and welcome to this lecture where I’ll discuss different <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">encryption</a> options available for the Amazon Elastic MapReduce Service, EMR. EMR is a managed service by <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> and is comprised of a cluster of EC2 instances that’s highly scalable to process and run big data frameworks such Apache Hadoop and Spark.</p>
<p>From EMR version 4.8.0 and onwards, we have the ability to create a security configuration specifying different settings on how to manage encryption for your data within your clusters. You can either encrypt your data at rest, data in transit, or if required, both together. The great thing about these security configurations is they’re not actually a part of your EC2 clusters.</p>
<p>They exist as a separate entity within EMR and therefore you can reuse the same security configuration for both existing and future clusters created. One key point of EMR is that by default, the instances within a cluster do not encrypt data at rest. The instances used within EMR are created from pre-configured AMIs, Amazon Machine Images that have been published and released by AWS.</p>
<p>However, if you need to ensure that the EBS root device volume is encrypted for your EC2 instances within a cluster, then you must use Amazon EMR version 5.7.0 or later and specify a custom AMI which will allow you to encrypt this volume. You may need this additional level of encryption at root volume level for specific compliance reasons.</p>
<p>Although EMR does not encrypt data at rest by default, there are a number of mechanisms you can use to enforce encryption. If you decide to use Elastic Block Store, EBS as persistence storage rather than <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-s3-and-amazon-athena-encryption-2/">S3</a> or DynamoDB, then there a number of options that can work together if you enable local disk encryption at rest in your EMR security configuration.</p>
<p>However, these are not possible for EBS root device volumes. Once enabled, the following features are available. Linux Unified Key Setup. EBS cluster volumes can be encrypted using this method whereby you can specify AWS KMS to be used as your key management provider, or use a custom key provider.</p>
<p>Open-Source HDFS encryption. This provides two Hadoop encryption options. Secure Hadoop RPC which would be set to privacy which uses simple authentication security layer, and data encryption of HDFS Block transfer which would be set to true to use the AES-256 algorithm.</p>
<p>If S3 was used, you could use S3’s own encryption tools discussed in a previous lecture. As a result, EMR supports the use of SSE-S3 or SSE-KMS to form the encryption service side at rest. Alternatively, you could encrypt your data using your client before storing on S3 using CSE-KMS or CSE-C where it would remain stored in an encrypted form.</p>
<p>From an encryption in transit perspective, you could enable open source transport layer security encryption features and select a certificate provider type which can be either PEM where you will need to manually create PEM certificates, bundle them up with a zip file and then reference the zip file in S3 or custom where you would add a custom certificate provider as a Java class that provides encryption artifacts.</p>
<p>Once the TLS certificate provider has been configured in the security configuration file, the following encryption applications specific encryption features can be enabled which will vary depending on your EMR version. Hadoop. Hadoop might reduce encrypted shuffle which uses TLS. Both secure Hadoop RPC which uses Simple Authentication Security Layer, and data encryption of HDFS Block Transfer which uses AES-256, are both activated when at rest encryption is enabled in the security configuration.</p>
<p>Presto. When using EMR version 5.6.0 and later, any internal communication between Presto nodes will use SSL and TLS. Tez. Tez Shuffle Handler uses TLS. And Spark. The Akka protocol uses TLS. Block Transfer Service uses Simple Authentication Security Layer and 3DES. External shuffle service uses the Simple Authentication Security Layer.</p>
<p>When using encryption at rest using KMS Customer Master Keys, you need to ensure that the role assigned to your EC2 instances within your cluster has the relevant permissions to enable access to the Customer Master Key. This is done by adding the relevant role to the Key users for the CMK. Finally, EMR has the option of implementing Transparent Encryption in HDFS.</p>
<p>This offers end to end encryption, applying both encryption at rest and in transit. When implemented, data is encrypted and decrypted transparently without requiring any change to application code. This is made possible by using HDFS encryption zones, each having its own KMS key. By default, EMR uses the Hadoop KMS, but you can select an alternative if required.</p>
<p>Each file within the encryption zone is encrypted by a different data key which are then encrypted by the HDFS encryption zone keys. With this in mind, it is not possible to move files between encryption zones as the data key and encryption zone key will not match. For details on how to configure this method of encryption, see the AWS documentation <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-encryption-tdehdfs.html#emr-configure-HDFS-transparent-encryption">link</a> here.</p>
<p>This lecture has covered the encryption mechanisms that you can choose to apply encryption across EMR, which remember is not provided by default. For more information on how to set up these different methods of encryption in detail, I recommend you visit the relevant AWS documentation pages on EMR. Coming up on the next lecture, I will look at encryption options when using the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/relational-database-service-rds-encryption-3/">relational database service RDS</a>.</p>
<h1 id="Relational-Database-Service-RDS-Encryption"><a href="#Relational-Database-Service-RDS-Encryption" class="headerlink" title="Relational Database Service (RDS) Encryption"></a>Relational Database Service (RDS) Encryption</h1><p>Hello and welcome to this short lecture covering RDS encryption options. RDS allows you to set up a relational database using a number of different engines such as MySQL, Oracle, SQL Server, etc. During the creation of your RDS database instance, you have the opportunity to Enable Encryption at the Configure Advanced Settings screen under Database Options and Enable Encryption.</p>
<p>By enabling your encryption here, you are enabling encryption at rest for your storage, snapshots, read replicas and your back-ups. Keys to manage this encryption can be issued by using KMS. It’s not possible to add this level of encryption after your database has been created. It has to be done during its creation.</p>
<p>However, there is a workaround allowing you to encrypt an unencrypted database as follows. You can create a snapshot of your unencrypted database, create an encrypted copy of that snapshot, use that encrypted snapshot to create a new database, and then, finally, your database would then be encrypted.</p>
<p>If the KMS key that was used for the encryption is disabled, then you’ll not be able to read or write to your database and RDS will move your database instances into a terminal state where it can no longer be accessed.</p>
<p>At this stage, the only option in retrieving your data is to reinstate the KMS key and then recover your database from a previous back-up. The previous RDS instance in a terminal state will still not be accessible. Read replicas follow the same encryption pattern as defined by the database source. So, for example, if your database had encrypted at rest enabled, then the read replica will also be encrypted. It would not be possible to have an encrypted read replica if the database itself was not encrypted.</p>
<p>In addition to encryption offered by RDS itself at the application level, there are additional platform level encryption mechanisms that could be used for protecting data at rest including Oracle and SQL Server Transparent Data Encryption, known as TDE, and this could be used in conjunction with the method order discussed but it would impact the performance of the database MySQL cryptographic functions and Microsoft Transact-SQL cryptographic functions.</p>
<p>If you want to use the TDE method, then you must first ensure that the database is associated to an option group. Option groups provide default settings for your database and help with management which includes some security features. However, option groups only exist for the following database engines and versions.</p>
<p>Once the database is associated with an option group, you must ensure that the Oracle Transparent Data Encryption option is added to that group. Once this TDE option has been added to the option group, it cannot be removed. TDE can use two different encryption modes, firstly, TDE tablespace encryption which encrypts entire tables and, secondly, TDE column encryption which just encrypts individual elements of the database.</p>
<p>RDS offers the ability to encrypt instances in all regions other than the China Beijing region and across the following Instance Types only. In comparison to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/elastic-mapreduce-emr-encryption-3/">EMR</a>, applying encryption at rest for RDS is simplified thanks to the built in application encryption option which EMR does not have.</p>
<p>When looking at Encryption in Transit for communication between your application and RDS, then you can secure this communication using SSL&#x2F;TLS which is Secure Sockets Layer Transport Layer Security which are both cryptographic protocols.</p>
<p>This is always recommended if you have to abide by specific compliance and governance controls or when the data being sent to RDS is highly sensitive such as containing customer details. The method in which this process is carried out varies dependent on which database type you have. For more information on the implementation of this encryption for the following database engines, take a look at the <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html">link</a> shown on the screen.</p>
<p>If you are using Oracle with RDS, then instead of using SSL encryption between a client and the database you could use Oracle’s Native Network Encryption, NNE, which will encrypt all connections to and from the database. It is, however, not possible to use both SSL and NNE together for encryption. You must use one or the other if required.</p>
<p>To enable NNE, you must add the NATIVE_NETWORK_ENCRYPTION to the database options group. More information on Oracle NNE can be found here.</p>
<p>That brings us to the end of this lecture. Coming up next I shall be looking at the encryption across big data frameworks starting with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-kinesis-encryption-1/">Amazon Kinesis Firehose</a>.</p>
<h1 id="Amazon-Kinesis-Encryption"><a href="#Amazon-Kinesis-Encryption" class="headerlink" title="Amazon Kinesis Encryption"></a>Amazon Kinesis Encryption</h1><p>Hello, and welcome to this lecture where I’m going to be looking at how Amazon Kinesis utilizes <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">encryption</a> mechanisms. I will be looking at both Kinesis Firehose and Kinesis Streams.</p>
<p>If you are new to Amazon Kinesis, you may find it useful to take our existing course covering AWS Kinesis found <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/intro-amazon-kinesis/introduction-to-amazon-kinesis/">here</a>.</p>
<p>Let me start by providing a high level overview of the differences between each of these services. Amazon Firehose. This service is used to deliver real-time streaming data to different services and destinations within <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a>, many of which can be used for big data such as S3 Redshift and Amazon Elasticsearch.</p>
<p>The service is fully managed by AWS, taking a lot of the administration of maintenance out of your hands. Firehose is used to receive data from your data producers where it then automatically delivers the data to your chosen destination. Amazon Streams. This service essentially collects and processes huge amounts of data in real time and makes it available for consumption.</p>
<p>This data can come from a variety of different sources. For example, log data from the infrastructure, social media, web clicks during feeds, market data, etc. So now we have a high-level overview of each of these. We need to understand how they implement encryption of any data process in stored should it be required.</p>
<p>When clients are sending data to Kinesis in transit, the data can be sent over HTTPS, which is HTTP with SSL encryption. However, once it enters the Kinesis service, it is then unencrypted by default. Using both Kinesis Streams and Firehose encryption, you can assure your streams remain encrypted up until the data is sent to its final destination.</p>
<p>As we know, Amazon Firehose is used to send data to a final destination. If Amazon S3 is used as a destination, Firehose can implement encryption using SSE-KMS on S3. Access to this key in the desired S3 bucket can be given to Firehose via an IAM role to enable this data encryption to take place. Once this role has been created, the relevant permissions must be assigned, which must include the following KMS actions against the CMK used, kms:Decrypt and kms:GenerateDataKey.</p>
<p>You can apply the following policy as a trusted entity on the role itself, ensuring you replace the account ID with your own, which would give Kinesis Firehose the relevant access. If you have configured Kinesis Firehose to use Redshift as a destination, then Firehose still copies the data to S3 first as an intermediary location.</p>
<p>In this instance, the same KMS permissions mentioned previously should be implemented to enforce encryption of the data at rest and before it is sent to your Redshift cluster from S3, plus the relevant permissions required for Redshift. Similarly, with Elasticsearch as a destination, S3 can also be used to backup all of the data it sends to Elasticsearch.</p>
<p>And so again, it would need the same KMS permissions plus the relevant permissions for Elasticsearch. Let’s now take a look at the encryption for Amazon Kinesis Streams.</p>
<p>Since July 2017, Amazon Streams now has the ability to implement SSE encryption using KMS to encrypt data as it enters the stream directly from the producers.</p>
<p>As a part of this process, it’s important to ensure that both producer and consumer applications have permissions to use the KMS key. Otherwise encryption and decryption will not be possible, and you will receive an unauthorized KMS master key permission error.</p>
<p>Put simply, a producer is something that adds data to a Kinesis stream, such as a web service sending log data, encryption happens at the producer level.</p>
<p>The Consumer is usually a Kinesis application that processes data from within the Kinesis stream. Decryption happens at the consumer level.</p>
<p>Your producers must have the following permissions against the CMK used, kms:GenerateDataKey, and the following against the Kinesis stream, kinesis:PutRecord and kinesis:PutRecords.</p>
<p>Your consumers on the other hand will require the following against the CMK, kms:Decrypt, and the following against the Kinesis stream, kinesis:GetRecords and kinesis:DescribeStream. Utilizing SSE with KMS for Kinesis Streams essentially encrypts a data entering a stream before it is saved to the Kinesis Streams storage layer and then decrypted after it’s accessed from the storage layer, giving full at-rest encryption within the stream.</p>
<p>Kinesis SSE encryption will typically call upon KMS to generate a new data key every five minutes. So, if you had your stream running for a month or more, thousands of data keys would be generated within this time frame. You may be wondering if by applying this encryption using the producers and then decrypting the data using the consumers, if any latency is added to the performance. And the simple answer is yes. It does add a small overhead, which impacts the performance of PutRecord and PutRecords and GetRecords by less than a hundred microseconds.</p>
<p>Before we finish this lecture, I just want to mention that AWS has released a blog post that shows how to implement encryption from client to destination by building a real-time streaming application using Kinesis, in which your records are encrypted while at rest and in transit, which you may want to take a look at here.</p>
<p>That now brings us to the end of this lecture. Coming up next, I shall be looking at encryption when using the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-redshift-3/">Amazon Redshift</a> service.</p>
<h1 id="Amazon-Redshift"><a href="#Amazon-Redshift" class="headerlink" title="Amazon Redshift"></a>Amazon Redshift</h1><p>Hello and welcome to this lecture. I want to talk to you about available <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">encryption</a> options when using Redshift. Redshift is a fully managed service that can scale up to over a petabyte in size, which is used as a data warehouse for big data solutions. Using Redshift clusters, you are able to run analytics against your datasets using fast, SQL-based query tools and business intelligence applications to gather greater understanding of vision for your business.</p>
<p>So how does Redshift handle encryption of huge amounts of data?</p>
<p>Redshift offers encryption at rest using a four-tired hierarchy of encryption keys using either KMS or CloudHSM to manage the top tier of keys. When encryption is enabled for your cluster, it can’t be disable and vice versa. When you have an unencrypted cluster, it can’t be encrypted.</p>
<p>Encryption for your cluster can only happen during its creation, and once encrypted, the data, metadata, and any snapshots are also encrypted. The tiering level of encryption keys are as follows, tier one is the master key, tier two is the cluster encryption key, the CEK, tier three, the database encryption key, the DEK, and finally tier four, the data encryption keys themselves.</p>
<p>As mentioned previously, the master keys can either be managed by KMS or CloudHSM. Amazon Redshift integrates well with KMS but not CloudHSM, and so integration with a HSM device requires additional configuration or steps to implement such as adding certificates to establish a trusted connection between both resources, your HSM device and your Redshift cluster.</p>
<p>The encryption method differs slightly between the two options of KMS and CloudHSM. So let me break each of these down individually starting with KMS. During the creation of your cluster, you can either select the default KMS key for Redshift or select your own CMK, which gives you more flexibility over the control of the key, specifically from an auditable perspective.</p>
<p>The default KMS key for Redshift is automatically created by Redshift the first time the key option is selected and used, and it is fully managed by AWS. The CMK is known as the master key, tier one, and once selected, Redshift can enforce the encryption process as follows. So Redshift will send a request to KMS for a new KMS key.</p>
<p>This KMS key is then encrypted with the CMK master key, tier one. This encrypted KMS data key is then used as the cluster encryption key, the CEK, tier two. This CEK is then sent by KMS to Redshift where it is stored separately from the cluster. Redshift then sends this encrypted CEK to the cluster over a secure channel where it is stored in memory.</p>
<p>Redshift then requests KMS to decrypt the CEK, tier two. This decrypted CEK is then also stored in memory. Redshift then creates a random database encryption key, the DEK, tier three, and loads that into the memory of the cluster. The decrypted CEK in memory then encrypts the DEK, which is also stored in memory.</p>
<p>This encrypted DEK is then sent over a secure channel and stored in Redshift separately from the cluster. Both the CEK and the DEK are now stored in memory of the cluster both in an encrypted and decrypted form. The decrypted DEK is then used to encrypt data keys, tier four, that are randomly generated by Redshift for each data block in the database.</p>
<p>When performing encryption using CloudHSM, the process is different. If you are new to CloudHSM, then you may want to look at our existing course covering the service found here. When working with CloudHSM to perform your encryption, firstly you must set up a trusted connection between your HSM client and Redshift while using client and server certificates.</p>
<p>This connection is required to provide secure communications, allowing encryption keys to be sent between your HSM client and your Redshift clusters. Using a randomly generated private and public key pair, Redshift creates a public client certificate, which is encrypted and stored by Redshift. This must be downloaded and registered to your HSM client, and assigned to the correct HSM partition.</p>
<p>You must then configure Redshift with the following details of your HSM client: the HSM IP address, the HSM partition name, the HSM partition password, and the public HSM server certificate, which is encrypted by CloudHSM using an internal master key. Once this information has been provided, Redshift will confirm and verify that it can connect and access development partition.</p>
<p>For detailed instructions on how to configure Redshift encryption using CloudHSM, please see the following AWS documentation that will provided step-by-step details.</p>
<p>If your internal security policies or governance controls dictate that you must apply key rotation, then this is possible with Redshift enabling you to rotate encryption keys for encrypted clusters, however, you do need to be aware that during the key rotation process, it will make a cluster unavailable for a very short period of time, and so it’s best to only rotate keys as and when you need to, or if you feel they may have been compromised.</p>
<p>During the rotation, Redshift will rotate the CEK for your cluster and for any backups of that cluster. It will rotate a DEK for the cluster but it’s not possible to rotate a DEK for the snapshots stored in <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-s3-and-amazon-athena-encryption-2/">S3</a> that have been encrypted using the DEK. It will put the cluster into a state of ‘rotating keys’ until the process is completed when the status will return to ‘available’.</p>
<p>To perform a key rotation of your cluster, it’s very simple using the AWS Management Console. Select Amazon Redshift from within the management console, navigate to clusters, select the cluster you wish to rotate keys for, select the database, rotate encryption keys, and select yes, rotate keys, then your cluster will temporarily be unavailable whilst the key rotation process completes.</p>
<p>This now brings us to the end of this lecture on Amazon Redshift encryption. Coming up next, I shall be providing a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/summary-3/">summary</a> of the key points throughout the previous lectures.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Hello, and welcome to this final lecture, where I shall be highlighting some key points from each lecture that you have covered throughout the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">course</a>.</p>
<p>I started off by providing an overview of encryption in general, where we learned unencrypted data is known as cleartext or plaintext. Data encryption is the mechanism in which information is altered, rendering the plaintext data unreadable through the use of mathematical algorithms and keys.</p>
<p>A key is simply a string of characters used with the the encryption algorithm, and the longer the key, the more robust the encryption. Key cryptography is either symmetric or asymmetric. Symmetric cryptography uses a single key to perform the encryption and decryption. And common symmetric algorithms are AES, DES, Triple-DES, and Blowfish.</p>
<p>Asymmetric cryptography uses different keys, one to perform encryption and one to perform decryption. In this process, one key is public, and one key is private. Common asymmetric algorithms are RSA, Diffie-Hellman, and Digital Signature Algorithm.</p>
<p>I then started to explain about the different encryption mechanisms that are used across a range of services, specifically ones that can be used for big data, starting with S3.</p>
<p>We learned that S3 offers server-side encryption, SSE, and client-side encryption, CSE. SSE offers three different options. SSE with Amazon S3-Managed Keys, which is SSE-S3, SSE with AWS KMS-Managed Keys, which SSE-KMS, and SSE with Customer-provided Keys, SSE-C. Client-side encryption offers two different options, client-side encryption with KMS, CSE-KMS, and client-side encryption using a custom client-side master key, CSE-C.</p>
<p>SSE-S3 is managed by AWS and uses AES-256 symmetric encryption, which supports bucket policies.</p>
<p>SSE-KMS uses the key management service to help with key management, and it allows you to use your own keys, the CMK, through KMS, giving more control and flexibility. The CMK encrypts the data key, not the data itself, and this also supports bucket policies.</p>
<p>SSE-C uses customer-provided keys using AES-256. During an upload of an object, you must also send the key with it. And it only works with HTTPS to secure data in transit, specifically the key.</p>
<p>Client-side encryption using KMS uses an S3 encryption client, such as the Amazon S3 Encryption Client in the AWS SDK for Java and you must supply the CMK ID from KMS. And the encryption happens prior to upload and after download of an object. CSE-C uses a custom master key, which is never sent to <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a>. It also uses an S3 client, like CSE-KMS, and again, encryption happens prior to upload and after download of an object. We then looked at Athena.</p>
<p>And Athena supports the ability to query encrypted data on S3. It can also encrypt queried results, even if the data queried was not encrypted. SSE-C and CSE-C are not currently supported by Athena. But Athena does support SSE-KMS, SSE-S3, and CSE-KMS. Athena will only query objects in the same region as where Athena is running.</p>
<p>And KMS Decrypt and KMS Generate Key permissions are required to allow Athena to query encrypted data on S3 using KMS. Following this lecture, I then looked at Elastic MapReduce Encryption. And the key points from this lecture were that by default EMR does not implement encryption at rest.</p>
<p>From EMR version 4.8.0 and onwards, you are able to configure a security configuration specifying different settings on how to manage encryption for your data. The security configuration allows you to configure encryption at rest, in transit, or both together. The security configuration exists separately from your EC2 clusters.</p>
<p>And using EMR version 5.7.0, you can specify your own custom AMI, allowing you to encrypt the EBS route device volume of your instances.</p>
<p>Using EBS as your persistent storage layer, you can implement Linux Unified Key Setup with KMS and open-source HDFS encryption. This provides two Hadoop encryption options, Secure Hadoop RPC and data encryption of HDFS block transfer.</p>
<p>When using S3, EMR supports the use of SSE-S3 or SSE-KMS to perform server-side encryption. You could also encrypt your data using your client before storing on S3 using CSE-KMS or CSE-C.</p>
<p>EMR in transit encryption, you can enable open-source TLS encryption features. When a TLS certificate provider has been configured, the following application-specific encryption features can be enabled: Hadoop, with Hadoop MapReduce Encrypted Shuffle, Secure Hadoop RPC, and data encryption of HDFS block transfer.</p>
<p>With Presto, when using EMR version 5.6.0 and later, any internal communication between Presto nodes will use SSL TLS. With Tez, Tez Shuffle Handler uses TLS. And Spark, the Akka protocol uses TLS, block transfer service uses SASL and Triple-DES, external shuffle service uses SASL.</p>
<p>Transparent encryption can also be used by implementing transparent encryption in HDFS.</p>
<p>Following EMR, I looked at encryption for the RDS service, and here we learned that you can configure encryption at rest during its configuration by selecting the checkbox for “enable encryption”. This encryption can only be implemented during the database creation. And read replicas will have the same level of encryption as the master database.</p>
<p>You can also implement application-level encryption using Oracle and SQL Server Transparent Data Encryption, TDE, MySQL cryptographic functions, and Microsoft Transact-SQL cryptographic functions. To use TDE encryption, the database must be a part of an option group with the TDE option added to the group.</p>
<p>TDE can use two different encryption modes, TDE table namespace encryption and TDE column encryption. RDS in-transit encryption can be enabled by using SSL between your application and the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/relational-database-service-rds-encryption-3/">RDS database</a>. To use Oracle’s native network encryption, NNE, you must add native network encryption to the database options group.</p>
<p>Moving on from databases, the next topic was encryption mechanisms when using the Amazon Kinesis platform for both Kinesis Firehose and Kinesis Streams. Within this lecture, we learned that data being sent to Kinesis can be sent using SSL for in-transit encryption. By default, once the data enters Kinesis, it is decrypted.</p>
<p>Kinesis Firehose can use SSE-KMS when sending data to S3. Kinesis Firehose must have the KMS decrypt and the KMS generate data key permission of the CMK when using this method. If data is being sent to Amazon Redshift by Kinesis Firehose, S3 will still be used as an intermediary storage location, and so the same encryption can be applied.</p>
<p>Since July 2017, Kinesis Streams can now apply SSE encryption to incoming data to the stream using KMS. Producers and consumers need to have the relevant permissions to the KMS CMK. Kinesis Streams will request a new data encryption key approximately every five minutes. And a performance hit of approximately 100 microseconds is added for the encryption and decryption to take place by the producers and consumers.</p>
<p>We then finished up by looking at encryption options within Amazon Redshift. Amazon Redshift uses a four-tiered structure of encryption keys. Tier one is the master key, tier two, the cluster encryption key, CEK, tier three, the database encryption key, DEK, and then tier four, the data encryption keys.</p>
<p>The master key can be generated by either KMS or CloudHSM. Integration exists between KMS and Amazon Redshift, but not between CloudHSM and Redshift. When using CloudHSM, a trust must be established between your HSM and Amazon Redshift to send secure encryption keys between the two resources. For this to take place, you must download a certificate from Redshift to your HSM device, and then configure Redshift with the following details of your HSM: the HSM IP address, HSM partition name, the HSM partition password, and the public HSM service certificate.</p>
<p>You can perform a key rotation using the AWS Management Console for both your CEK and DEK.</p>
<p>That has now brought me to the end of this lecture and to the end of this course. I hope it has given you a good understanding of encryption itself, including symmetric and asymmetric cryptography, and opened you to some encryption mechanisms that are offered by services which are commonly used for big data solutions, using Amazon S3, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-s3-and-amazon-athena-encryption-2/">Athena</a>, Elastic MapReduce, the RDS service, Kinesis Firehose, Kinesis Streams, and Redshift.</p>
<p>You should now be able to enforce additional security controls, including encryption, into your existing infrastructure to help secure your data.</p>
<p>If you have any feedback on the course, positive or negative, please do leave a comment on the course landing page. We do look at the comments, and your feedback is greatly appreciated.</p>
<p>Thank you for your time, and good luck with your continued learning of cloud computing.</p>
<p>Thank you.</p>
<h1 id="4Elastic-MapReduce-EMR-Encryption"><a href="#4Elastic-MapReduce-EMR-Encryption" class="headerlink" title="4Elastic MapReduce (EMR) Encryption"></a>4<strong>Elastic MapReduce (EMR) Encryption</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-encryption-tdehdfs.html#emr-configure-HDFS-transparent-encryption">Encryption Method Configuration</a></p>
<h1 id="5Relational-Database-Service-RDS-Encryption"><a href="#5Relational-Database-Service-RDS-Encryption" class="headerlink" title="5Relational Database Service (RDS) Encryption"></a>5<strong>Relational Database Service (RDS) Encryption</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html">Encryption Implementation</a></p>
<h1 id="6Amazon-Kinesis-Encryption"><a href="#6Amazon-Kinesis-Encryption" class="headerlink" title="6Amazon Kinesis Encryption"></a>6<strong>Amazon Kinesis Encryption</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/intro-amazon-kinesis/introduction-to-amazon-kinesis/">Course: Introduction to Amazon Kinesis</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-Manage-Your-Own-Encryption-Keys-Using-AWS-CloudHSM-35/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-Manage-Your-Own-Encryption-Keys-Using-AWS-CloudHSM-35/" class="post-title-link" itemprop="url">AWS-Security-Specialty-Manage-Your-Own-Encryption-Keys-Using-AWS-CloudHSM-35</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:40" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:40-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 22:55:40" itemprop="dateModified" datetime="2022-11-19T22:55:40-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-Manage-Your-Own-Encryption-Keys-Using-AWS-CloudHSM-35/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-Manage-Your-Own-Encryption-Keys-Using-AWS-CloudHSM-35/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Introduction-to-CloudHSM"><a href="#Introduction-to-CloudHSM" class="headerlink" title="Introduction to CloudHSM"></a>Introduction to CloudHSM</h1><p>Hello, and welcome to this course that will be focused on AWS CloudHSM, which is a security service offered by AWS that allows you to generate and use your own encryption keys to protect your data through encryption.</p>
<p>Before we start I’d like to introduce myself, my name is Stuart Scott, and I am the AWS content and security lead here at Cloud Academy. Feel free to connect with me to ask any questions using the details shown on the screen, alternatively you can always get in touch with us here at Cloud Academy by sending an e-mail to <a href="mailto:&#x73;&#117;&#x70;&#x70;&#x6f;&#x72;&#116;&#64;&#x63;&#108;&#111;&#x75;&#x64;&#x61;&#99;&#97;&#x64;&#101;&#x6d;&#x79;&#x2e;&#x63;&#x6f;&#x6d;">&#x73;&#117;&#x70;&#x70;&#x6f;&#x72;&#116;&#64;&#x63;&#108;&#111;&#x75;&#x64;&#x61;&#99;&#97;&#x64;&#101;&#x6d;&#x79;&#x2e;&#x63;&#x6f;&#x6d;</a> where one of our Cloud experts will reply to your question.</p>
<p>This course has been designed for those who are responsible for protecting data stored within AWS. If you are looking to utilise a managed service to help you perform cryptographic operations then this course can help you understand how to manage those controls. Also, if you are preparing for an AWS certification that requires you to have knowledge of securing data, having knowledge of CloudHSM will help.</p>
<p>The objectives of this course are to explain what AWS CloudHSM is and does, the architecture of CloudHSM and its implementation, Access Control of your HSM Cluster, how to use CloudHSM as a custom key store in KMS, the Key Management Service, and Monitoring and Logging.</p>
<p>As a prerequisite to this course, it would be beneficial to have a basic awareness of the fundamentals of AWS and some of its core services, such as VPC architecture, in addition to some basic cryptography knowledge, but this is not essential.</p>
<p>Feedback on our courses here at Cloud Academy is valuable to both us as trainers and any students looking to take the same course in the future. If you have any feedback, positive or negative, it would be greatly appreciated if you could contact <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>.</p>
<p>Please note that, at the time of writing this content, all course information was accurate. AWS implements hundreds of updates every month as part of its ongoing drive to innovate and enhance its services.</p>
<p>As a result, minor discrepancies may appear in the course content over time. Here at Cloud Academy, we strive to keep our content up to date in order to provide the best training available. </p>
<p>So, if you notice any information that is outdated, please contact <a href="mailto:&#115;&#x75;&#x70;&#x70;&#x6f;&#114;&#x74;&#x40;&#x63;&#x6c;&#111;&#117;&#100;&#97;&#99;&#x61;&#x64;&#x65;&#109;&#x79;&#x2e;&#99;&#x6f;&#109;">&#115;&#x75;&#x70;&#x70;&#x6f;&#114;&#x74;&#x40;&#x63;&#x6c;&#111;&#117;&#100;&#97;&#99;&#x61;&#x64;&#x65;&#109;&#x79;&#x2e;&#99;&#x6f;&#109;</a>. This will allow us to update the course during its next release cycle.</p>
<p>Thank you! </p>
<h1 id="What-is-CloudHSM"><a href="#What-is-CloudHSM" class="headerlink" title="What is CloudHSM?"></a>What is CloudHSM?</h1><p>Hello and welcome to this lecture where I shall provide you with a foundational view of the AWS CloudHSM service.</p>
<p>Firstly, what does the HSM stand for? Well HSM stands for Hardware Security Module, but what is a hardware security module? It’s a physical tamper-resistant hardware appliance that is used to protect and safeguard cryptographic material and encryption keys.</p>
<p>The AWS CloudHSM service provides HSMs that are validated to Federal Information Processing Standards (FIPS) 140-2 Level 3, which is often required if you are going to be using your CloudHSM for document signing or if you intend to operate a public certificate authority for SSL certificates.</p>
<p>As I mentioned, CloudHSM is a physical device, and it’s important to note that this device is not shared with any other customer, so it’s NOT a multi-tenant device. It is a dedicated single-tenant appliance exclusively made available to you, for your own workloads. The fact that the HSM is based upon single tenancy should not be surprising bearing in mind how sensitive the information is that it contains.</p>
<p>CloudHSM is an enterprise-class service used for secure encryption key management and storage which can be used as a root of trust for an enterprise when it comes to data protection allowing you to deploy secure and compliant workloads within AWS.</p>
<p>There are a number of different operations that CloudHSM can help you provide, these include:</p>
<ul>
<li>The creation, storage and management of cryptographic keys, allowing you to import and export both asymmetric and symmetric keys.</li>
<li>The ability to use cryptographic hash functions to enable you to compute message digests and hash-based message authentication codes, otherwise known as HMACs.</li>
<li>Cryptographic data signing and signature verification.</li>
<li>Using both asymmetric and symmetric encryption algorithms.</li>
<li>And the ability to generate cryptographically secure random data.</li>
</ul>
<p>I just mentioned both symmetric and asymmetric encryption keys, and I feel like I should quickly explain the difference between the two.</p>
<p>Asymmetric encryption involves two separate keys. One is used to encrypt the data and a separate key is used to decrypt the data. These keys are created both at the same time and are linked through a mathematical algorithm. One key is considered the private key and should be kept by a single party and should never be shared with anyone else. The other key is considered the public key and this key can be given and shared with anyone. It doesn’t matter who has access to this public key as without the private key, any data encrypted with it cannot be accessed. </p>
<p>Both the private and public keys are required to decrypt the data when asymmetric encryption is being used. So how does it work? </p>
<p>If another party wanted to send you an encrypted message or data, they would encrypt the message using your own public key which can be made freely available to them or anyone. The message is then sent to you where you will use your own private key which has that mathematical relationship with your public key to decrypt the data. This allows you to send encrypted data to anyone without the risk of exposing your private key.</p>
<p>Some common examples of asymmetric cryptography algorithms are RSA, Diffie-Hellman, and Digital Signature Algorithm. </p>
<p>With symmetric encryption, a single key is used to both encrypt and also decrypt the data. So for example if someone was using a symmetric encryption method, they would encrypt the data with a key and then when that same person needed to access that data, they would use the same key that they used to encrypt the data to decrypt the data. As a result, this key must be sent securely between the two parties and here it exposes a weakness in this method. If the key is intercepted by anyone during that transmission, then that third party could easily decrypt any data associated with that key. </p>
<p>Some common symmetric cryptography algorithms that are used are AES which is Advanced Encryption Standard, DES, Digital Encryption Standard, Triple DES and Blowfish. </p>
<p>AWS CloudHSM is not the only encryption service available with AWS, you may have also heard of the Key Management Service, known as KMS. KMS is a managed service used to store and generate encryption keys that can be used by other AWS services and applications to encrypt your data. Much like CloudHSM, KMS uses HSMs, but with KMS, these are managed by AWS, as a result you have less management control of the keys and key material. Later in this course, I shall explain the integrations that exist between the 2 services.</p>
<p>For more information on KMS, please see our existing course <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-web-services-key-management-service-kms/kms-encryption-introduction/">here</a>.</p>
<h1 id="Understanding-AWS-CloudHSM-Architecture-amp-Implementation"><a href="#Understanding-AWS-CloudHSM-Architecture-amp-Implementation" class="headerlink" title="Understanding AWS CloudHSM Architecture &amp; Implementation"></a>Understanding AWS CloudHSM Architecture &amp; Implementation</h1><p>Hello and welcome to this lecture where I want to provide an overview of the architecture of CloudHSM and the general steps of implementation to help you understand its deployment. </p>
<p>Let me start with the CloudHSM Cluster. When you implement CloudHSM, you will begin by creating a cluster. This cluster is simply a grouping of different HSMs which will act as a single unit when configured and deployed. Having multiple HSMs provides an element of high availability as you are able to select multiple different subnets, one from each availability zone that your VPC operates in, to deploy an HSM into. Any requests to your CloudHSM cluster are then automatically load-balanced between the HSMs in the cluster, and if one HSM fails, AWS will automatically deploy another one within your cluster. As a result, running a VPC is a prerequisite of implementing your cluster.</p>
<p>During the deployment of your HSMs, it’s actually an Elastic Network Interface (ENI) that is placed within the subnet that you select of your VPC. The HSM itself actually resides in a different AWS-owned VPC, and located in the same AZ as you select during its deployment. So it’s the ENI that is deployed in your VPC which acts as an interface between your network and the HSM residing in an AWS-owned VPC.</p>
<p>When you create the cluster, CloudHSM will do 2 things. Firstly, a new service-linked role will be created ‘AWSServiceRoleForCloudHSM’ which gives CloudHSM the permission to send log data to CloudWatch Logs log groups and log streams on your behalf. For those familiar with IAM policies, the policy looks as shown.</p>
<p>Secondly, CloudHSM will also create a new security group for the cluster (cloudhsm-cluster-clusterID-sg). This is an important security group as it controls which resources can communicate with the HSMs. The security group itself will allow both inbound and outbound connectivity over TCP ports 2223-2225, which enables each of your HSMs within your cluster to communicate with each other. When this security group is created by CloudHSM, no other resources are associated with it. </p>
<p>Once your cluster has been defined and created in the different subnets and availability zones that you have selected, it will have been provisioned in an ‘uninitialized state’. From this point, you can create your HSMs in each availability zone that you selected and ‘initialize’ the cluster. As this is a beginner course, I will not dive into this initialization process, however, if you would like a detailed technical understanding of how to perform this step, please refer to the AWS documentation <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/cloudhsm/latest/userguide/initialize-cluster.html">here</a>.</p>
<p>When your cluster is initialized you can then connect to your cluster HSM network interfaces, and one of the easiest ways to do this is via an EC2 instance provisioned in the same VPC. There are 2 steps which must be carried out for your EC2 instances to interact with the HSMs. Firstly, you must configure a security group. And secondly, you need to install the AWS CloudHSM client software on your instance.</p>
<p>So, firstly, the security group. You must add your instance to the cloudhsm-cluster-clusterID-sg security group. As we already know, this security group allows your HSMs to communicate with each other, but this same security group is also used to define which EC2 instances can communicate with your CloudHSMs, which must be manually added to the security group. If you want to connect to your CloudHSM using a Windows EC2 instance then you must add a rule to this SG using RDP with port 3389, if using a Linux instance then you must select SSH using port 22.</p>
<p>Next, you must install the client and command-line tools. To do this, connect to your instance that you added to the security group as I just mentioned. </p>
<p>If using a Linux instance, then you need to run a command, and this command will be different depending on the OS you are running. For a list of commands relating to the following OS’s please refer to <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/cloudhsm/latest/userguide/install-and-configure-client-linux.html">this AWS resource</a>.</p>
<p>Once you have installed the client and tools, you need to modify the client configuration to enable you to connect to your cluster. Firstly you need to copy your issuing certificate (created when you initialize your cluster) to &#x2F;opt&#x2F;cloudhsm&#x2F;etc&#x2F;customerCA.crt</p>
<p>You must also run the following command, replacing the red text with your HSMs IP address </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /opt/cloudhsm/bin/configure -a &lt;IP address&gt;</span><br></pre></td></tr></table></figure>

<p>If you are using a Windows instance, then you will need to download the installation from here.</p>
<p>After running the MSI file, you will need to copy the self-signed issuing certificate to the following.</p>
<p>And then finally, you need to run the following command to configure the client software replacing the text in red with your own HSM details.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\Amazon\CloudHSM\configure.exe -a &lt;HSM IP address&gt;</span><br></pre></td></tr></table></figure>

<p>So let’s take a quick logical look at how the infrastructure would look like at this stage.</p>
<p>So as you can see, we have the customer VPC split across 3 different availability zones and subnets, each with an EC2 client containing the HSM client software and an HSM ENI. Each EC2 client can communicate with ANY of the HSM ENI across the different subnets within the cluster using the cloudhsm-cluster security group. These ENIs then communicate with the HSMs located in an AWS-owned VPC.</p>
<p>We also have the IAM role that has been created allowing HSM to send log data to CloudWatch Logs log groups and log streams on your behalf. </p>
<p>Once your infrastructure is in place and you have configured your CloudHSM connectivity, you simply need to activate your HSM cluster before use.</p>
<h1 id="Access-Control"><a href="#Access-Control" class="headerlink" title="Access Control"></a>Access Control</h1><p>Hello and welcome to this lecture where I want to highlight how you can access AWS CloudHSM. </p>
<p>More often than not in AWS, access to resources can be controlled by IAM controls, however, CloudHSM is slightly different. Instead of using IAM users, the service has its own users and security held on the HSMs themselves utilizing a role-based access control method. Do bear in mind, however, you will still need permissions from within IAM to use the CloudHSM service.  As you might expect, there are different types of users with different levels of controls as to what actions they can perform on the module. So let’s take a look. </p>
<p>The types of users available on the HSM are as follows:</p>
<ul>
<li>Precrypto Office (PRECO).</li>
<li>Crypto Office (CO).</li>
<li>Crypto User (CU).</li>
<li>Appliance User (AU).</li>
</ul>
<p>After you have created your HSM cluster, the first HSM you connect to will be provisioned with the Precrypto Office (PRECO) user with a default username and password. This is a temporary user with temporary credentials of read-only access to the cluster. Using the PRECO user you must activate your cluster. As a part of the activation process of your cluster you will need to change the PRECO password, and by doing so your PRECO user will then become the Crypto Office (CO) user. </p>
<p>The Crypto Office (CO) user contains a more advanced permission set than that of the PRECO user. The CO has the ability to carry out user management tasks, such as the creation and deletion of users, in addition to changing users’ passwords. It can also perform some administrative level operations as well, including:</p>
<ul>
<li>The ability to zeroise data on the HSM, which will delete certificated, keys and any other data on the HSM.</li>
<li>Obtain HSM details such as the different HSM IP address in the cluster, the models, and serial numbers.</li>
<li>View and determine the synchronization status across your cluster.</li>
</ul>
<p>A Crypto User (CU) is used predominantly to perform the cryptographic operations and key management functions with your CloudHSM cluster, these include: </p>
<ul>
<li>Create, delete, import&#x2F;export, and share cryptographic keys.</li>
<li>Perform encryption and decryption, plus signing and verifying.</li>
</ul>
<p>Also, much like the CO, CUs are also able to zeroise data and basic cluster information such as IP address and serial number and retrieve cluster synchronization status.</p>
<p>The Appliance User (AU) performs cloning and synchronization across your cluster and it exists on all HSMs. The CloudHSM calls upon the AU to ensure the synchronization of your HSMs within your cluster is maintained. </p>
<p>Here is a summary of the different user types used on the HSMs. (Image source: <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/cloudhsm/latest/userguide/manage-hsm-users.html#user-permissions-table">https://docs.aws.amazon.com/cloudhsm/latest/userguide/manage-hsm-users.html#user-permissions-table</a>)</p>
<p>The hardware security modules are designed with physical tamper detection and response processes. This means that if the HSM detected any kind of physical breach or tampering of the device, it would begin key deletion across the hardware. </p>
<p>In addition to this, the HSMs are also designed with protection against brute force login attacks. This means that if you were to incorrectly enter the wrong passwords for a Crypto User, then that HSM would lock out that user, and would have to be unlocked by a Crypto Officer.</p>
<h1 id="Using-CloudHSM-as-a-Custom-Key-Store-in-KMS"><a href="#Using-CloudHSM-as-a-Custom-Key-Store-in-KMS" class="headerlink" title="Using CloudHSM as a Custom Key Store in KMS"></a>Using CloudHSM as a Custom Key Store in KMS</h1><p>Hello and welcome to this lecture where I want to explain the interaction between the two AWS encryption services, AWS Key Management Service and AWS CloudHSM.</p>
<p>When working with AWS KMS, you are able to create custom key stores. A key store is effectively a storage location which can store and protect your cryptographic keys used to encrypt and decrypt your data in AWS. When working with AWS KMS, the default key stores are managed by KMS and are stored on HSMs managed by AWS, and so as a user of KMS you have no control over these HSMs which underpin the cryptographic storage of KMS.</p>
<p>However, if you have specific compliance controls that you need to adhere to, where you might require a greater level of control of your key stores. By creating a custom key store you can leverage the power of your CloudHSM cluster which you have full management of, as explained in the previous lecture. </p>
<p>A benefit of AWS KMS is that it has a wide range of integrations with other AWS services, allowing you to perform server-side encryption often at the click of a button with minimal configuration required. This makes it a great choice when protecting your data. </p>
<p>KMS creates and stores Customer Master Keys (CMKs) which is the main key type in KMS and there are two types of customer master keys. Firstly, those which are managed and created by you and I, as customers of AWS, which can be created by using KMS and then those that are managed and created by AWS themselves. </p>
<p>CMKs that are generated and created by us as customers, rather than AWS, provide the ability to implement greater flexibility, such as being able to manage the key, including rotation, governing access and key policy configuration, along with being able to both enable and disable the key when it is no longer required. </p>
<p>So, if within your organisation you want to use the seamless integration of KMS with many AWS services, but require the security and compliance of maintaining your own key material outside of KMS then you can create a custom key store backed by your CloudHSM cluster.</p>
<p>The custom key store is a resource managed from within KMS, but allows you to store your key material within your managed HSMs of your CloudHSM cluster. This allows you to use the key material located within your HSM cluster to create the CMKs that KMS uses to implement encryption across different AWS services. CMKs created from your custom key store are 256-bit, non-exportable AES symmetric keys that never leave the HSM unencrypted. All cryptographic operations made with the CMK happens within the HSM cluster</p>
<p>So as you can see from this diagram, AWS services use CMKs managed by KMS using existing integration, but your CMKs can either come from the default key store created and stored by HSMs managed by AWS, or by using the custom key store which are managed by you allowing you to control access to your key material used within the CMKs.</p>
<p>Bear in mind that each HSM Cluster can only be associated with one custom key store for KMS, and both the cluster and the KMS creation of the custom key store must be within the same region. KMS is a regional service, and keys can’t be used between multiple regions. If you want to create CMKs within your custom key store, then your cluster must have at least 2 HSMs activated in different availability zones. </p>
<p>As a part of the process to create your custom key store you must upload the trust anchor certificate for the cluster to KMS, and this certificate is generated when the cluster is first initialized. Also, you must create a dedicated Crypto User called kmsuser (without 2 factor authentication) and generate a password, which you then provide to KMS. Going forward KMS will use this kmsuser CU to perform its operations in addition to rotating the password every time the user is authenticated.</p>
<h1 id="Monitoring-amp-Logging"><a href="#Monitoring-amp-Logging" class="headerlink" title="Monitoring &amp; Logging"></a>Monitoring &amp; Logging</h1><p>Hello and welcome to this lecture which will look at how to monitor and log events from AWS CloudHSM. </p>
<p>As with most other AWS services, CloudHSM is able to push metric data to Amazon CloudWatch. For those unfamiliar with Amazon CloudWatch, it is a global service that has been designed to be your window into the health and operational performance of your applications and infrastructure.</p>
<p>It’s able to collate and present meaningful operational data from your resources allowing you to monitor and review their performance. This gives you the opportunity to take advantage of the insights that CloudWatch presents, which in turn can trigger automated responses or provide you with the opportunity and time to make manual operational changes and decisions to optimize your infrastructure if required.</p>
<p>The following are the current metrics that CloudWatch can record and monitor at the time of writing this course.</p>
<ul>
<li>HsmUnhealthy: This determines if a HSM is not performing as expected. When CloudHSM identifies a faulty HSM it is automatically replaced for you by the service.  </li>
<li>HsmTemperature: If the processor of the HSM reaches a temperature of 110 degrees centigrade then this system will automatically shut down.</li>
<li>HsmKeysSessionOccupied: This will display the number of session keys that are in operation with a particular HSM.</li>
<li>HsmKeysTokenOccupied: This will display the number of token keys that are in operation with a particular HSM.</li>
<li>HsmSslCtxsOccupied: Displays the number of encrypted channels to the HSM.</li>
<li>HsmSessionCount: Displays the number of open connections to the HSM.</li>
<li>HsmUsersAvailable: This displays the number of additional users that can be created on the HSM.</li>
<li>HsmUsersMax: This displays the maximum number of users that can be created on the HSM instance.</li>
<li>InterfaceEth2OctetsInput: Calculates the total traffic sent to the HSM.</li>
<li>InterfaceEth2OctetsOutput: Calculates the total traffic sent from the HSM.</li>
</ul>
<p>Using CloudWatch you are able to configure alerts and notifications if any of these metrics reach a specific threshold allowing you to take corrective action. </p>
<p>For more information on how to configure these alerts and notifications, please see our existing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-cloudtrail-introduction/aws-cloudtrail-an-introduction-1/">course</a> content covering <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-cloudtrail-introduction/aws-cloudtrail-an-introduction-1/">Amazon CloudWatch</a>. </p>
<p>When it comes to logging in CloudHSM there are a couple of different options to consider. </p>
<ul>
<li>Firstly, we have AWS CloudTrail to track and record all API calls relating to CloudHSM. </li>
<li>We also have CloudWatch Logs for HSM Audit Logs.</li>
</ul>
<p>So let’s take a look at both of these options in a bit more detail, starting with AWS CloudTrail.</p>
<p>AWS CloudTrail is a service that has a primary function to record and track all AWS API requests made. These API calls can be programmatic requests initiated from a user using an SDK, the AWS command-line interface, from within the AWS management console or even from a request made by another AWS service, such as CloudHSM.</p>
<p>When an API request is initiated, such as a ‘CreateHsm’ call, AWS CloudTrail captures the request as an event and records this event within a log file which is then stored on S3. Each API call represents a new event within the log file. CloudTrail also records and associates other identifying metadata with all the events. For example, the identity of the caller, the timestamp of when the request was initiated, and the source IP address. </p>
<p>Here is an excerpt from a CloudTrail log that captures this request of CreateHsm as the “eventName.” </p>
<p>For more information on AWS CloudTrail and how it is configured and a deeper understanding of the logs, please see our existing course here.</p>
<p>Let me now take a quick look at Audit logs. CloudHSM Audit logs are logs that are generated by your AWS CloudHSM Clients using the CloudHSM client daemon. These logs can be retrieved by viewing the file on the client, or by entering a simple command, it’s all dependent on the OS that the client is running. Use the following <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/cloudhsm/latest/userguide/hsm-client-logs.html">AWS resource</a> to find the best method for your OS.</p>
<p>The Audit logs are an essential feature that can’t be disabled or turned off, and they contain records of requests that have been initiated using the AWS CloudHSM command lines tools and software libraries, containing all commands that have been submitted from the client. This allows a full audit of all the actions and requests that have made changes to the HSM, such as the creation and deletion of clusters, users, and keys. </p>
<p>These audit logs are used by CloudHSM which are then sent to Amazon CloudWatch Logs, and this is where the permissions from the AWSServiceRoleForCloudHSM role I explained in a previous lecture come into effect. Much like the creation of these logs themselves, having them sent to CloudWatch is also mandatory which can’t be disabled.</p>
<p>When data is fed into Cloudwatch Logs you are able to monitor the logstream in real time and set up metric filters to search for specific events that you need to be alerted on or respond to. This allows CloudWatch Logs to act as a central repository for real-time monitoring of log data. </p>
<p>For more information on Amazon CloudWatch Logs and how they are managed, please see our existing course <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-1-2/introduction/">here</a>.</p>
<p>Interpreting the logs is a fairly straightforward process, the following shows an example of a log entry that shows the creation of a Key Pair.</p>
<p>Let me just run through the different fields quickly.</p>
<p>Time: This shows the date and time that the event occurred on the HSM using the UTC time zone.</p>
<p>Sequence No: This number increments by 1 for every new event stored within the same log stream.</p>
<p>Reboot counter: This is a A 32-bit persistent ordinal counter that is incremented when the HSM hardware is rebooted.</p>
<p>Command type(hex): This is used to define the command’s category.</p>
<p>Opcode: This shows which command was carried out, in this example the generation of a new key pair.</p>
<p>Session handle: A value to represent which session the command was carried out on.</p>
<p>Response: This determines if the command was successful or not.</p>
<p>Log type: This signifies which log type of the CloudHSM log that recorded the request.</p>
<p>The last 2 entries show the values of the Private and Public key handles that were created as a result of the command issued.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Hello and welcome to the final lecture of this course where I will summarize the key points taken from each of the previous lectures. </p>
<p>I started the course by explaining what AWS CloudHSM is and in this lecture we learnt that:</p>
<ul>
<li><p>CloudHSM is an enterprise-class service used to store and secure encryption key management which can be used as a root of trust for an enterprise when it comes to data protection allowing you to deploy secure and compliant workloads within AWS.</p>
</li>
<li><p>HSM stands for Hardware Security Module which is a physical tamper-resistant hardware appliance used to protect and safeguard cryptographic material and encryption keys</p>
</li>
<li><p>AWS CloudHSM is validated to FIPS 140-2 Level 3</p>
</li>
<li><p>CloudHSMs are NOT multi-tenant devices</p>
</li>
<li><p>It can be used to </p>
</li>
<li><ul>
<li>Create, store and manage cryptographic keys</li>
</ul>
</li>
<li><p>Manage cryptographic hash functions </p>
</li>
<li><p>Perform cryptographic data signing and signature verification</p>
</li>
<li><p>Generate cryptographically secure random data</p>
</li>
<li><p>Asymmetric encryption involves two separate keys. One is used to encrypt the data and a separate key is used to decrypt the data. </p>
</li>
<li><p>Symmetric encryption uses a single key to both encrypt and also decrypt the data. </p>
</li>
<li><p>The Key Management Service, known as KMS is another AWS encryption service</p>
</li>
<li><p>KMS HSMs are managed by AWS</p>
</li>
<li><p>CloudHSMs allow the customer to manage the HSM</p>
</li>
</ul>
<p>In the next lecture I look at the architecture and implementation of the AWS CloudHSM service where I explained the following points: </p>
<ul>
<li>An HSM cluster is a grouping of different HSMs which will act as a single unit when configured and deployed. </li>
<li>HSMs must be deployed in a VPC</li>
<li>Multiple HSMs provides an element of high availability</li>
<li>If one HSM fails, AWS will automatically deploy another one within your cluster</li>
<li>An Elastic Network Interface (ENI) is placed within each subnet of your deployment</li>
<li>The HSM itself actually resides in a different AWS owned VPC located in the same AZ</li>
<li>The ENI acts as an interface between your network and the HSM residing in an AWS-owned VPC.</li>
<li>When you create a cluster, CloudHSM will create a service-linked role allowing permission to send log data to CloudWatch </li>
<li>It will also create a security group to control which resources can communicate with the cluster</li>
<li>Your cluster will need to be initialized before you can connect to the ENIs </li>
<li>You need to add EC2 instances to the clusters security group and install and configure the AWS CloudHSM client to enable communication between the 2 resources</li>
<li>When all resources are in place, you can activate your cluster</li>
</ul>
<p>I then shifted focus over to access control to understand how CloudHSM managed security from that perspective. In this lecture we learnt that:</p>
<ul>
<li><p>CloudHSM has its own users and security held on the HSMs themselves utilizing a role-based access control method. </p>
</li>
<li><p>Different types of users have different levels of controls </p>
</li>
<li><p>There are 4 user types, these being:</p>
</li>
<li><p>Precrypto Office (PRECO)</p>
</li>
<li><p>Crypto Office (CO)</p>
</li>
<li><p>Crypto User (CU)</p>
</li>
<li><p>Appliance User (AU)</p>
</li>
<li><p>The Precrypto Office (PRECO) user is a temporary user with read-only access to the cluster, used to activate your cluster. As a part of this process, you must change the password of the user which will change the user type to the Crypto Office (CO) user. </p>
</li>
<li><p>The Crypto Office User contains a more advanced permission set than that of the PRECO user as has the ability to carry out user management tasks and administrative level functions</p>
</li>
<li><p>The Crypto User (CU) is used predominantly to perform the cryptographic operations and key management functions </p>
</li>
<li><p>The Appliance User (AU) performs cloning and synchronization across your cluster and it exists on all HSMs. </p>
</li>
<li><p>The HSM are designed with protection against brute force login attacks</p>
</li>
</ul>
<p>I then took a quick look at how AWS KMS has a level of integration with CloudHSM, and during this lecture I covered the following:</p>
<ul>
<li>KMS allows you to create custom key stores. </li>
<li>A key store is used to store and protect your cryptographic keys</li>
<li>KMS Default key stores are managed by KMS and are stored on HSMs managed by AWS</li>
<li>Custom key stores allow you to leverage the power of your CloudHSM cluster</li>
<li>The custom key store is a resource managed from within KMS, but allows you to store your key material within your managed HSMs of your CloudHSM cluster. </li>
<li>CMKs created from your custom key store are 256-bit, non-exportable AES symmetric keys that never leave the HSM unencrypted. </li>
<li>All cryptographic operations made with the CMK happens within the HSM cluster</li>
<li>Each HSM Cluster can only be associated with one custom key store for KMS</li>
<li>KMS and the Cluster must be in the same region</li>
<li>You must upload the trust anchor certificate for the cluster to KMS to create a custom key store</li>
<li>You must also create a dedicated Crypto User called <strong>kmsuser</strong></li>
</ul>
<p>In the final lecture, I covered an overview of logging and monitoring, the key takeaways from this lecture were:</p>
<ul>
<li><p>CloudHSM is able to push metric data to Amazon CloudWatch. </p>
</li>
<li><p>CloudWatch can record and monitor a number of different metrics relating to CloudHSM to determine its health, connection details, user capacity and more</p>
</li>
<li><p>Using CloudWatch allows you to be alerted and notified if any configured metric thresholds are met </p>
</li>
<li><p>AWS CloudTrail can track and record all API calls relating to CloudHSM </p>
</li>
<li><p>When an API request is initiated, such as a ‘CreateHsm’ call, AWS CloudTrail captures the request as an event and records this event within a log file </p>
</li>
<li><p>Each API call represents a new event within the log file. </p>
</li>
<li><p>CloudTrail records and associates identifying metadata with all the events. For example, the identity of the caller, the timestamp of when the request was initiated and the source IP address. </p>
</li>
<li><p>CloudWatch Logs can record your HSM Audit Logs </p>
</li>
<li><p>CloudHSM Audit logs are logs that are generated by your AWS CloudHSM Clients using the CloudHSM client daemon. </p>
</li>
<li><p>Audit logs can’t be disabled or turned off, and they contain records of requests that have been initiated using the AWS CloudHSM command lines tools and software libraries.</p>
</li>
<li><p>Audit logs used by CloudHSM are sent to Amazon CloudWatch Logs</p>
</li>
<li><p>Cloudwatch Logs allow to monitor the logstream in real time and set up metric filters to search for specific events that you need to be alerted on or respond to</p>
</li>
</ul>
<p>That now brings me to the end of this lecture and to the end of this course, and so you should now have a greater understanding of AWS CloudHSM and how it can be configured and deployed within your VPC.</p>
<p>Feedback on our courses here at Cloud Academy is valuable to both us as trainers and any students looking to take the same course in the future. If you have any feedback, positive or negative, it would be greatly appreciated if you could contact <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>.</p>
<p>Thank you for your time and good luck with your continued learning of cloud computing. Thank you.</p>
<h1 id="2What-is-CloudHSM"><a href="#2What-is-CloudHSM" class="headerlink" title="2What is CloudHSM?"></a>2<strong>What is CloudHSM?</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-web-services-key-management-service-kms/kms-encryption-introduction/">Course: How to Use KMS Key Encryption to Protect Your Data</a></p>
<h1 id="3Understanding-AWS-CloudHSM-Architecture-amp-Implementation"><a href="#3Understanding-AWS-CloudHSM-Architecture-amp-Implementation" class="headerlink" title="3Understanding AWS CloudHSM Architecture &amp; Implementation"></a>3<strong>Understanding AWS CloudHSM Architecture &amp; Implementation</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/cloudhsm/latest/userguide/initialize-cluster.html">AWS Documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/cloudhsm/latest/userguide/install-and-configure-client-linux.html">Full list of commands</a></p>
<h1 id="6Monitoring-amp-Logging"><a href="#6Monitoring-amp-Logging" class="headerlink" title="6Monitoring &amp; Logging"></a>6<strong>Monitoring &amp; Logging</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-cloudtrail-introduction/aws-cloudtrail-an-introduction-1/">Amazon CloudWatch course</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/cloudhsm/latest/userguide/hsm-client-logs.html">Find the best method for your OS</a></p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-1-2/introduction/">Course: How to Implement &amp; Enable Logging Across AWS Services (Part 1 of 2)</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-Sharing-Secrets-Between-Multiple-Accounts-Using-AWS-Secrets-Manager-34/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AWS-Security-Specialty-Sharing-Secrets-Between-Multiple-Accounts-Using-AWS-Secrets-Manager-34/" class="post-title-link" itemprop="url">AWS-Security-Specialty-Sharing-Secrets-Between-Multiple-Accounts-Using-AWS-Secrets-Manager-34</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:38" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:38-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 22:57:54" itemprop="dateModified" datetime="2022-11-19T22:57:54-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-Sharing-Secrets-Between-Multiple-Accounts-Using-AWS-Secrets-Manager-34/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-Sharing-Secrets-Between-Multiple-Accounts-Using-AWS-Secrets-Manager-34/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hello and welcome. In this course, I will be explaining how you can share secrets such as database API keys and database credentials between different AWS accounts through the use of resource-based policies and AWS Secrets Manager.</p>
<p>My name is Stuart Scott and if you have any questions, please reach out to me using the details shown on-screen. Alternatively, you can always get in touch with us here at Cloud Academy by sending an e-mail to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a> where one of our cloud experts will reply to your question.</p>
<p>This course has been created for those who are responsible for managing security and credentials within AWS, specifically if you’re trying to architect the removal of hard-coded passwords and keys from applications and services. By the end of this course, you’ll understand how to securely allow identities in multiple AWS accounts to access secrets from within another AWS account using AWS Secrets Manager and resource-based policies. To get the most from this course, you should be familiar with JSON policies and their syntax and the basic concepts of the Key Management Service, IAM, and the AWS CLI. Okay, let’s get started.</p>
<h1 id="Sharing-Secrets-with-AWS-Secrets-Manager"><a href="#Sharing-Secrets-with-AWS-Secrets-Manager" class="headerlink" title="Sharing Secrets with AWS Secrets Manager"></a>Sharing Secrets with AWS Secrets Manager</h1><p>Welcome to this lecture which will provide a high-level focus on the AWS Secrets Manager service in addition to providing a demonstration on how to share secrets between multiple accounts.</p>
<p>Firstly, what is considered a secret? A secret in this instance can be passwords, third party API keys, database credentials on Amazon RDS or redshift clusters, or simply plain text. Essentially, it’s typically something that you want to remain hidden from the open world.</p>
<p>AWS Secrets Manager is a great service to enhance your security posture by allowing you to remove any hard-coded secrets within your application and replacing them with a simple API call to the aid of your secrets manager which then services the request with the relevant secret. As a result, AWS Secrets Manager acts as a single source of truth for all your secrets across all of your applications.</p>
<p>AWS Secrets Manager enables the ease of rotating secrets and therefore enhancing the security of that secret. An example of this could be your database credentials. Other secret types can also have automatic rotation enabled through the use of lambda functions, for example, API keys. </p>
<p>Being an enhanced security service, it also offers integration with other key AWS services such as KMS, the Key Management Service which is used to encrypt your secrets within AWS Secrets Manager. AWS CloudTrail on Amazon CloudWatch can be used to monitor the activity of your secrets, for example, when an API call is triggered to rotate a secret, CloudTrail will log this detail and cloud watch can be configured to report on this deletion through the use of CloudTrail logs and then notify your team. This provides full visibility and auditing capabilities as well as notification of any unexpected behavior, for example, a deletion of one of your secrets.</p>
<p>Access to your secrets within AWS Secret Manager is governed by fine-grained IAM identity-based policies in addition to resource-based policies. Identity-based policies are attached to identities that have been created within the IAM service and associated specific permissions to their identity. Resource-based policies are attached to an individual resource instead of an identity.</p>
<p>Now I’ve covered some of the high-level details of AWS Secrets Manager, let me now focus on how to share secrets between multiple accounts. You might want to do this to have a centralized and managed store of your secrets instead of having multiple stores between different accounts. You can then share your secrets to AWS accounts as and when needed in a secure manner.</p>
<p>I will now perform a demonstration to show you how to manage and control access to a secret in Secrets Manager between two separate accounts. Let me call these my primary account and my secondary account. My primary account will be used to house the secret and the secondary account will have an IAM user who will retrieve the secrets from the primary account. </p>
<p>For this demonstration, I already have an existing KMS key and secret created within the primary account and an IAM user named Stuart in the secondary account.</p>
<p>I shall follow these steps: firstly, I’ll start by identifying the ARNs of both the secret and the KMS key as these will be needed through the configuration, I will then login to the secondary account to find the ARN of the IAM user Stuart, from here, I will add an in-line policy to the user allowing access to retrieve the value of the secret as well as access to decrypt the KMS key using the following policy.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;Version&quot; : &quot;2012-10-17&quot;,</span><br><span class="line">  &quot;Statement&quot; : [</span><br><span class="line">&#123;</span><br><span class="line">   &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">   &quot;Action&quot;: &quot;secretsmanager:GetSecretValue&quot;,</span><br><span class="line">      &quot;Resource&quot;: &quot;ARN OF SECRET&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">   &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">   &quot;Action&quot;: &quot;kms:Decrypt&quot;,</span><br><span class="line">      &quot;Resource&quot;: &quot;ARN OF KMS KEY&quot;</span><br><span class="line">&#125;</span><br><span class="line">  ]</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>I will then log back in to the primary and edit the key policy of the KMS key allowing KMS decrypt access for the user Stuart using the following policy.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;Sid&quot;: &quot;AllowUseOfTheKey&quot;,</span><br><span class="line">   &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">   &quot;Principal&quot;:</span><br><span class="line">           &#123;&quot;AWS&quot;: &quot;ARN OF STUART&quot;&#125;,</span><br><span class="line">   &quot;Action&quot;: [</span><br><span class="line">   &quot;kms:Decrypt&quot;,</span><br><span class="line">   &quot;kms:DescribeKey&quot;</span><br><span class="line">],</span><br><span class="line">   &quot;Resource&quot;: &quot;ARN OF KMS KEY&quot;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Using the AWS CLI credentials of an admin in the primary account, I’ll add a resource- based policy to the secret in the primary account allowing the user Stuart access to retrieve the secret value using the following policy.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;Version&quot; : &quot;2012-10-17&quot;,</span><br><span class="line">  &quot;Statement&quot; : [</span><br><span class="line">	&#123;</span><br><span class="line">  	&quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">      &quot;Principal&quot;: &#123;&quot;AWS&quot;: &quot;ARN OF STUART&quot;&#125;,</span><br><span class="line">  	&quot;Action&quot;: &quot;secretsmanager:GetSecretValue&quot;,</span><br><span class="line">      &quot;Resource&quot;: &quot;*&quot;,</span><br><span class="line">      &quot;Condition&quot;: &#123;&quot;ForAnyValue:StringEquals&quot;: &#123;&quot;secretsmanager:VersionStage&quot;: &quot;AWSCURRENT&quot;&#125;&#125;</span><br><span class="line">	&#125;</span><br><span class="line">  ]</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Finally, I will test access by attempting to retrieve the values of the secret using the credentials of the user Stuart from the AWS CLI using the following command.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws secretsmanager get-secret-value --secret-id ARN OF SECRET --version-stage AWSCURRENT</span><br></pre></td></tr></table></figure>

<p>Ok, let’s take a look. Ok, so I’m starting off in my primary account where I have my AWS secret that’s already created and also my AWS KMS key. So, let’s go ahead and take with both of those. So if I take a look at my KMS key first. Go to Key Management Service. I can see here that I have my key and this is the key that I’ll be using, so if I select that we can take a note of the ARN here so you need to make sure you have the ARN of your KMS key to hand when you’re doing this configuration.</p>
<p>Now, if I go across to Secrets Manager, now here we have my list of secrets and the secret that we’re going to be using is MySecret. Now, here again we have the ARN of the secret and we need to have that to hand. Now, the values of the secret is simply a username key with the value of Alice and the password key with the value of password1. So they are the details that are contained within this secret but like I say, for this configuration, what we need is the ARN of the KMS key and also the ARN of the secret that we’re going to be using. And this secret is encrypted with the KMS key that we looked at just now, MyKey.</p>
<p>Okay, so now we have those ARNs, what I need to do now is go across to my secondary account where the IAM user Stuart exists, so let me flip over to that account now. Okay, so I’m now in my secondary account so I want to go across to the IAM service first to look at my user. If I go down to users and select my user which is Stuart. Now, once we’re looking at this user, we also need to make a note of the ARN of this user as well as we’re going to need that going forward.</p>
<p>Now, from here I want to add an inline policy, so if I go across to to add inline policy here, and I’m gonna paste in a JSON version of the policy. So we just paste that in. So this does two things, this policy. Firstly, it allows this user which is Stuart access to get the secret value from this secret and this is the ARN of the secret from our primary account. Now, the second section here also allows access to KMS decrypt of our KMS key, so this user will also need to be able to have decrypt access to the KMS key that is used to encrypt the secret. So if you’re setting this up in your own account, you’ll need to ensure you have the right ARN in there for your secret and also the ARN of your KMS key in here.</p>
<p>Okay, click on review policy and then give this policy a name and then create policy. Okay and we can now see that we have the inline policy attached here—I call it Secret. Okay, so now what I need to do is go back to the primary account and edit the key policy of this KMS key. So let me flick back to our primary account. Okay, so I’m back at the primary account. Let me go over to KMS. Now, I need to edit the key policy because, although I’ve allowed decrypt access for the user, I still need to edit the key policy to ensure that the key policy of that KMS key allows that user to use it.</p>
<p>So now I’m in the KMS key, if I switch down to switch to policy view and then go to the key policy and I select edit, I need to paste in a new section, so let me just add that under the access for key administrators. Let me just put it in here. Okay, so this is the section I just pasted in. So what this does it allows the use of the key for this user here and this is the ARN of the IAM user in the secondary account, Stuart, and it allows these actions KMS Decrypt and DescribeKey and again is the resource of the KMS key. So, although we allowed KMS Decrypt on the inline policy of the actual user itself, we also need to add those permissions within the key policy of the KMS key itself. So if you save those changes.</p>
<p>Okay, so the next part what I need to do is create a resource based policy and attach this to the secret. Now, currently, that’s not something you can do from within the AWS management console, so we need to use the AWS CLI for this. So let me jump across to the terminal. Now, I’ve already created a JSON file for this. So let me just show you that quickly. I’ve called it resource.JSON and we can see here that it’s a very simple policy. Now, all this does, it allows the IAM user Stuart to get the secret value of the secret that I’m going to apply it to. So let me just go back.</p>
<p>Okay and the command to attach this policy is as follows. So the command is aws secretsmanager put-resource-policy –secret-id and then the name of the secret that we have which is MySecret, and then –resource-policy, file, and then the name of the file that contains the JSON policy that we want to attach. Okay, that is now attached. So now what we want to do is to test the access. So, so far, what we’ve done we have our KMS key created. We have our secret key created. And that secret is encrypted with the KMS key.</p>
<p>We have our user in the secondary account and we’ve added an inline policy that allows that user to get a secret value and also decrypt the KMS key. We’ve updated the KMS key policy to allow that same user that decrypt access and now we’ve just added a resource-based policy that allows the user to get the secret value of the secret and return that value. Now, to test that access, we enter the following command. So it’s aws secretsmanager get-secret-value using the –secret-id and here we can paste in the ARN of the secret and then –version-stage of AWSCURRENT, then I’m going to use the AWS credentials of the AWS user Stuart.</p>
<p>Now, this profile here of Stuart matches the user credentials of the IAM user Stuart in the secondary account. So let’s give this a test. And there we go, we can see that we have returned the values of the secret and we have here the two values where the username was Alice and also the password was Password1. And that’s it. So that’s how you can share secrets between accounts by attaching a resource-based access policy to your secret.</p>
<p>Feedback on our courses here at Cloud Academy is valuable to both us as trainers and any students looking to take the same course in the future. Any feedback, positive or negative, it would be greatly appreciated if you can contact <a href="mailto:&#x73;&#117;&#x70;&#112;&#x6f;&#114;&#116;&#64;&#x63;&#x6c;&#111;&#117;&#x64;&#x61;&#99;&#97;&#x64;&#101;&#109;&#121;&#46;&#99;&#111;&#x6d;">&#x73;&#117;&#x70;&#112;&#x6f;&#114;&#116;&#64;&#x63;&#x6c;&#111;&#117;&#x64;&#x61;&#99;&#97;&#x64;&#101;&#109;&#121;&#46;&#99;&#111;&#x6d;</a>. Thank you for your time and good luck with your continued learning. of cloud computing. Thank you.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/132/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/132/">132</a><span class="page-number current">133</span><a class="page-number" href="/page/134/">134</a><span class="space">&hellip;</span><a class="page-number" href="/page/274/">274</a><a class="extend next" rel="next" href="/page/134/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
