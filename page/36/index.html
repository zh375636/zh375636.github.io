<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hang&#39;s Blog">
<meta property="og:url" content="https://example.com/page/36/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/page/36/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Managing-Networking-and-Compute-Resources-on-Google-Cloud-Platform-15/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Managing-Networking-and-Compute-Resources-on-Google-Cloud-Platform-15/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Managing-Networking-and-Compute-Resources-on-Google-Cloud-Platform-15</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:56" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:56-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:51:16" itemprop="dateModified" datetime="2022-11-22T20:51:16-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Managing-Networking-and-Compute-Resources-on-Google-Cloud-Platform-15/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Managing-Networking-and-Compute-Resources-on-Google-Cloud-Platform-15/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to Managing Network and Compute Resources on Google Cloud Platform. My name is Thomas Mitchell and I’ll be taking you through this course. I’m a content author at Cloud Academy and I have over 25 years of IT experience - several of those with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn or send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>.</p>
<p>This course is intended for IT professionals who deploy applications, monitor operations and manage enterprise solutions using Google Cloud Platform services and offerings. It’s also intended for those interested in obtaining the <a target="_blank" rel="noopener" href="https://cloudacademy.com/learning-paths/google-associate-cloud-engineer-exam-preparation-844/">Associate Cloud Engineer Certification</a>.</p>
<p>To get the most from this course you should have a <a target="_blank" rel="noopener" href="https://cloudacademy.com/learning-paths/google-cloud-platform-fundamentals-54/">basic understanding of the Google Cloud Platform</a> and its offerings. We’ll kick off the first half of this course by covering the management of network resources. In this first half, you’ll learn how to add a subnet to an existing VPC and how to expand a CIDR block subnet. You’ll also learn how to reserve static internal and external IP addresses. We’ll wrap up the first half of the course by covering the different management interfaces including Cloud Console, Cloud Shell, and Cloud SDK, as they relate to network resource management.</p>
<p>The second half of the course will cover the management of Compute Engine resources. In it, you’ll learn how to manage VM instances and how to connect to them via SSH and RDP. As we progress through the second half of the course, you’ll learn how to attach a GPU to a VM instance and how to install the CUDA libraries. We’ll then cover how to view information about current running VM inventory.</p>
<p>Later on, you’ll learn how to create, view, and delete snapshots. You’ll also learn how to create images, how to view those images, and how to delete them.</p>
<p>Coming down the home stretch, you’ll learn how to work with instance groups and how to use the different management interfaces as they relate to Compute Engine management. By the time you complete this course, you’ll have a full understanding of how to manage network resources and Compute Engine resources on Google Cloud Platform.</p>
<p>We’d love to get your feedback on this course, so please give it a rating when you’re finished. So, if you’re ready to learn how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/managing-network-resources/">manage network</a> and compute resources on <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a>, let’s get started.</p>
<h1 id="Managing-Network-Resources"><a href="#Managing-Network-Resources" class="headerlink" title="Managing Network Resources"></a>Managing Network Resources</h1><p>Welcome to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">Managing Network Resources</a>. In this section, we’re going to cover several network management topics. In this section, you’ll learn how to add subnets to existing VPCs, how to expand CIDR blocks, and how to reserve static internal and external IP addresses. You’ll also learn how to perform management tasks in Cloud Shell.</p>
<p>Join me in the next lesson where I’ll show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-adding-a-subnet-to-an-existing-vpc/">add a subnet to an existing VPC</a>.</p>
<h1 id="DEMO-Adding-a-Subnet-to-an-Existing-VPC"><a href="#DEMO-Adding-a-Subnet-to-an-Existing-VPC" class="headerlink" title="DEMO: Adding a Subnet to an Existing VPC"></a>DEMO: Adding a Subnet to an Existing VPC</h1><p>Hi, everyone, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">welcome</a> to this demonstration. In this demonstration, I’m going to show you how to add a subnet to an existing VPC.</p>
<p>When you create a subnet, you need to specify a name, a region, and at least a primary IP address range for the subnet. To complete this process, what you need to do is browse to the VPC networks page in <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a> Console. From here, we need to click an existing VPC network. What this will do is show the network details page.</p>
<p>To add the subnet, click Add subnet and then provide a name for the subnet, and choose a region to deploy to. </p>
<p>From here, specify the primary IP range for the subnet. For this exercise, I’ll add a subnet with a range of 10.0.0.0&#x2F;16. As you can see here, we could enable Private Google Access for the subnet right now, if we wanted to. We can also leave it disabled for now and change it later. I’m not going to bother enabling it for this exercise, so we’ll just leave it alone. We would typically enable this option in order to allow any VMs on this network to connect to Google APIs and services, without giving those VMs external IP addresses.</p>
<p>If I needed a way to record network flows sent to and from the VM instances on this subnet, I could enable VPC flow logs right here for the subnet. VPC flow logs are generally used for network monitoring, forensics, and real-time security analysis. Since this is a lab, I’m not terribly worried about any of these things, so I’ll leave this option alone. Clicking Add down here, adds the newly configured subnet, and then what we’ll do here is refresh, and you can see my new subnet is now listed.</p>
<p>Join me in the next lesson, where we’ll discuss the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/expanding-a-cidr-block-subnet-to-have-more-ip-addresses/">expansion of CIDR block subnets</a>.</p>
<h1 id="Expanding-a-CIDR-Block-Subnet-to-Have-More-IP-Addresses"><a href="#Expanding-a-CIDR-Block-Subnet-to-Have-More-IP-Addresses" class="headerlink" title="Expanding a CIDR Block Subnet to Have More IP Addresses"></a>Expanding a CIDR Block Subnet to Have More IP Addresses</h1><p>Hi everyone, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">welcome</a> back. In this lecture, we’re going to cover the expansion of a CIDR block subnet.</p>
<p>In a production environment and maybe even while sitting an exam, you may find yourself needing to expand a subnet. That being the case, it’s important that you know how to do this.</p>
<p>To expand the primary IP range of an existing subnet, you need to modify its subnet mask. By setting the mask prefix length to a smaller number, you make more addresses available on the subnet itself. If you need to expand the range of an automatically created subnet within an auto mode network, the broadest subnet mask or prefix that you can use is &#x2F;16. Using a subnet mask that’s broader than &#x2F;16 would conflict with the primary IP ranges of the other automatically created subnets. The same rule applies to a custom network that was previously an auto mode network.</p>
<p>It’s important to know that you cannot undo the expansion of the primary IP range of a subnet, nor can you shrink the primary IP range of a subnet. That being the case, you should always be conservative when expanding primary IP ranges. If you find that you need even more addresses than expected, you can always expand again later.</p>
<p>You should also be sure to factor in any IP address space of any networks that will be connected to your VPC network when expanding the subnet’s primary IP range. You need to ensure that you don’t overlap any connected IP address spaces.</p>
<p>Join me in the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-expanding-a-cidr-block-subnet-to-have-more-ip-addresses/">next lesson</a> where I’ll show you how to expand a CIDR block subnet for an existing subnet within a VPC.</p>
<h1 id="DEMO-Expanding-a-CIDR-Block-Subnet-to-Have-More-IP-Addresses"><a href="#DEMO-Expanding-a-CIDR-Block-Subnet-to-Have-More-IP-Addresses" class="headerlink" title="DEMO: Expanding a CIDR Block Subnet to Have More IP Addresses"></a>DEMO: Expanding a CIDR Block Subnet to Have More IP Addresses</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">Welcome</a> back. In the last lesson, we talked about some of the details surrounding the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/expanding-a-cidr-block-subnet-to-have-more-ip-addresses/">expansion of a CIDR block subnet</a>. In this demonstration, I’m going to show you how to do it.</p>
<p>On the screen here, you can see that I’m logged in to my Google Cloud Platform Console. To expand my CIDR block subnet, I need to browse over here to the VPC Networks page. Now, from this page, I can see all of my networks and subnets in my project. Now, these are going to be shown, as you can see here, in a hierarchical view. My existing subnets are shown as entries within each of the networks.</p>
<p>What I need to do here is click the name of the network that contains the subnet that I want to expand. And we’re going to expand my new subnet here. So we’ll click test-network. From this VPC Network Details page I can then click the name of the subnet in the Subnets tab so I can view the subnet’s details page.</p>
<p>Now, clicking Edit here allows me to enter a broader CIDR block in the IP address range field. I’ll change this subnet from a &#x2F;16 to a &#x2F;15. What this does is make more addresses available for devices within this subnet. So, with my new CIDR block defined here, I just have to click Save to make it active.</p>
<p>Now, just a heads up, the expansion of the primary IP range of a subnet can actually take several minutes to complete. However, traffic within the subnet will continue to flow, unaffected, during the expansion. This process creates zero downtime.</p>
<p>Join me in the next lesson where we’ll talk about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/reserving-static-internal-ip-addresses/">reserving IP addresses</a>.</p>
<h1 id="Reserving-Static-Internal-IP-Addresses"><a href="#Reserving-Static-Internal-IP-Addresses" class="headerlink" title="Reserving Static Internal IP Addresses"></a>Reserving Static Internal IP Addresses</h1><p>Hi, everyone, and welcome to this lecture. In this lecture, we’re going to talk a little bit about reserving static internal IP addresses. If you <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">deploy</a> a VM instance that requires a fixed internal IP address, you can obtain a static internal IP address for it in one of two ways. You can either simply reserve a new static internal address and then assign it to the new VM instance, or you can promote an existing ephemeral internal IP address to become a static internal IP address.</p>
<p>With static internal IPs, you can reserve internal IP addresses from the private RFC 1918 IP range that’s configured within the subnet. You can then assign those reserved internal addresses to your resources as needed. Obviously, when you reserve an internal IP address, that IP address is taken out of the dynamic allocation pool. This prevents the address from being used for automatic allocations.</p>
<p>By leveraging reserved static internal IP addresses, you can ensure that the resource that is assigned the reserved address always uses the same IP address, even if the resource is deleted and recreated.</p>
<p>It’s important to note before we dive into the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-reserving-static-internal-ip-addresses/">demonstration that’s up next</a>, that the reservation of a static internal IP address requires specific IAM permissions. This ensures that only authorized users can reserve static internal IP addresses. I should also note that you can only reserve up to 200 static internal IP addresses per region, by default. Another thing to keep in mind is that the reservation of static internal IP addresses is only supported for VPC networks. You can’t reserve static internal IP addresses for legacy mode networks.</p>
<h1 id="DEMO-Reserving-Static-Internal-IP-Addresses"><a href="#DEMO-Reserving-Static-Internal-IP-Addresses" class="headerlink" title="DEMO: Reserving Static Internal IP Addresses"></a>DEMO: Reserving Static Internal IP Addresses</h1><p>Welcome back. In the last lecture, we talked about the ways that you can <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/reserving-static-internal-ip-addresses/">reserve a static internal IP address</a>. In this lesson, I’m going to show you how to reserve an IP address using the console.</p>
<p>Now, before we <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">get started</a> I need to point out that in order to reserve and to manage static internal IP addresses, I need to be granted the compute.networkAdmin role. I’m logged in as the admin here so I’m good there.</p>
<p>As mentioned previously, you can reserve a static internal IP address before creating the resource it will be assigned to, or you can create the resource with an ephemeral internal IP address and then promote the ephemeral IP address to a static internal IP address.</p>
<p>In this demonstration, we’re going to reserve a static internal IP address and then assign it to a resource.</p>
<p>To get started, I need to identify a subnet from my VPC network that I want to work with because remember, you can only reserve IPs using a VPC network. To do this, I need to go to my VPC networks page in my GCP console here. Now, what I’ll do is I’ll use this test VPC network down here for this demonstration.</p>
<p>Next, I need to go to my VM instances page where I can create my instance and reserve the IP when I create the instance. So let’s browse over to our compute instances. And we’ll go ahead and create our instance. I’m going to call my instance myvm, and then I’ll select my regions here, along with the zone. And then from here, I need to provide the rest of the info for my instance: the size, the generation, all of that other fun stuff. I’ll leave this at the default because that’s not what I’m trying to demonstrate here. </p>
<p>Next, I need to expand the “Management, security, disks, networking, sole tenancy” menu down here at the bottom. And then from here, I can click on Networking to edit my networking resources.</p>
<p>Under Network interfaces here, I need to choose the subnet that I’m reserving an address for, and then we’ll select our network. Now, under Primary Internal IP here, I can choose to reserve a static IP address. But do the dropdown here, I can select reserve static internal IP address.</p>
<p>Now, I’ll give this internal IP address resource a name. I’ll just call it myinternalip. And then what we can do is we can select whether to assign an address automatically or let me choose. For this demonstration, I’ll just let it assign an address and I’ll reserve it. I’ll leave the rest of the settings here at their defaults and just minimize this dropdown. And then from here I can click Create to create my resource. And what this is going to do is spin up a new instance that’s connected to my subnet within my VPC. When it comes up, it’s going to do so with a reserved static internal IP address.</p>
<h1 id="Reserving-Static-External-IP-Addresses"><a href="#Reserving-Static-External-IP-Addresses" class="headerlink" title="Reserving Static External IP Addresses"></a>Reserving Static External IP Addresses</h1><p>Hi, everyone, welcome to this lecture. In this lecture, we’re going to talk about reserving static external IP addresses. If you <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">deploy an instance</a> that requires a static external IP address that’s never going to change, you can reserve a static external IP for that instance. You can actually reserve two different types of external IP addresses. You can reserve a regional IP address or a global IP address.</p>
<p>A regional IP address can be used by VM instances with one or more network interfaces and also by network load balancers. A global IP address can be used for global load balancers. A reserved external IP address can be assigned to a new instance during creation of the instance, or it can be assigned to an existing instance that’s already been created. You have two options when reserving a static external IP address. You can either reserve a new static external IP address and then assign it to the new VM instance, or you can promote an existing ephemeral external IP address to a static external IP address.</p>
<p>As was the case with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/reserving-static-internal-ip-addresses/">static internal addresses</a>, when you reserve an external IP address, that IP is also removed from the dynamic allocation pool so that the reserved address is never used for an automatic allocation. Reserving a static external IP address for a resource ensures that the resource that’s assigned the reserve address always uses the same external address. </p>
<p>In this next lesson, I’ll show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-reserving-static-external-ip-addresses/">reserve a new static external IP address</a>.</p>
<h1 id="DEMO-Reserving-Static-External-IP-Addresses"><a href="#DEMO-Reserving-Static-External-IP-Addresses" class="headerlink" title="DEMO: Reserving Static External IP Addresses"></a>DEMO: Reserving Static External IP Addresses</h1><p>Hi, everyone, welcome back. In the last lesson, we covered <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/reserving-static-external-ip-addresses/">static external IP addresses</a>. In this lesson, I’m going to show you how to reserve a new static external IP address, using the Google Cloud Platform console.</p>
<p>As you can see here, I have my <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">GCP console up and running</a>. To reserve my address, I need to browse to the VPC Network page, and then from there, we’ll go to External IP addresses.</p>
<p>So, let’s go out and browse here, and then hit External IP addresses. From this External IP addresses page, I can reserve my address. I’ll go ahead and click Reserve. And now I need to give my new static address a name and I need to specify the network service tier. So let me give it a name here. Hovering over the question mark here for the Premium service tier tells me that choosing this tier is going to cause traffic to traverse Google’s global backbone, entering and exiting at Google edge peering points that are closest to the use. If I hover over the question mark for the Standard option here, it tells me that traffic will enter and exit the Google network at a peering point that’s closest to the cloud region it’s either destined for or originated from.</p>
<p>Now, for this exercise, I’m going to leave this set at Premium. Now, I also need to specify whether this address needs to be IPv4 or IPv6. Now, I should note that IPv6 addresses can only be global, and they can only be used with global HTTP(S) or HTTP SSL proxy and TCP proxy load balancers. For this exercise, I’m going to leave the IP version set to IPv4. I also need to determine whether my IP address is regional or global. Now, I showed you earlier here by clicking the IPv6, that if I select IPv6 it defaults to global. Since I’m doing IPv4, we have two options here. For this exercise, I’m going to select regional here.</p>
<p>Now, since I’m reserving a regional address here, I need to specify the region to create the address in. So I’ll leave this set to us-central1. Now, what I could do here is choose a resource to actually connect this IP address to or attach this IP address to. For this exercise though, I’m just going to reserve the IP and not attach it to anything. We could always attach it later on. So to complete my reservation, I simply click the Reserve button here to reserve the IP. And at this point, I now have a regional static IP address that’s reserved. Since it’s a regional address that I’ve reserved, I can later assign it to either a VM instance or to a network load balancer.</p>
<h1 id="Working-with-Management-Interfaces"><a href="#Working-with-Management-Interfaces" class="headerlink" title="Working with Management Interfaces"></a>Working with Management Interfaces</h1><p>Over the last few lessons, we covered the reservation of static IP addresses using the Cloud Console. However, you can also perform these functions using the Cloud Shell. In the next lesson, I’m going to show you <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-reserving-a-static-ip-address-with-cloud-shell/">how to use the Cloud Shell to reserve a static internal IP address</a> so that you can get a little bit more familiar with the use of Cloud Shell for common <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">management</a> tasks.</p>
<h1 id="DEMO-Reserving-a-Static-IP-Address-with-Cloud-Shell"><a href="#DEMO-Reserving-a-Static-IP-Address-with-Cloud-Shell" class="headerlink" title="DEMO: Reserving a Static IP Address with Cloud Shell"></a>DEMO: Reserving a Static IP Address with Cloud Shell</h1><p>Welcome back. In this lesson, I’m going to demonstrate how to use gcloud to reserve a new static external IP address. It’s a short demo, but I wanted to familiarize you with using gcloud for typical <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">management</a> tasks, like reserving IP addresses.</p>
<p>On the screen here, you can see I’m logged into my console. What I’m going to do is click the Cloud Shell icon to launch gcloud. Once I’ve got my Cloud Shell up, I can use gcloud compute to reserve my address. What I’m going to do here is use the <code>addresses create</code> subcommand and then specify that I’m reserving a regional IP address. So what I’m going to do here is type the command out so you can see what it looks like. We’ll start with <code>gcloud, a</code>nd then we’ll go with <code>compute, a</code>nd then what we’re going to do is specify <code>addresses create</code>. Now what I need to do is give my reserved address resource a name. So I’ll call it myreservedaddress<code>, </code>and then what I need to do is specify the region I want to deploy this to. So we’ll use the <code>--region</code> flag and then we’ll specify, I guess, <code>us-central</code>. More specifically, <code>us-central1</code>. </p>
<p>Now, since I’m reserving a regional address, I don’t need to specify the IP version. If I were specifying a global address, what I would use is the <code>--ip-version-flag</code> here, and then specify either IPv4 or IPv6. Since this is a regional address that we’re reserving, the <code>--ip-version</code> flag doesn’t work so we’ll go ahead and backspace over this. And then what we’ll do is hit Enter here. Now, once this command completes, I’m left with the reserved static IP in the uscentral1 region, and if I go back into my VPC here, we can see my reserve address is now listed. It’s a static address and it’s IPv4. So that is how you reserve a static external IP address using gcloud.</p>
<h1 id="Managing-Compute-Engine-Resources"><a href="#Managing-Compute-Engine-Resources" class="headerlink" title="Managing Compute Engine Resources"></a>Managing Compute Engine Resources</h1><p>Welcome to Managing Compute Engine Resources. In this section, we’re going to cover several Compute Engine <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">management</a> tasks. In this section, you’ll learn how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/managing-a-single-vm-instance/">manage VM instances</a>. You’ll learn how to start instances, stop them, and how to delete them. You’ll also learn how to edit an instance configuration. After working through Compute Engine management, you’ll learn how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-ssh-to-a-linux-instance/">connect to a VM instance via SSH</a> and via RDP. Next, you’ll learn how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/attaching-a-gpu-to-a-new-instance-and-installing-cuda-libraries/">add a GPU to an existing VM and how to install the CUDA libraries</a> to support the GPU. After learning about GPUs and CUDA libraries, you’ll learn how to view current running VM inventory. We’ll then get into <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/working-with-snapshots/">snapshots</a>, images, and instance groups. Join me in the next lesson where we’ll take a look at VM instance management.</p>
<h1 id="Managing-a-Single-VM-Instance"><a href="#Managing-a-Single-VM-Instance" class="headerlink" title="Managing a Single VM Instance"></a>Managing a Single VM Instance</h1><p>Hi, everyone, welcome to this lecture. In this lecture, we’re going to cover VM instance management. We’ll touch on what <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">management tasks</a> require you to stop an instance, and what happens when you stop it. So let’s jump in.</p>
<p>There will be times when you need to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-stopping-and-starting-vm-instances/">stop and restart a VM instance</a>. When you stop a VM instance, the instance shuts down the guest OS and the instance loses its application state. That said, the instance retains configured persistent disks, internal IPs, and MAC addresses. Basically, what happens when you stop an instance, is that the instance gets reset to its power-on state.</p>
<p>Stopping an instance is necessary when you need to perform many different administrative tasks. For example, if you need to change the machine type, or add and remove attached disks, you’ll need to stop the instance. You’ll also need to stop the instance if you want to change the minimum CPU platform, add or remove GPUs, or basically resize the instance.</p>
<p>It’s important to note that when you stop an instance, the Compute Engine sends an ACPI Power Off signal to the instance itself. This causes the guest operating system to perform a clean shutdown before powering off. Compute Engine will then wait a bit to allow the guest OS to finish shutting down before transitioning the instance to the terminated state.</p>
<p>Although a stopped instance incurs no charges, resources that are attached to the instance will still continue to incur charges. An example of this would be a persistent disk or an external IP address. Both resources would continue to incur charges, even after the instance is stopped, because those resources are still allocated. They don’t go away when the instance is stopped unless you reconfigure the stopped instance to not use those resources, and then delete the resources.</p>
<p>In the next lesson, I’ll show you how to use the portal to stop and start a VM instance. I’ll then show you how to stop and start the instance using gcloud.</p>
<h1 id="DEMO-Stopping-and-Starting-VM-Instances"><a href="#DEMO-Stopping-and-Starting-VM-Instances" class="headerlink" title="DEMO: Stopping and Starting VM Instances"></a>DEMO: Stopping and Starting VM Instances</h1><p>Hi everyone, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">welcome</a> back. In this lesson, I am going to show you how to stop and start a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/managing-a-single-vm-instance/">VM Instance</a> using both the Cloud Console and gcloud. As you can see on your screen, I’m logged in to my console here. To stop a running VM, what I need to do is go to the VM Instances page in my console. So, we’ll go ahead and browse to our instances page here. From here, I simply need to choose the instance that I want to stop. So, we’ll select my VM here, and then after I’ve selected my instance, I can see at the top of the page I have the option to stop my VM. So we go ahead and click Stop, and then we’ll confirm it.</p>
<p>As I mentioned earlier, what happens when I do this is the Compute Engine sends a shutdown signal to the instance itself, which causes the OS to gracefully shut down. Compute Engine then waits a short while for this shutdown to complete, and then it terminates the VM. The terminated instance doesn’t go away; it still exists, complete with its configuration settings and instance metadata. However, it does lose any in-memory data and the virtual machine state itself. Any resources that are attached to this instance remain attached. That includes virtual NICs, persistent discs, etc. Now that my instance is stopped, I can either restart the instance or delete it. I’ll just go ahead and restart it here.</p>
<p>So that’s how you stop and start a VM using the Console. Now, if I wanted to perform the same tasks in Cloud Shell, I can do that by launching Cloud Shell from up top here. With Cloud Shell launched, I can use the <code>gcloud compute instances stop</code> command to stop my instance. To use this command, just type out what you see on the screen here and we’ll go through it right now. We’ll use <code>gcloud compute instances</code>, and then we’ll specify the <code>stop</code> command and then the name of the VM I’m stopping. Now, what I also want to do here is specify the zone that hosts my VM. So we’ll use the <code>--zone</code> flag here, and then we’ll specify <code>us-central1-a, </code>and we’ll go ahead and hit Enter here. And then we can see once I’ve executed this command, the same process begins. The OS gets shut down, and then the instance is terminated. If we wanted to start the VM using gcloud, we’d simply use the <code>start</code> command instead of <code>stop</code>. So that’s how you stop and start VMs using both the Console and gcloud.</p>
<h1 id="DEMO-Editing-a-VM-Configuration"><a href="#DEMO-Editing-a-VM-Configuration" class="headerlink" title="DEMO: Editing a VM Configuration"></a>DEMO: Editing a VM Configuration</h1><p>Hi everyone, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">welcome</a> back. In this lecture, you’re going to learn how to edit a VM configuration. So, let’s jump right in. In a production environment, you may find yourself in a spot where you need to change the machine type of a VM or some other configuration of the instance. In this demonstration, I want to show you how to change the machine type of a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-stopping-and-starting-vm-instances/">stopped instance</a>. </p>
<p>Now, as long as my instance isn’t part of an instance group, I can change the machine type without affecting the instance’s persistent disk data, SSH keys, or other instance configurations like instance metadata. However, if my instance is using an ephemeral external IP address, that IP address might change. Let’s open up my VM here. And to change the machine type here, I need to first stop my instance. I can do this via the console, via the setMachineType method in the API, or via gcloud. For this exercise, I’m going to do this in the console.</p>
<p>So let me go ahead and stop my instance here. So now that my instance is stopped, I can click the Edit button here at the top of the page. Under the Machine configuration section here, I need to choose the new machine type that I want to use. I could also create a custom machine type if I wanted to as well. Now, for this exercise, I’ll just select a new type here, and then I’ll save my changes at the bottom. At this point, I can start my instance back up using the new machine type. And that’s how you stop a VM and then edit its configuration.</p>
<h1 id="DEMO-SSH-to-a-Linux-Instance"><a href="#DEMO-SSH-to-a-Linux-Instance" class="headerlink" title="DEMO: SSH to a Linux Instance"></a>DEMO: SSH to a Linux Instance</h1><p>Hi, everyone, welcome back. Since we just finished working with a Linux VM in our last lesson, I wanted to quickly show you how to connect to such a Linux VM instance using SSH through the GCP console. To SSH to a Linux instance from the console, browse to the VM Instances page, and then from the instances page, click SSH next to the VM you want to connect to.</p>
<p>When you connect to a Linux instance for the first time, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/managing-compute-engine-resources/">Compute Engine</a> generates an SSH key pair for you. This key pair, by default, is added to your project or instance metadata. However, if your account is configured to use OS login, Compute Engine stores the key with your user account. Once you’ve connected to your Linux instance, you can use the terminal to run commands on the instance like you would any other Linux VM. To disconnect from your instance, just use the exit command. And that is how you SSH to a Linux instance through the GCP console <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">on Google Cloud Platform</a>.</p>
<h1 id="DEMO-SSH-to-a-Linux-Instance-via-Gcloud"><a href="#DEMO-SSH-to-a-Linux-Instance-via-Gcloud" class="headerlink" title="DEMO: SSH to a Linux Instance via Gcloud"></a>DEMO: SSH to a Linux Instance via Gcloud</h1><p>Hi, everyone. Now that you know how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-ssh-to-a-linux-instance/">connect to Linux VM via SSH through the console</a>, let me quickly show you how to SSH to a Linux instance via GCloud. To connect to a Linux VM through GCloud, launch the Cloud Shell from the upper right-hand corner of your console. Let me go ahead and expand this here. Now, once you have your console opened up here, what I’m going to do here, I’ll copy the command into the screen here so you can see what it looks like. What you’re going to do is run the GCloud compute command that you see on your screen. When you run this GCloud compute command, what you need to do is specify SSH as your method for connecting, and then what you need to do is use the <code>--project</code> flag and specify the project that holds the VM you’re going to connect to.</p>
<p>In this case, I’m using the cloud academy content team project. You’ll also need to use the <code>--zone</code> flag to specify the zone that hosts your VM as well. And then lastly, specify the name of the VM that you want to connect to. So, let me go ahead and hit enter here to run this command. Now, when I run this command, I’m prompted for a passphrase for the key that is stored for my instance. If this was my first time connecting, GCP would have created a key pair along with a passphrase that I set to protect my connection. Since I’ve already connected to this VM previously, I just need to specify the passphrase that I set up earlier when I first connected to it. So, I’ll go ahead and enter that in here. And as you can see here, I’m now sitting at a command prompt and can <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">manage</a> my VM like any other Linux machine.</p>
<h1 id="Attaching-a-GPU-to-a-New-Instance-and-Installing-CUDA-Libraries"><a href="#Attaching-a-GPU-to-a-New-Instance-and-Installing-CUDA-Libraries" class="headerlink" title="Attaching a GPU to a New Instance and Installing CUDA Libraries"></a>Attaching a GPU to a New Instance and Installing CUDA Libraries</h1><p>Hi, everyone. Welcome back. In this lecture, I’m going to talk a little bit about graphics processing units, or GPUs. Google Compute Engine provides GPUs that you can add to VM instances. These GPUs are typically used to accelerate certain workloads that are run on <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">compute</a> instances. Workloads like data processing and machine learning are the types of workloads that benefit most from the use of GPUs. If you plan to create a compute instance that will leverage a GPU, you need to be sure that you choose which boot disk image that you’re going to use for that instance. You also need to install the appropriate GPU driver on the instance. Some images like the Deep Learning VM images already have GPU drivers pre-installed, and they include packages like TensorFLow and PyTorch. Many public images, however, might require unique GPU drivers. Ultimately, you need to make sure that you identify what drivers you need for your images when leveraging GPUs. </p>
<p>Before you attempt to attach a GPU to an instance, you should check your quotas page to ensure there are enough GPUs available within your project. You can, of course, always request a quota increase if there are not enough available. Whenever you provision an instance that includes a GPU, you need to ensure that you can configure the instance to terminate on host maintenance. This is because an instance with a GPU attached cannot live migrate. It cannot live migrate because the instance, under the covers, is assigned to specific hardware devices. So keep that in mind when working with GPUs. In the next lesson, I’m going to show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/demo-attaching-a-gpu-and-installing-cuda-libraries/">attach a GPU</a> to an existing compute instance. I’ll also show you how to install the necessary CUDA libraries to support the GPU.</p>
<h1 id="DEMO-Attaching-a-GPU-and-Installing-CUDA-Libraries"><a href="#DEMO-Attaching-a-GPU-and-Installing-CUDA-Libraries" class="headerlink" title="DEMO: Attaching a GPU and Installing CUDA Libraries"></a>DEMO: Attaching a GPU and Installing CUDA Libraries</h1><p>Hi, everyone. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">Welcome</a> back. In this lesson, I’m going to demonstrate how to add a GPU to an existing VM instance. So, let’s get started. What I’m going to do here is browse to my VM instance called MyInstance. Now, notice here that my VM instance is currently stopped. I can’t add a GPU to a running instance. Also, before I add a GPU, I need to change its host maintenance setting so that it terminates rather than live migrates. So what I need to do here is click Edit at the top and then scroll down here and set the “on host maintenance” option to “terminate”.</p>
<p>In the Machine configuration section up top here, I need to click on the CPU platform and GPU link. Clicking Add GPU here displays a list of available GPUs. As you can see here, clicking the GPU Type dropdown displays four different types of GPU that are available. I can also select the number of GPUs in the Number of GPUs dropdown. What I’m going to do here is choose the Tesla K80 and select one as the number of GPUs that we’re going to install. At the bottom of the instance page here, I can click Save to apply my changes. What this does is attach the GPU to my VM. I can now start my instance with my GPU attached.</p>
<p>Once this VM comes up, I can RDP to it and install the GPU driver so Windows can use it. To RDP to my VM, I just have to download the RDP file here. I can then use it to connect to my instance. At this point, I’m logged in to my VM. Now, for most driver installs on Windows machines, you’ll obtain drivers by installing the NVIDIA CUDA Toolkit. I should also note that on Windows Server instances like this one, you <em>must</em> install the driver manually. I say this because on other instances you can also script the install. So, to manually install the drivers here, I’m going to download the NVIDIA CUDA Toolkit on this instance where I’ve installed or attached the new GPU. To download this toolkit, I need to open my browser here and browse to the NVIDIA developer site here. So, it’s <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit">developer.nvidia.com&#x2F;cuda-toolkit</a>. And then from here, I’ll download the toolkit and then I’ll select my OS, the architecture, and then my server.</p>
<p>Now, I can also install from network or local. The local downloads the entire package whereas the network package is a smaller installer and what it does is it pulls the information - or the bits - from the internet as needed. So we’ll go ahead and use this option here, and then we’ll download it. Now, with the installer downloaded, I have to launch it just like any other installer, and I just have to work through the wizard here. Now, what the CUDA toolkit is doing here is checking my system for compatibility with the toolkit and the drivers included with it. So what I’ll do here is agree to the licensing agreement, and then we can do an express or a custom installer. I’m just going to do the express here so it overwrites any current display drivers and installs the correct driver for my GPU. </p>
<p>Now, what this CUDA Visual Studio integration screen is telling me is that there are no supported versions of Visual Studio installed on my VM. Some components of the CUDA toolkit require it so what I’m going to do before I continue my installation here, I’m going to click on the Visual Studio link here. We’ll cancel out of this installer and we’ll download Visual Studio here, and we’ll save it. And let’s install this first. And we’ll just work through the wizard here, and this process doesn’t take too long, just a few moments. And we’re just concerned about the core editor here so we’ll click install. We don’t need to install any workloads. And this part of the Visual Studio installation takes a few minutes to complete. It’s not too terrible. And we’re going to uncheck the start after installation here. And we now have our Visual Studio installed so we’ll close this out and we’ll go back into our downloads and relaunch our CUDA install here. </p>
<p>And again we’ll go through the system compatibility check. With our system check complete we can agree to the license agreement again, and then we’ll choose the express option and then the installer will prepare for the installation. Once it finishes preparation it begins the download of the rest of the installation packages that are needed. If you remember back when we downloaded the installer, we downloaded the network-based installer so now it’s pulling down the installation packages it needs. And then at this point, it begins the installation, and we can see here it’s now installing the graphics driver which is what we’re looking for. As you can see, the installation of these CUDA libraries can take quite a while, especially when you’re doing the minimized download. You can speed things up on the backend of this install by completing the full download or the local download, but instead, we chose the network version. </p>
<p>So we’ll let this run and then when it completes we’ll confirm that our graphics driver has been installed correctly, and then we can go ahead and click Next to finish the installation. After the installer finishes, I just need to verify that the GPU driver’s installed correctly. I can do this by looking at the GPU in device manager so let’s pull device manager up. And let’s go over to display adapters here and we can see NVIDIA Tesla K80 is listed. If we look at the properties here, we can see the driver provider is in fact NVIDIA. As long as there are no error icons floating around, I can confirm that everything installed correctly, and with that, my GPU is now functioning on my VM instance.</p>
<h1 id="Working-with-Snapshots"><a href="#Working-with-Snapshots" class="headerlink" title="Working with Snapshots"></a>Working with Snapshots</h1><p>Hi, everyone, and welcome to this lecture. In this lecture, I’m going to explain what snapshots are and what they’re used for. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">On Google Cloud Platform</a> you can use snapshots to backup zonal persistent disks and regional persistent disks. A snapshot is an exact copy of a disk as it exists at a specific point in time and it can even be taken while reads and writes are happening to the disk being snapshotted. </p>
<p>Snapshotting a disk is like stopping the disk head while the disk is in use and then copying all the sectors from the disk. Because snapshots are so easy to use, they’re an appealing backup solution for VM instances. By scheduling snapshots on a regular basis, you can ensure you never have to deal with lost data.</p>
<p>When working with snapshots, it’s important to note that they are incremental and they are automatically compressed. What this means is that the first successful snapshot of a persistent disk is, in fact, a full snapshot. It contains all the data that resides on the persistent disk being snapshotted. However, the second snapshot only contains new data that’s been written to the disk since the first snapshot. The second snapshot will also contain existing data that’s been modified since the first snapshot. Although the second snapshot doesn’t contain any data from the first, the second snapshot <em>does</em> contain pointer references to the first snapshot for any unchanged data that’s contained in the first snapshot.</p>
<p>If you take a third snapshot, that third snapshot will contain any new or changed data since the second snapshot. Instead of including unchanged data from the first two snapshots, the third one will contain pointer references to blocks in the first two snapshots for any unchanged data. This process repeats itself for any subsequent snapshots that you take.</p>
<h1 id="DEMO-Creating-and-Viewing-Snapshots"><a href="#DEMO-Creating-and-Viewing-Snapshots" class="headerlink" title="DEMO: Creating and Viewing Snapshots"></a>DEMO: Creating and Viewing Snapshots</h1><p>Hi, everyone, and welcome to this lesson. In this lesson, I am going to perform a demonstration that shows you how to create a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/working-with-snapshots/">snapshot</a> of a regional persistent disk in the Google Cloud Console. So, let’s jump right in.</p>
<p>On the screen here, you’ll see that I’m logged in to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">my GCP console</a>. To create a snapshot, I need to browse to Compute Engine and then to Snapshots. From this Snapshots page, I can begin the process by clicking Create Snapshot at the top here. I need to give my snapshot a name. If I hover over the question mark here, it tells me the name that I use must start with a lower case letter and it must be followed up with up to 62 additional lower case letters, numbers or hyphens. The name that I use cannot end in a hyphen. I’ll call this snapshot “mysnapshot”. The description here is optional, so I’ll just leave it blank for this exercise.</p>
<p>Using the Source Disk dropdown here, I can choose the disk that I want to snapshot. I’m going to snapshot myvm here. In this Location section here, I need to tell GCP where to store my snapshot. I also have to decide if I want to store it in one region or if I want to make the snapshot multi-region. A region is a specific geographical place, like London, for example. A multi-region is a large geographical area, like the United States, for example, that contains two or more geographic places. If I choose multi-region here, my snapshot becomes geo-redundant. I’ll leave these options at their defaults here and, as a result, my snapshot is going to be stored in the same location as my source disk that I’m snapshotting.</p>
<p>Under Labels here, I can add a label if I want to. You would typically use labels to organize your environment. I’m not going to bother here. At this point, I can click Create to create my snapshot. Now obviously, my snapshot can take a little while to create, so we’ll let this complete. After my snapshot is created, I can click on it from my list of snapshots. In here I can view the details of my snapshot.</p>
<h1 id="Working-with-Images"><a href="#Working-with-Images" class="headerlink" title="Working with Images"></a>Working with Images</h1><p>Hi, everyone, and welcome to this lecture. In this lecture, I’m going to explain what images are and what they’re used for. An image provides the base operating environment for applications to run on a Compute instance. You can use images to archive application versions for disaster recovery, and even to roll back an instance. After registering an image, the image can be used to create one or more exact replicas of the original disk. You can use operating system images to create boot disks for <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">Compute instances</a>. </p>
<p>There are two types of images available. They include public images and custom images. Public images are provided and maintained by Google, open-source communities, and even some other third-party vendors. All GCP projects have access to public images so they can be used to create instances. There are many pre-configured public images available in Compute Engine that have compatible Linux operating systems and Windows operating systems. These systems images can be used to create and start instances.</p>
<p>When you use an image, Compute Engine will create a persistent boot disk for each instance that you spin up, using your chosen image. By default, the boot disk that is created will be the same size as the image that was used. In situations where you need a persistent boot disk that’s larger than the image used, you can always resize the boot disk later. While most public images are available at no additional cost, some premium images will result in additional costs to your instances. </p>
<p>Custom images are available only to your project. Custom images can be created from boot disks and even from other images. After creating a custom image, you can use it to create an instance. You can use a custom image to import a boot disk image from an on-prem machine into Compute Engine. You can also use custom images to import virtual disks from existing virtual machines that are running in your environment. A custom image that’s imported into Compute Engine will not add any additional cost to your instances. However, it will incur an image storage charge, as long as you keep the custom image in your project.</p>
<h1 id="DEMO-Creating-and-Using-Images"><a href="#DEMO-Creating-and-Using-Images" class="headerlink" title="DEMO: Creating and Using Images"></a>DEMO: Creating and Using Images</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">Welcome</a> back. In this demonstration, I’m going to show you how to create an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/working-with-images/">image</a> from the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/working-with-snapshots/">snapshot</a> that we took earlier.</p>
<p>To create my image, I need to browse to Images within Compute Engine. This Images page that I’m taken to displays all existing images. I can begin the image creation process by clicking Create Image at the top of the page here. On the Create an Image page, I need to provide a name for my image, so I’ll call this “myimage”. From this Source dropdown box here, I need to specify the source for my image. This can be a persistent disk, a snapshot, another image, a cloud storage file, or even a virtual disk like a VHD or VMDK file. I’m going to choose the snapshot option, and then specify the snapshot that I created earlier.</p>
<p>Now, as was the case with the snapshot, I have to specify a location, and whether I want my image to be regional or multi-regional. I’ll leave these at their defaults for this exercise. Doing this causes Compute Engine to store my image in the multi-region closest to my image’s source location. The optional Family field here lets me specify the family for my image. Specifying a family causes the latest, non-deprecated image in the family to be used. I’m not using a family here, so I’ll leave this blank. I can also provide an optional description for my image as well. I’ll leave this blank, and I can also label it if I wish to. </p>
<p>Under this encryption section, GCP tells me that the data is encrypted automatically. However, I have a few different options for my encryption key management. I can accept the default and let Google manage the key, I can specify the customer-managed key option, or I can choose the customer-supplied key option. If I select customer-managed, I need to select a customer-managed key that already exists. Choosing the customer-supplied option requires me to provide an actual key. For this exercise, I’ll use the first option to allow Google to handle things. With all my choices configured, I can now click Create to create my image. Once my image is created, I can view its details from the Images page here. And that is how you create an image from a snapshot using the Google Cloud Platform console.</p>
<h1 id="Instance-Groups"><a href="#Instance-Groups" class="headerlink" title="Instance Groups"></a>Instance Groups</h1><p>Hi, everyone, and welcome to this lecture. In this lecture, I’m going to talk about instance groups. An instance group is actually a collection of VM instances. The key advantage of an instance group, however, is the ability to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">manage</a> all of the instances as a single entity. Google Compute Engine offers two kinds of VM instance groups. They include managed instance groups, or MIGs, and unmanaged instance groups.</p>
<p>Using a managed instance group allows you to run applications on several identically configured virtual machines. Additionally, a managed instance group offers several automated services such as autoscaling, auto-healing, regional deployment, and auto updating. By leveraging the many automated services that are offered by a managed instance group, you can make workload scalable and highly available.</p>
<p>Typically you’d want to use a managed instance group for stateless workloads, like maybe a website frontend. Managed instance groups are also a good choice for high-performance workloads and batch workloads, such as image processing from a queue. It’s important to note that each VM instance within a managed instance group is created from an instance template. If you prefer - or need - to load balance apps across a fleet of virtual machines that you need to manage yourself, you might want to consider unmanaged instance groups.</p>
<p>An unmanaged instance group contains multiple heterogeneous VM instances. You can, as needed, add and remove instances from the group. As you would expect, an unmanaged instance group does not offer any of the features that a managed instance group provides. You get no autoscaling, no auto-healing, and no rolling update support. As a rule of thumb, you should only consider using unmanaged instance groups if you need to apply load balancing to groups of heterogeneous instances, or if you need to manage the instances within the group yourself.</p>
<h1 id="Instance-Templates"><a href="#Instance-Templates" class="headerlink" title="Instance Templates"></a>Instance Templates</h1><p>Hi, everyone, and welcome to this lecture. In this lecture, we’re going to cover instance templates. Instance templates are used to create VM instances and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">manage</a> instance groups. When you create an instance template, what you’re really doing is defining the machine type, the boot disk image, the container image, if necessary, any labels, and any other properties that will be used to deploy your instance or <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/instance-groups/">instance group</a>.</p>
<p>Once the instance template settings are defined, you can use the template to create either a managed instance group or to create individual VM instances. The purpose of an instance template is to facilitate the creation of identically configured instances. That being the case, it’s not possible to update or change an existing instance template once it’s been created. If you need to make changes to a configuration, you need to create a new instance template.</p>
<p>It’s important to note that instance templates are global resources; they are not bound to a specific zone nor to a specific region. However, when you create an instance template, you may need to specify some zonal resources. This, in essence, restricts the template to whatever zone in which those zonal resources reside. For example, if an instance template includes a persistent disk from the US-Central-1A zone, you won’t be able to use that instance template in any other zone since the disk exists only in zone US-Central-1A.</p>
<p>Join me in the next lesson where I’ll show you how to create and assign an instance template.</p>
<h1 id="DEMO-Create-and-Assign-an-Instance-Template"><a href="#DEMO-Create-and-Assign-an-Instance-Template" class="headerlink" title="DEMO: Create and Assign an Instance Template"></a>DEMO: Create and Assign an Instance Template</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/introduction/">Welcome</a> back and welcome to this demonstration. You can create <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/instance-templates/">instance templates</a> through the Google Cloud Platform Console, the gcloud compute tool or through the API. In this demonstration, I am going to show you how to create an instance template via the console.</p>
<p>To create my instance template, I need to browse to Compute Engine and then to Instance Templates. So, let’s go ahead and browse here. This Instance Templates page shows all existing instance templates that have been created. To begin the creation of my instance template, I just have to click Create Instance Template up here at the top. From this Create an instance template page, I can provide the specifics for my template. I can either accept the default values or I can provide specifics as necessary. </p>
<p>In a default configuration, the machine type is set to n-1standard-1 and the boot disc image is set to the latest Debian image. The disk itself is a standard persistent disk that’s 10GB in size. If I click down here on “Management, security, disks, network, sole tenancy” and look at the network settings, I can see here that the image connects to the default network and is assigned an ephemeral IP address. </p>
<p>If we bounce over to Disks, here, I can see that I can add more disks to my instance template, if necessary. Other optional settings are accessed via the Management tab, the Security tab and via the Sole Tenancy tab. If I click Equivalent REST at the bottom of the page here, I can see the REST requests body which includes the JSON representation of my instance template. If I click “command line” here, it shows me how to create my template via the gcloud command line using parameters I’ve chosen. I can even click “run in Cloud Shell” here to create my template in Cloud Shell using these parameters.</p>
<p>For this exercise though I’m just going to close this out and then I’m going to click Create down here at the bottom to create my instance template. With my instance template created here, I can now view it in this instance templates page. I can also click the ellipses over here at the right, and then from here I can either create a VM from my instance template or create an instance group from my instance template. What I’ll do here is just show you what happens when I click Create VM from my instance template.</p>
<p>We can see here we have the source template. And then we can configure our VM with whatever settings we need, or we can just leave the settings as they are, as they were configured in the instance template. And then again we just go through, click Create to spin up our VM based on the instance template that we created.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>I hope you’ve enjoyed learning how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/instance-templates/">manage networking and compute resources on Google Cloud Platform</a>. Let’s review what you’ve learned.</p>
<p>We started things off by covering the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/managing-network-resources/">management of network resources</a> where you learned how to add a subnet to an existing VPC and how to expand a CIDR block subnet. You also learned how to reserve static internal and external IP addresses.</p>
<p>Next, you learned about the different <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/working-with-management-interfaces/">management interfaces</a>, including Cloud Console, Cloud Shell, and Cloud SDK.</p>
<p>In the second half of this course, you learned how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/managing-a-single-vm-instance/">manage VM instances</a> and how to connect to them via SSH and RDP. As we progressed through this course, you learned how to attach a GPU to an instance and how to install the CUDA libraries. We also covered how to view information about current running VM inventory.</p>
<p>Later in this course, you learned about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/working-with-snapshots/">snapshots</a>. You also learned how to create images and how to view those <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/working-with-images/">images</a>. </p>
<p>Wrapping things up, you learned how to work with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/instance-groups/">instance groups</a> and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-networking-and-compute-resources-on-google-cloud-platform/instance-templates/">instance templates</a>. </p>
<p>By now you should have a full understanding of how to manage network resources and Compute Engine resources on Google Cloud Platform. To learn more about managing network and compute resources on Google Cloud Platform, you can, and should, read Google’s documentation. Be sure to also watch for new courses on Cloud Academy, because we’re always publishing new ones. Be sure to give this course a rating, and if you have any questions or comments, please let us know. Thanks for watching and happy learning.</p>
<h1 id="19DEMO-Attaching-a-GPU-and-Installing-CUDA-Libraries"><a href="#19DEMO-Attaching-a-GPU-and-Installing-CUDA-Libraries" class="headerlink" title="19DEMO: Attaching a GPU and Installing CUDA Libraries"></a>19<strong>DEMO: Attaching a GPU and Installing CUDA Libraries</strong></h1><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit">Toolkit download</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-14/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-14/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-14</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:54" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:54-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:54:06" itemprop="dateModified" datetime="2022-11-22T20:54:06-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-14/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-14/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Planning-and-Configuring-a-Google-Cloud-Platform-Solution-13/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Planning-and-Configuring-a-Google-Cloud-Platform-Solution-13/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Planning-and-Configuring-a-Google-Cloud-Platform-Solution-13</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:53" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:53-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:50:44" itemprop="dateModified" datetime="2022-11-22T20:50:44-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Planning-and-Configuring-a-Google-Cloud-Platform-Solution-13/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Planning-and-Configuring-a-Google-Cloud-Platform-Solution-13/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Greetings. Welcome to Cloud Academy’s course on configuring a <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a> solution. I’m delighted you’ve decided to join me on what is bound to be an educational and exciting adventure into the world of Google Cloud. First, let me begin by introducing myself. My name is Jonathan, I’m one of the course developers with Cloud Academy. I worked professionally as a technical consultant specializing in DevOps data engineering and security. Now, long ago in another life, I was actually a public school teacher so I love education and teaching and I am thrilled to be teaching again, only now teaching technology.</p>
<p>This course is designed to be very practical. It’s meant for technology professionals, developers data architects, CTOs, that kind of thing, and the goal is really to help them get a solid understanding of how to build infrastructure using Google Cloud services. This course will also help you to prepare for the Google Associate Cloud Engineer Certification exam.</p>
<p>Now, to earn this certificate you need a good general knowledge of GCP Google Cloud Platform: the different solutions, how to configure them. You’ll also need to be able to use both the GCP web console and the command line.</p>
<p>Now, this course will focus mainly on the console since it’s more of an introductory course but we will also do some work with the command line tools in the video demonstrations. I want to stress, though, that this course will not cover everything that you need for the Associate Cloud Engineer exam. There are five core areas of study in that exam and as you can see from the exam guide, this course is meant to focus on area 2: Planning and Configuring a Google Cloud Solution.</p>
<p>So then, you’re probably wondering what are the prerequisites for a course like this. What do you need to already know to be successful in this class? Well, the answer is not that much. You should have some general knowledge of computers and the concept of the cloud, you know, you should know what a data center is, what is a virtual machine, and understand just the basic concept of hosting, you know, hosting infrastructure as a service. You don’t need to be a programmer but it definitely will help if you have some knowledge of software development. You know, this will help you to appreciate what each of the GCP products actually does. I also recommend having some basic networking knowledge, things like HTTP and SSL. Knowing what those are will help you to understand the GCP networking products better. So basically, if you’ve been working around technology for a while, you’re probably fine. If you’re a moderately tech-savvy adult, you should be fine.</p>
<p>So let’s get more specific. What are the actual learning objectives for this course? So in this course, there are three main takeaways related to GCP. One: the student will learn to deploy and configure <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-one-overview/">Google Cloud compute resources</a> and understand the differences between each service. Two: the student will learn to deploy and configure <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-two-overview/">Google Cloud storage resources</a> and understand the differences between each service, and then, three: the student will learn to deploy and configure <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-three-overview/">Google Cloud network resources</a> and understand the differences between each service. And you notice a pattern there obviously. In this course, we’re focusing on three things— compute, storage, network—all in the context of Google Cloud. The lesson content is therefore divided into three sections corresponding to these topics. Now, if you master these three fields deeply, computing, storage, and networking, then you will have all the tools you need to be, you know, comfortable as an infrastructure developer on GCP.</p>
<p>One last thing though before we start, I want to encourage everyone to leave feedback. Email <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a> if you have any questions, comments, suggestions, concerns, we always appreciate people taking the time to do that. Now, without further ado, let’s get <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-one-overview/">started</a>.</p>
<h1 id="Section-1-Overview"><a href="#Section-1-Overview" class="headerlink" title="Section 1 Overview"></a>Section 1 Overview</h1><p>In this first section of the course, we’re going to focus on <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">Google Cloud</a> compute resources. Now, by <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction-to-google-cloud-compute-options/">compute</a> we mean virtual machines that can run workloads in the cloud at scale. If you’ve ever worked with Amazon you may know EC2, their VM service, or digital ocean, their concept is droplets. If you’re familiar with either of these then you already know a little bit about cloud compute.</p>
<p>So with <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google</a> Cloud you have three main approaches to compute: App Engine, Compute Engine, and Kubernetes Engine. We will explain how each of these work in the next lesson and then we’ll give some advice to help you know which is best for different scenarios. And then after that, we’ll follow up with two shorter lessons digging into price estimation planning and then the virtual machine types and then the section will end with our demo, a video demo, of how to actually use all these things. So if you’re ready, let’s get this party started.</p>
<h1 id="Introduction-to-Google-Cloud-Compute-Options"><a href="#Introduction-to-Google-Cloud-Compute-Options" class="headerlink" title="Introduction to Google Cloud Compute Options"></a>Introduction to Google Cloud Compute Options</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-one-overview/">Cloud Compute</a> is one of <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google</a>‘s core offerings for businesses looking to run their apps in the cloud. It’s your foundation. The hardware and CPU cycles needed to actually run your software. Now, under the compute umbrella are a few different specific services and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">configuration</a> options and products. For our purposes, though we are going to focus on three main offerings—Compute Engine, App Engine, and Kubernetes Engine— and will briefly mention Cloud Functions and Cloud Run.</p>
<p>I’ll start by giving you a quick high-level distinction between these three main offerings. So Compute Engine is for deploying virtual machines or VMs much like Amazon EC2. App Engine is a serverless compute product for running code without thinking about the ends and then Kubernetes Engine is for, you guessed it, running Kubernetes workloads for customers that need container orchestration.</p>
<p>So let’s dig in a bit more on each service, starting with Compute Engine. As I’ve said, it is analogous to Amazon’s EC2 but let’s get a little more specific for folks who may not know AWS. Compute Engine is for deploying virtual machines. You can create a variety of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/compute-virtual-machine-types/">virtual machine types</a> with different amounts of CPU, storage, memory, network bandwidth, you can create VMs in different physical regions as Google Cloud has data centers all around the world and then regions have names denoting their location like us-west1. Each region can have multiple zones like A and B so a full location name for a compute resource per VM could be something like us-west1-c which denotes it’s both the region and the code. So a region is usually a part of a country like US West or US East.</p>
<p>Now, Compute Engine offers a variety of predefined machine types with different operating systems and configurations to match different workloads. There’s also the possibility of creating custom machine types if needed, if you need a specific hardware CPU memory setup. Billing for these virtual machines is done by usage per second so you only pay for exactly what you use and there are also discounts for sustained usage and sort of a commitment-based, committed pay upfront sort of commitment-based long-running jobs and the lesson after this will cover machine types in more detail and that lesson will also cover pricing in more depth.</p>
<p>Now let’s switch over and talk a little bit about App Engine. App Engine is designed to let you deploy software without managing individual servers. Instead, you pick an environment and a runtime. Runtimes are language-specific minimal container configurations, they’re runtimes for things like Python 2.7, Python 3, Java, PHP, Node, Ruby, Go. The app environment is the underlying hardware and when it comes to picking an environment there are two types of environments you can choose. There’s the standard environment and there’s the flexible environment. So the App Engine standard environment only supports very specific language runtimes, you can’t modify the environment after the fact, you can choose an instance class which will allocate a certain range of CPU and memory and auto scaling ability, however, you can’t SSH into the instances. It’s more fixed. In essence, you can think of the standard environment like a sandbox: it spins up quickly and it can auto scale pretty effectively but the main trade-off is limited ability to alter the environment over time. And then, by contrast, there is the flexible App Engine environment. Now, this does let you modify the runtime via Docker files. So if you know Docker files, you know they’re pretty flexible, you can do a lot there, you can set up SSH access, you can run pretty much any programming language, you can access other Google Cloud resources and Compute Engine instances within the network. So in short, the flexible environment does less for you but it gives you more control.</p>
<p>And then the third main Google Cloud compute service is GKE: Google Kubernetes Engine. If you’re already running or planning to run a Kubernetes application, GKE is by far one of the best ways to do it, as Kubernetes was actually originally designed by Google, so it’s a first-class integration. GKE platform gives you a very powerful API for managing a Kubernetes cluster. You can do this in the console or via CLI tools, you can quickly get information about the cluster, change config, scale pods, alter the access controls, do all kinds of administrative tasks. Kubernetes, in general, is known for being one of the most powerful container orchestration frameworks available but it is also known for being fairly complex, tough to debug. GKE removes much of this pain. With GKE you do almost everything in the console with a mouse, you get fantastic documentation, you get tutorials, you get Quick Start guides, and you get very good instrumentation and logging. GKE runs on top of Compute Engine, it’s using VM instances as GKE nodes. Node is the Kubernetes term for a single compute resource. It’s very easy to get GKE to intermingle with Compute Engine resources, if necessary. If part of your application is in Kubernetes and part of it isn’t, if they’re all within Google Cloud, it’s not a problem to get them to work together. Now, actually teaching Kubernetes itself is out of scope for this course but we will spend a little time covering how to create a cluster in the demo, where we’ll touch on it briefly.</p>
<p>Now finally, I want to mention two other lightweight GCP compute options that are available for specialized use cases and these are GCP Cloud Functions and GCP Cloud Run. Cloud Functions are analogous to the Amazon Lambda service. They let you define single purpose standalone functions that respond to specific events. Now, this is again a serverless compute option and it can work well for circumstances where all you want to do is run some specific function in response to an event that it’s watching, so kind of a targeted use case there.</p>
<p>Now, Cloud Run is also a serverless option like Cloud Functions, but the difference here is that instead of running just code you create containers. With Cloud Run, you invoke stateless containers using HTTP requests or you can have them be generated in response to specifically monitored events. Now, this is a very simple way of creating container-based workloads with all considerations of hardware abstracted away. You don’t think about even an environment like with App Engine. Now, as of the creation of this course, Cloud Run is still in beta so we’re not going to spend a lot of time on it but it is definitely worth checking out.</p>
<p>So Compute Engine, App Engine, Kubernetes Engine, your three main purposes. How do I know which to select when working on a Google Cloud application? It’s probably easiest to start by thinking about GKE. If you’re already using Kubernetes locally or with another cloud provider, then I highly recommend migrating to GKE, creating a cluster, and provisioning needed storage and compute resources take seconds and you should be able to reuse much of your existing configuration. Compute Engine and App Engine are great options for everyone outside of the Kubernetes ecosystem.</p>
<p>When it comes to these two services, the real question is how much control do you need? Maybe you like to have root access to your machines by default or maybe you’re migrating from EC2 or maybe you have an unusual environment not easily supported by App Engine. In the base case, I would recommend starting with Google Compute Engine. App Engine is generally a better choice for an earlier stage project, particularly if you can use the standard environment with its various language runtimes. The App Engine flexible environment is more of a niche solution for scenarios where you know for whatever reason you don’t want to use Compute Engine but you don’t get enough control from the standard environment.</p>
<p>So, that’s it. At a pretty high level you now know enough about GCP compute offerings to be dangerous. You can differentiate GKE, Compute Engine, App Engine, and you should know a little bit about Cloud Run and Cloud Functions. You should be able to pick what is best for a given project. Very cool stuff. So in the next lesson, we’ll take a deeper dive in VM instance types, we’ll learn about cost and hardware optimization as we tour Compute Engine’s menu of options. See you there.</p>
<h1 id="Compute-Virtual-Machine-Types"><a href="#Compute-Virtual-Machine-Types" class="headerlink" title="Compute Virtual Machine Types"></a>Compute Virtual Machine Types</h1><p>Now, in this lesson, we’re going to go over the various types of virtual machines you can launch in <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction-to-google-cloud-compute-options/">Google Cloud Compute Engine</a>. Our emphasis here will be on cost savings and usage, so as we discussed in the previous section, Cloud Compute offers a range of instance types based upon our apps’ resource needs, we can also choose from a variety of Linux operating system flavors as well as Windows.</p>
<p>Now, as far as hardware goes, there are three main families of instance types. There are compute-optimized, memory-optimized, and sole tenant. Compute-optimized instances offer the highest performance per core with a range of options going up to instances with four hundred and sixteen virtual CPUs. Now, memory-optimized instances are for memory-intensive workloads. You can get up to several thousand gigs of memory in a single VM if needed, and then finally, there are sole tenant offerings that isolate your VMs and workloads on their own physical servers. So, see the documentation for a more detailed list of the exact instance type names but these are the three basic categories.</p>
<p>Now, by default, your Cloud Compute instances are billed based on uptime. The cost is calculated per second and the price is largely based on the instance type, however, region also plays a factor. So for example, an instance with a lot of memory will cost more than one with very little. Instances in us-east4 Virginia might cost a little more than instances in us-east1, which is South Carolina. Usually, these region price differences are fairly small but it’s good to be aware of them. </p>
<p>Now, so far we’ve been talking about standard, on-demand instances that are created upon request. There are actually two other types of instances that we need to consider to fully understand Cloud Compute, and these are custom machine types and preemptable VMs. So, let’s start with the former. Custom machine types. Now, even though GCP, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a>, it offers a wide variety of Linux operating systems and Windows VM types, sometimes we want to get really specific about memory and CPU configuration for our workload. So for example, we may find that GCP’s high-memory instance types have more CPU than we need or vice versa. Maybe we need a lot of CPU and little memory. With the custom machine type option you can actually specify the exact amount of memory and the exact amount of virtual CPUs, provided it’s an even number. You need an even number, of course. Now, you can do this with a single command. Here’s an example here at gcloud compute instances create my VM you just do - - custom CPU - - custom memory.</p>
<p>There are many different operating systems that are compatible with the custom machine type API. You can pick Debian, CentOS, OpenSUSE, Ubuntu. Windows is also an option, whether via the console or the command-line. Custom machine types are straightforward to set up and launch for workloads that need them. Now, we should talk a bit about preemptable VMs, these are very interesting, these are actually short-lived VM instances that run for up to 24 hours at a time. Now the upside, because they’re so short-lived, is that they are extremely cheap—to 80 percent less than a regular VM.</p>
<p>Now, the downside here is that they are not suitable for any kind of fault-tolerant workload. With preemptable instances, you don’t know when they might die. They’re guaranteed to shut down within 24 hours, you can create a managed instance group of preemptable VMs if you want to try to keep a certain number up and running, however, the thing is, preemptable VMs come from excess GCP Compute capacity so because of that, there’s no guarantee that a certain number of preemptable VMs will be available, particularly if you need a specific type.</p>
<p>So, you know, for example, you might have a managed instance group of 30 preemptable VMs and maybe they’ll run for a while, but if there’s not sufficient capacity in that GCP region you may be down to only 20 instances for a while, you might just lose ten of them and because of the inability to guarantee availability, preemptable VMs are not appropriate for any use case that requires consistent uptime or stability. They’re great for batch processing, short jobs that can tolerate instances coming and going. And also note that preemptable instances are available for predefined instances and for the custom machine types that we talked about a minute ago.</p>
<p>By combining a custom machine type with a preemptable VM you can really optimize your costs for fault-tolerant jobs. Preemptable VMs are not the only method for controlling costs, there are actually two other really important discount options available on GCP. These are sustained use discounts and committed use discounts. Now, the latter, as the name implies (committed use), is a discount for paying for a certain amount of usage time upfront. This is similar to like Amazon reserved instances. With committed use contracts, you can pay upfront for one year or three years of compute service and get a discount of 50 to 70% of the cost and actually when I say pay upfront, you don’t actually pay the full year or three years cost right away, the billing is actually still done monthly so you don’t have to worry about some huge you know three years of compute paying upfront. You pay monthly and, you know, if you stop using the instance after six months, you’ll still get billed for the full year, but it’s still a really great option if you can actually plan ahead with your infrastructure and you know that something’s gonna run for a year or two years this is the way to save money and so because, you know, you get a 50 to 70% discount.</p>
<p>So on top of that, there’s also something called a sustained use discount. Sustained use discounts, these kick in automatically if you run a VM instance for a certain percentage of time over the course of a month. So, for example, you can get a price cut of around 10% if you run an instance for more than 25 percent of the month and if you run that same instance for 100 percent of the month with no break, you can get up to a 30 percent discount in the cost.</p>
<p>Now, I’m using a little bit of imprecise language, this is kind of rough amounts because the exact discount varies a lot by instance type, but in general, the more you run your instances the bigger the discount. Sustained use discounts are really great because you don’t have to think about them at all. They apply to custom machine types as well and they kick in automatically. Now, the only exception, the only instances that do not get sustained use discounts are App Engine flexible environment instances and also Cloud Dataflow VMs. Very specific, if you use Cloud Dataflow it’s not applicable for sustained use discounts. So with this combination of preemptable VMs with sustained use discounts with committed use discounts, you have three really good ways to save money on GCP.</p>
<p>Consider your workload to identify which is best for you, you only need compute instances for very very small periods of time, if so, definitely go with the preemptable VMs. Very, very cheap. If, by contrast, you know for certain that your instances have to run for a year or longer, then the committed user discounts can cut your bill in half, no additional upfront cost and if you can be certain of either of these scenarios or well actually no, if you can’t be certain of either of these scenarios, well then take solace in the fact that there are automatic sustained use discounts that kick in, you know, without any effort or decision-making on your end. So we will stop there.</p>
<p>You should now have a good grounding of GCP instance types and cost optimization. Congrats. Now, to help you save even more, we’ll go over the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/gcp-price-calculator/">GCP price calculator tool</a> in the next lesson. See you there!</p>
<h1 id="GCP-Price-Calculator"><a href="#GCP-Price-Calculator" class="headerlink" title="GCP Price Calculator"></a>GCP Price Calculator</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a> has probably the best price planning tool available compared to any other cloud provider and I’m not being paid to say that. The reason we’re doing a separate lesson on pricing is largely because their price calculator is really good. It’s very flexible and it’s a very good place to start when <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">planning a GCP project</a>.</p>
<p>So the first thing you’ll notice about the calculator web app is that it breaks out everything by product. You can select everything from Compute Engine to App Engine, storage products like Datastore, everything in between, just about every single GCP product is selectable and for each one you can completely describe what sort of component you want to add to your system.</p>
<p>So, for example, we can go to the Compute Engine tab, we can go in there, we can select an instance type, region, instance count, time commitment, several other options, and then after that, once we have a thorough detailed view of our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction-to-google-cloud-compute-options/">compute architecture</a>, we click Add to estimate and we immediately get a monthly cost.</p>
<p>Now, the cool thing is you can do this for several services or multiple times for a single product. So you can actually name each component which is kind of cool. So you can have a breakdown with something like dev environment storage and production environment storage, where you have multiple instances of storage products or the same storage product. I’m gonna add like test environment GKE, and see each component broken down by price in the tool with a grand total at the bottom.</p>
<p>Now, estimates, once they’re generated, you can save them by clicking save estimate, and this will generate a link that you can share with people you know your team or whoever you need to. There’s also an email estimate button that you will, that, you know, as you guessed it, it’ll email it to an address of your choice. These are two nice little quality of life features that help you share and preserve estimates. It’s particularly nice if you have a really complex architecture that you’re proposing and you need to share with a lot of different people a lot of specifically configured products.</p>
<p>One other handy thing about this GCP pricing tool is that Google Cloud actually exposes an API for querying pricing data and on top of that, there’s actually a simplified web page as well if you just want to see a text list of prices. So for the API this is really good for tooling. For example, if you want to create a script that generates reports or tracks prices, you can use the API along with the Google Cloud CLI tools and there or the libraries and it’ll just you can it’ll do that for you.</p>
<p>The GCP SKU web page, by contrast, is really just a simple search page with a list of prices by service. So this is helpful if you just want to get a general sense or show it to someone, basic prices by service. So in the demo video, we’re gonna go a little bit over the pricing calculator. It’s fairly intuitive but we’ll show you how to run through a couple of simple scenarios, generate a few different estimates for different use cases. And that’s basically it.</p>
<p>Now you have some knowledge about pricing tools, we’re ready to go into our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/planning-compute-resources-demo/">practical demo</a>. It’ll be a lot of fun, we’ll see you there.</p>
<h1 id="Planning-Compute-Resources-Demo"><a href="#Planning-Compute-Resources-Demo" class="headerlink" title="Planning Compute Resources Demo"></a>Planning Compute Resources Demo</h1><p>Welcome to the first of three practical demonstrations on how to use <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a>. In this first demo, we’re going to do a few things to get you familiar with GCP. Generally, we’ll start by quickly going over the web console and the Cloud Shell, we’ll show how to set up your first project. These will these things will help you get a general sense of how to interact with GCP services and then after that, we’ll take a quick look at the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/gcp-price-calculator/">GCP pricing tool</a>, we’ll run a few estimates for a few services, and then lastly, we’ll take a closer look specifically at Compute services. There we’ll take a look at App Engine, Kubernetes Engine, Compute Engine, and even run through the process of launching a VM.</p>
<p>So, to get started, you can go over to <a target="_blank" rel="noopener" href="https://console.cloud.google.com/">console.cloud.google.com</a> or just <a target="_blank" rel="noopener" href="https://cloud.google.com/">cloud.google.com</a>. If you don’t already have a Google Cloud account, you can set one up from there. All you need is a Google account of some kind like a Gmail and it can just click through you can set one up very quickly and you can even get up to three hundred dollars worth of free service.</p>
<p>So here we’re just going to go ahead and click on Console and let it load in a sec and we can see all of our different GCP services here. We can kind of scroll around and see the different options here. Now, one important thing to note is we can’t actually do anything with these services until they have a project to work with, so if we click on this, it’s going to say create a project, it’s going to put you through that first.</p>
<p>GCP expects everything to be contained within a project so we can go ahead and create the project, we’ll give it a name, you know, you know, we’ll just call it TestProject, Create, and this will generate it for us, and projects, these live within an organization. So GCP also expects a name for your organization. We’re just going to leave the default for that and if we give it a moment it will create.</p>
<p>So we can see here the dashboard will come up after the project is created, it should only take a few seconds, and then we can see basically TestProject with an ID. Now, for most of our demos, we’re going to use the GCP web console. As you can see, it’s got a pretty nice UI, it’s very easy to navigate, however, there are situations where we might want to use a command-line. And now there are two ways we can use a terminal with all of our GCP services.</p>
<p>One method is to set up the Google command-line tools on our local machine, like a MacBook or a Linux desktop, but whatever we use for development work and this requires installing the tools and setting up the credentials to authenticate to GCP. We’re not going to go through that here, we’ll include <a target="_blank" rel="noopener" href="https://cloud.google.com/sdk">links</a> with instructions if you want to do things that way.</p>
<p>There is an easier method, though. The easier method for using a shell is to just use GCP’s built-in Cloud Shell tool. It’s right here in the top right of the page. Now, you just click on this once and we can hop right into a shell environment that will have all of our necessary g-cloud tools and credentials pre-configured. So yeah, just give that a second to provision. So yeah, it might take a few minutes the very first time you use the shell, the Cloud Shell, it has to spin up an instance for it to run, but eventually, you’ll get this nice little prompt right here and you can see it’s like any terminal environment. It has our g-cloud tools already installed, so this is just kind of the default output there. You can look around a little bit, queue out of it, but this is, this allows us to do, you know, run scripts to basically do anything we would want to do in a shell environment without having to worry about setting things up on a local machine. So very helpful.</p>
<p>Now, before we start, actually spinning up any resources or creating anything we might want to get a sense of what it will cost us. So let’s take a quick look at the pricing tool. Now, remember, we don’t actually have to be logged in to GCP to use this. We actually just go to this link here: <a target="_blank" rel="noopener" href="https://cloud.google.com/pricing">cloud.google.com&#x2F;pricing</a>. But you know, it’s useful, of course, to have the pricing and the console open at the same time, so we can kind of check things out before we create anything.</p>
<p>So we can just go here to Calculators and let’s run through a very basic scenario. Let’s say, for example, I want to create a single VM. So here we have our tool and you know, we’re going to start with Compute Engine. That’s already selected. And then it’s going to ask us to fill out some basic information, so a number of instances, we’ll say one. What are these instances for? It’s really just labeling, so we’ll say tests. Operating system, you know, we can be more specific, but we’ll stick with one of the free ones here, Free Debian CentOS Core Ubuntu. Machine class, we’re just going to go with regular. Here is where you can also select preemptable if you want to get that as your free estimate. Machine family, so as we mentioned, there are compute-optimized, memory-optimized, and general. We’ll stick with general, we’ll just stick with first-generation, we’ll go with a micro. Really all the defaults here. And once we’re good, we can just click Add to estimate and it pops right out total estimated cost here per month. So pretty straightforward.</p>
<p>Now, let’s say I want to add something to this estimate. Let’s say, okay I want to add a database of some kind. So we go up here, we look for the relevant service, let’s say we want to do cloud SQL. So we go here, you know, we still have this estimate as well, it lets us aggregate everything. But let’s say we want just the defaults here, we want one cloud SQL instance. You know, there’s some configuration we could change here but the only thing it really needs, you know, you can select in a high availability in location. We’re gonna select all the defaults. The only thing we absolutely have to put in here is a minimum storage amount SSD, we’re gonna say 10 gigabytes and keep all the other defaults. Hours running per day, you know, days per week. We’ll add that to the estimate and we can see this is a little more expensive than the VM, but yeah, 13.25 per month. So this is your price estimation tool, it’s, as I said, it’s pretty straightforward, pretty intuitive to use. So that’s the pricing tool.</p>
<p>Now, we’re going to go ahead and try to create a virtual server. So, here in the list of services, we can see the compute section here. We’ve got App Engine, Compute Engine, and Kubernetes Engine, we have Cloud Functions and Cloud Run, more lightweight abstracted services there at the bottom, and what we’re gonna do is create an instance inside of Compute Engine. Now, you can see just to just to give you a sense of what it looks like, Kubernetes engine here, we can click on it and we can create a cluster. So this is, if you’re familiar with the Kubernetes paradigm, this will generate your cluster and will create the nodes on top of which your container orchestration will run your cluster.</p>
<p>If we go back, we can pick App Engine as well, which is our serverless solution and here the tutorial it takes you through creating an application. If you start going through it, it’ll ask for a region and then eventually it’ll ask you to select a language, runtime, and the type of environment. As we mentioned, there’s the standard and there’s the flexible. So that’s App Engine. We’re not going to make anything with those but what we’ll do is we’ll go here into Compute Engine and we’ll go through the simplest case creating a single virtual machine.</p>
<p>So we just go through our QuickStart guide, we can click on Create instance. It’s gonna ask for some basic information about it, we’re gonna again stick with all of our defaults we’ll just call it Instance-1 in us-central, general-purpose, first-generation, one vCPU, 3.7 gigs of memory, very, very lightweight, again, all defaults, and we’ll just click Create. And just like that, we have our first virtual instance up and running and of course, we can, you know, do this with the shell as well and we can be a lot more specific with the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">configuration</a>, but as you can see, just getting a Compute resource up and running is pretty straightforward.</p>
<p>So, I think that’s where we will stop with this demo. In the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-two-overview/">later sections</a>, we’ll go into more depth on storage setup and networking, but with this, you should have a general sense of how to get started with GCP, how to get into the console, set up your project, and interact with the compute services. So I hope this has been beneficial.</p>
<h1 id="Section-2-Overview"><a href="#Section-2-Overview" class="headerlink" title="Section 2 Overview"></a>Section 2 Overview</h1><p>Welcome to section two of our course on <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">configuring a Google Cloud Platform solution</a>. In the previous <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/planning-compute-resources-demo/">section</a>, you learned all about GCP’s various compute offerings. However, it’s likely that you’ll need to do more than just computation in your application. You’ll probably want to store data somewhere for later retrieval that is what this section is all about: storage. <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">GCP</a> offers a number of storage options from managed SQL to column stores to in-memory-only caching systems.</p>
<p>In the next lesson, we’ll do a broad survey of each of these <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction-to-google-cloud-storage-options/">options</a>, then in the lesson after that, we’ll offer some insight into <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/choosing-the-right-storage-option/">how to choose the right storage solution</a> for a given use case. So without further ado, let’s dig in.</p>
<h1 id="Introduction-to-Google-Cloud-Storage-Options"><a href="#Introduction-to-Google-Cloud-Storage-Options" class="headerlink" title="Introduction to Google Cloud Storage Options"></a>Introduction to Google Cloud Storage Options</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud</a> gives you a lot of ways to store your data. There are a variety of managed services that handle infrastructure, scaling, backups, all of that for you, and then there are more configurable approaches for people that want to directly administer everything.</p>
<p>Probably the easiest way to break it down is to make a distinction here between storage and databases. So when we talk about databases, we usually mean data stored with a certain structure. The database has storage, of course, but the key thing is the software for accessing it. Storage is the more generic term. Google Cloud has five distinct offerings for simple storage without any concern for structure or database software.</p>
<p>So as mentioned, the first is VM-attached persistent disk storage. Now, this is analogous to an Amazon EBS volume. This is a block of HDD or SSD storage that’s attached to individual Compute Engine instances. Now, this is a great solution if you’re doing a model at the gap on a single server and you need all of your data in one place and possibly a database engine running on that instance. Two really nice features about GCP’s persistent disk storage is zero downtime scalability and automatic encryption. So you get the peace of mind of knowing that your data is secure at rest, it’s encrypted, and it’s very easy to add more storage to an instance without interrupting anything.</p>
<p>Now, GCP also has an NFS storage product called Cloud Filestore. This is similar to persistent disk, you can mount NFS instances on two VMs for applications that need a file system interface. This is a type of NAS, or network-attached storage. So the critical thing to consider here is latency. Filestore offers two different performance tiers: there’s a standard performance tier and premium. So the main difference here is that the premium tier offers substantially higher read&#x2F;write throughput, so be sure to check the specs here very carefully, we’ll add a little chart you can look at and, you know, there are many applications, of course, that can be bottlenecked by NAS systems.</p>
<p>So the three remaining GCP storage products are all very similar, they are all managed object storage systems similar to Amazon S3. The difference between these three products concerns the frequency of access of the things that you’re storing. So the names of these products in order of greatest flexibility, the highest price, they are Cloud Storage, Cloud Storage Nearline, and Cloud Storage Coldline.</p>
<p>So all of these products, the Cloud Storage, they work using buckets—that’s the standard approach. We create a bucket in the console or using the command line and in these buckets we can store any arbitrary data we want and again like S3, we can set all kinds of security configuration on the buckets. We can integrate them with our applications, we can make them publicly available, we can grant access so that things can read and write from Cloud Storage. The only thing different about the Nearline and the Coldline versions of Cloud Storage are the act access frequency SLA and the cost. So Nearline is for data that is accessed relatively rarely, say, once a month, and because of that, it’s much cheaper than just the regular cloud storage. Now, Coldline is really for archiving. This is, by far, the cheapest Cloud Storage you can get but with its access SLA, it is really only for data that’s accessed maybe once per year, if ever. So Coldline is a really good place to dump log files, compliance records, noisy metrics, you know, debug files, redundant backups, other data that might only be relevant in a really unusual kind of disaster scenario.</p>
<p>So that, those are the basic you know raw storage methods for VM instances and for other CCP service. You know, you could use Filestore or persistent disk if you need to attach storage directly to a server. And now you should know a little more about Cloud Storage as a solution for managed storage buckets. Now, for most applications though we’re going to need some structure to our data. We need more than just a bucket. We want to run SQL-like queries we want an SQL-like interface or some sort of query language, we want a proper database solution. And for that, GCP offers five distinct products again.</p>
<p>So, let’s start with the more popular offering, and that would be Cloud SQL is analogous to Amazon RDS. Again, sorry with all the Amazon comparisons but it’s the easiest way if you’re familiar with it. So what cloud SQL is you create database instances similar to VM instances in your account in specific regions. There are actually a few different flavors of Cloud SQL, three different ones. There’s a MySQL one, a PostgreSQL one, and a vanilla SQL type. So this is just depending on the type of SQL engine you wanna use, based on your preferred SQL implementation. All versions though include the same basic features: automatic encryption of data at rest, seamless scalability for adding read replicas, and multi-region support. You can add more CPU and more memory for tougher workloads, all of that is supported.</p>
<p>Now, Cloud SQL is not the only relational database offering for GCP, there’s also something called Cloud Spanner and Cloud Spanner is actually a very interesting product. It’s a very interesting SQL solution in that it tries to give you all the benefits of a traditional relational database without any of the trade-offs demanded by massive scale. So if you’ve ever studied cap theorem, CAP, you might know the old saying that there’s consistency, there’s availability, and partition tolerance and you can only get two of those things. You have to pick two. So if you want consistency and availability, you have to sacrifice partition tolerance. If you want partition tolerance and availability, you have to sacrifice consistency, so on and so forth. Cloud Spanner is a product that tries to break this rule and give you all three and it does this by throwing Hardware at the problem. So the trade-off is price.</p>
<p>So let me be a little more specific. With cloud spanner basically you get high availability, strong consistency, and the ability to scale horizontally. And this last point is accomplished by adding nodes. So nodes are compute resources that can be <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">configured</a> as part of your Cloud Spanner setup. What they do is they add CPU and RAM resources to your spanner database and they allow you to ensure strong performance even across many geographic regions. So with Cloud Spanner, you can have a massive amount of traffic, literally thousands of writes and reads per second, with strong consistency guarantees. You get, you know, classic relational acid guarantees and guaranteed availability across the globe with guaranteed performance using an SQL-like interface.</p>
<p>So basically, you have your cake and eat it too, you have everything. Now, the trade-off, as we said, is price. Generating the necessary amount of nodes and replicas will not be cheap. Now, check the GCP pricing tool here for more details. Here’s a quick example just for reference. As you can see, the small, for a small workload, a single node in a single region, the spanner deployment is actually an order of magnitude more expensive than Cloud SQL. In general, Cloud SQL is going to be much cheaper and is the more standard approach for a managed SQL solution in GCP. Cloud Spanner is really for more unique use cases. Very unusual use cases. So be sure to look into that documentation there. </p>
<p>Now, GCP offers also two distinct NoSQL databases, one is called BigTable and one is called Firestore. Now, the former, BigTable, is a wide column database and the latter, Firestore, is a document database. So if you have worked with like Cassandra or MongoDB, CouchDB, maybe you are familiar with NoSQL systems, you might know a little bit about, kind of the use cases and the problems they’re are meant to solve. Column databases tend to be great for more write-heavy workloads, you know, such as scan data, time series data. Document databases are often used for JSON or unstructured text. So again, these are for particular use cases. </p>
<p>And then finally, we have the Memorystore and Firebase. The memory store is simply a managed Redis service. This is for storing data in memory on customizable nodes. It’s generally used as a caching layer to speed up read performance, kind of like ElastiCache again in AWS, however, it can also be used as a datastore in its own right, if you want to have all of your data just in memory. Firebase database is a real-time syncing database that stores data as JSON documents. It’s used often in mobile applications that need to keep client data in sync, so Google acquired Firebase, as you may know, several years ago and tightly integrated the Firebase database product with GCP. This is distinct from Firestore, so you know, be sure to look at the documentation there:</p>
<p><a target="_blank" rel="noopener" href="https://cloud.google.com/docs/#section-24">https://cloud.google.com/docs/#section-24</a></p>
<p><a target="_blank" rel="noopener" href="https://cloud.google.com/storage/docs/storage-classes">https://cloud.google.com/storage/docs/storage-classes</a></p>
<p>If you’re familiar with Firebase, this is the GCP version of it and it’s definitely a great option if you’re already using Firebase.</p>
<p>So, okay, that’s it. Well that was a lot and thankfully we’re done, we’ve covered all of the main GCP data storage options. You should have a good understanding of each but maybe not enough to make strong recommendations for a specific use case. So, in our next lesson, we’ll cover that exact issue. We will talk very specifically about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/choosing-the-right-storage-option/">which storage technology you should choose</a>. We’ll talk about them generally, and we’ll relate them to specific GCP use cases. So when you’re ready, we’ll see you there.</p>
<h1 id="Choosing-the-Right-Storage-Option"><a href="#Choosing-the-Right-Storage-Option" class="headerlink" title="Choosing the Right Storage Option"></a>Choosing the Right Storage Option</h1><p>Now, choosing the right <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction-to-google-cloud-storage-options/">data storage</a> technology is absolutely critical for developing a performant scalable cloud application. Many great app ideas and startups have struggled due to bottlenecks and data management issues caused by using the wrong database.</p>
<p>So our focus here is database, not pure storage, per se. We’re not going to worry about GCP persistent disk or Filestore. Google Cloud Storage service can actually be used as an application data layer or database if you want but it’s generally not as good as a proper database that structures data in a predictable way. So we’re going to focus on GCPs dedicated managed database offerings.</p>
<p>So, when choosing a storage technology, there are really four critical issues to keep in mind. One: what is the data model? Two: what are my access patterns? Three: what is the expected amount of data now and into the foreseeable future? And then four: are there any external constraints around cost, compliance, data location, etc.?</p>
<p>So, data model, that’s our first consideration because it’s most likely to cause suffering if we get this wrong. If we get the data model wrong, we’re gonna suffer later on trying to fix it. You know, one example of that if you opt for a technology like Cassandra, column database, and you need to support a variety of complex arbitrary read queries on your data, you’re gonna have a bad time, it just isn’t meant for that. So deciding between relational versus NoSQL, that’s a good place to start. If you’re dealing with, again, time-series data, scan data, JSON documents, binary blobs, there are a number of technologies particularly suited for those use cases. You know, you might want to look at Cassandra, MongoDB and then in <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud</a>, there are versions of that. BigTable, for example.</p>
<p>Now, consider also access patterns here and here we have to consider several different factors. Do we expect to mostly write a lot of data without doing many reads or perhaps the inverse of that, perhaps something more balanced? Do we have a strict SLA that requires very fast data retrieval? Do we need to support access from many different regions? Do we need some sort of caching strategy, either through hardware and database options or an additional technology like Redis?</p>
<p>So this question of access patterns is very, very important. And then, the third consideration is data volume and growth. Now here, we need to consider the expected data size both at inception and over time, and this could be a very hard thing to predict, so it’s good practice to overestimate. So, for example, if you’re starting with say 10 gigs of production data and expect it to grow to 100 gigs in a year, that’s your expectation. Then you want to plan for at least one terabyte of data or more, and this will ensure that you’re ready for unexpected usage spikes or application behavior, some, you know, spiking log files, something like that. We need to account for data volume and growth, both for budgeting purposes and for our operational concerns. We need to know how difficult it is also to increase storage capacity. You know, with some solutions it’s easier to increase storage than others.</p>
<p>And then finally, we need to think about, you know, the non-technical factors, regulatory issues, legal requirements around data, and of course, budget. So in some countries, for sensitive industries that deal with personal data, there may be requirements that data be encrypted and stored within a specific geographic region. These issues need to be accounted for upfront because again that can create huge operational headaches and even get a company into legal trouble if they’re ignored.</p>
<p>So now, how do we take these four considerations and then apply them to the GCP storage technologies we’ve introduced?</p>
<p>So let’s start with data model. GCP CloudSQL is a great option if you need a robust, managed, relational database service. You can, of course, just set up your own database instances on a Compute Engine VM, but then you don’t get the same strong uptime guarantees, built-in security, backups, upgradability, it’s a trade-off of more fine-grained control in exchange for more operational overhead. And then of course, Cloud Spanner is another great SQL option if you need global scalability and can tolerate a little bit more latency and cost.</p>
<p>Now, if you’re in the NoSQL world, then you have a couple of things to consider in GCP. You have memory store which is a Redis service for low latency and very fast in-memory storage, depending on your use case. It may be your main storage engine or it could be a caching layer in your architecture. And then you have Cloud Firestore as your document DB option and BigTable, which is your column-based storage offering. So, consider your own app’s data model and determine which of these make sense as a good fit.</p>
<p>And then we have to factor in access patterns. Now, we should be able to narrow down our range of choices by considering data model first and then thinking about whether our workload is going to be read-heavy, write-heavy, balanced, or something else. So we need to consider what sort of queries we need to support, what latency can we tolerate, whether or not we need to support multiple geographic regions, so for example, there’s the case of CloudSQL versus Cloud Spanner. The latter is a clear choice if we need global support access and the former is a clear choice if you want the lowest possible latency particularly at the regional level.</p>
<p>And then, the third consideration, data volume, well, for GCP products we might think about an in-memory solution like Memorystore. This might be super fast but it can be expensive and painful to scale if our data grows by several orders of magnitude. And the best way to make this decision is to use the GCP pricing tool of course and get estimates for different storage technologies at very large amounts of data and this should help future-proof your choice from a cost perspective. You also need to consider the difficulty of increasing storage. Cloud Spanner and BigTable, in particular, are very easy to grow if necessary.</p>
<p>So this last consideration, more nuanced to compliance, regulatory issues, budgeting. These non-technical issues can cause major disruptions if you don’t account for them, so the nice thing about GCP storage solutions, in general, is they’re very flexible. For example, all of these solutions support multi-region in different ways. All of them support access control encryption, detailed logging, and auditing. If you’re in a sensitive industry like healthcare and finance, it’s still a good idea to do a more thorough deep dive on the documentation just for, you know, whichever solution might seem like the best fit.</p>
<p>So that concludes the second and final lesson in our section on GCP storage. You should now have a solid understanding of the major offerings and should be able to determine which is likely the best for your use case. Congrats on making it this far. In the last part of this section, we’ll do a demo, we’ll walk through <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/planning-storage-resources-demo/">planning an implementation of a storage solution</a> in the web console. It’ll be a blast. See you there.</p>
<h1 id="Planning-Storage-Resources-Demo"><a href="#Planning-Storage-Resources-Demo" class="headerlink" title="Planning Storage Resources Demo"></a>Planning Storage Resources Demo</h1><p>Welcome to the second practical demonstration on using <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a> services. This video will focus on using <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/choosing-the-right-storage-option/">GCP storage products</a> with the web console and the command line. We’re going to do a couple of things. First, we’ll just do a quick survey of the different products in the console, so you can kind of see what it looks like. Then we’ll actually go ahead and create some storage. First, we’ll create cloud storage buckets using the web console and the command line, and then after that, we’ll go ahead and create a Cloud SQL database instance and configure it with some specific settings.</p>
<p>So first, let’s just look around the console generally. You can see here on the left- hand side, we have the storage section. So we have BigTable, we have Datastore and Firestore, and Filestore, SQL, Spanner, Memorystore. Here in storage, this is for all of the cloud storage products, including Nearline and Coldline and the different, you know, depending on archival and access patterns. And then we have a Filestore, which is kind of the NAS version of that, a network-attached storage version of that. So this is basically where things are, you can click around a little bit and see, you know, for example, BigTable, you know, we don’t have any instances running now but you can run through the Create Instance wizard to actually see what that looks like. We can do that with all of them. I mean, they’re all pretty straightforward here in the console. We’re not going to create everything now but we can kind of see how things look.</p>
<p>So let’s move on. Ok, so now let’s go ahead and actually create a sample bucket in Cloud Storage using the command line. Now, we’re going to use the Cloud Shell. You click on this icon here in the top right to get it to work. I already have it running. Be aware, again, the first time you click on it, it might take some time to come up.</p>
<p>So as you recall, you have your tools already installed in this little environment that uses new gcloud command line. We should get some output there. And what we’re actually going to use is <code>gsutil</code>, the other command line tool. And so, to create a bucket, we’re gonna do <code>gsutil</code> make bucket and then we have to give it a URL for the bucket. We’ll do <code>gs://</code> we’ll just call it <code>cool-cloudacademy-bucket</code>. And if I’m entering that command it’ll go ahead and it’ll create our storage bucket, and we can go into the storage UI here. Oh sorry, that’s SQL, we want to go to Cloud Storage here and we should be able to see our bucket right there, cool-cloudacademy-bucket.</p>
<p>Now, this is one way to create a bucket. You’ll see here that because we didn’t add any arguments, it created a bucket with all the defaults. So by default it’s multiple regions in the United States, you know, public access is per object, there’s no lifecycle enable, there’s a whole lot of default things here, and so what we might want to do is change some of that and to show you some of the different options you have, what I’m gonna do is use the web console and create another bucket.</p>
<p>So you go here, we click Create a bucket, and we’re going to give it a name. We’ll call it cool-cloudacademy-bucket2, and then, there’s a number of options we can add. So there’s some estimates here, we can put for a storage size of data retrieval, if we want to worry about that, click continue. We can decide if we want multi-region or single region. We can decide if we want to do Nearline or Coldline for longer-term archival. Access control model on how, what permissions we want to set. We’re gonna stick with most of the defaults here but really just showing all the options here. We can add labels, tags, essentially. Then, when we’re done we just click Create and once again, we’ll see the bucket come right up.</p>
<p>So go to our storage dashboard and then it is: cool bucket2. And now the last thing we’re gonna do is we’re gonna create an actual database instance in the console using the Cloud SQL dashboard, so we go into Storage here. A lot of different options for storage as mentioned. We just click on SQL and we’re gonna create an instance, there’s an option here as well to migrate data. You see again one of the first choices we make is do we want to use MySQL or PostgreSQL and we’ll go for this will go with MySQL as our flavor. And then, once this comes up, we have some options here. Sample, we’ll just call it sample1. We can set a root password, you know something bad, don’t do that. Some regions, zones, our database version, and then once we’re ready, just click Create, and just like that, we will have our instance. We have a database instance ready to go. So the instance ID will come up and some other details, but it is really, really quite simple. We can do this same thing with the command line. But now you should have a general understanding of how to create storage and databases using Google Cloud using the console or the command line. So thanks for sticking around.</p>
<h1 id="Section-3-Overview"><a href="#Section-3-Overview" class="headerlink" title="Section 3 Overview"></a>Section 3 Overview</h1><p>It’s all well and good to have virtual servers running your applications with top-of-the-line <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/planning-storage-resources-demo/">storage and database solutions</a> backing them. Unfortunately, none of that will matter without the right network setup. Your network is the glue that makes everything work together. We’re talking things like DNS configuration, secure data transfer, load balancing, access control, VPCs, peering, and overall, traffic optimization for a geographically distributed user base.</p>
<p>Now, fortunately, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">GCP</a> offers a plethora of networking services to ensure your application has optimal performance and security. In this section, we’ll start by reviewing the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction-to-gcp-network-resources/">core networking products</a>, we’ll have separate lessons on <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/load-balancing-with-gcp/">load balancing</a> and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/cloud-dns-in-gcp/">DNS</a>, since those are particularly crucial and we’ll also talk about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/resource-geolocation/">resource geolocation</a> in its own short lesson, since multi-region support is one of GCPs strongest characteristics. So if you’re ready, let’s begin.</p>
<h1 id="Introduction-to-GCP-Network-Resources"><a href="#Introduction-to-GCP-Network-Resources" class="headerlink" title="Introduction to GCP Network Resources"></a>Introduction to GCP Network Resources</h1><p>In this section, we’re going to briefly introduce each of the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-three-overview/">GCP networking services</a>. Networking is a complex topic, there’s a lot of room for error, if we try to not think about it or make a lot of random assumptions, but fortunately, GCP’s solutions are pretty intuitive. Now, it’s out of scope for us to explain in minute detail computer networking concepts so this section is not meant to go in-depth on the tooling or configuration for any of the products, we’re just going to give a basic overview on the problems that each service is meant to solve. In the following lessons and the demo video, we’ll do a deeper dive on the products most critical to setting up an application and passing the certification exam.</p>
<p>So, we’ll start by talking about GCP Cloud DNS and Cloud Load Balancing. Now, the former is the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">GCP solution</a> for configuring DNS records for domains that you own. It’s not a domain registrar, that’s actually a separate <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google</a> product. You can register domains with Google, but the Cloud DNS, rather, is a means for associating a domain name like, you know, mycoolapp.com with the actual servers or endpoints hosting the content. So it’s analogous to Amazon route 53 and AWS or any other domain name servicing company. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/load-balancing-with-gcp/">GCP Cloud Load Balancing</a> is the traffic routing layer. Now, there are many types of GCP load balancers to serve different use cases, such as internal traffic, external internet-facing traffic, SSL offloading, HTTP requests, TCP UDP requests, both Cloud DNS and load balancing, we’re going to cover these in more depth in their own lessons but that’s just the basic for those two.</p>
<p>Now, the next thing we want to cover are GCP’s Network Peering services. Now, there are a few different ones here, so let’s go through this carefully. Peering, in case you aren’t familiar, is simply the process of connecting two separate networks so that they can exchange traffic. And there are many business cases where you may need to connect GCP traffic to an internal corporate network or a customer’s private data center or some other distinct endpoint. So the two main solutions for this are GCP Direct Peering and Carrier Peering. Now, the former works by creating a dedicated connection between your private network of choice and Google’s Edge Network, and the latter, Carrier Peering, works through a service provider like Softbank or level 3 or Verizon.</p>
<p>So in the case of Carrier Peering, you have a service provider acting as a kind of black box or middleman, and there are a few specific enterprise-level use cases where this can be really necessary. For example, for security purposes, a company might want to expose only a portion of their network to the public internet for accessing GCP services, however, configuring and maintaining a DMZ, basically, a perimeter network, that might be too much overhead, particularly for smaller companies, so instead the company might just go to their service provider, say, Verizon, and ask them to create a dedicated link for traffic to GCP. This is the problem that carrier peering can solve.</p>
<p>Now, for direct connections to GCP, Direct Peering is a logical solution. This creates a peering connection between your internet internal network and Google. Now, there’s another version of this similar that’s even more direct, this is called Dedicated Interconnect. Dedicated Interconnect Solution. This is similar to direct peering but it goes further by creating literally a dedicated physical connection. You set up a colocation facility and with routing hardware that matches GCPs requirements, you create a dedicated wire connection from your systems to Google’s. Very useful if you need an air gap or you need physical control over the infrastructure for whatever reason. Now, on top of this, there’s actually another fourth option for situations where you need the dedicated physical connection but your company’s data center, for whatever reason, cannot access a GCP colocation facility. And this is a somewhat niche scenario, it’s covered by a product called GCP Partner Interconnect and this is again similar to the Carrier Peering solution in that it works through a third-party service provider. So essentially, you select a service provider from a list of GCP partners, there’s a <a target="_blank" rel="noopener" href="https://cloud.google.com/interconnect/docs/how-to/carrier-peering#service_providers">link</a>, we can show you some of the examples, and you use their direct connection to GCP. So you’re relying on both GCP and another company’s hardware which may potentially create additional concerns around performance and security, however, it may still be your best option if you already have a trusted third party ISP and you still need that dedicated physical connection to GCP. So to review, Direct Peering, Carrier Peering, Direct Interconnect, and Partner Interconnect. Make sure to keep in mind the basic differences, especially if you’re responsible for your business’s network or data management.</p>
<p>Now let’s move on to two important network security solutions and that would be Cloud VPN and Virtual Private Cloud. Now, the former is a virtual private network service designed to protect traffic traveling between GCP and some other endpoint. Like any typical VPN, this is a good way to ensure data coming from the public Internet is secure before it hits your GCP systems. GCP offers both classic and high availability VPN types, the latter being more restrictive in its configuration but promising a better SLA.</p>
<p>Cloud VPN is a simple way of connecting an outside network to GCP endpoints, including a Google Cloud Virtual Private Cloud, or VPC, so let’s review that. What is Google Cloud VPC or GCP VPC? Kind of hard to say; quite a mouthful. Anyway, GCP VPC, what that is is a virtual private cloud service within Google Cloud. The virtual private cloud is simply an isolated subset of a larger network with firewalls to block unauthorized access. AWS has the same basic product: VPC. Generally, a VPC is the key unit of measure for defining your application’s network resources. So, for example, a single instance of your app or your database, it might live inside of a single VPC, which is usually within a single data center or zone.</p>
<p>And what’s unique actually about Google Cloud VPCs is that they can actually span multiple geographic regions, so you can have a single VPC with instances on the United States west coast and instances on the east coast, and they can still talk to each other without accessing the public internet. This isn’t the only cool thing also in with Google Cloud VPCs, you get a built-in integration with Cloud VPN and very easy peering between VPCs and the ability to expand the subnet range of available IP addresses within a VPC with zero downtime. So if you have ever had to deal with any of this stuff, if you’ve ever had to manually, you know, expand subnet ranges in a less full-featured cloud provider, then you’ll appreciate a lot of these quality of life enhancements. And suffice to say, Google Cloud VPC will give you the tools you need to manage your app’s private cloud configuration.</p>
<p>So let’s get into some of the more niche networking services, stuff you probably won’t need to worry about right away. So we’re going to talk about Cloud CDN, Traffic Director, and Cloud Armor. Now, Cloud CDN is a content delivery network which maybe you guessed if you know the acronym CDN. It’s meant to do one thing really well: cache content near your end-users for faster performance. It does this by working with Cloud Load Balancer to cache various types of content: images, video, text, any sort of media at one of its dozens of edge site locations. HTTPS&#x2F; SSL support is built-in, so you don’t need to worry about performance overhead from encrypted traffic. You know, this is a really great solution if low latency access to content is a critical requirement for your app, given the number of edge site locations they have around the globe.</p>
<p>Now, traffic director. This is a network traffic management tool specifically for service mesh architectures. Now, the term service mesh may not be familiar to everyone so, you know, basic summary: a service mesh is an additional software infrastructure layer that controls service to service communication. This is only relevant when you have a microservice cloud architecture with many different small software services communicating with each other. Tools like Lyft’s Envoy Proxy are an example of a service mesh product. GCP traffic director is meant to work on top of that for even easier service traffic management and load balancing. Again, somewhat niche, not something most people are going to worry about at first, however, as a microservice app grows and becomes orders of magnitude more complex, the surface mesh paradigm can become a very useful approach and GCP Traffic Director makes it easy to manage.</p>
<p>And then finally, you have Cloud Armor. This is a DDoS prevention system and this can be really the difference between life and death for a company. Depending on your threat model, if you’re a company that’s worried about DDoS attacks, this is something that you’re going to want to look at. You may or may not, it may or may not be a major concern for your infrastructure but if they are, then Cloud Armor is the way to go. It works directly with TCP load balancing, it offers a way to automatically mitigate suspicious load spikes, you can configure IP range-based blocking, even configure blocks for specific geographic regions if you need to.</p>
<p>So, OK, wow, that was a lot. Congratulations on making it through. You now know all about the basic networking with GCP or at least you know enough to sound credible. In the following three lessons, we’re going to dig in on three of the core elements of networking in a cloud provider that would be load balancing, DNS, and multi-region support. Can’t wait to see you there.</p>
<h1 id="Load-Balancing-with-GCP"><a href="#Load-Balancing-with-GCP" class="headerlink" title="Load Balancing with GCP"></a>Load Balancing with GCP</h1><p>Distributing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction-to-gcp-network-resources/">network</a> load properly is one of the most important architectural challenges when designing a cloud-based application. Poor choices regarding load balancing can lead to runaway costs, poor app performance, security risks, and a number of other business hazards.</p>
<p>So for this reason, it’s worth focusing on GCP’s load balancing catalog in its own short lesson. There are exactly six specific types of load balancers, each designed for a particular type of traffic workload. Three of the six are designed for global load distribution and three are regional. We will start by considering the three global load balancer types.</p>
<p>The three global types are the HTTP Load Balancer, the SSL Proxy, and the TCP Proxy. The first, is as the name suggests, meant for HTTP or HTTPS traffic. This is perhaps the most common type of load balancer for a typical web application. It’s internet-facing, meaning it takes external traffic on port 80 or port 8080 or 443 for HTTPS, and then it routes that traffic to your back-end services.</p>
<p>The other two global types—the TCP Proxy and the SSL Proxy—are for more targeted use cases. Specifically, the SSL Proxy is meant for SSL offloading. Now, SSL offloading, in case you don’t know, this is the practice of decrypting SSL traffic before sending it to some other endpoint. Now, this is an optimization, it’s a method for reducing the strain on back-end systems by ensuring that they don’t have to spend CPU cycles decrypting secure traffic. Now, the TCP proxy load balancer is for TCP connections that are not SSL and not HTTP. This is another global internet-facing load balancer, it supports ipv6 traffic, but one detail to note is that the TCP proxy load balancer will not preserve client IP addresses, so be aware of that if that’s necessary.</p>
<p>Now, the three regional load balances are ideal for situations where you need explicit control over where TLS connections are terminated, possibly for legal or security reasons. Your options here are the networked TCP&#x2F;UDP load balancer and then the internal HTTP load balancer and the internal TCP&#x2F;UDP load balancer. Now, the netWORK TCP&#x2F;UDP load balancer is the only one of these three that is meant for external traffic. There are two specific scenarios where this is your best choice over the other external load balancers we described earlier. One scenario is you need to load balance UDP traffic. If you, if you’re doing UDP traffic, this is the way to go. And two, the other scenario is that your load balancing TCP traffic and you need to preserve client IP addresses. So if either of those things are important to you, then you’ll want to look at this option.</p>
<p>Now, the internal TCP&#x2F;UDP and the internal HTTP load balancers are comparable to their global counterparts, their global external counterparts. They handle the same basic use cases. One is meant for a TCP&#x2F;UDP traffic, the other is meant for HTTP traffic or HTTP requests. The only difference is that they are situated within a private network, they cannot accept requests direct from the public Internet, they are instead meant for routing traffic between microservices or within a VPC, for example, or from one Compute Engine instance to some other back-end service or endpoint within GCP. You can, of course, combine multiple types of load balancers in your architecture. For example, you could start with a global external load balancer that will first route a client request that could eventually hit an internal load balancer that targets the appropriate service—this is one approach.</p>
<p>Now, to make this a little easier to understand, there’s a handy chart that <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">GCP</a> gives us that gives you everything you need to know to decide which load balancer is best for you. And going from left to right, we can see the basic questions we need to ask ourselves about our traffic. Do we need to accept HTTP connections? Do we need SSL offloading? Do we need to preserve client IDs? You know, by going through this flow chart we could determine which of the six load balancer types best matches our needs.</p>
<p>So that’s all you need to know at a fairly high level in order to pick the right little balancer for your situation. Next lesson, we’re going to talk about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/resource-geolocation/">resource geolocation</a> and it’s going to be a ton of fun. See you there.</p>
<h1 id="Resource-Geolocation"><a href="#Resource-Geolocation" class="headerlink" title="Resource Geolocation"></a>Resource Geolocation</h1><p>Now that we’ve covered the bulk of GCP’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction-to-gcp-network-resources/">network services</a> and reviewed <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/load-balancing-with-gcp/">load balancing</a> options, I think it’s a good opportunity to take a step back and think about our <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud</a> architecture from a global view. How can we optimize our GCP services in terms of their physical location? One of the best practices around mapping out where our GCP resources will live, ensuring optimal availability, performance, and cost. So in this short lesson, we’ll offer some guidance and best practices that should serve both at work and on test day, if you’re aiming for certification.</p>
<p>Now, probably the best place to start is with Google Cloud’s global location page. This will tell you which services are available in what region. So obviously, if you already know you need a specific GCP product, it’s a good idea to ensure that it’s available in the region you want. So, for example, as of the recording of this course, GCP BigQuery and Firestore are not available in us-west Oregon region. So plan accordingly if that’s what you need.</p>
<p>The general rule is that for latency purposes, we want to have our cloud infrastructure situated near our user base. So if the vast majority of your users are in the EU, it makes sense to use one of GCP’s European data centers, perhaps Zurich or Frankfurt. Sure your app will still be usable by people outside of Europe but it might be a little bit slower if they have to cross the ocean in order to hit your data centers.</p>
<p>Now, this gets harder to optimize, of course, if you have a global user base. If traffic is coming and going all around the world, then you need to think about how to distribute infrastructure in a cost-effective way. Now, the earlier lessons on GCP storage products should give you enough guidance to know which services are the best fit for a global or multi-region use case. As far as networking goes, hopefully, the previous lesson on load balancing offered enough insight to know which GCP load balancer offers the best situation, the best offering for a complex worldwide traffic routing. GCP’s Cloud CDN is another important piece of the puzzle, as it can serve as a kind of global cache for frequently requested content.</p>
<p>Now, finally, when you’re considering resource geolocation, we, of course, can’t forget about security. In general, GCP is good for this, but things like, you know, with things like default encryption and a lot of logging for forensic and performance analysis, however, at the network level, we have to think more specifically about connectivity and access control. A good practice is to use a VPC, virtual private clouds. Remember, they can span multiple regions so you can have one VPC hitting the data centers in different parts of the world so that your back-end services can be optimized, and make sure that your requests are properly authenticated coming through a load balancer. If you need some direct access to part of the VPC, consider using GCP’s VPN offering to lock down that connection.</p>
<p>So those are some basic tips about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">planning</a> for a distributed architecture. We could definitely go deeper than this for more unique scenarios but what we have covered here are the main principles to ensure you know enough to get started. Now, we’re ready to move on to our last lesson in this section before the demo, that’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/cloud-dns-in-gcp/">Cloud DNS</a>. When you’re ready, we’ll see you there.</p>
<h1 id="Cloud-DNS-in-GCP"><a href="#Cloud-DNS-in-GCP" class="headerlink" title="Cloud DNS in GCP"></a>Cloud DNS in GCP</h1><p>In this final instructive lesson, we’re going to go in-depth on GCP’s Cloud DNS service. DNS servicing is a critical make-or-break component of any web-facing application, so we want to make sure you understand GCP’s approach.</p>
<p>So if you’ve worked with DNS providers before like Route 53 or maybe GoDaddy or something like that, then you understand the basic purpose. DNS providers let you publish domain names and route traffic to specific servers and infrastructure. So if we have a website running on a random IP address and we want to connect it to our domain coolsite.com, a DNS provider can create the necessary records to do that. Now, this is, of course, distinct from a domain name registrar service. Cloud DNS is not meant for purchasing domain names, but you can do that through Google as we mentioned, domains.google.com lets you buy domains. You can also buy domains from any other service including Route 53 or GoDaddy and then configure them using Google Cloud DNS. The DNS provider is actually about doing something with a domain name not buying it.</p>
<p>So Google Cloud DNS. How do we actually start doing things with it? Well, once we have a domain name registered and we’re ready to work with it, we start by creating what are called managed zones within Cloud DNS. These are analogous to DNS zones and within <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">GCP</a>, there are two types: public zones and private zones. Both are just containers for DNS records. For example, you know, an A-record pointing to an IP address the difference is that public zones are visible to the public internet, while private zones can only be seen by specifically authorized VPCs—virtual private clouds—within a GCP account. So in essence, private zones are not visible to the public Internet.</p>
<p>Now, you will configure public zones for applications that need to be reachable by users from your public, from the public internet. For example, your main website will have a DNS name and you may create a record in a managed zone config that routes traffic to it. Now, this could be an A-record and directly at a VM listening for HTTP requests, or perhaps more likely, a load balancer that’s directing traffic to your site instances. On the backend, you can make use of private zones for traffic within the VPC. So, for example, you can have an internal load balancer, with an internal DNS name that’s usable by your back-end services. So now, instead of having to configure IP addresses or have some service discovery layer, you can just use a predictable DNS name internally that’s configured within the private zone and have your back-end instances talk to each other that way.</p>
<p>Now, that use case may seem a bit complex and I will say that the ins and outs of DNS routing and traffic configuration, you know, there are other courses that go into that, we’re not going to dig into that here, but I definitely recommend reading up on the official GCP DNS cloud DNS documentation if you need a deeper dive on these sort of internal use cases.</p>
<p>The most important takeaway here is that both public and private managed zones are a part of GCP Cloud DNS. This is your basic paradigm and your one-stop-shop for creating DNS configuration and records. We’ll talk a little bit more about Cloud DNS in the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/planning-network-resources-demo/">demo</a> coming up. You’ll get to see kind of how it works in the console and how things are actually configured. When you’re ready, we’ll see you there.</p>
<h1 id="Planning-Network-Resources-Demo"><a href="#Planning-Network-Resources-Demo" class="headerlink" title="Planning Network Resources Demo"></a>Planning Network Resources Demo</h1><p>Welcome to the third and final practical Google Cloud demonstration as part of this <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">course</a>. In this video, we’re going to go over how to use GCP network services in the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud</a> web console. There are three specific services we’re going to showcase here: VPC, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/load-balancing-with-gcp/">load balancers</a>, and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/cloud-dns-in-gcp/">Cloud DNS</a>. We will work with an existing instance and see how we can change VPC configurations such as firewall settings. We’ll then create an external load balancer for a back-end service and we’ll take a closer look at Cloud DNS to see how zones are created and configured.</p>
<p>So let’s start with VPC. As we can see, on the left side we have our network services area and in here we can click on VPC and VPC networks. And then in the VPC network section, we see one called default come up. Now, this default network was created for us automatically. It’s similar to AWS: whenever you create a VM in Google Cloud, it’s by default placed into a VPC for security purposes. Now, we can see that this one is configured for multiple regions, we have subnets for every region, and then from this dashboard, we can do a lot of different things. We can change firewall rules, we can go click on multiple ones that we don’t need and delete them if we want. We can generate new firewall rules here, you just click create and it’ll ask for some basic information: a test rule, test tag. Let’s say we want for all IP ranges. All right and then, oh sorry, there’s an extra period there, and then we can have an additional filtering options for IP ranges. Let’s not worry about that for now, we’ll just do allow all and we’ll go with create. Now, this is a very open firewall rule but just to show how simple it is to create it’ll take a while and it’ll come up. We can do a few other things here, we can also change our external IP addresses and from here we can reserve new static addresses. It’s kind of like Amazon Elastic IPs, so you can reserve new ones here and associate them with instances. So basically, this is your one-stop-shop for all VPC configuration, this section.</p>
<p>Okay, so now let’s walk through the process of creating a load balancer. Now, the key thing to remember with load balancers is that they need to be connected to a back-end service and those services need an instance group. You can also connect to a bucket but we’re gonna do a service since that’s a more common use case. Creating an instance group is similar to how we created an instance in the first demo.</p>
<p>So in compute, go to Compute Engine, we go to instance groups, and there’s already one here created for this demo but to create one you just go create instance group, it’s the same process as before: you select an operating system and an instance type and then you can generate your instance group. So, to create the load balancer, we’re going to go to our Network Services, Load Balancing and we’re gonna click Create load balancer.</p>
<p>We’ll go with an external HTTP load balancer, this will allow traffic to our service. So we want internet-facing, and we can see here, so we have to give it a name, we’ll call it testlb and we’re going to do, so back in configuration it’s going to ask create or select a backend service or bucket. We’re gonna do backend services. There’s one there but we’ll go through the process of creating it, creating a service. We just give it a name, test-service2, we’ll say. Instance groups, we’re gonna select an existing instance group. We’re gonna have it set for port 80 and basically default capacity. You can actually add more CPU utilization capacity here if you want but we’ll stick with the defaults.</p>
<p>And then, we don’t need Cloud CDN but we do need a health check. We’ll do a standard TCP health check, it’ll do a TCP connection to port 80 and make sure the instance is healthy. And then we click Create. and now we’ve got our back-end service configured. That’ll also set up our host path and rules, front-end configuration here, frontend IP, we’ll just call it testfrontend. We want HTTP, and we’ll click done, we’ll click create and just like that, our load balancer will come out. So, this is a, we’ll just connect to a set of back-end instances but you can test this yourself if you have a GCP account. Try this yourself, set up a simple web application, maybe a Python flask app or WordPress, and you can, because there are WordPress images actually, then you can create a load balancer and connect to it and there it is.</p>
<p>So finally, let’s take a brief look at Cloud DNS. So to do that, you just go to our Networking section here and we go to Cloud DNS and we can see just from the start it gives us the ability to create a zone. So click Create zone. We’ve put in some information, we’ve put in a name for the record, we’ll call it the example zone. An example DNS name, we’ll call it, this is what I actually, erm, examplezone.com, We don’t need DNSSEC, we’ll put, we don’t need a description for now. We’re gonna make this a public, this is kind of the key decision here. This is a private zone, this is a public zone. Do external clients need to be able to look this up or is it only our internal GCP services that need it? That’s really the question. For this demo, we’ll go with public and then we click Create and voila! We have now our manager zone and from here, we can add record sets. Click Add record set up here. We can do A-records CNAMES, txt records, whatever we want. This is an A-record type, so something like that, we can connect it to some IP address and yeah, sure, 192.1.1.1, something like that, Create. And we’ve got a record now for our DNS. So it’s really that simple. And that’s basically it.</p>
<p>So that’s our basic GCP network service demo. We’ve covered a few key tools: DNS, load balancing, VPC. This is really just an introduction. Our goal in this course is to get you familiar with the GCP product so that you know which ones solve specific problems. That’s the main thing you’ll need for the certification exam. Please check out some of our other Cloud Academy courses for a deeper dive on specific features to really learn the ins and outs of each service. Thanks for watching and good luck.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>So, congratulations! You made it! Give yourself a pat on the back. It has been a long and tough ride but here we are at the end. We went through a lot of material so before we start popping the champagne and celebrating, let’s take a quick minute to just review what we’ve covered in this <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/introduction/">course</a>.</p>
<p>Now, by completing this course, you should have a working knowledge of how to create an infrastructure plan using <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a>. You should know how to design a foundation of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-two-overview/">storage</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-three-overview/">networking</a>, and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/section-one-overview/">compute</a> services on top of which app developers can deploy their code. Now let’s get a little more specific and take a moment to review those course objectives.</p>
<p>Objective one: the student will learn to deploy and configure Google Cloud compute resources and understand the differences between each service. So we did this in section one, where you learned all about Compute Engine, App Engine, Kubernetes, you should know how to deploy any of these three services via the console or CLI.</p>
<p>Number two: the student will learn to deploy and configure Google Cloud storage resources and understand the differences between each service. This was in section two, we covered it. We talked about the different storage solutions including relational and NoSQL and we discussed their trade-offs.</p>
<p>Learning objective three: the student will learn to deploy and configure Google Cloud network resources and understand the differences between each service. So, in section three, we covered load balance and Cloud DNS, resource geolocation, network configuration, all of the different resources in detail. You should have enough understanding to cover this objective thoroughly.</p>
<p>So, with these three learning outcomes solidified in your mind, you should now be ready to dig in and build your own infrastructure in GCP. You should also have a conceptual foundation necessary to branch out to other infrastructure platforms such as AWS, if you’d like. Go you!</p>
<p>Now that you’re done, I’d like to invite you to send any feedback you have about the course to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. We greatly appreciate your comments, questions, suggestions, whatever you have to say. Congratulations again on fighting through the whole course and good luck in your future endeavors.</p>
<h1 id="6Planning-Compute-Resources-Demo"><a href="#6Planning-Compute-Resources-Demo" class="headerlink" title="6Planning Compute Resources Demo"></a>6<strong>Planning Compute Resources Demo</strong></h1><p><a target="_blank" rel="noopener" href="https://cloud.google.com/sdk">Google Cloud SDK Command Line Tools</a></p>
<p><a target="_blank" rel="noopener" href="https://cloud.google.com/pricing">Google Cloud Pricing</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Introduction-to-Google-Cloud-NAT-12/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Introduction-to-Google-Cloud-NAT-12/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Introduction-to-Google-Cloud-NAT-12</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:51" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:51-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:52:40" itemprop="dateModified" datetime="2022-11-22T20:52:40-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Introduction-to-Google-Cloud-NAT-12/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Introduction-to-Google-Cloud-NAT-12/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hello, and welcome to “Introduction to Google Cloud NAT”. My name is Daniel Mease and I’ll be taking you through this course. I am a trainer at Cloud Academy with over 20 years of software and web development experience.</p>
<p>This course is intended for GCP Network Engineers, GCP Security Engineers, and anyone preparing for a Google Cloud certification (such as the Professional Data Engineer exam).</p>
<p>After completing this course, you will be able to answer the following questions:</p>
<ul>
<li>What is Google Cloud NAT?</li>
<li>What configuration options are available?</li>
<li>How do you set up logging and monitoring for it?</li>
</ul>
<p>The following prerequisites will be helpful:</p>
<ul>
<li>Basic knowledge about networking and TCP&#x2F;IP.</li>
<li>Access to a Google Cloud Platform account.</li>
</ul>
<p>Feedback on our courses is valuable, both to us as trainers and our future students. If you have any criticisms or suggestions for improvement, we would greatly appreciate it if you would share those with us.</p>
<p>Please note that, when this video was recorded, all course information was accurate. Google is constantly updating its products and services as part of its ongoing drive to innovate. As a result, over time, minor discrepancies may appear in the course content. Here at Cloud Academy, we strive to keep our content up to date in order to provide the best training available. </p>
<p>If you notice any information that is outdated, please contact <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. This will allow us to make all necessary fixes to the course during its next release cycle.</p>
<h1 id="Features-of-Google-Cloud-NAT"><a href="#Features-of-Google-Cloud-NAT" class="headerlink" title="Features of Google Cloud NAT"></a>Features of Google Cloud NAT</h1><p>Securing cloud resources can be a challenge. As your systems grow and become more complex, the total number of potential vulnerabilities increases. If you allow your attack surface to grow too large, eventually even the most talented security professional will miss something. That is why it is important to try to minimize your attack surface as much as possible.</p>
<p>Physically securing a room with a single door is much easier than trying to secure an entire building with many entrances. In much the same way, securing a private network is much easier than trying to secure a public one. That is why it is recommended to only assign public IPs when it is absolutely necessary.</p>
<p>Now of course, this strategy does have some drawbacks. Cutting your VMs and Kubernetes clusters off from the internet also means cutting them off from a lot of updates and patches. Luckily, it is possible to get the best of both worlds using Network Address Translation. Network Address Translation (or NAT for short) allows you to assign a single IP address to a group of computers. This allows those machines to make requests out to the internet, but (by default) prevents incoming requests to resolve to any specific machine. So essentially, requests that originate from your internal network can reach the internet. But requests from the internet to your internal network will fail.</p>
<p>Now there are several ways to set up a NAT in GCP, but the easiest is to use Google Cloud NAT. Cloud NAT works with both your Compute Engine VMs as well as with Google Kubernetes Engine (GKE).  It is fully managed and does not require you to maintain your own NAT Gateways. It is also extremely scalable and reliable.  Cloud NAT can automatically manage the NAT IPs for you, if you wish. And if a zone ever goes down, Cloud NAT will continue to stay available across the region. </p>
<p>Just because the service is managed, it doesn’t mean that your options are limited. You can use manual mode to manage the settings yourself. Or you can just leave it on auto mode and Cloud NAT will handle everything for you. With Google Cloud NAT, you have an easy way to help keep your VMs both secure and up-to-date.</p>
<h1 id="Google-Cloud-NAT-Configuration"><a href="#Google-Cloud-NAT-Configuration" class="headerlink" title="Google Cloud NAT Configuration"></a>Google Cloud NAT Configuration</h1><p>Now that you understand what Cloud NAT can do, I want to show you how to actually set it up. So for this demo, I have already created a couple of Virtual Machines. Let me show you those. I’ll navigate to Compute Engine.</p>
<p>Here you can see I have a public VM that has both an internal and external IP address. And I have a private VM with just an internal IP address. They both exist in the same VPC but in separate subnets. So you can think of my public VM as representing some internet-facing service, like a web server. The private VM could be an internal database or application server, something you would NOT want to be publicly accessible. </p>
<p>Let’s verify that the public VM does indeed have internet access. I can quickly test this out using the curl command. This first website will return my public IP address. And I will also try to get the Apple homepage as well. So, you can see my public VM is connected to the internet.</p>
<p>Next, let’s verify the private VM. Here we see that when I try to run a curl command it’s just going to time out. That is because there is no valid route between my private VM and the internet.</p>
<p>So no one is able to directly attack my private VM without first gaining access to my GCP account. However, downloading patches and updates is going to be pretty difficult. So now I am going to show you how easy it is to create a NAT Gateway using Cloud NAT. This will allow me to download updates from the internet, without assigning an external IP address to the VM.</p>
<p>So to get started, I need to navigate to Cloud NAT and then click on “Get Started”.  When creating a NAT Gateway, you need to specify a name. I’m going to call this “nat-demo-gateway”. In order to be able to route to the public internet, I am going to need a router. You can select one here, or if you don’t already have one, you can create a new one. In this case, I will select the network my VPC is in, select the region, and then pick “Create a new router”.</p>
<p>So this will open a new side window where I can create a router. This screen has several options, but for a basic working router, all I have to do is to give it a name. The network and region are already set to what I picked on the previous form so I don’t have to change those. And now I can click “Create” to create my new router. So now my gateway has a Cloud router assigned to it.</p>
<p>There are two more sections I could make changes to if I wanted. However, for this first example, I am going to leave the defaults. This will automatically handle all the details for me. It’s going to map all subnets in the VPC to the NAT gateway and it will automatically assign NAT IP addresses. If you just need basic internet access, this works best. There are other options available under “Advanced configurations’’ but we will look at those later. I will go ahead and click on “Create” to create a new NAT Gateway.</p>
<p>Ok, now at this point I just have to wait for the gateway to be created. So now I should have a working router and NAT gateway. My private VM should be able to connect to the internet. Let me try running those curl commands again to verify.</p>
<p>So now when I connect, I am getting a response. I can also see that my NAT public IP address has been assigned to 104.155.143.187. Because I am using automatic mode, this address can change. But if I just want to download updates, then that will not be an issue at all. Cloud NAT is going to manage everything. It will add, remove and update the IPs as needed.</p>
<p>If I try to download the Apple homepage, we now see that it is successful as well. So, as you can see, it is actually quite simple to use Cloud NAT.</p>
<p>Let me go back and show you some of the more advanced features.  I can click on my gateway to see the details. And if I want to change anything, I just need to click on the “Edit” button at the top. </p>
<p>So first I’ll show you how to set your own IP addresses. Maybe you need a specific IP for creating a firewall rule or to add to a whitelist. To manage it myself, I can simply click on NAT-IP Addresses and set it to “Manual” mode. Now I can add my IP addresses. </p>
<p>The addresses used will be reserved public IPs. Since I don’t have any IP addresses reserved already, I’ll just pick “Create IP address”. I have to give this IP address a name. This is so I can later remember what I plan to use it for. So it looks like it reserved 34.72.21.122.</p>
<p>I could add more addresses if I wanted. If you have a lot of VMs, you might need more than one IP. But a single address will work fine for several VMs. The exact number depends on how many connections each VM will require.</p>
<p>So let me go ahead and save this. Now I have to wait for the changes to propagate. And now I should see that the public IP address for my private VM has changed from a 104 address to a 34. There we go. The change happens pretty quickly. You won’t have to wait long at all to see the new IP.</p>
<p>Let’s look at some of the other things you can change. I’ll open up Advanced Configurations this time. The first option allows you to enable logging. You can tell it to either log errors or network translations or both. Error logging is useful for debugging issues. Translations might also be useful to look at if you are doing something more advanced. So if you are experiencing intermittent errors, both could be useful. Just remember the more you log, the higher your storage costs will be. I’ll go ahead and enable both for this example.</p>
<p>So now everything that happens in Cloud NAT will be written to the logs. I’ll demonstrate a little later how to view the logs and what the entries look like. I want to show you a few more options first. You can change the minimum assigned ports per instance. By default, my VM can create 64 connections at once. This is usually more than enough. If you need more you can increase it here. Just remember that increasing this number means you are also decreasing the number of VMs that can share this IP. If you don’t need 64 simultaneous connections, you can decrease this number.</p>
<p>You also can change the timeout values for TCP, UDP, and ICMP protocols. This is definitely more advanced stuff. If you are running into timeout issues, you can probably fix those by tweaking these values. If too many connections are timing out, you might want to increase these. However, making these too high means it will take longer for connections to fail. Make sure you know what you are doing before messing with these values.</p>
<p>There are a few more options here, but I covered the main ones. You can hover your mouse cursor over the question marks to get details on any of them. Again, it’s pretty easy to make any changes, so feel free to experiment on your own.</p>
<p>I previously showed you how to enable logging. Now it’s time I show you how to access the logs. The easiest way is to go to your gateway in Cloud NAT and click on the Logs tab. Then I just have to click on the “Cloud Logging” link and it will take me to Logs Explorer. You can also directly navigate to Logs Explorer, but then you have to set up the filters to show you the NAT logs. If you use the link I showed you, it automatically selects the correct filters for you.</p>
<p>Now at this point I don’t have any logs because I haven’t actually done anything since I enabled logging. Let me run a few more curl commands and then refresh the page. Now we can see three entries for the three curl commands I just ran. And if you start opening up the different parts of the logs you can access the details for each entry. So that’s how you view the Logs for Cloud NAT.</p>
<p>The last thing I wanted to show you is how to access the pre-built monitoring graphs. You get to them in a similar way to the logs. Just select your gateway and then click on the “Monitoring” tab here. This will give you information on the number of open connections, the amount of egress data, and a bunch of other things. If you want something else, you can (of course) go to Cloud Monitoring and build your own custom dashboards as well. But the prebuilt dashboards are usually enough, especially when you are just starting out.</p>
<p>And that is pretty much it. That gives you enough details to start using Cloud NAT on your own.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>At this point, you should understand what Google Cloud NAT is and how to use it. You saw how to enable internet connectivity to VMs without using an external IP. You also saw how to enable logging, and monitor for any issues.</p>
<p>There is one last thing I wanted to show you before I wrap things up. If you are planning to use NAT to protect your VMs and Kubernetes Clusters, you might also want to consider setting some Organization Policy Constraints.</p>
<p>So let’s say that you decide to only allow your web servers to have public IPs. Everything else should use NAT. And you make a bunch of changes to enforce that. Now, how will you guarantee that it will stay like this in the future? What is preventing another employee from spinning up a database VM with a public IP. Well, you can actually prevent this wIth a Policy Constraint.</p>
<p>You can access your list of current policies by searching for “Organizational Policies”. As you can see, there are quite a few. So let’s look at a couple of policies you might find useful.</p>
<p>First, search for “external IP” and choose “Defined allowed external IPs for VM instances”. This policy allows you to limit which VMs can get an external IP. So you could specify your web servers here. And that way, all other VMs will be forced to use NAT instead.</p>
<p>Another useful policy can be found by searching for “Cloud NAT”. The “Restrict Cloud NAT usage” policy can dictate which networks are allowed to use Cloud NAT. So maybe you want to prevent any internet connection at all in certain networks. You can enforce that with this policy.</p>
<p>Changing a policy is pretty simple. Just click on the name and then (if you have the correct permission) you can change them to the values you wish. As you can see, in this account I do not have permission to make any changes.</p>
<p>Organization Policies are not directly related to Cloud NAT but can be used in conjunction to enhance your overall security.</p>
<p>Well, that’s all I have for you today. Remember to give this course a rating, and if you have any questions or comments, please let us know. Thanks for watching, and make sure to check out our many other courses on Cloud Academy!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Introduction-to-Google-Cloud-DNS-11/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Introduction-to-Google-Cloud-DNS-11/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Introduction-to-Google-Cloud-DNS-11</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:50" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:50-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:52:16" itemprop="dateModified" datetime="2022-11-22T20:52:16-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Introduction-to-Google-Cloud-DNS-11/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Introduction-to-Google-Cloud-DNS-11/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hello, and welcome to Introduction to Google Cloud DNS. My name is Daniel Mease and I’ll be taking you through this course. I’m a trainer at Cloud Academy with over 20 years of software and web development experience. This course is intended for networking engineers, security engineers, or anyone who’s interested in managing DNS on Google Cloud Platform.</p>
<p>After completing this course, you will be able to one, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-google-cloud-dns-2358/features/">understand what Cloud DNS is</a> and what it can do. Two, manage DNS records. Three, enable DNS security extensions. Four, create public and private <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-google-cloud-dns-2358/zones/">zones</a>. Five, set <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-google-cloud-dns-2358/policies/">DNS policies</a>. And six, log and monitor DNS activity.</p>
<p>The following prerequisites are required. You should already have a solid understanding of DNS. Now, this course is going to assume that you already understand the basics, such as what DNS is, how it works, and what DNS records are.</p>
<p>Feedback on our courses is valuable, both to us as trainers and our future students. If you have any criticisms or suggestions for improvement, we would greatly appreciate it if you would share those with us.</p>
<p>Please note that when this video was recorded, all course information was accurate. The products and services mentioned are constantly being updated. As a result, over time, minor discrepancies may appear in the course content. Here at Cloud Academy, we strive to keep our content up-to-date in order to provide the best training available. So if you notice any information that is outdated, please contact support at cloudacademy.com. This will allow us to make all necessary fixes to the course during its next release cycle.</p>
<h1 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h1><p>Cloud DNS is Google’s global domain name service. It has everything you need to manage, and serve your domains. You can use it for mapping public IP addresses to public domain names, and for creating private domain names as well. Now, this second feature is extremely useful for managing highly complex infrastructure. Instead of hard coding the IP addresses of various services in your code, you can use internal DNS names instead. That means that when an IP address changes, you don’t have to change your code. It also makes testing and deployment much easier since the same DNS names can work across multiple environments including development, testing, staging, and production.</p>
<p>With Google Cloud DNS, there’s no need to maintain your own DNS servers or software. The service is fully managed and highly scalable. It can handle millions of records. Cloud DNS all offers a hundred percent availability and low latency access from anywhere in the world. On top of that, you can also generate detailed logs to use for <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/managing-your-google-cloud-infrastructure/monitoring-3/">monitoring</a> and troubleshooting. If you already have a <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">GCP</a> account, then using Cloud DNS is a no-brainer.</p>
<h1 id="Zones"><a href="#Zones" class="headerlink" title="Zones"></a>Zones</h1><p>Probably the most common activity when working with Cloud DNS is to create or update DNS records. But before you can start modifying records, you need to be familiar with DNS zones. A DNS zone is a container of DNS records for the same DNS name suffix. All DNS records are stored within a zone. DNS zones also automatically generate certain records like the NS and SOA so you don’t have to add them yourself.</p>
<p>Now, Cloud DNS offers two types of zones. Public and private. Public zones are visible to the whole internet. While private zones are only visible to the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/implementing-a-gcp-virtual-private-cloud-1224/shared-vpcs/">VPC networks</a> that you specify. So, an internet-facing website would use a public zone but a company intranet site like a wiki would use a private zone. Now, there are times where you might want to mix both private and public zones. Now, this would allow you to return different results for the same domain name depending upon the source IP. This is called Split Horizon DNS.</p>
<p>So, let’s imagine the following scenario. Say, you have a web server running in a VPC with both a public and private IP. Now, you want your internet users to be able to access this web server via the public IP. You also want internal resources such as other <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/compute-virtual-machine-types/">VM</a>s to be able to access it via private IP. Split horizon DNS would allow you to use the same DNS name for both. Internet clients would get the public IP and internal clients would get the private IP.</p>
<p>Now, to set up split DNS, all you have to do is create both a public and private zone for the same domain. Then, just add the appropriate records. Public DNS zones can also be configured to enforce DNS security extensions. Now, DNS security extensions or DNSSEC is a feature that authenticates responses for domain name lookups. Now, before DNSSEC was introduced, you had to trust that your DNS results were accurate. But if a response was poisoned it could result in redirecting you to a different and potentially harmful server. By enabling DNSSEC for a zone, you can cryptographically verify that the data received actually came from where it was supposed to. You can also verify that the data was not modified in transit.</p>
<p>Now, zones can also be used for DNS Forwarding. Forwarding allows requests for certain domains to be resolved by another DNS server. Now, this is useful if you wanna resolve names that you do not control yourself. So, if say you were connecting from your on-prem environment to your GCP environment, you could use DNS forwarding to get access to private DNS records in GCP.</p>
<p>Now, forwarding can be either outbound or inbound. Outbound forwarding means that you will be forwarding DNS requests outside of <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud platform</a>. Inbound forwarding will be routing requests into Google Cloud platform. Another option you have with DNS zones is called peering. DNS peering works similarly to DNS forwarding but with one main difference. With DNS peering, you’re allowing requests to be forwarded from one VPC to another for specific zones. This works regardless of whether the VPC networks are actually connected or not.</p>
<p>Now, this is important to note. DNS forwarding does not let you forward requests between VPCs nor does it support transitive routing. DNS forwarding only handles external to internal and internal to external routing. DNS peering is for internal to internal routing between VPCs. It also does support transitive routing, but only through a single hop. DNS peering can make it possible for your teams to independently manage their own DNS zones while also sharing them with the rest of your organization.</p>
<p>You should also be careful not to confuse DNS Peering with VPC Network Peering. They are different. VPC peering allows VMs in different projects to reach each other but it does not affect name resolution. DNS peering allows you to access DNS records in a different VPC, but it does not affect the connectivity of those VPCs. You can use both options at the same time but they do different things.</p>
<h1 id="Zones-Demo"><a href="#Zones-Demo" class="headerlink" title="Zones Demo"></a>Zones Demo</h1><p>So now that you understand what zones are, let me run you through a practical demonstration of how you will typically use them. First, I will show you how to map a public IP for a website to a public domain name. Then, I’ll show you how to create a private DNS name for internal use. And finally, I’ll also show you how to set up DNS peering and DNS forwarding. Now, before I start, you should know that I’ve already set up a few VPCs and VMs. I have two Linux virtual machines, both running Apache, and serving up a single webpage. Now each <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/planning-configuring-google-cloud-platform-solution/compute-virtual-machine-types/">VM</a> has its own public and private IP and they’re running inside their own separate <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/implementing-a-gcp-virtual-private-cloud-1224/shared-vpcs/">VPC</a>. I’ve also added firewall rules to open ports 80 and 22. So I can connect to each VM via SSH and HTTP. Here, you see that I can already connect to the web servers by using their IP address.</p>
<p>But now, I’m going to add a public DNS record so that I can use a domain name to connect instead. So for the first step, I need to bring up the Cloud DNS page. Now you can see here that there are options for working with zones and for working with policies. I’m going to be adding a DNS record, so I need to create a zone. Now when creating a zone, you have to specify which kind you want. This is going to be a public domain name, so I need to create a public zone. To set up a public zone, you need to have a domain name registered. Now I’ve already done this using Google Cloud Domains.</p>
<p>Cloud DNS does not handle domain registration, so you’ll need to use a different tool. Here, you can see my domain name. Now you can use Cloud Domains as well if you wish. However, it’s not required. There are many other domain registrars out there, so pick the one you like best. To create my new public zone, I have to assign it a name. I’m gonna set the name to be the same as the domain, except I’ll need to replace the periods with dashes. Zone names can only contain letters, numbers and dashes.</p>
<p>Next, I need to specify the domain name, so let me enter that. And now, I can choose to enable DNS Security Extensions. Now this is generally recommended, so I’m gonna enable that here as well. You can see under DNSSEC that there are three options provided: Off, On and Transfer. It should be obvious what the Off and On options do. Transfer is used when you’re in the middle of transferring a domain name over to Google and you already have DNSSEC enabled. While this option is supported, I would generally not recommend using it.</p>
<p>It’s usually safer and easier to disable DNS Security extensions before starting the transfer. You can then re-enable DNSSEC after the transfer has completed. Now I can optionally add a description here if I want. It’s unnecessary for this demo since I’m only going to end up with a few zones. But this field becomes more useful when you have hundreds or thousands of zones. So at this point, I can confirm the zone creation. Now, in my demo, I’m gonna be using the cloud console a lot, but you can also accomplish the same things using command lines tools as well. So here is where you can see the equivalent command for creating a public zone.</p>
<p>Alright, now that I’ve created the zone, let’s review the details. Here, you can see the domain name, as well as verify that DNS Security extensions has been enabled. You also should notice that the SOA and NS records were automatically generated. Now, if I return to the zone page, you can see what this new entry looks like here. Remember, I still haven’t actually added the A record yet. I’ve just created the zone. So, let me do that next. I’ll click on the zone and I’ll select Add Record Set.</p>
<p>Now adding a DNS record is very simple. The default type is already set to A, so I don’t need to change that. Now if I wanted to add an IPv6 address, I could create a AAAA record as well. All I need to do is specify the server name, which I will call WWW, and then I’ll specify the IP address, which I can copy from the Compute Engine screen. If you want to use the command line to do this, you can get those commands from here. Okay, so now I have created my A record. There’s just one last thing to do. I need to tell my registrar to forward requests for the new domain to Cloud DNS. Now this is going to be simple since I’m using Google service. But you can accomplish the same thing using a different registrar. Of course, if you do, the steps will probably be slightly different than what you see here.</p>
<p>Now, in theory, I should be able to start using <a target="_blank" rel="noopener" href="http://www.ca-demo-domain.com/">www.ca-demo-domain.com</a> to access my apache web server. I say in theory because DNS changes can take a while to propagate. This is probably not gonna work right away. You see that I’m getting an error here because it’s gonna take a while for the records to actually be available. Now this could take hours, might even take a whole day, so let me go ahead and skip ahead. Okay, now you can see the DNS record is working properly. Luckily, I have my own private DNS server and so I was able to force it to grab the updated records pretty quickly.</p>
<p>Now most people will not have that option, so again, you might have to wait up to a day before it finally starts working. But now we see that my domain name is correctly resolving to the first apache web server instance. So now you know how you create a new public DNS zone and record. Next, I’m going to show you how to work with private records. I’m going to create a private domain name and map that to the private IP for my second VM.</p>
<p>Now this domain name is only going to be usable inside of my <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">GCP</a> account. So to do this, I need to return to the Cloud DNS page and then create a new zone. This zone is going to be private. And you’ll notice, when I select private, that some of the options have changed. I still have to provide a zone name and a domain name. But the DNS Security extensions option has disappeared. That is because it’s only available for public zones.</p>
<p>Also, now I have to pick what kind of private zone this will be. Here is where you can set up forwarding or peering or pick some other advanced options as well. Now for this zone, I’m just gonna keep to the default type. Finally, I have to choose the network, or networks, that this zone will be active for. So here, I’m going to pick VPC-2 because that is what contains my second VM. Now I have a new private domain called privatedomain.com configured for VPC-2. Again the SOA and NS records are added automatically.</p>
<p>So, my last step is just to add the A record. So I can copy the private IP address here. And then, I’ll set the domain name to be the same as the instance. And now, apache-2-vm.privatedomain.com should resolve to my Apache 2 instance. Remember, this is an internal DNS record, so I can’t use my browser to test like last time. Instead, I’m gonna SSH to the VM instance and then use the ping command to verify that it worked. So here we see ping is returning the correct IP. That means our DNS record is working. So now you know how to create a private DNS zone and record.</p>
<p>Currently, this private DNS record is working for Apache-2-vm, but it will not work for Apache-1-vm. Now this is because Apache-1 is in a different VPC. If I want, I can use DNS peering to share the DNS records in VPC-2 with VPC-1. So let me do that next. I need to go back to Cloud DNS and create yet another zone. As we saw last time, DNS Peering and Forwarding are available under a private zone. I need to pick a name. And here, I need to specify the domain name that I wish to peer. I also have to specify the network that I wish to share my DNS records with. So this should be VPC-1. And then finally, I have to select the network that I’m sharing from. Because this can actually be a network in a completely different project, I need to pick the project first. And now I can pick the network.</p>
<p>Okay, so this is going to share all DNS records for privatedomain.com created in VPC-2 with VPC-1. I should now be able to resolve apache-2-vm.privatedomain.com from apache-1-vm. Here, we see the ping command can resolve the IP address, so peering is working. You will also notice that, unlike last time, that ping is not getting a response. Now this is completely expected. DNS Peering only shares DNS records. It does not enable connectivity between VPCs. While I now can look up the IP address, I still can’t actually connect. If I wanted to allow apache-1 to be able to successfully ping apache-2, I would need to configure VPC peering.</p>
<p>Now the last thing I want to quickly demonstrate is how to set up DNS Forwarding. For this, I need to create yet another private zone, and then select Forward Queries to another server. A Forwarding zone is going to require me to specify an external DNS server. Setting up an external DNS server is beyond the scope of this demo. So instead, I’m just going to forward DNS requests for the google.com domain to one of Google’s public DNS servers. Now this is not something you would typically do. Normally, you would use this option to forward requests to say, an on-prem domain. And then the DNS server would be your internal on-prem server. But this will at least show you the basic idea. So now, any requests for the google.com domain in either VPC-1 or VPC-2 will be forwarded to Google’s public DNS server at 8.8.8.8 instead of trying to resolve it locally. So now you know how to create the four main types of zones: public, private, peering and forwarding.</p>
<h1 id="Policies"><a href="#Policies" class="headerlink" title="Policies"></a>Policies</h1><p>In order to use all the features of Cloud DNS, you need to be aware of policies. In this lesson, I’m going to describe what DNS policies are and what they can do. Cloud DNS policies allow you to override Cloud DNS settings. Policies can be simple, like enable login, or they can be more advanced. To help you understand when you might need to use a policy, let’s think about the following scenario. Say your company is using the hybrid Cloud architecture and it has multiple authoritative DNS servers. You have some on-prem resources, running under an on-prem DNS server, and you have some GCP resources running under Cloud DNS.</p>
<p>In order to make both systems work together, you have a few options. Number one, you can handle all DNS resolution on-premises. Number two, you can handle all DNS resolution with cloud DNS, or number three, you can set up a hybrid DNS environment.</p>
<p>First, let’s talk about handling all DNS resolution on-premises. This can be achieved by adding a Cloud DNS policy that specifies an alternative name server. An alternative name server tells Cloud DNS to forward all requests to the specified server. This effectively bypasses Cloud DNS for name resolution. You can think of it as being similar to DNS forwarding, except it applies globally to all domains. Now, be aware, if you choose to move all your GCP DNS resolution to on-premises, there will be some trade offs.</p>
<p>First, DNS requests from GCP are going to have a higher latency. Second, if your on-prem connection is ever disrupted, then your GCP resources will not be able to resolve any DNS names. Third, it’s going to be more difficult to support highly flexible GCP environments, such as autoscaled instance groups. And fourth, you might not be able to use certain GCP products, ones that rely on reverse DNS resolution of instance names, for example, Dataproc.</p>
<p>All right, next, let’s talk about the second option, handling all DNS resolution with Cloud DNS. Now, this can be achieved via another DNS policy that enables inbound query forwarding. Now, by default, a VPCs name resolution services are only available to that <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/implementing-a-gcp-virtual-private-cloud-1224/shared-vpcs/">VPC</a> itself. However, you can create an inbound server policy to share these name resolution services with other networks, either via <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/creating-a-vpn-connection/">Cloud VPN</a>, or cloud Interconnect. Now, in this setup, all your on-prem DNS requests are going to be sent to Cloud DNS. Similar to the first solution, this design also suffers a few drawbacks.</p>
<p>First, your on-prem DNS requests will have a higher latency. And second, if your connection to GCP is ever disrupted, your on-prem resources will not be able to resolve any DNS names. So while you can choose between either a 100% on-prem, or 100% cloud DNS strategy, it’s generally recommended that you go with a hybrid one instead. You can use Cloud DNS for your Google resources, and your on-prem DNS server for your on-prem resources.</p>
<p>Now, this setup is slightly more complex, but it gives you the best of both worlds. Here is what a hybrid setup would look like. To access on-premises resources from <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud platform</a>, you would need to set up a forwarding zone for your corporate domain. You do not wanna use an alternative name server here. That would cause you to lose access to compute engine internal DNS names. Also, all public IP resolution would have an extra hop added, as they too would be routed through your on-premises name server. A forwarding zone here is the better option.</p>
<p>Next, to access GCP from on-premises, you would create a DNS server policy that enabled inbound DNS forwarding. Inbound DNS forwarding will allow your on-prem systems to query all private zones in the project, as well as internal DNS IP addresses and peered zones. Once this policy is added, Cloud DNS will create a set of regional IP addresses. You will then use this list to update your on-prem DNS and enable the appropriate forwarding. Now, this hybrid approach is considered a best practice by Google. It will generally offer the most options with the least headaches.</p>
<h1 id="Polices-Demo"><a href="#Polices-Demo" class="headerlink" title="Polices Demo"></a>Polices Demo</h1><p>Now that you understand what DNS policies can do, let me demonstrate how to create them. First, I’m going to show you how to add an alternative name server. Then, I’ll show you how to enable inbound query forwarding. And finally, I’ll show you how to enable DNS logging. So, you create new policies by going to the Cloud DNS page, and then clicking on the “DNS Server Policies” tab.</p>
<p>Now currently, you can see that there are no policies set. So, for my first policy, let me specify an alternative name server. I just need to click on “Create Policy” to start. I do not want to enable “Inbound Query Forwarding” yet, so let me turn that off. For some reason it’s enabled by default for every new policy. You can also see that it’s possible to enable multiple options with a single policy. I can specify my alternative name server down here. I’m just going to use 8.8.8.8, which is one of Google’s public DNS servers. This is not something that I typically would do, as it’s going to forward all DNS requests to a DNS server that I have no control over.</p>
<p>Typically, I would enter the IP address of an on-prem DNS server here. And now all I have to do is to specify a name for this policy. So, this policy is gonna forward all DNS requests to one of Google’s public DNS servers. However, even though I added the policy, it’s still not affecting anything yet. And that is because I did not specify any networks yet. I also need to pick the networks that this policy is going to be applied to. Let me do that now. I’m gonna go ahead and add all my networks.</p>
<p>So now, I’ve effectively replaced Cloud DNS with 8.8.8.8 for all of my <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/implementing-a-gcp-virtual-private-cloud-1224/shared-vpcs/">VPC</a>s. So for the next part, I want to show you how to do the opposite. I’m going to create a policy that will allow me to replace an external DNS server with Cloud DNS. Now before I do this, I need to delete my previous policy first. In order to delete a policy, you have to remove all attached networks. Now you can see, I can delete the actual policy. So, I’m gonna create a new policy and this time I’m going to leave the “Inbound Query Forwarding” option enabled. You’ll notice that there’s not really any other options to choose. And that’s because all we’re doing is we’re telling Cloud DNS to accept external DNS requests.</p>
<p>So here, I just have to specify a name and then pick the networks that this will apply to. You can prevent sharing certain DNS records by excluding certain networks. Okay, so all the configuration changes have been completed on the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google</a> side. The only step left would be to update my external DNS server. Now, those exact steps are gonna depend upon the type of DNS server that you’re running, and so I’m not gonna cover that part. However, I will show you how to get a list of IP endpoints that you will need.</p>
<p>Now, you can run this following command using the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-google-cloud-sdk-1675/using-google-cloud-sdk/">Cloud SDK</a> to get the list of IPs. Now these IPs are what you’re going to forward your DNS requests to. If you don’t have the Cloud SDK installed locally, then you could still use Cloud Shell to run the command instead. Okay, for this last policy, I’m gonna show you how to enable DNS logging. Let me delete the previous policy. Now I can add the new policy. I’ll give it a name. I need to enable “Logs” and then disable “Inbound Query Forwarding”. And of course, I need to specify the networks that this will apply to.</p>
<p>With this new policy, Cloud DNS is going to begin to keep detailed logs for any DNS lookups. You should be aware that cached responses are not logged, so keep that in mind. Also, you should be aware that this can potentially generate a significant amount of data. Enabling these logs might result in extra storage costs. All metrics are exported to Cloud Monitoring and you can view that using Logs Explorer. So, here’s where you can search for your logs, you view your logs, and you can build different queries. I’m not gonna take the time to teach you how to actually use Logs Explorer, since that’s covered elsewhere.</p>
<p>If you’re interested, you can look up the details afterwards. This is how you enable logging and where you go to find the logs. You’re gonna find this extremely helpful for troubleshooting any DNS related issues you might run into. All right, so that’s about it. You know how to use the three main policy types in Google Cloud DNS.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>At this point, you should have a good understanding of how to start using Cloud DNS. Before I wrap things up, let’s quickly review the topics that were covered. In this course, we focused on <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-google-cloud-dns-2358/zones-demo/">DNS zones</a> and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-google-cloud-dns-2358/polices-demo/">DNS policies</a>. Zones are used for managing DNS records, while policies are used for overriding DNS behavior. When you want to modify DNS resolution for a domain or subdomain, you use a zone. When you want to replace one DNS server with another, you would use a policy.</p>
<p>DNS zones allow you to create and update DNS records, but they also support other <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-google-cloud-dns-2358/features/">features</a>, as well. DNS forward allows you to forward requests for certain domains from Cloud DNS to an external DNS server, and vice versa. Remember, forwarding does not support internal forwarding from one VPC to another. That is what DNS Peering is for. You use DNS Peering to share domain records managed by one VPC with other VPCs. DNS policies are used to completely override DNS server behavior. So you can shift all DNS resolution to an external server by specifying an Alternative Name Server policy. Or, you can shift DNS resolution to Cloud DNS by creating a enable inbound query forwarding policy. And if you just wanna enable DNS logging, you can create a policy for that, as well.</p>
<p>Well, that’s all I have for you today. Remember to give this course a rating, and if you have any questions or comments, please let us know. Thanks for watching, and make sure to check out our many other courses on Cloud Academy.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-10/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-10</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:48" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:48-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:54:12" itemprop="dateModified" datetime="2022-11-22T20:54:12-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-10/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-10/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Starting-a-Linux-Virtual-Machine-on-Google-Compute-Engine-9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Starting-a-Linux-Virtual-Machine-on-Google-Compute-Engine-9/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Starting-a-Linux-Virtual-Machine-on-Google-Compute-Engine-9</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:47" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:47-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:56:46" itemprop="dateModified" datetime="2022-11-22T20:56:46-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Starting-a-Linux-Virtual-Machine-on-Google-Compute-Engine-9/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Starting-a-Linux-Virtual-Machine-on-Google-Compute-Engine-9/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:45" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:45-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:51:08" itemprop="dateModified" datetime="2022-11-22T20:51:08-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Course-Intro"><a href="#Course-Intro" class="headerlink" title="Course Intro"></a>Course Intro</h1><p>Hello and welcome to “Deploying Networking and Compute Resources on Google Cloud Platform”. My name is Thomas Mitchell and I’ll be taking you through this course. </p>
<p>I’m a Content Author at Cloud Academy and I have over 25 years of IT experience, several of those with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn, or send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>.</p>
<p>This course is intended for Google Cloud Engineers who deploy applications, monitor operations and manage enterprise solutions. It’s also intended for those interested in obtaining the Associate Cloud Engineer certification.</p>
<p>To get the most from this course, you should have a basic understanding of the Google Cloud Platform, its Compute Instance offerings, and its Network offerings.</p>
<p>We’ll kick off this course by diving into the deployment and implementation of networking resources such as VPCs and subnets. You’ll learn how to create a VPC and how to define subnets contained within the VPC. You’ll also learn how to create ingress and egress firewall rules for a VPC.</p>
<p>Later on, you’ll learn how to create a VPN connection between a Google VPC and an external network. You’ll also learn how to distribute network traffic to an application by using a load balancer.</p>
<p>As we work through the course, you’ll then learn how to deploy and implement Compute Engine resources via the Cloud Console and via gcloud. After deploying a compute instance, you’ll learn how to create and assign disks to an existing compute instance and how to assign an availability policy to a compute instance.</p>
<p>As we enter the home stretch of this course, you’ll learn how to create an autoscaled managed instance group, using an instance template, and how to generate and upload custom SSH keys for compute instances.</p>
<p>Rounding out the course, you’ll learn how to configure a VM for Cloud Operations, and how to install the Ops Agent. You’ll also learn how to assess compute quotas and how to request quota increases.</p>
<p>By the time you complete this course, you’ll have a full understanding of how to Deploy Networking and Compute Resources on Google Cloud Platform.</p>
<p>We’d love to get your feedback on this course, so please give it a rating when you’re finished. So, if you’re ready to learn how to Deploy Networking and Compute Resources on Google Cloud Platform, let’s get started.</p>
<h1 id="VPCs-and-Subnets"><a href="#VPCs-and-Subnets" class="headerlink" title="VPCs and Subnets"></a>VPCs and Subnets</h1><p>A VPC network is a virtual network that’s deployed in the Virtual Private Cloud, hence the term VPC Network. Just like any other physical network, a VPC network provides connectivity for VMs, Kubernetes clusters, and many other resources that need to communicate. </p>
<p>In this lesson, we’re going to talk a little bit about VPC networks, their properties, and the different types of VPC networks that are available to you. Once we’ve covered the basics of VPC networks, we’ll work through a demo so you can see how a VPC network is deployed. </p>
<p>Now, before we get into the two types of VPC networks that are available, what I want to do is briefly touch on subnets and the role that they play. Any VPC network that’s created will need to have at least one subnet defined before the network can be used. This is because VPC networks, themselves, do not have any IP address ranges associated with them. Instead, IP ranges are defined for the subnets which are defined within the network itself. </p>
<p>The type of VPC network that you deploy will determine how the initial subnet for the network is deployed. GCP offers two types of VPC networks, determined by their subnet creation mode. </p>
<p>Creating an auto mode network results in one subnet from each region to automatically be created within the network. The subnets that are automatically created use a set of predefined IP ranges from the 10.128.0.0&#x2F;9 CIDR block. </p>
<p>Now, while an auto mode VPC network automatically creates subnets, this does not preclude you from adding additional subnets manually, as needed. However, any manually added subnets that you create need to use IP ranges outside of 10.128.0.0&#x2F;9 range. </p>
<p>Alternatively, you can also create what’s called a custom mode network. When a custom mode network is created, it’s created with no subnets at all. In practice, you would typically deploy custom mode networks when you need more control over the subnets and IP ranges that are provisioned within them. </p>
<p>In the upcoming demonstration, I’m going to show you how to deploy a custom mode network. After <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploying the network</a>, I’ll show you how to create a single subnet within the network.</p>
<h1 id="DEMO-Creating-a-VPC-with-Subnets"><a href="#DEMO-Creating-a-VPC-with-Subnets" class="headerlink" title="DEMO: Creating a VPC with Subnets"></a>DEMO: Creating a VPC with Subnets</h1><p>So, what we’re going do here is create a custom mode <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">network</a>. To create our custom mode network, what I’m going to do here is browse to the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/vpcs-and-subnets/">VPC</a> networks page. </p>
<p>From here, all I need to do is click the CREATE VPC NETWORK link here, and this begins the process. I’m just going to provide a name here for my network, and then what I’ll do is I’ll tell GCP that I want to create a custom network by choosing Custom for the Subnet creation mode. </p>
<p>Now, what I need to do here in the New subnet section is specify my subnet configuration. So, what I’m going to do here is provide a name for the subnet, and then select a Region, and what I’ll do is, I’ll just set this Region to us-central. </p>
<p>I’m going to provide a primary IP address range for my subnet, and what I’m going to use here is 192.168.0.0&#x2F;16. Now, I don’t need a secondary IP address range for this exercise, so I’ll leave this alone. </p>
<p>Now, if I enable Private Google access for the subnet, any GCP, VM instances that I deploy, will only be able to use internal IP addresses only. They won’t be able to have external IP addresses. So, for this exercise, I’m going to leave Private Google access disabled. </p>
<p>I’m also going to leave the Flow logs disabled as well. </p>
<p>Now, I’ll go ahead and click Done here, and what I’ll do is I’ll leave the Dynamic routing mode set to Regional dynamic routing, which is the default setting. In this mode, routes to on prime resources that are learned by a given Cloud Router in the VPC network, only apply to the subnets in the same region as the Cloud Router. Setting a DNS server policy provides me with access to name resolution servers that are provided by GCP in a VPC network with inbound forwarding. </p>
<p>Now, this DNS server policy is an optional setting that I don’t need to configure for this exercise, so I’ll leave it set to No policy. At this point, I can click Create to deploy my custom VPC network. Now, once my VPC network is created, I can view it’s properties. We’ll go ahead and select it here, and from here I can see the details of my new custom network. </p>
<p>So, with that said, you now know how to deploy a custom mode VPC network on Google Cloud Platform.</p>
<h1 id="Ingress-and-Egress-Firewall-Rules-for-a-VPC"><a href="#Ingress-and-Egress-Firewall-Rules-for-a-VPC" class="headerlink" title="Ingress and Egress Firewall Rules for a VPC"></a>Ingress and Egress Firewall Rules for a VPC</h1><p>GCP firewall rules are used to allow or deny traffic to and from VM instances, based on your security needs. Once configured and enabled, GCP firewall rules are always enforced, which means deployed instances are protected, regardless of their OS, configuration, or even startup status. </p>
<p>It’s worth noting that every <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/vpcs-and-subnets/">VPC</a> <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">network</a> actually functions as a distributed firewall. That said, although firewall rules are defined at the network level, connections to instances are actually allowed and denied on a per-instance basis. As such, GCP firewall rules essentially exist between instances and networks, as well as between individual instances within the same network. </p>
<p>Whenever you create GCP firewall rules, you need to specify a VPC network, along with settings that define what the rule is supposed to do. The settings that you configure will allow you to target specific types of traffic, based on protocols, sources, destinations, and ports. </p>
<p>There are three ways to create and modify GCP firewall rules. You can perform these functions through the Google Cloud Platform Console, the gcloud command line tool, and via REST API. </p>
<p>Anytime you create or modify a firewall rule, you can also specify the distinct instances to which the rule should apply. You can do this by using the target component of the rule that you’re defining. </p>
<p>In the next lesson, I’m going to show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/ingress-and-egress-firewall-rules-for-a-vpc/">create an ingress firewall</a> for a VPC network.</p>
<h1 id="DEMO-Creating-an-Ingress-Firewall-Rule-for-a-VPC"><a href="#DEMO-Creating-an-Ingress-Firewall-Rule-for-a-VPC" class="headerlink" title="DEMO: Creating an Ingress Firewall Rule for a VPC"></a>DEMO: Creating an Ingress Firewall Rule for a VPC</h1><p>Welcome back. In this demonstration, we’re going to walk through the process of creating an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/ingress-and-egress-firewall-rules-for-a-vpc/">Ingress Firewall Rule for the VPC network</a> that we created earlier. </p>
<p>So, let’s get started by going to the Firewall rules page in our Google Cloud Platform console. Now, to get there, what I need to do is, browse to VPC network, under the Networking section, and then from here, click on Firewall rules. </p>
<p>Now, from here, what I need to do is, click on Create Firewall Rule, and this begins the process. Now, let’s give our firewall rule a Name, and then specify the network where the firewall rule is going to be implemented. I’ll call my firewall rule, rdp-in, and what I’m going to do is apply it to my testnetwork. </p>
<p>What we need to do here is specify the priority of the rule that we’re deploying. The lower the number, the higher the priority, the higher the number, the lower the priority. For this exercise, I’m going to leave it at the default setting of 1000. </p>
<p>Now for this rule, I’m going to choose Ingress as the direction of traffic, because I want to allow rdp from my workstation IP. </p>
<p>Obviously, we want to choose Allow as the action on match, and then we need to specify the Targets of our rule. </p>
<p>Now what I’m going to do here, is select All instances in the network. Now what this does, is ensure that this rule applies to all instances that are eventually connected to this network. We’ll <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploy</a> a VM later to this network, so I want this Ingress rule to apply to it when it’s deployed. Now, with that said, what I could do here, if I wanted to, is instead, set the rule to apply to specific instances by target tag. This would allow me to specify which instances the rule would apply to. </p>
<p>For this exercise, we’re applying the rule to all instances, so there’s no need to do this. What we need to do next here, is specify the Source filter. In the Source filter dropdown, I can specify an IP address range, source tags, or even in some cases, a service account. I’m going to leave this set to IP ranges, since I’m going to specifically allow traffic from the IP of my workstation that I’m working from. For this exercise, I’m going to browse to whatsmyip.org to check the public IP of my workstation. </p>
<p>What we’ll do here is, get my public IP address, and bounce back over to our portal here. We’ll put my public IP in the Source IP ranges field. Now, when I do this, I need to use the CIDR notation. So what I had to do is append the &#x2F;32 to my IP address. At this point, I need to define the protocols and ports to which my new rule is going to apply. In this case, I’m going to specify a destination port of TCP 3389, so I can allow rdp to any VM instances I deploy later. So we’ll select tcp, and then we’ll specify 3389. Now with that set, I can leave the rest of the options at their defaults, and then click Create to deploy my Ingress rule. </p>
<p>So now that I have my Ingress rule deployed, when I spin up my VM later on and connect it to my subnet, the VM will be protected by my new rule.</p>
<h1 id="Creating-a-VPN-Connection"><a href="#Creating-a-VPN-Connection" class="headerlink" title="Creating a VPN Connection"></a>Creating a VPN Connection</h1><p>In Google Cloud Platform, Cloud VPN supports several types of networks. These <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">supported networks</a> include <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/vpcs-and-subnets/">VPC</a> custom networks, auto-mode networks, and legacy networks. </p>
<p>When creating a VPN in GCP, you should be sure to adhere to Google’s best practices. These best practices include using VPC networks instead of legacy networks and using custom mode VPC networks instead of auto-mode networks. </p>
<p>Because legacy networks do not support subnets, when you provision a legacy network, the entire network will use a single range of IP addresses. Legacy networks also cannot be converted into VPC networks if needed. </p>
<p>When it comes to custom mode VPC networks, these networks provide you with full control over the range of IP addresses that are used by their subnets. It’s also important to note that when you connect two VPC networks using Cloud VPN, at least one of the networks needs to be a custom mode network. This is because auto-mode networks use the same range of internal IP addresses for their subnets. This would cause an overlap problem if you didn’t use at least one custom mode network when creating the VPN. </p>
<p>When configuring a VPN, you’ll have a few different routing options. While classic VPN supports dynamic and static routing options from VPN tunnels, HA VPN requires dynamic routing. </p>
<p>Dynamic routing, by the way, uses the Border Gateway routing Protocol, otherwise known as BGP, and it uses a Cloud Router to automatically manage the exchange of routes using the BGP protocol. </p>
<p>The dynamic routing mode of a VPC network controls the behavior of all its Cloud Routers and it determines whether or not the routes learned from peer networks are only applied to GCP resources in the same region as the VPN tunnel or if they’re applied in all regions. </p>
<p>Static routing comes in two flavors: policy-based and route-based. If you can’t use BGP or dynamic routing or HA VPN, you should consider the static routing option. When using policy-based routing, the local IP ranges and remote IP ranges are both defined as part of the tunnel creation process. However, when you create a route-based VPN, you only need to specify the list of remote IP ranges. </p>
<p>In the next lesson, I’ll show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-how-to-create-a-vpn/">create a VPN</a> between a Google VPC and an external network, using Cloud VPN.</p>
<h1 id="DEMO-How-to-Create-a-VPN"><a href="#DEMO-How-to-Create-a-VPN" class="headerlink" title="DEMO: How to Create a VPN"></a>DEMO: How to Create a VPN</h1><p>Welcome back. In this lesson, we’re going to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/creating-a-vpn-connection/">create a classic VPN gateway</a> and a tunnel using static routing. For this exercise, we’ll <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploy</a> a policy-based VPN. </p>
<p>So to configure our VPN, what I need to do is browse to the VPN page from my Google Cloud Platform console. I can actually find this page under Hybrid Connectivity. </p>
<p>Once I’m here, I can begin the deployment process by clicking create. </p>
<p>Now, from this Create a VPN page, I can create either a HA VPN or a classic VPN. For this particular exercise, I’m going to create a classic VPN. </p>
<p>From here, I need to configure my VPN gateway. A VPN gateway serves as an endpoint for a VPN tunnel. I need to give it a name, a description, and I need to specify which GCP network to deploy the gateway and tunnel to. And since cloud VPN gateways and tunnels are regional objects, I also need to tell GCP which region the gateway needs to be deployed to. </p>
<p>I should also point out that for best performance the gateway and tunnel should be located in the same region as the GCP resources that will be accessed over the tunnel. </p>
<p>What I also need to do here is create a new external IP address for my gateway. I could also select an existing external IP address if I already had one created. </p>
<p>So let’s get started. What I’m going to do here is call my gateway, myvpngateway. </p>
<p>I’m going to leave the description blank for this exercise. And what I’m going to do is deploy my gateway to the default region here. I’m going to deploy my gateway to my test network, so I need to select it from the Network dropdown. </p>
<p>Since I don’t have an existing external IP address to associate with my gateway, let’s go through the process here to create one. </p>
<p>With this information supplied, I can now create my tunnel. </p>
<p>To create the tunnel, I need to provide more information. I need to give my tunnel a name and a description. I also need to tell my tunnel what the public IP is for the remote side of my VPN. For IKE version, I need to choose a version that’s supported by both the GCP side of the tunnel and the remote side. IKEv2 is the preferred option as long as the remote side supports it. </p>
<p>The pre-shared key is a text value that’s used for authentication. Whatever I provide here for the pre-shared key needs to also be provided on the other side of the VPN connection. </p>
<p>So what I’ll do here is I’ll call my tunnel, myvpntunnel. As I did with the gateway, I’ll leave the description blank. The remote peer IP address is 40.86.78.94. This was taken from the VPN device on the foreign side of my VPN tunnel. </p>
<p>Since my Azure VPN, which is what I’m using on the foreign side, supports IKEv2, I’ll choose IKEv2 here. And then I need to provide a pre-shared key. What I’d need to do with this pre-shared key is provide it to the admin on the foreign side of the VPN tunnel, so the admin on the foreign side could configure the VPN on that side as well. </p>
<p>Without matching keys, the VPN wouldn’t come up. Now, since I’m creating a policy-based tunnel, I need to select policy-based here. This is my routing option. If we hover over Routing options here, we can see that BGP provides the easiest to configure as well as the most resilient IPsec VPN configuration. However, this won’t work if the foreign device doesn’t support it. We also have route-based options and policy-based. For this demonstration, we’re using policy-based. </p>
<p>The remote network ranges that I add here are those networks on the remote side of the VPN that I want to access over the VPN. For local IP ranges, I need to select the local subnetworks that I want to grant access to over the VPN. I can either specify local IP ranges or select local subnets. So I’ll go ahead and select my default subnet here for my test network. Now, after click done here and with my gateway and tunnel information complete, I just have to create to deploy the VPN. Now, it’s important to note here that the process I just followed on the GCP side of the VPN also needs to be followed in some fashion on the remote side as well. That’s because both sides of the VPN will have different configuration processes. For example, if the remote side is an Azure VPN gateway, you’d have to follow the Azure VPN setup process to configure that side of the VPN. </p>
<p>If the remote side is a Cisco ASA, you’d have to follow the Cisco documentation to configure the Cisco ASA device. Since this is a GCP course, I’m not going to get into the configuration of the remote side of the VPN. I just wanted to make sure that you knew how to configure the GCP side, since that’s what’s covered on the exam.</p>
<h1 id="Launching-a-Compute-Instance-Using-Cloud-Console"><a href="#Launching-a-Compute-Instance-Using-Cloud-Console" class="headerlink" title="Launching a Compute Instance Using Cloud Console"></a>Launching a Compute Instance Using Cloud Console</h1><p>When you create a VM instance from a boot disk image, you can use either a regular image or a Shielded VM image. </p>
<p>Shielded VM images provide advanced security features like UEFI-compliant firmware, Secure Boot, and vTPM-protected Measured Boot. </p>
<p>There are several ways to create a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">compute instance</a> from an image. You can create an instance from a public image, a custom image, or even from an image that’s been shared with you. You can also create an instance from a snapshot or from a container image. Let’s talk a little bit about each option. </p>
<p>As I mentioned, instances can be provisioned from public images. These public images are provided by Google, different open-source communities, and even some third-party vendors. By default, all GCP projects have access to these public images. As such, they can be used to create compute instances. </p>
<p>While public images are available to all projects, a custom image belongs only to a specific project. To use a custom image to create an instance, you first must create the custom image. </p>
<p>In cases where another user has shared an image with you, you can use the shared image to create a new compute instance. Another way to provision a compute instance is to use a snapshot. For example, if you backed up a boot persistent disk with a snapshot, you could then use the snapshot to create a new compute instance. </p>
<p>Yet another way to provision a compute instance is to use a container image. To deploy and launch a container on a Compute Engine instance, you’d need to specify a container image name along with any optional configuration parameters. The Compute Engine then creates the compute instance using the latest version of the Container-Optimized OS public image, which has Docker installed. The container is then launched by the Compute Engine when the VM starts. </p>
<p>In the next lesson, we’re going to walk through a demonstration that shows you <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-how-to-launch-a-compute-instance-in-cloud-console/">how to launch a compute instance in Cloud Console</a>.</p>
<h1 id="DEMO-How-to-Launch-a-Compute-Instance-in-Cloud-Console"><a href="#DEMO-How-to-Launch-a-Compute-Instance-in-Cloud-Console" class="headerlink" title="DEMO: How to Launch a Compute Instance in Cloud Console"></a>DEMO: How to Launch a Compute Instance in Cloud Console</h1><p>Welcome back. In this lesson, what we’re going to do is <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/launching-a-compute-instance-using-cloud-console/">launch a compute engine instance</a> using a custom network configuration. We’re going to connect this compute engine instance to the virtual network that we deployed earlier. To begin the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deployment</a>, what we need to do is browse to the VM instances page under compute engine over here on the left. </p>
<p>Now, from here, what we want to do is click the Create button. I’ll call my instance vm1. And you’ll notice, if I try to use capital letters here, it’s going to tell me that the name must be lowercase, numbers, and hyphens. Now over here on the right side, I can see the monthly estimate for my VM instance as configured, and then in these two dropdowns, I can specify the region, which is the geographical location where the VM is going to run, and the zone, which is an isolated location within that region. Now, what the zone does, as you can see here, is determine what computing resources are available and where data is stored and used. Now, in the machine type box, here, I can customize my VM. I can select the CPUs and memory that my VM should use. </p>
<p>What I’m going to do here is select two CPUs and 7.5 gig of memory. What this is, is the N1-standard-2 size. And when I make that change, I can see my monthly estimate changes as well. Now, if I hover over the icon next to container, I can see that I can deploy a container to this VM instance by using a container-optimized OS image. I’m not going to do that for this lesson here. What I am going to do, is under boot disk, here, I’m going to change this boot disk. We can see right now that the current boot disk is a 10 gig standard persistent disk running the Debian&#x2F;GNU Linux 9 image. What I’m going to do here, is change this. And for this exercise, we’re going to deploy a Windows Server 2016 Datacenter image. So, we’ll go ahead and scroll down here, and we can see Windows Server 2016 Datacenter. So, we’ll go ahead and select it here. And then down here, we can select the boot disk type and the size. If we select the dropdown here, we can select a standard persistent disk or an SSD. I’ll leave this standard persistent here and 50 gig will suffice for this exercise. So, we’ll click Select. </p>
<p>Now, as we scroll down the page here, we have an option here for identity and API access. If we hover over the icon next to identity and API, we can see that any applications that run on the VM, they use the service account to call Google Cloud APIs. Now, from here, we can select the service account that we want to use, along with the level of API access that we want to allow. For this demonstration, we’re going to leave this at its default setting. We don’t need to do anything special here. In the firewall section, what we can do is add tags and rules to allow specific network traffic to and from the internet. What I’m going to do is allow HTTP traffic in case I want to do some kind of demonstration later on, using this VM. Now, to customize the configuration of the VM, regarding the network we’re going to connect to, any additional NICs, any additional disks, et cetera, what we can do here is select the management, security, disks, network, and sole tenancy dropdown here. </p>
<p>Now, from here, under Management, we can provide a description for our VM, any labels for our VM, and if we hover over the icon for labels, we can see that you use them to organize projects and to kind of group resources together. We’re not going to do any labeling or description here and then we can also specify deletion protection. What deletion protection does is ensure that a VM can’t be deleted. You can see here if we check the box, nothing really changes. This is just something that happens on the underside or under the covers, so to speak. So, we’ll uncheck this box here. We can also specify metadata for our VM and then under availability policy, we can specify premptability, on-host maintenance, and automatic restart. Now, that being said, a pre-emptible VM, although it’s going to be cheaper, will only last for 24 hours. And, essentially, it can be terminated if system demands need that. This option might be good for development environments or quick testing. And then of course, the on-host maintenance and automatic restart options relate to infrastructure maintenance that’s performed within the Google platform. I’m going to leave these options at their defaults. But, if we select the dropdown, you can see we can either migrate VM instances or terminate them in the event that they need to go down for any kind of infrastructure maintenance. The automatic restart is either on or off. Essentially, automatic restart tells the compute engine to automatically restart any VM instances if they’re terminated for non-user initiated reasons. Typically, this means maintenance events or hardware failures. We’ll leave these options at their defaults and then switch over to security, here. </p>
<p>We can see, here, we have options for shielded VM. Now, you can see here that they’re turned off here. They’re not even enabled. Now, if we hover over shielded VM here, we can see that these features include trusted UEFI firmware, and also options for secure boot, TPM and integrity monitoring. We can also specify SSH keys, which we’re not going to do here. We’ll do this at a later time in another lesson. And then, under disks, we can specify deletion rules for the boot disk. Essentially, we can tell Google Cloud Platform to delete the boot disk when the instance is deleted. This is on by default, which makes sense. </p>
<p>Typically, you don’t want the boot disk to sit around if you’ve killed off the instance. And then we can also specify encryption options. We can allow Google to manage our keys. We can select customer-managed keys, or we can select customer-supplied keys. We can also configure additional disks here. If we have an existing disk we want to attach, we can attach it here, or we can add a new disk. So, what I’ll do here is add a new disk here, and I’ll just leave the naming set to its default disk1. And then, under the type, here, we have a couple different options. We can use a local SSD scratch disk, a persistent SSD disk, or a standard persistent disk. </p>
<p>If we hover over type, here, we can see that what this tells us is that storage space is obviously less expensive for a standard persistent disk. SSD persistent disks are better for random IOPs or for streaming throughput, with lower latencies. What we’ll do is, we’ll leave this set to standard persistent disk, and then, obviously, for source type, we can use either an image or we can use a blank disk. We’re going to use a blank disk here, and for mode, we’ll leave the option at read&#x2F;write. We’re not going to make a read-only disk. Now, the deletion rule, here, is a little different than the boot disk. By default, the deletion rule, here, says to keep the disk when you delete the instance. What I want to do here is delete my disk if we delete the instance from my lab environment. </p>
<p>Now a good reason to leave this default of keep disk is that for example, if you have a file server you’ve deployed, what you want to do is make sure than when you delete the instance, that you don’t delete any data that may be critical. So, if you have a separate disk that you’ve provisioned to store shares and whatnot, if you delete the instance, you may want to keep that data. So, if you leave this when deleting instance deletion rule set to keep disk, you don’t have to worry about losing that data if you delete the instance as part of a migration or whatever kind of maintenance you’re going to do. Of course, here, for size, we can specify the size of the disk. </p>
<p>I’m going to change this to 10 gigabytes. And when I do that, it tells me that this may result in reduced performance because I’ve entered a volume of less than 200 gig. This is a lab environment, and a demonstration, so I’m not really worried about performance here. And then as you can see here, we also have the encryption options that we were offered for our boot disk. We’ll leave this at the default Google Managed Key. </p>
<p>And then what we can do is click Done to provision the disk here. Now, under networking, we can assign network tags, or we can set a custom host name for this instance. We’ll leave the default here, but more importantly, this is where we can either add new network interfaces or edit the existing ones. So, for example, the default network interface is called default-default with an address of 10.128.0.0. </p>
<p>What I’m going to do is connect this to my test network, which is a 192 network. So, I select the dropdown here, and then select the test network. And then we can see it’s automatically assigned to the default <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/vpcs-and-subnets/">subnet</a> of that network, and then from here, I have an option to specify a primary internal IP address. An ephemeral IP address won’t change when you restart the instance. However, deleting and recreating an instance will change its internal IP. </p>
<p>Now, if we select the dropdown, here, we have a couple different options. We have an ephemeral automatic, an ephemeral custom, or we can reserve static internal addresses. If we hover over the icon, here, we can see that if we select the ephemeral automatic, what Google is going to do is assign an address from the subnetwork range, or, if we select ephemeral custom, we can manually enter an address. Now, if we select the third option, which is a static internal IP address, what this will do is allow our instance to keep its IP even when it’s deleted and recreated. So, we’ll go ahead and we’ll reserve a static internal IP address. And then, what we have to do, when we do this, is give the IP address a name. </p>
<p>So, what I’m going to do is call this privateIPVM1. So, that tells me that it’s a private IP for my VM1 virtual machine. We can see it’s already associated with the default subnet and then we can either assign it automatically or let me choose. So, let’s let me choose, here, and what I’ll do is, I’ll give it an address of 192.168.1.25. That falls within the range of my subnet. So, we’ll go ahead, and we’ll reserve that IP. </p>
<p>Now, for the external IP, what we can do is create an external IP address that’s associated with my instance. What we can do is either use an ephemeral address, or we can select none. We can also select an unused static address. Now, if we select none, we’re not going to have external internet access. So, what I can do here, is I’ll just choose ephemeral. </p>
<p>Now, the network service tier gives us a couple different options. We can choose premium or standard. What this tier does is allow you to optimize network quality and performance. I don’t need premium performance here for my lab environment, so I’ll select standard. We don’t need to do any IP forwarding, nor do we need to create a public DNS pointer record, so we’ll just click Done, here. </p>
<p>If I wanted to create a new network interface, I could click add, here, and create a second NIC for my VM. I don’t need that for this lab environment, so I’ll cancel here. Now, if we select sole tenancy, we can see, here, we can specify tenancy affinity labels. We don’t need to do that here. So, what we can do now, with our VM configured, we can look at the monthly estimate here, and suddenly the cost of my VM has gotten a little more expensive than what it was when we started. But, to provision our VM, we now scroll down and click create. What this is going to do is create a VM called VM1 on my test network, with the options that I’ve chosen throughout this configuration process. </p>
<p>So, with that said, you can see that lots of configuration can be done right from within the VM deployment wizard. You can pretty much deploy your VM with any combination of configuration options that you need.</p>
<h1 id="DEMO-Launching-a-Compute-Instance-Using-Cloud-SDK"><a href="#DEMO-Launching-a-Compute-Instance-Using-Cloud-SDK" class="headerlink" title="DEMO: Launching a Compute Instance Using Cloud SDK"></a>DEMO: Launching a Compute Instance Using Cloud SDK</h1><p>While it’s very easy to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/launching-a-compute-instance-using-cloud-console/">launch a compute instance using the Cloud Console</a>, it’s also quite easy to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">launch a compute instance</a> using the Cloud SDK or G Cloud. In this demonstration, I’m going to show you how to launch a compute instance in GCP using the Cloud SDK. </p>
<p>What we’re going to do here is launch a basic VM with a default configuration. In doing so, you’ll get to see which switches and commands are absolutely necessary to deploying a compute instance using G Cloud. </p>
<p>As you can see on your screen here, I’m logged into my Google platform. To bring up the Cloud SDK, I simply click the Activate Cloud Shell icon along here at the top right corner. What I’ll do here is expand this. </p>
<p>From here, in order to launch a default compute instance, I’m going to use the G Cloud Compute Instances Create command. </p>
<p>By running the G Cloud Compute Instances Create command and specifying “my new VM 3,” we’re going to deploy an instance called My New VM 3. By specifying the zone switch, we’re telling GCP to deploy the instance in the US Central 1-A Zone. </p>
<p>Once I hit Enter, the deployment begins. Since I haven’t specified any network information, disc information, or OS information, GCP is going to provision a VM with default settings. In this case, my VM is going to be created as an M1 Standard-1 Machine type with a single nick. The image for my VM is going to be debian by default. If I switch over to my portal here and take a look, I can see My New VM 3 being deployed. Now, if I wanted to deploy an instance with a bit more customization, I could run the same command, but with additional switches to find. However, before doing that, I need to run the G Cloud Compute Images List command to see what public images are available. </p>
<p>As you can see on your screen, we have quite a few images available to us here. I can also see the different projects and families for each image as well. With this information, I can specify the Image Switch and the Image Project Switch with the G Cloud Computer Instances Create command to specify which OS I want my VM to run. What I’ll do here: I’ll open a separate window to make things a little easier to see. Now, as you can see here, the command that I’m going to run creates a new VM called My New VM 4 and uses the Windows Server 2016 DC image under the Image Project Windows Cloud. What we’re going to do is deploy the VM into the US Central 1-A Zone. </p>
<p>So we’ll go ahead and hit Enter here. And if we go up into our Instances pane here and refresh, we can see My New VM 4 shows up, and starts to deploy. For a complete list of all switches that you can use when deploying a compute instance with G Cloud, visit the URL that you see on your screen. </p>
<p>So, while we’re going to call it a wrap for this demo, I encourage you to experiment with many different switches in your own lab environment. You never know which switch may make an appearance on an exam.</p>
<h1 id="Assign-Disks-to-a-Compute-Instance"><a href="#Assign-Disks-to-a-Compute-Instance" class="headerlink" title="Assign Disks to a Compute Instance"></a>Assign Disks to a Compute Instance</h1><p>When <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">adding</a> storage to a compute instance, you have a choice of a few different disk types. You can add zonal persistent disks, regional persistent disks or you can add local SSDs. </p>
<p>Zonal persistent disks are available as either standard hard disk drives or solid state drives. The compute engine actually manages the hardware underneath the zonal persistent disks so they can be added and resized without the need to deal with striping or redundancy. I should also note that unless you’re creating a new zonal persistent disk from an image, the disk will start with no data or file system. That being said, you’ll have to format any new disk after you attach it to an instance. </p>
<p>Regional persistent disks are like zonal persistent disks but different in a few ways. For example, regional persistent disks cannot be used as boot disks. In addition, regional persistent disks support force attachment to another VM instance in the event of a zonal failure. It’s also important to note that you can create a regional persistent disk from snapshots but not from images. Local SSD disks, unlike persistent disks, are physically attached to the server that hosts the virtual machine instance. This configuration offers superior performance to persistent disks, higher IOPS than persistent disks, and very low latency when compared to persistent disks. </p>
<p>Earlier on, you learned how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-how-to-launch-a-compute-instance-in-cloud-console/">deploy a compute instance</a>. During the demonstration, I showed you how to add a second disk to the VM. The process for adding a disk to an insisting VM is essentially the same as it is when provisioning a new instance. So I’m not going to drag you through another demo just to show you how to add a disk to an existing instance. Just refer to the VM deployment demo to see how to add a disk to a VM instance.</p>
<h1 id="Assign-an-Availability-Policy-to-a-Compute-Instance"><a href="#Assign-an-Availability-Policy-to-a-Compute-Instance" class="headerlink" title="Assign an Availability Policy to a Compute Instance"></a>Assign an Availability Policy to a Compute Instance</h1><p>Just like any other cloud platform, Google Compute Engine performs regular maintenance on its underlying infrastructure. To ensure that your GCP-based solutions remain up during these maintenance events, you can <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">configure</a> instance availability options that control the behavior of VM instances when these types of maintenance events occur. </p>
<p>Certain maintenance events that occur will sometimes require Google to move a VM off the host that’s undergoing maintenance. When this is necessary, Compute Engine will automatically handle the scheduling behavior of these instances. If an instance’s availability policy is configured to use live migration, Compute Engine will live migrate the VM instance during maintenance in order to prevent any applications that are running on that instance from experiencing a disruption during the maintenance event. Now that said, you can also opt to terminate your instances during these types of maintenance events instead of live migrating them. If you opt to do this, any apps that are running on those instances will obviously experience an outage. </p>
<p>The availability policy assigned to a compute instance will determine how the instance behaves when a maintenance event requires Google to move the instance to another underlying host. To configure an instance’s availability policy, you need to configure two settings. You need to set the instance’s maintenance behavior and you need to configure the instance’s restart behavior. An instance’s maintenance behavior controls whether or not the instance is live migrated or terminated whenever there’s a maintenance event. </p>
<p>The restart behavior controls whether or not the instance automatically restarts if it crashes or gets terminated. By default, maintenance behavior is set to live migrate. However, if you prefer to terminate instances during maintenance events, you can change the behavior to terminate the instance during maintenance events instead. If you choose to terminate an instance during maintenance, you can either opt to leave the instance terminated or you can set it to restart automatically after termination. If you choose to do this, what Google Compute Engine will do is tell the instance to shut down. It will then wait a short period of time to ensure that the instance shuts down cleanly. Google Compute Engine will then terminate the instance and then restart it on hardware that’s not part of the maintenance event. </p>
<p>In the next lesson, I’ll show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-working-with-availability-policies/">set the availability policy of an existing VM instance</a>.</p>
<h1 id="DEMO-Working-with-Availability-Policies"><a href="#DEMO-Working-with-Availability-Policies" class="headerlink" title="DEMO: Working with Availability Policies"></a>DEMO: Working with Availability Policies</h1><p>In this demonstration, I’m going to show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/assign-an-availability-policy-to-a-compute-instance/">change the availability policy</a> for an existing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">compute instance</a>. Although this can be done via the console or G-Cloud or via A-P-I, I’m going to do it via the console in this demonstration. So to change the availability policy for my existing instance, I need to browse to the V-M instances page in the console. </p>
<p>From here I just need to click on the instance that I want to edit, and then from the instance details page that I am taken to, I need to click the edit button at the top of the page. Scrolling down, under availability policies, I can update the policy for the instance as needed. For this example, I’ll set my policy to terminate the V-M on host maintenance, but I’ll leave the automatic restart option set to on. To save my new availability policy settings, I just have to click save. </p>
<p>Now with these settings, what will happen is, my instance will terminate and restart on new hardware automatically whenever a maintenance event occurs on the underlying hardware.</p>
<h1 id="Autoscaled-Managed-Instance-Groups"><a href="#Autoscaled-Managed-Instance-Groups" class="headerlink" title="Autoscaled Managed Instance Groups"></a>Autoscaled Managed Instance Groups</h1><p>Whenever you’re <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploying an application</a> that may or may not experience usage spikes, it’s a good idea to leverage a managed instance group. What a managed instance group does is allow you to operate an application across multiple identical VMs. To achieve robust scalability and availability, you can leverage managed instance group features that include things like autoscaling, autohealing, regional deployment, and even auto-updating. When you take advantage of an autoscaled managed instance group, you have the ability to automatically add or delete instances as the load on the application increases or decreases. </p>
<p>Hosting an application on an autoscaled managed instance group allows that application to gracefully handle traffic increases. It also helps reduce costs because the number of instances is reduced when the load is no longer there. In the next lesson, we’ll walk through the process of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-creating-an-autoscaled-managed-instance-group-using-an-instance-template/">creating an autoscaled managed instance group</a> from an instance template.</p>
<h1 id="DEMO-Creating-an-Autoscaled-Managed-Instance-Group-Using-an-Instance-Template"><a href="#DEMO-Creating-an-Autoscaled-Managed-Instance-Group-Using-an-Instance-Template" class="headerlink" title="DEMO: Creating an Autoscaled Managed Instance Group Using an Instance Template"></a>DEMO: Creating an Autoscaled Managed Instance Group Using an Instance Template</h1><p>In this demonstration, I’m going to show you how to create an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/autoscaled-managed-instance-groups/">autoscaled managed instance group</a> from an instance template. However, before I create the autoscaled managed instance group, I need to first create an instance template. </p>
<p>To create an instance template, what I need to do is browse my GCP Console and then go to the Instance Templates page. This is found under the Compute Engine page. From here, I simply click Create Instance Template. For this exercise, I’m going accept the default settings. My machine type will be n1-standard-1, my image will be a latest Debian image, actually, it’ll be the latest Debian image. My boot disk is going be named after my instance name. </p>
<p>Because this is a default image, the template is going to use the default VPC <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">network</a> and an ephemeral external IP address will be assigned. With my template configuration set, what I can do is scroll down and click Create at the bottom to create the template that I’m going to use for my autoscaled managed instance group. </p>
<p>Now, with my instance template created, I can now create my autoscaled managed instance group. To do this, what I need to do is browse to the Instance Groups page in the GCP Console, and then form here I can click create an instance group. I’ll call my managed instance group here mymig for managed instance group and then I need to tell GCP which zone to locate the group in. So I’m going to select the default here which is us-central1 and us-central1a. </p>
<p>Now we can see here on the left-hand side I’m actually creating a managed instance group versus an unmanaged instance group. Now, under the Instance Template dropdown, I can select my instance-template-1 that I just created earlier. Since we’re creating an autoscaled instance group, we’re going to leave autoscaling turned on. And under Autoscaling Policy, we’ll base our autoscaling on CPU usage and then what we’ll do is leave the defaults here for the target CPU usage. If we hover over the icon here, what this is going to do is tell me that autoscaling will add or remove instances in the group to maintain this particular level of CPU usage on each instance. </p>
<p>Under minimum and maximum number of instances, this is, as it states, the minimum number of instances in my managed instance group and the maximum number of instances in my group. Now, if I hover over the icon here for maximum, we’ll see that this is indeed the largest number of VM instances that’s allowed, even if the target is exceeded. On the flip side, if we hover over minimum number of instances, we can see that this number here is the least number of VM instances that the group will contain even if the target is not met. So we’re always going to have one instance and we’re never going to have more than 10 instances. </p>
<p>Now, if we hover over the cool down period here, we can see that what this is, this is the number of seconds to wait before collecting information from a new instance. Now, essentially what this should be is at least the amount of time it takes to initialize the new instance when it spins up. We’ll leave this at the default here. We’re not going to do any auto healing here. We’ll leave this turned off by default and now to create my new autoscaled managed instance, I can simply click Create. </p>
<p>After a few minutes, I’ll see my new autoscaled managed instance group up and running in my coil here. And you can see we get the green check box telling me that my instance group is ready to go. So let’s call it a wrap here and I’ll see you over in the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-load-balancing-http-traffic-with-a-load-balancer/">next lesson</a>.</p>
<h1 id="DEMO-Load-Balancing-HTTP-Traffic-with-a-Load-Balancer"><a href="#DEMO-Load-Balancing-HTTP-Traffic-with-a-Load-Balancer" class="headerlink" title="DEMO: Load Balancing HTTP Traffic with a Load Balancer"></a>DEMO: Load Balancing HTTP Traffic with a Load Balancer</h1><p>Welcome back. Another skill that Google tests for on their exams is the ability to effectively load balance applications, using various types of load balancers available on GCP. What we’re going to do here is configure some basic load balancing for IIS across two different VM instances. </p>
<p>In this demonstration, we’ll configure TCP load balancing to publicly load balance port 80 across two IIS webservers, called WEB1 and WEB2. Now, what I’ve done ahead of time to prepare for this demo is spin up the two IIS servers. Each IIS instance displays the name of the web server when you browse to the instance. I’ve also ensured that the existing firewall in GCP allows port 80 to reach my VMs. </p>
<p>To get started with our load balancer configuration, let’s browse to my instances. If I browse to the IP for each, I can see that Web1 displays WEB1 on the IIS page, and I can see Web2 displays WEB2 on the page. This tells me that IIS is working as it should on each specific instance. </p>
<p>So, now that we know IIS is good on each instance, let’s get started on the load balancer <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deployment</a>. To begin the deployment process, what I need to do is browse to the Load Balancing page, now this located here under Network Services. From here, I can begin the setup by clicking create load balancer. Now, when we do that, we’re presented with three options. We can deploy a layer-7 HTTPS load balancer, a layer-4 TCP load balancer, or a layer-4 UDP load balancer. </p>
<p>For this exercise, we’re going to deploy the one in the middle, which is a TCP load balancer, so let’s click Start configuration to get rolling here. As we get started here, we can see that we have a couple different options for this load balancer. We can make the load balancer internet facing, or we can load balance only between VMs in my network. What we’re going to do in this exercise is create an internet-facing load balancer. Another choice that I need to make here is whether or not I make my load balancer span multiple regions or if I just want to place the backend in a single region only. Since both of my VMs are in the same region, we’ll choose the single region option and then click continue. </p>
<p>At this point, I need to give my load balancer a name, so I’ll call it myloadbalancer. In addition, what I need to do is configure the backend for the load balancer and the front end for the load balancer. The backend configuration specifies what the load balancer will be load balancing, and what load balancing rules it needs to follow. </p>
<p>The front-end configuration is where I define the public IP for the load balancer, and which ports to load balance. So, let’s click Backend configuration. If you look at the name field here, the load balancer name that I already provided shows up and can’t be modified. For my region, I’m going to deploy my load balancer to us-central1. Since I’m load balancing specific instances, rather than <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/autoscaled-managed-instance-groups/">instance groups</a>, I can specify those instances by choosing the select existing instances option, and then selecting my two web servers. We’re not going to use a backup pool here and our failover ratio isn’t really critical, so we’ll leave these at their defaults. </p>
<p>Under Health check, what I need to do is Create a new health check. This health check is used to determine which instances are alive on the backend. It’s what prevents the load balancer from sending traffic to a downed instance. So I’ll create a new health check here and I’ll call it port80alive. I can leave the rest of the settings at their defaults. And then to finish the set up of my backend, I need to click the Save and Continue button. The blue circle with a check mark here tells me that my backend configuration was completed successfully. Now, what I have to do is configure my front end. To start off, I need to give my front-end rule a name, so I’ll call this myfrontend. Now, I’m going to change the network service tier here to standard, since I don’t need premium features for this exercise. And when I do that, it tells me that the standard tier uses the same region as my backend’s which is fine. For the IP here, I want to reserve a static IP address. </p>
<p>I could use an ephemeral address, but that’s likely to cause problems if the address changes later. So, static it is. We’ll call it mylbIP and then we’ll reserve it. Since we’re load balancing port 80 for this exercise, we’ll specify port 80 here in the port box. And then we can click Done. After I’ve done so, I see the blue circle with the check mark that indicates the front-end config is successful as well. From here, I can click the review and finalize option here to ensure my settings are what I need them to be, and then I can click create to deploy the configured load balancer. We’ll give this a few minutes to deploy and get up to speed and then we’ll test it. On the load balancer screen, under the Backend column for the load balancer, we can see a green check mark that indicates the new load balancer is healthy. </p>
<p>So, now that the load balancer is configured, let’s open a browser window and browse to the public IP of our load balancer. We can see that it returns the name of the web server that I was directed to. If I go in and shut down my web1 server here and then try again, we’ll see that this time we’re sent to the other web server. And we can see web2 is now listed. This tells me that load balancing is working as expected. Although I’ve shown you how to provision a TCP load balancer here, there are other options, as I mentioned earlier. </p>
<p>So, be sure to get in and play around with the different load balancer options to get a feel for how they work.</p>
<h1 id="DEMO-Generating-and-Uploading-a-Custom-SSH-Key-for-Instances"><a href="#DEMO-Generating-and-Uploading-a-Custom-SSH-Key-for-Instances" class="headerlink" title="DEMO: Generating and Uploading a Custom SSH Key for Instances"></a>DEMO: Generating and Uploading a Custom SSH Key for Instances</h1><p>When connecting to a Linux VM instance, you’ll sometimes need or want to connect, using a custom SSH key. To connect to a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">GCP compute instance</a> using a custom SSH key, you first need to generate the keypair. This keypair includes the public key that gets added to the compute instance as well as the private key that you use to connect with. What we’re going to do here in this lesson is walk through the process of creating a custom SSH key that we’re going to use to connect to an existing Linux VM that I’ve deployed. </p>
<p>Now, since windows doesn’t offer a built-in tool for generating SSH keys, I’m going to use the PuTTYgen tool to create my keypair. On the screen, here, you can see that we’re going to be working with VM2, which is actually a Linux VM. To create a custom SSH key for this VM, let’s drag my PuttyGen console over from the other screen. </p>
<p>To create a keypair, I just need to click generate here and then follow the instructions for moving my mouse around. Now, I do have to make sure that the key I’m generating is at least 2,048 bits. When I’m done here, my pubic key is shown at the top here. </p>
<p>Now, at this point, I can save my private key and my public key. Now, in the key comment section, what I need to do is replace this existing text with the username for whom the key is going to apply. So I’ll call this vmadmin. I can also provide a passphrase to protect my key if I wanted to. But I’m going to skip that for this exercise. So let me save my private key. And then I’ll save my public key. </p>
<p>Now after I’ve saved my keys, what I want to do is copy the public key from the top of the PuttyGen window, because I’m going to add this to my VM instance. With my pubic and private keys saved, and my pubic key value copied to my clipboard, I can switch back over to my VM here and I can click Edit. If I scroll down to SSH Keys, I can see that I have no SSH keys assigned yet. I’m going to change this by clicking Show and Edit. At this point, I need to paste my public key value into the box here, and then click Save down at the bottom. What this does is store the public key with the VM instance. Before I navigate away from my VM instance, I need to copy the external IP of it, so I can try to connect to it. </p>
<p>With the public key stored and the external IP copied, let’s drag my Putty utility over and try to connect. To connect, what I need to do is copy the external IP address of my instance into the hostname field here. I also need to ensure that SSH is selected here. Now, before I connect, what I need to do is expand SSH down here on the left side and select the Auth option. From here, I can browse to my private key that I’m going to use to authenticate. </p>
<p>At the prompt here, I need to provide the username that I entered in the key comment section when I created the key. If everything works like it’s supposed to, I’m granted access to the VM, like you see here. So that is how you create a key or really a keypair, how you upload the public key to your instance and how you use the private key to connect to that instance using a third-party utility.</p>
<h1 id="Monitoring-and-Logging-with-Cloud-Operations"><a href="#Monitoring-and-Logging-with-Cloud-Operations" class="headerlink" title="Monitoring and Logging with Cloud Operations"></a>Monitoring and Logging with Cloud Operations</h1><p>To monitor VMs, you can use the Ops Agent which collects system and application metrics from virtual machine instances. It then sends these metrics to Cloud Operations monitoring. The agent, by default, collects metrics information on disk, CPU, network, processes, and more.</p>
<p>Now, with all that said, using the Ops agent, although recommended, is only optional. However, without the agent, only some instance metrics can be captured. For example, if all you are interested in is CPU utilization, basic disk traffic information, uptime info, and network traffic, you can get away without using the agent. However, Cloud Operations uses the agent to access additional system resources and application services in VM instances. If you need (or want) this additional information, you need to install the Ops agent. </p>
<p>When using the Ops agent with a Google Compute Engine instance, the agent sends monitoring information to each instance’s associated project. However, it should be noted that for instances without external IP addresses, you need to enable Private Google Access in order to allow the Ops agent to send metrics.</p>
<h1 id="Configuring-a-VM-for-Cloud-Operations"><a href="#Configuring-a-VM-for-Cloud-Operations" class="headerlink" title="Configuring a VM for Cloud Operations"></a>Configuring a VM for Cloud Operations</h1><p>Before installing the Ops agent, you need to be sure that you are running a supported VM instance in a Google Cloud project, and a supported operating system. Visit the URL on your screen for a complete list of supported instances and operating systems:</p>
<p><a target="_blank" rel="noopener" href="https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent">https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent</a></p>
<p>You’ll also need credentials on the VM instance that authorize communication with Cloud Logging and Cloud Monitoring. Since Google’s Compute Engine VM instances typically already have the correct credentials by default, this should rarely be an issue.</p>
<p>In addition to the proper credentials, you’ll also have to enable the services for both the Cloud Logging API and Cloud Monitoring API, and you’ll have to ensure that neither the legacy Cloud Logging agent, nor the Cloud Monitoring agent are installed on the VM. </p>
<p>I do want to mention that there are a few different ways to install the Ops Agent, depending on your environment. For example, you can use gcloud and Agent policies to install agents on a fleet of VMs. More specifically, you use the Google Cloud CLI to create an Agent Policy, which, in turn, installs and manages the agents on all of your VMs.</p>
<p>You can also install and manage agents on your fleet of VMs using automation tools like Ansible, Chef, Puppet, and Terraform.</p>
<p>And then, of course, you can install the Ops Agent on individual VMs, using the Google Cloud CLI or Google Cloud console.</p>
<p>So, depending on your needs, you can use one method, or you can mix and match as necessary.</p>
<p>Before you install the Ops agent, you need to be sure that the VM instance has the credentials that the agent needs, because the agent needs to be able to send monitoring information to Cloud Operations. Generally speaking, this permission is granted via service account credentials that are stored on the VM instance. For an installation on a Compute Engine VM instance on GCP, the default service account on the instance should, by default, have the necessary credentials.</p>
<p>So, with that said, I’m going to show you, in the next lesson, how to install the Ops agent on a GCP compute instance.</p>
<h1 id="DEMO-Installing-the-Ops-Agent-for-Monitoring-and-Logging"><a href="#DEMO-Installing-the-Ops-Agent-for-Monitoring-and-Logging" class="headerlink" title="DEMO: Installing the Ops Agent for Monitoring and Logging"></a>DEMO: Installing the Ops Agent for Monitoring and Logging</h1><p>Welcome back. So, what I’m going to do in this quick demonstration is just walk you through the process of installing the Ops Agent on an existing VM in Google Cloud Platform. Now, on the screen I’m logged into my platform, and I have my project open here. And what we’re going to do here is browse into the monitoring section, and then we’ll actually open up a VM, and we’ll install the agent. </p>
<p>So, to do this, we’re going to select the hamburger here for the navigation menu, and then what happens here is we scroll down, and it’s near the bottom here. Under Operations, we have Monitoring. What we’re going to do here is open our dashboards here, under Monitoring. And then from here, since we’re going to install this Ops Agent on a VM instance, we’re going to select VM instances in the dashboards options here.</p>
<p>Then you’ll see here, I have server01. Server01 is going to be the server we install on. You’ll notice we have no agent detected currently, so to do this, we simply select the checkbox next to server01 and then we click on ‘Install Agents’. Now, what we could do here is just copy the code that it gives us here. If we were going to run this in Cloud Shell manually, but what you can do here is simply click ‘Run in Cloud Shell, and when I do this, it’s going to open these commands right in Cloud Shell. So, we’ll go ahead and click ‘Run in Cloud Shell’. And let me see if I can drag this up a little bit, there we go. I’m going to just scroll this back down. </p>
<p>So, you’ll notice here it opened up these commands already, and it’s actually running this using a file called agentstoinstall.csv. This has already created that CSV for me, I didn’t create any files, this actually does it for me based on the servers that I selected. So, what I’m going to do here is just hit ‘Enter’ on my keyboard. And what it does here is it asks me to authorize Cloud Shell, so we’ll go ahead and authorize it. You see the progress bar here, and we’ll give this a few minutes to complete. You’ll see we got one of one succeeded, zero of one failed, and one of one completed. </p>
<p>What I’ll do here is I’ll close Cloud Shell up, and you see here that the agent now shows pending. So, we’ll give this a few minutes and then what we’ll do is refresh and we’ll see what this shows when everything is said and done. Let’s go ahead and refresh the screen. Now, notice here, and this is something to keep an eye on. Right now, it’s telling me the Legacy Agent is installed. Now, we didn’t cover Legacy Agent here because it’s being phased out, but if we give this another minute or two, this actually does go through the process and it does in fact install the Ops Agent. </p>
<p>So, we’ll go ahead and just refresh here and see if it shows up right away. All right, let’s give it another minute or two, and we’ll do a refresh and you’ll see how this agent summary will eventually show one VM with Ops Agent. Let’s go ahead and refresh one more time here. It usually takes a few minutes, and there we go. So, now we have one VM with the Ops Agent and none with the legacy and none with no agents. You’ll see down here server01 shows the Ops Agent is installed and active. So, that’s how you can use the Google Cloud Platform console to install the Ops Agent on a Virtual Machine in Google Cloud.</p>
<h1 id="Assessing-Compute-Quotas"><a href="#Assessing-Compute-Quotas" class="headerlink" title="Assessing Compute Quotas"></a>Assessing Compute Quotas</h1><p>When <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploying resources on GCP</a>, it’s important to consider what your quotas may be. This is because Compute Engine enforces resource quotas for several reasons, most notably, to protect the overall GCP community from unexpected usage spikes. This is especially true for free trial accounts.</p>
<p>While GCP may offer expanded quotas for paying customers, the free trial quotas that are in place provide limited access for organizations that are just kicking the tires of the Google Cloud Platform on a free trial basis. Now, with that said, even for paying customers, quotas may differ. For example, an organization that is growing rapidly, and deploying compute resources at a fast clip, may see its quotas expanded more quickly than a smaller organization that deploys one or two compute instances a year. However, organizations expecting an upcoming usage increase can proactively request quota adjustments, using the Quotas page in the GCP Console. It’s important to note, though, that if a project’s billing service is disrupted, the quotas for that project will reset to default values. So, it’s important that you keep billing in check and invoices paid on time!</p>
<p>Checking the available quota for resources in a given project is easy. All you have to do is browse to the Quotas page in the Google Cloud Platform Console and see what’s available. Although, you can also use the gcloud command-line tool, to check quotas by running the command that you see on your screen. This command checks project-wide quotas. Simply replace yourproject with your own project ID. Now, since this command doesn’t list per-region quotas, you can, instead, run this next command that you see on your screen to list quotas in a region Just replace REGION with the region for which you want to list quota information. </p>
<p>In the next lesson, I’ll show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-requesting-an-increase-in-quota/">request a quota increase</a>.</p>
<h1 id="DEMO-Requesting-an-Increase-in-Quota"><a href="#DEMO-Requesting-an-Increase-in-Quota" class="headerlink" title="DEMO: Requesting an Increase in Quota"></a>DEMO: Requesting an Increase in Quota</h1><p>Welcome back. In this quick demonstration, what we’re going to do is request a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/assessing-compute-quotas/">quota</a> increase from the Quotas page in the GCP console. </p>
<p>Now although we’re going to request an increase in quota, we aren’t going to incur any new charges because there’s no charge for requesting a quota increase. The only time our charges will increase is when we actually use the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">new resources</a> that become available as a result of the quota increase. </p>
<p>Now before requesting our quota change we have to be sure that the account we’re using to make the request has the service usage quotas update permission. Since this permission is included by default for owner, editor and quota administrator roles, we’re good to go here since I’m logged in as the owner. </p>
<p>To make my quota change request, what I need to do is go to the Quotas page. The Quotas page is found under IAM &amp; admin and then under Quotas. From this Quotas page, what I need to do is select the quota that I want to change and then click Edit Quotas at the top of the page. What I’m going to do here is check the box of the service that I want to edit. And then I’ll go ahead and click Edit Quotas. </p>
<p>What I’ll do here is request an increase to 300 and in the Request description, I’ll just leave a description here, to let Google know why I’m requesting this. And then I’ll click Done. Once I’ve done this, I can submit my request. </p>
<p>Now, had I request a quota decrease, my request would be rejected by default. If I really, really wanted to reduce my quota, what I would need to do is reply to the eventual rejection email with an explanation of my requirements. What would then happen is that GCP support reps would respond to my request. Generally speaking, the Compute Engine team responds to requests within 48 hours. </p>
<p>So because of that slight delay what you’ll want to do in a production environment is request any necessary quota increases at least a few days ahead of time so there’s enough time for support to fulfill the request before the added resources are actually needed.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>I hope you’ve enjoyed learning how to Deploy Networking and Compute Resources on Google Cloud Platform. Let’s review what you’ve learned.</p>
<p>We kicked off the course by covering the deployment and implementation of networking resources such as VPCs and subnets. You learned how to create a VPC and how to define subnets contained within the VPC. You also learned how to create ingress and egress firewall rules for a VPC.</p>
<p>Later on, in the course, you learned how to create a VPN connection between a Google VPC and an external network. You also learned how to distribute network traffic to an application by using a load balancer.</p>
<p>As we moved through the course, you learned how to deploy and implement Compute Engine resources via the Cloud Console and via gcloud. After deploying a compute instance, you learned how to create and assign disks to an existing compute instance and how to assign an availability policy to a compute instance.</p>
<p>Down the home stretch of this course, you learned how to create and autoscaled managed instance group, using an instance template, and how to generate and upload custom SSH keys for compute instances.</p>
<p>Rounding out the course, you learned how to configure a VM for Cloud Operations, and how to install the Ops Agent. You also learned how to assess compute quotas and how to request quota increases.</p>
<p>At this point, you should now have a full understanding of how to Deploy Networking and Compute Resources on Google Cloud Platform.</p>
<p>To learn more about Deploying Networking and Compute Resources on Google Cloud Platform, you can, and should, read Google’s documentation. Be sure to also watch for new courses on Cloud Academy, because we’re always publishing new ones. Be sure to give this course a rating, and if you have any questions or comments, please let us know. As always, thanks for watching and happy learning!</p>
<h1 id="19Configuring-a-VM-for-Cloud-Operations"><a href="#19Configuring-a-VM-for-Cloud-Operations" class="headerlink" title="19Configuring a VM for Cloud Operations"></a>19<strong>Configuring a VM for Cloud Operations</strong></h1><p><a target="_blank" rel="noopener" href="https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent">Ops Agent Supported Systems</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Designing-a-Google-Cloud-Infrastructure-7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Designing-a-Google-Cloud-Infrastructure-7/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Designing-a-Google-Cloud-Infrastructure-7</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:44" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:44-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:51:00" itemprop="dateModified" datetime="2022-11-22T20:51:00-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Designing-a-Google-Cloud-Infrastructure-7/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Designing-a-Google-Cloud-Infrastructure-7/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Course-Introduction"><a href="#Course-Introduction" class="headerlink" title="Course Introduction"></a>Course Introduction</h1><h1 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h1><p>Suppose you’ve been hired to help a company called Great Inside, which offers interior design software as a service.</p>
<p>Great Inside makes its money by selling subscriptions to its web-based interior design application. It also has a free version that’s supported by advertising. Their customers are primarily in North America, but they hope to expand in Europe and Asia at some point in the future.</p>
<p>The company has grown slowly for five years, but recently closed a venture capital round, brought in experienced executives, and is now growing more quickly. The company’s existing infrastructure is not capable of scaling up quickly enough, so they would like to move to the cloud.</p>
<p>Great Inside started off with a Microsoft-centric infrastructure and then migrated to a LAMP stack. The only Microsoft infrastructure left is the payment processing system and an Active Directory server. They would like to retire their Microsoft servers in the future, other than Active Directory. But that isn’t a priority right now, and the company would like to move both types of servers to the cloud. They’ve also started a pilot project using a NoSQL database.</p>
<p>Since they accept credit cards, they need to be PCI DSS compliant. Since their volume is increasing, they need to ensure that their payment processing environment meets a higher level of compliance. Note that Great Inside passes the validation and processing of credit card information to a certified payment processor.</p>
<p>They would like to improve their disaster recovery solution. At the moment, they’re backing their data up to a cloud service, but it would take them a long time to recover from a disaster.</p>
<p>Their existing technical environment is all in a single data center.</p>
<p>They have three types of databases. MySQL for the interior design application, Microsoft SQL Server for payment processing, and a NoSQL database in the development environment.</p>
<p>They have two types of web and application servers. Apache and Tomcat are running on six servers, each with 2 dual-core CPUs, 24GB of RAM, and two mirrored 200GB disks. These servers are for their interior design application. IIS is running on four servers- two customer-facing and two internal, each with a dual-core CPU, 16GB of RAM and two mirrored 250GB disks. These servers are for payment processing.</p>
<p>They have a variety of infrastructure servers, including Active Directory and a file server for internal documents, etc.</p>
<p>Here are their business requirements. Scale easily to handle rapid growth, move as much of the development, test, and production infrastructure as possible to the cloud, and increase performance, reliability, and security while reducing management overhead.</p>
<p>And their technical requirements are: connect the data center’s network with the cloud environment’s network, encrypt all data, design <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/high-availability-1/">high availability</a> into all tiers, and create a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/disaster-recovery-1/">disaster recovery</a> solution that will reduce recovery time to a few hours, rather than a day.</p>
<p>I should mention up front that some aspects of this case study may not be completely realistic. It’s simplified so we can go through it in a reasonable amount of time, but it has just enough complexity to allow us to cover the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">key topics</a>.</p>
<h1 id="Compute"><a href="#Compute" class="headerlink" title="Compute"></a>Compute</h1><p>Although most Google Cloud designs include virtual machine instances, that doesn’t mean VMs are your only option for compute resources. Before you start designing a solution using only Compute Engine instances, you should consider App Engine and Kubernetes Engine.</p>
<p>App Engine is designed for people who don’t want to manage an application’s underlying infrastructure. App Engine provisions and scales all of the resources your application needs behind the scenes, without any human intervention required. That sounds great, doesn’t it? So why wouldn’t you use App Engine?</p>
<p>The main reason is that it is much easier to develop a new application on App Engine than it is to migrate an existing one to it. So if you’re developing an application from scratch, then App Engine may be a good choice. If you have an existing application, then you’ll need to check if App Engine supports the programming languages your app is written in and if your app has any operating system dependencies (such as only being able to run on Windows, which isn’t supported by App Engine).</p>
<p>You’ll also need to look at your application’s architecture to see if it would be able to run on App Engine without having to re-architect it. App Engine is designed for microservices-based apps, so if your existing application has a monolithic architecture, then it might require some work to migrate it.</p>
<p>For all of these reasons, it’s usually advisable to use App Engine only for new applications rather than existing ones.</p>
<p>The next option is Kubernetes Engine. It provides many of the benefits of App Engine, in that you don’t have to worry about the underlying operating system running your application. It also handles scaling, although you have to configure that yourself first. It does require more management than App Engine, but it doesn’t require as much management as Compute Engine.</p>
<p>The ideal case for using Kubernetes Engine is, of course, if your application already runs in containers, especially Docker containers, since that’s what Kubernetes Engine supports. On the other hand, if your application will only run on certain operating systems, especially Windows, then it won’t run in Kubernetes Engine.</p>
<p>If you have an existing app that does not currently run in containers, then you might want to see if it’s possible to containerize it so you can take advantage of Kubernetes Engine.</p>
<p>If your existing application runs on virtual machines, then the easiest way to migrate it to Google Cloud is to use Compute Engine instances. If it doesn’t run on virtual machines, then you’ll have to virtualize it before you can run it on Google Cloud.</p>
<p>Although Compute Engine requires more management than App Engine or Kubernetes Engine, it does give you ultimate flexibility. For example, you could run an application that requires Windows, a specific network driver, and high-performance GPUs.</p>
<p>Since our case study involves an existing application that doesn’t currently run in containers, we’re going to choose Compute Engine for our design.</p>
<p>The case study company, GreatInside, currently has 6 machines running Apache and Tomcat, and 4 machines running IIS. Let’s have a look at Google’s predefined machine types . We need to decide how many vCPUs and how much memory to use. Memory is pretty straightforward. Our existing machines have 24GB for the Tomcat servers and 16GB for the IIS servers. VCPUs are more complicated, though.</p>
<p>The existing Tomcat servers have two dual-core CPUs and the IIS servers have one dual-core CPU. How does that translate into vCPUs? Some people say that cores and vCPUs are equivalent, but that’s not quite true. A vCPU on a Compute Engine instance is implemented as a single hyper-thread on an Intel Xeon processor. Since each Xeon processor has 2 hyperthreads, that means you need to multiply the number of cores by 2 to get the number of threads, and thus the number of vCPUs.</p>
<p>So our Tomcat servers have the equivalent of 8 vCPUs (4 cores times 2) and our IIS servers have the equivalent of 4 vCPUs (2 cores times 2). Of course, if we really wanted to be accurate, we’d need to take into account things like the clock speed of the CPUs, but we’re not going to go that far.</p>
<p>So, we need 8 vCPUs and 24GB of RAM for the Tomcat servers and 4 vCPUs and 16GB of RAM for the IIS servers. Do any of the predefined machine types match these requirements? Well, the n1-standard-4 is almost identical to the IIS server requirements. It has 4 vCPUs and 15GB of RAM. Having one less gig of RAM is probably fine, but you can monitor it in production to make sure it’s sufficient.</p>
<p>The Tomcat servers are another story, though. The closest match is the n1-standard-8, which has 8 vCPUs and 30GB of memory. That’s 6GB more than we need, so we should consider a custom machine type. We can select the exact size we need. With this custom configuration, it says it will cost $190.54 per month. Let’s see how that compares to the n1-standard-8. That costs $194.58 per month, which is more expensive, but only 2% more.</p>
<p>I should mention that there are a couple of ways to reduce those costs: sustained-use discounts and committed-use discounts. If you know that you’re going to be running an instance continuously for a long period of time, then you can pay much less by purchasing either a one-year or three-year contract, which is called a committed-use contract. This will typically reduce the cost by up to 57%. However, that’s a pretty big commitment, so Google provides a way to reduce costs without signing a long-term contract. You start getting an automatic discount after an instance runs for more than 25% of a month, and the discount increases the longer the instance runs during that month. For most machine types, you’ll receive a sustained-use discount of 30% if you run the instance for the entire month.</p>
<p>Okay, let’s get back to our case study. Since IIS and SQL Server run on Windows, we’ll need to figure out how to license them. Let’s start with IIS. For Windows Server itself, you can either use Google’s pay-as-you-go Windows licensing or you can bring your own license. </p>
<p>There are two ways to use Google’s pay-as-you-go Windows licensing. The first way is to create a new instance with one of the pre-configured Windows Server boot disks . The second way is to import a Windows VM. There are two options for importing a VM. The first option is to import a virtual disk and turn it into an image that you can use to create a Compute Engine instance. That’s quite simple to do, but it’s not meant for migrating mission-critical applications or migrating a large number of VMs in an automated fashion.</p>
<p>A more sophisticated option is to use Cloud Migrate for Compute Engine. This service makes replicas of existing VMs you have running on-premises or on another cloud platform. It will take care of the many steps that are needed to migrate important applications. </p>
<p>If you want to bring your own Windows licenses, then you can run your Windows VMs on sole-tenant nodes, which are dedicated physical servers that are not shared with other customers.</p>
<p>If you need to run any Microsoft applications, then you’ll need licenses for those too, of course, but Microsoft is more flexible with its application licensing than with Windows licensing. If your organization has active Software Assurance contracts for its Microsoft applications, then you can move those licenses to either Compute Engine instances or sole-tenant nodes.</p>
<p>Now let’s move on to SQL Server. You can use any of the options I just mentioned, but fortunately, there are also easier options for SQL Server. One option is to create instances with pre-configured SQL Server boot disks . These include pay-as-you-go licenses for both Windows Server and SQL Server. The second option is to use Cloud SQL, which is a managed service. I’ll tell you more about it in the next video.</p>
<p>For premium Linux OSs (such as Red Hat or SUSE), licensing is much simpler. You can either create an instance with a pre-configured boot disk or you can import your Linux VM. In both cases, you can either use a Google pay-as-you-go license or bring your own license.</p>
<p>I should mention one other Compute Engine option – preemptible VMs. They’re up to 80% cheaper than regular instances, but since Google can remove them with only 30 seconds’ notice, you would usually only use them as disposable instances for things like big data batch jobs. That doesn’t fit our use case, so we’ll stick with regular instances.</p>
<p>And that’s it for this lesson.</p>
<h1 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h1><p>Each of the instances for the Tomcat and IIS servers will come with a standard persistent boot disk by default, but we might need something different. There are many options for instance storage, including Standard Persistent Disk, SSD Persistent Disk, Local SSD, RAM Disk, and Cloud Storage.</p>
<p>Standard Persistent Disks are magnetic drives. Their main advantage is low cost. SSD Persistent Disks (or solid state disks) have up to 4 times the throughput and up to 40 times the I&#x2F;O operations per second of a Standard Persistent Disk, so if you need high performance, SSDs are a must.</p>
<p>But SSD Persistent Disks aren’t even your fastest option. Local SSDs are up to 600 times as fast as Standard Persistent Disks in IOPS and up to 15 times as fast in throughput.</p>
<p>Why are Local SSDs so much faster than SSD Persistent Disks, which are obviously both using SSD technology? Well, it’s because Local SSDs are not redundant and are directly attached to an instance. That gives them major speed advantages, but with high risk because if they suffer a hardware failure, then your data will be gone. Furthermore, Local SSDs disappear when you stop or delete an instance, so you should only use them for temporary data that you can afford to lose, such as a cache.</p>
<p>There are a couple more disadvantages of Local SSDs too. First, they are only available in one size – 375GB, which is kind of an awkward number. Second, they can’t be used as boot disks.</p>
<p>If you need even faster storage, then you can use a RAM disk, which essentially makes a chunk of memory look like a filesystem. Although RAM disks are the fastest option, they’re even less durable than Local SSDs, so they’re only suitable for temporary data. It’s also an expensive option because RAM is much more expensive than SSDs.</p>
<p>One more option is Cloud Storage. This is kind of a weird way to add storage to an instance because a bucket is object storage rather than block storage. That means it can’t be used as a root disk and it may be unreliable as a mounted filesystem. So why would you ever use it? The first advantage of using Cloud Storage is that multiple instances can write to a bucket at the same time. You can’t do that with persistent disks, which can only be shared between instances in read-only mode. The danger is that one instance could overwrite changes made by another instance, so your application would have to take that into account.</p>
<p>The second advantage is that an instance can access a bucket in a different zone or region, which is great for sharing data globally, especially if it’s read-only data, which would avoid the overwriting problem.</p>
<p>However, Cloud Storage usually isn’t a good option for instance storage. It is good for general-purpose file serving, though, so it would be a potential choice for replacing GreatInside’s internal file server if they want to move it to the cloud. To do this, you’d need to use Cloud Storage FUSE, which is open source software that translates object storage names into a file and directory system. Essentially, it makes Cloud Storage buckets look like network file systems. A better choice, though, would be Cloud Filestore, which is a fully-supported file sharing service that’s designed specifically for this purpose. It’s compatible with NFS version 3.</p>
<p>So, which instance storage option should we use for our instances? Since performance is important, we should use something faster than Standard Persistent Disks. SSD Persistent Disks are many times faster than standard ones, so they’d be a good choice. Should we consider Local SSDs or RAM disks? Well, neither of those can be boot disks, so we would have to use them in addition to a persistent boot disk. The higher performance wouldn’t outweigh the extra cost and complexity of using one of these options, though, so we should just stick with SSD Persistent Disks. Furthermore, since persistent disks are redundant, we don’t need to have two mirrored disks on each instance like GreatInside does in its existing data center. We can just have a single persistent boot disk on each instance.</p>
<p>As for the size, we can specify the exact amount we need, so for the Tomcat servers, we should use one 200GB disk on each instance, and for the IIS servers, we should use one 250GB disk on each.</p>
<p>Next, we need to look at our database options. Google Cloud has 5 different database services: Cloud SQL, Cloud Datastore, Bigtable, BigQuery, and Cloud Spanner.</p>
<p>Cloud SQL is a relational database. It’s a managed service for MySQL, PostgreSQL, or Microsoft SQL Server. It’s suitable for everything from blogs to ERP and CRM to ecommerce.</p>
<p>Cloud Datastore is a NoSQL database service. Unlike a relational database, such as Cloud SQL, it is horizontally scalable. A relational database can scale vertically, meaning that you can run it on a more powerful VM to handle more transactions, but there are obviously limits to the size of a VM. You can also scale a relational database horizontally for reads by using read replicas, but most relational databases can’t scale horizontally for writes. That is a major problem that is solved by NoSQL databases.</p>
<p>Because of this and because it’s an eventually consistent database, Cloud Datastore is faster than Cloud SQL. It’s best suited to relatively simple data and queries, especially key-value pairs. Typical examples include user profiles, product catalogs, and game state. For complex queries, Cloud SQL is a better choice.</p>
<p>Cloud Bigtable is also a NoSQL database. It’s designed to scale into the petabyte range with high throughput and low latency. It does not support ACID transactions, so it shouldn’t be used for transaction processing. It’s best suited for storing huge amounts of single-keyed data. If you have less than one terabyte of data, then Bigtable is not the best solution. It can handle big data in real-time or in batch processing. Typical examples are Internet of Things applications and product recommendations.</p>
<p>BigQuery also handles huge amounts of data, but it’s more of a data warehouse. It’s something you use after data is collected, rather than being a transactional system. It’s best suited to aggregating data from many sources and letting you search it using SQL queries. In other words, it’s good for OLAP (that is, Online Analytical Processing) and business intelligence reporting.</p>
<p>Google’s newest database service is Cloud Spanner, which seems to combine the best of all worlds. It’s a relational database that also scales horizontally. That is, it combines the best features of traditional databases like Cloud SQL and the best features of NoSQL databases like Cloud Datastore. So why wouldn’t you use it for all of your database needs? Well, mostly because it’s more expensive than the other options. Also, if your application is written specifically for a particular database, such as MySQL, then Cloud SQL would be a better choice, unless you can rewrite it to work with Cloud Spanner. </p>
<p>So use Cloud Spanner when you need a relational database that is massively scalable. Typical uses are financial services and global supply chain applications.</p>
<p>Now, which database services should GreatInside use? It currently has two production databases – MySQL for the interior design application and SQL Server for payment processing. There are two ways you could migrate the MySQL database to Google Cloud. You could use Cloud SQL or run MySQL on a regular instance. Considering that GreatInside wants to reduce system management tasks, Cloud SQL would be the best choice since it’s a fully managed MySQL service, with automatic replication and backups.</p>
<p>For SQL Server, you have the same two options. You could use Cloud SQL, or you could run it on a regular instance. Again, Cloud SQL is the best choice.</p>
<p>GreatInside does have one more database – their experimental NoSQL datastore. Since the development team is still evaluating this technology, you should talk to them about trying Cloud Datastore. They should also try App Engine because Cloud Datastore works best when used with App Engine.</p>
<p>And that’s it for storage and databases.</p>
<h1 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h1><p>Before we talk about networks, we need to talk about how we can make our applications highly available.</p>
<p>If you have an application that’s running on only one VM instance, then, of course, it’s a single point of failure, and if it goes down, your application goes down. So, at a minimum, you should always have at least two VMs for every component of your solution. But where should those instances be located?</p>
<p>When you create a VM instance, it gets created in a particular zone, such as us-central1-a. A zone is an isolated location. You can think of a zone as a data center or an isolated portion of a data center.</p>
<p>If you put both instances in the same zone, then both of them could potentially go down if there’s a problem in that zone. So, you should put the instances in different zones. For performance reasons, you may need to put them in zones that are in the same region, such as us-central1. Notice that the zone name is just the region name with a dash and a letter at the end. All of the zones in a region have high-bandwidth, low-latency network connections between them, so if instances that are spread across a region need to mirror data with each other, then they can do this quickly.</p>
<p>Although “region” sounds like a geographic area, it’s just a data center campus in one location. For example, all of the zones in the us-central1 region are in Council Bluffs, Iowa. So, for maximum availability, you may also want to distribute your instances across different regions.</p>
<p>For a higher level of availability, you can use autoscaling instance groups. This was covered extensively in the “Google Cloud Platform: Systems Operations” course, so I’ll just go over the highlights.</p>
<p>An instance group consists of identical instances that perform processing for your application. If one of the instances fails, then a health check will notice this and replace the instance with a new one. If the load on the instance group gets too high, then the autoscaler will add more instances to maintain good application performance.</p>
<p>To ensure availability even if an entire zone fails, you should distribute the instances across multiple zones. Luckily, this is very easy to do. You just have to select “Multizone” when you’re creating the instance group.</p>
<p>If you want to make sure you’ll still have enough instances to handle the load if an entire zone goes down, then you should overprovision by 50%. For example, if your instances are spread across 3 zones and you need 6 instances to handle your normal traffic load, then you should provision 9 instances. That way if one of the zones goes down (which would take out 3 of the instances), you’ll still have 6 instances left in the two remaining zones.</p>
<p>You can either overprovision by 50% at all times or you could save money by just setting the upper limit on your autoscaler to at least 50% more than the normal number of instances. If you decide to depend on the autoscaler during a zone failure, then the instances in your remaining two zones will be very heavily loaded until the autoscaler provisions additional instances, so only choose this option if you can tolerate this temporary performance degradation.</p>
<p>Since GreatInside has 6 web tier instances for its main application, this is how it should be set up. For the 2 customer-facing IIS instances in the payment processing system, you’d set an upper limit of 3 instances, which is 50% more than the 2 instances that it normally needs.</p>
<p>To make the instance group work as a high availability solution, you’ll need a couple of other components. First, the instance group has to be behind a load balancer that will distribute incoming requests to different instances. Second, the instances cannot have any stateful data. Otherwise, the same instance would have to handle all requests from a given user. Although you can enable the “session affinity” option in this situation, it will ruin your high availability since a failed instance will impact all of the users on it.</p>
<p>Since most applications do have stateful data, you have to put it on other components, such as a database or Cloud Storage. Unfortunately, that just moves the availability issue to a different layer, but fortunately, Google Cloud has good ways to handle storage availability.</p>
<p>If Cloud Storage is sufficient for your stateful data needs, then you’re covered because Cloud Storage is automatically replicated either across zones in a region (for the Regional type) or across regions (for the Multi-Region type).</p>
<p>If you need a database for your stateful data, then there are different availability solutions depending on the data service.</p>
<p>With Cloud SQL, you can simply check the “High availability” box when you create a Cloud SQL instance. This will create a failover replica in another zone. In the event of a failure, Cloud SQL will automatically fail over to the replica. This option is available for MySQL, PostgreSQL, and SQL Server.</p>
<p>Since Cloud Datastore is a NoSQL database, it scales horizontally, which makes high availability easier than with Cloud SQL. Cloud Datastore automatically replicates data across zones in a region. When you create a Datastore instance, you specify which region and it does the rest.</p>
<p>Bigtable is also a NoSQL database that scales horizontally, but if you want it to replicate across multiple zones, then you’ll have to configure it to do that. You can even configure it to support replication across regions if you need that. But in its simplest configuration, it only stores data in a single zone, which gives it higher performance. It’s still stored redundantly in that configuration but within the same zone.</p>
<p>BigQuery automatically replicates data within a region, but it’s a data warehouse, so it’s not suitable for real-time stateful data storage.</p>
<p>Cloud Spanner also automatically replicates data within a region, so it’s highly available out of the box, and unlike Cloud SQL, it doesn’t need a failover replica, which is a less available solution.</p>
<p>In summary, if a NoSQL database is sufficient for your application, then Cloud Datastore is your best choice for storing stateful data. If you need to use a relational database, then either use Cloud SQL and enable high availability or use Cloud Spanner for even higher availability if you’re willing to pay a higher price.</p>
<p>Since GreatInside is going to use Cloud SQL for both MySQL and SQL Server, then we just need to enable the high availability option when we create those databases.</p>
<p>And that’s it for this lesson.</p>
<h1 id="Networks"><a href="#Networks" class="headerlink" title="Networks"></a>Networks</h1><p>Now we know all of the components we want to use and we just need to connect them together with networks. Google provides what are called Virtual Private Clouds, or VPCs, but I’m just going to call them networks.</p>
<p>There are 5 layers in <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">Google Cloud</a> you can use to isolate and manage resources: organizations, folders, projects, networks, and subnetworks.</p>
<p>You aren’t required to have organizations or folders, but they can be useful, especially for large companies.</p>
<p>Projects are required, though. You use them to provide a level of separation between resources. Not only are resources in different projects unable to communicate with each other, but they’re even in different billing accounts. Projects also have separate security controls, so for example, you could give Bob in QA the highest level of access in the Test Environment project, but a lower level of access in the Production Environment project.</p>
<p>Each project has one default network that comes with preset configurations and firewall rules to make it easier to get started, but you can customize it, or you can create up to 4 additional networks (for a total of 5). If 5 networks per project isn’t enough for you, then you can request a quota increase to support up to 15 networks in each project.</p>
<p>A network belongs to only one project, a subnet belongs to only one network, and an instance belongs to only one subnet.</p>
<p>Instances in the same subnet or even different subnets within the same network can communicate with each other. Subnetworks are used to group and manage resources.</p>
<p>A network spans all regions, but each subnet can only be in one region. A subnet allows you to define an IP address range and a default gateway for the instances you put in it. The IP address ranges of the different subnets must be non-public (such as 10.0.0.0) and must not overlap, but other than that, there are no restrictions on them. For example, they can be different sizes. They must be IPv4 addresses, though, because Compute Engine doesn’t support IPv6 yet.</p>
<p>A network can have either automatic or custom subnets. With automatic, the subnets are created for you, one in each region. With custom, you create them yourself. If you discover that you need to customize a network with automatic subnets, then you can convert it to custom mode, but once you do, you cannot convert it back to automatic mode.</p>
<p>On the default network, instances within the same subnet can communicate with each other over any TCP or UDP port, as well as with ICMP. Instances in the same network can communicate with each other, regardless of which subnets they’re in, because Google Cloud creates routes between all of the subnets in a network. However, the default network’s firewall rules only allow ssh, rdp, and icmp traffic between subnets.</p>
<p>If you don’t want instances in different subnets to be able to reach each other, then you can change the firewall rules to deny traffic between them.</p>
<p>Note that only the default network comes with predefined firewall rules. When you create a new network, it doesn’t have any firewall rules. However, the instances in that network will still be able to communicate with the Internet, assuming they have external IP addresses, because all outgoing traffic from instances is allowed. Only incoming traffic is blocked. And when an instance sends a request over the Internet, the incoming response is allowed, so two-way traffic is enabled at that point.</p>
<p>Each network includes a local DNS server so VM instances can refer to each other by name. The fully qualified domain name for an instance is [HOSTNAME].c.[PROJECT_ID].internal. This name is tied to the internal IP address of the instance. An Instance does not know its external IP address and name. That translation is handled elsewhere in the network.</p>
<p>To reach Internet resources, each VM needs an external IP address. An ephemeral external IP address is created for each VM by default, but an ephemeral address gets replaced with another one if you stop and restart the instance, so if you want an instance to always have the same IP address, then you need to assign a static IP address to it.</p>
<p>Since IPv4 addresses are a scarce resource, Google doesn’t want customers to waste them. So you’re not charged for having static IP addresses as long as you’re using them. But if a static IP address is not associated with a VM instance or if it’s associated with an instance that’s not running, then you’ll be charged for it.</p>
<p>Normally, if a VM needs to send requests to other Google services, such as Cloud Storage, then by default, it has to do so using a public IP address rather than an internal one. This is problematic if you don’t want any of your internal network communications to go over the Internet. However, if you enable the Private Google Access option in a subnet, then VMs in that subnet can connect to Google services using internal IP addresses, so their requests will go over Google’s network rather than the Internet.</p>
<p>If you want instances in different projects to communicate with each other, then you have three options: the Internet, VPC Network Peering, or a Shared VPC. Connecting over the Internet is slower, less secure, and more expensive than the other two options, so it’s not usually the best choice.</p>
<p>The simplest alternative is VPC Network Peering. This allows two VPCs to connect over a private RFC 1918 space, that is, using non-routable internal IP addresses, such as 10.x.y.z. In other words, they don’t need public IP addresses, and they communicate over Google’s network. Not only can you do this for VPCs in different projects, but you can even use it to connect VPCs in different organizations. To make this work, both sides have to set up a peering association. If only one side sets up a peering association with the other VPC, then the networks won’t be able to communicate with each other. Also bear in mind that there can’t be any overlapping IP ranges in the two networks. You’ll notice in this example that the two ranges are not overlapping.</p>
<p>A more complicated option is to use a Shared VPC. The idea is that instances in different projects can share the same network. This is kind of a weird idea. If you’ve put resources in different projects, you probably want them to be managed separately, so why would you get them to use the same network? In most cases, it’s to enforce security standards. For example, if you want to use the same firewall rules across all of your projects, then this is a good way to do that.</p>
<p>To set up a Shared VPC, you need to designate one of the projects as the host project and the others as service projects. The host project is the one that contains the Shared VPC. Instances in the service projects can use subnets in the Shared VPC. This is made possible by giving Service Project Admins the authority to create and manage instances in the Shared VPC but nothing more. Meanwhile, the Shared VPC Admins have full control over the network. Note that all of the projects in this arrangement have to be part of the same organization.</p>
<p>OK, we’ve gone over a lot of networking topics. Now how should we apply these concepts to GreatInside?</p>
<p>At a minimum, we should create separate projects for the Development, Test, and Production environments. Inside each project, we should stick with the default network. There’s no need to add any additional ones. We should also stick with automatic subnetworks. The only subnetwork we need right now is one in the US, such as us-central1, since we don’t currently have any plans to expand into other parts of the world. When GreatInside decides to add instances overseas, then they can be added to the other regional subnets.</p>
<p>The default firewall rules should also be fine, since they only allow internal traffic plus ssh, icmp, http, and https. We should remove the rule that allows rdp traffic in the Production network, though, since we don’t have any Windows instances in it.</p>
<p>We don’t want the Production, Development, and Test environments to be part of the same network, so we don’t need a Shared VPC. In fact, we don’t want them to communicate with each other at all, so we don’t need to use VPC Network Peering either.</p>
<p>By the way, you probably noticed that everything I’ve shown so far is only for the interior design application. I’m going to get into the details of how to set up the payment processing environment in the Legislation and Compliance lesson.</p>
<p>One last item is that we have to decide which components need external IP addresses. That’s easy in this case because the load balancer is the only one that needs an external IP address (and ideally it should be a static address). Users will connect to the web instances through the load balancer, so the web instances only need internal IP addresses, and for security reasons, that’s all they should have.</p>
<p>That does raise the question of how a system administrator could connect to them for troubleshooting, though. One way is to give your administrators access to the internal network by interconnecting it with the company’s on-premises network. That’s something that GreatInside has already requested, so let’s see how to do that. There are three ways: Cloud VPN, Cloud Interconnect, and Direct Peering.</p>
<p>Cloud VPN lets you set up a virtual private network connection between your own network and Google Cloud. To do this, you need to have a peer VPN gateway in your own network and it needs to use IPsec to connect to the Cloud VPN Gateway and encrypt traffic. You can have multiple tunnels to a single VPN gateway.</p>
<p>By itself, Cloud VPN requires you to make changes to static routes on your tunnels manually. But if you use Google Cloud Router, then the routes will be updated dynamically using BGP (that is, Border Gateway Protocol). Network topology changes are propagated automatically.</p>
<p>The second way to connect is called Cloud Interconnect. Instead of connecting over the Internet, you can use an enterprise-grade connection to Google’s network edge. There are two ways to do this: Dedicated Interconnect and Partner Interconnect. If your internal network extends into a colocation facility where Google has a point of presence, then you can connect your network to Google’s. This is called Dedicated Interconnect. It’s a great solution that provides higher bandwidth and lower latency than a connection over the public internet. It’s a bit expensive, though, because the minimum bandwidth is 10 Gbps.</p>
<p>If you don’t have a presence in a supported colocation facility or you want to pay for a connection that’s smaller than 10 Gbps, you can use Partner Interconnect. With this option, you connect to a service provider that has a presence in a supported colocation facility. You can purchase a monthly contract for connections as small as 50 Mbps and as large as 10 Gbps. </p>
<p>The third way is to use Peering. This is similar to Cloud Interconnect because you connect your network to Google’s network at a point of presence either directly (which is called Direct Peering) or through a service provider (which is called Carrier Peering). One big difference with peering is that it doesn’t cost anything. So why would anyone pay for Cloud Interconnect when they could peer with Google for free? Well, because with Cloud Interconnect you get a direct connection between your on-premises network and one of your VPCs in Google Cloud. You have full control over the routing between your networks. If you want to change a route, you can change it on your on-premises router, and it will be picked up by BGP. Although the peering option uses BGP, too, it’s done at the most basic level. It doesn’t create any custom routes in your VPC network.</p>
<p>Since we don’t have requirements for low latency and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/high-availability-1/">high availability</a> between the company network and Google Cloud, we should go with Cloud VPN to connect. We should also use Cloud Router so network routes will be updated dynamically.</p>
<p>And that’s it for networks.</p>
<h1 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h1><p>The first step in giving secure access to your <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">Google Cloud infrastructure</a> is to decide how to authenticate your users. By default, Google Cloud Platform requires users to have a Google account to access it. But if you have more than a handful of users, then you’ll want to find a centralized way to manage your user accounts. The solution is to use the G Suite Global Directory. You don’t have to use G Suite products like Google Docs, you can just use G Suite for user management.</p>
<p>Most organizations already have a user directory, so the best policy is usually to manage users in your existing directory, and then synchronize the account information in G Suite. There are three ways to do this: Google Cloud Directory Sync or GCDS, the Google Apps Admin SDK, or a third party connector.</p>
<p>Google Cloud Directory Sync is the easiest solution if you have either Active Directory or an LDAP server. It synchronizes users, groups, and other data from your existing directory to your Google Cloud Domain Directory. GCDS runs inside your <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/networks-1/">network</a> on a machine that you control.</p>
<p>It’s a one-way synchronization, so GCDS doesn’t modify your existing directory. Of course the synchronization can’t be a one-time event. It has to happen on a regular basis to keep your Google Directory up-to-date.</p>
<p>To make authentication even easier for your users, you can implement single sign-on or SSO. Google Cloud Platform supports SAML 2.0-based SSO. If your system doesn’t support SAML 2.0, then you can use a third party plugin.</p>
<p>Once you’ve implemented SSO, then when a user would normally have to login, Google will redirect your authentication system. If the user is already authenticated in your system, then they don’t have to login to Google Cloud separately. If they aren’t already logged in, then they’re prompted to login.</p>
<p>In order for this to work, your users must have a matching account in Google’s Directory. So you still need to use GCDS or one of the other synchronization options.</p>
<p>In our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/case-study-1/">case study</a>, since we have an active directory server, we’ll use GCDS for synchronization and also implement single sign-on.</p>
<p>And that’s it for authentication.</p>
<h1 id="Roles"><a href="#Roles" class="headerlink" title="Roles"></a>Roles</h1><p>To give a user permission to access particular Google Cloud resources, you assign a role to them. Basic roles act at the project level. There are 3 basic roles available: Owner, Editor, and Viewer. There are also fine-grained roles for individual resources. These are called predefined roles. (They were previously known as curated roles.) For example, the Cloud SQL Viewer role gives read-only access to Cloud SQL resources.</p>
<p>You can assign roles at different levels of the hierarchy, that is, at the organization, folder, project, and resource levels. If you assign roles to the same user at different levels, then their effective permissions are the union of the permissions at the different levels.</p>
<p>For example, if you granted Marie the Viewer role at the organization level and the Editor role at the project level, then she would have Editor permissions for all of the resources in that project. The Viewer role at the organization level would not override the Editor role at the project level. Similarly, if you assigned them in the opposite way, with the Editor role at the organization level and the Viewer role at the project level, Marie would still have the Editor role for all of the resources in that project because the project-level permissions would not override the organization-level permissions.</p>
<p>There are a few principles you should apply when setting roles and permissions. </p>
<p>First, use the principle of least privilege when granting roles. That is, assign roles with the least permissions required for people to do what they need.</p>
<p>Second, whenever possible, assign roles to groups instead of to individuals. Then, when you need to grant a role to a user, you can just add them to the group. Not only is this easier to manage, but it also ensures consistent privileges among members of a particular group. You can also use a descriptive group name that makes it clear why group members need those permissions.</p>
<p>Third, keep tight control of who can add members to groups and change policies. If you don’t, then people could give themselves or others more privileges than they should have.</p>
<p>Fourth, to make sure that inappropriate policy changes aren’t made, audit all policy changes by checking the Cloud Audit Logs, which record project-level permission changes.</p>
<p>Now let’s apply these principles to GreatInside. First, you would grant the project owner role to a few key system administrators. Owners are the only ones who can change policies (unless you grant users the Organization Administrator role). You should always have more than one owner. Otherwise, if that person is unavailable or leaves the organization, it would be difficult to for someone else to take their place as owner. So avoid that situation by giving the owner role to several people, but choose wisely because owners can do just about anything. </p>
<p>Similarly, you would have a small number of G Suite administrators who could add users to groups.</p>
<p>Obviously, there would be a large number of users who would need permissions, so I’m not going to talk about every type of user, but I’ll give a couple of examples. One example would be a network administration group that you would grant the Compute Network Admin role to.</p>
<p>Another example would be a QA team. You could grant their group the editor role on the Test Environment project and the viewer role on the Production Environment project. Alternatively, if the QA people don’t need full access to the Test Environment, then you could grant them several predefined roles, such as Compute Instance Admin, Cloud SQL Admin, and Compute Storage Admin.</p>
<p>Regarding audit logs, someone would need to take on the responsibility of checking for policy changes. The Admin Activity audit logs are viewable by all project members, so you wouldn’t need to grant access to the person who does the checking.</p>
<p>And that’s it for roles.</p>
<h1 id="Service-Accounts"><a href="#Service-Accounts" class="headerlink" title="Service Accounts"></a>Service Accounts</h1><p>Now that you have user authentication and permissions figured out, it’s time to plan how your applications will access the Cloud Platform services it needs to use. To avoid embedding credentials in an application, you need to use service accounts. For example, if an application uses Cloud Datastore as a database, then it needs to have authorization to use the Datastore API.</p>
<p>You would accomplish this by enabling Datastore API access on any VM instances that will be involved in the part of the application that uses the database. By default, all VM instances run as the Compute Engine default service account. If you want something different, then you can create your own.</p>
<p>A service account has an email address and a public&#x2F;private key pair that it uses to prove its identity. Your instances use that identity when communicating with other Cloud Platform services. However, by default, an instance running as the Compute Engine default service account has limited scope in how it can interact with other services. For example, by default an instance can only read from Cloud Storage and can’t write to it.</p>
<p>To give an instance more permissions, you need to set the scope when you’re creating the VM. So, in the case of interacting with Datastore, you have to enable access to the Datastore API. You also have to enable the Datastore API at the project level, but you only have to do that once.</p>
<p>Then your application code has to obtain credentials from the service account whenever it uses the Datastore API. Google Cloud Platform uses OAuth 2.0 for API authentication and authorization. There are two ways to do it: Application Default Credentials and access tokens.</p>
<p>The easiest way is to use Google Cloud Client Libraries. They use Application Default Credentials (or ADC) to authenticate with Google APIs and send requests to those APIs. One great feature of ADC is that you can test your application locally and then deploy it to Google Cloud without changing the application code. </p>
<p>Here’s how it works. To run your code outside Google Cloud Platform, such as in your on-premise data center or on another cloud platform, create a service account and download its credentials file to the servers where the code will be running. Then set the environment variable GOOGLE_APPLICATION_CREDENTIALS to the path of the credentials file.</p>
<p>So while you’re developing locally, the application can authenticate using the credentials file and when you run it on a production instance, it will authenticate using the instance’s service account. This works because ADC allows applications to get credentials from multiple sources.</p>
<p>The second way is to use OAuth2 access tokens to directly connect to the API without going through a client library. One reason you’d have to use this method is if your application needs to request access to user data.</p>
<p>The way it works is the application requests an access token from the metadata server and then uses the token to make an API request. Tokens are short-lived, so your application needs to request new ones regularly.</p>
<p>If you need to write shell scripts that access other Cloud Platform services, then you can use gcloud and gsutil commands to make API calls. These two tools are included by default in most Compute Engine images and they automatically use the instance’s service account to authenticate with APIs.</p>
<p>So what service accounts would you need to create for GreatInside? The load balancer and the web instances communicate over HTTPS, so you don’t a service account for that. Since the Tomcat instances communicate with the MySQL database in Cloud SQL, you would need a service account for that. Similarly, the IIS instances communicate with SQL Server in Cloud SQL, so you’d need a service account for that, too. There may be a need for other service accounts when we add more features to our architecture, such as disaster recovery, but we’ll cover that later.</p>
<p>And that’s it for service accounts.</p>
<h1 id="Data-Protection-and-Encryption"><a href="#Data-Protection-and-Encryption" class="headerlink" title="Data Protection and Encryption"></a>Data Protection and Encryption</h1><p>Protecting data is critical in any organization. Google Cloud Platform is very strong in this area because of its default encryption policies. Before we get into encryption, though, let’s look at Access Control Lists (or ACLs).</p>
<p>ACLs specify who has access to Cloud Storage buckets and objects in buckets. I’m not going to cover this topic in depth, but there are a few things to keep in mind when you’re deciding what ACLs to apply to your Cloud Storage.</p>
<p>First, there are actually five different mechanisms for controlling access to Cloud Storage: IAM permissions, ACLs, Signed URLs, Signed Policy Documents, and Firebase Security Rules. With so many different ways to control access, you have to be careful not to create conflicting permissions. Start with the first two: IAM permissions and ACLs.</p>
<p>IAM permissions work at the project level. For example, you can specify that a user has full control of all the objects in all of the buckets in your project, but cannot create, modify, or delete the buckets themselves. So they’re a nice way to grant broad access to buckets and objects, but if you want to set fine-grained access, such as which buckets or objects a particular group can read, then you need to use ACLs.</p>
<p>The confusing thing about using these two mechanisms is that you have to look at both of them to get a complete picture of access permissions. For example, you could list the ACLs for a bucket and see that only Bob has been granted write access, but it wouldn’t show that Jill has also been granted write access to all buckets by IAM. For this reason, whenever possible, you should try to use either IAM or ACLs, but not both.</p>
<p>Another potential source of confusion is that bucket and object ACLs are independent of each other. The ACLs on a bucket do not affect the ACLs on objects inside that bucket. For example, you might think that Jane doesn’t have access to the objects in a bucket because she hasn’t been granted access to the bucket itself, but she could have been granted access to any of the objects in the bucket.</p>
<p>So you should keep a couple of principles in mind. First, apply the principle of least privilege. Grant users and groups only as much access as they need. Second, keep your access control as simple as possible. Try to use as few control mechanisms as you can.</p>
<p>If GreatInside decides to replace its internal file server using Cloud Storage, then the best way to secure the files would be to use ACLs. You would create groups to match the teams in the company and create ACLs that give those groups access to the appropriate resources. For example, you could create a bucket for each group. Then for each bucket, you would make the associated group a writer of the bucket. Finally, you would set the object default permissions so that any new objects uploaded to the bucket would get the same permissions and everyone in the group would have full access. If the company’s needs aren’t that simple, then you would set more complex ACLs.</p>
<p>Now let’s move on to encryption. To ensure that your data is encrypted at all times, it needs to be encrypted when it’s in storage (also known as “at rest”) and when it is being sent over a network (also known as “in flight”). Google Cloud Platform takes care of both of these situations.</p>
<p>Encryption in flight is handled very simply. All of the Cloud Platform services are accessible only by API (even when you’re using other methods, such as the Cloud Console or the gcloud command, they’re making API calls under the hood). And all API communication is encrypted using SSL&#x2F;TLS channels. Furthermore, every request has to include a time-limited authentication token, so the token can’t be used by an attacker after it expires. Of course, for any communications between your Google Cloud infrastructure and outside parties, such as website visitors, you have to use SSL&#x2F;TLS yourself to encrypt the traffic.</p>
<p>Encryption at rest is just as simple if you’re willing to leave it to Google because Cloud Platform encrypts all customer data at rest by default.</p>
<p>So without you having to do anything, all of your data will be encrypted both at rest and in flight. Then why isn’t this the end of this lesson? Well, because your organization might want to take on some of the encryption responsibilities itself.</p>
<p>There are actually two layers of encryption for data at rest. First, the data is broken into subfile chunks, and each chunk is encrypted with an individual data encryption key (or DEK). These keys are stored near the data to ensure low latency and high availability. The DEKs are then encrypted with a key encryption key (or KEK). The keys are AES-256 symmetric encryption keys.</p>
<p>Google always manages the data encryption keys, but your organization can manage the key encryption keys if that’s your preference. There are two options for doing this: Customer-managed encryption keys or Customer-supplied encryption keys.</p>
<p>With the customer-managed option, you use the Cloud KMS service to create, rotate (or automatically rotate), and destroy your encryption keys. The keys are hosted on Google Cloud. You can have as many keys as you want, even millions of them if you actually need that many. You can set user-level permissions on individual keys using IAM and monitor their use with Cloud Audit Logging.</p>
<p>Cloud KMS is a nice service, but why wouldn’t you just let Google manage your key encryption keys and not have to deal with it yourself? The biggest reason is compliance with standards or regulatory requirements, such as HIPAA (for health information) or PCI (for credit card information).</p>
<p>If your organization requires that you generate your own keys and&#x2F;or that they’re managed on-premises, then you have to use Customer-supplied encryption keys. Be aware that this option is only available for Cloud Storage and Compute Engine.</p>
<p>With CSEK, Google doesn’t store your key. You have to provide your key for each operation, and your key is purged from Google Cloud after the operation is complete. Here’s how to do it from the command line with each of the two supported services. To encrypt the disk on a Compute Engine instance, you add the csek-key-file flag and point it to a file that contains the key. To encrypt data you’re uploading to Cloud Storage, you have to do it a bit differently. Rather than adding an encryption flag to the gsutil command, you need to add the encryption key to your .boto file, which is the configuration file for the gsutil command. Then all of your gsutil commands will use that key.</p>
<p>It only stores an SHA256 hash of the key as a way to uniquely identify the key that was used to encrypt the data. When you make a request to read or write the data in the future, your key can be validated against the hash. The hash cannot be used to decrypt your data.</p>
<p>There’s a big risk in using this method, though. If you lose your keys, you won’t ever be able to read your data again, and you’ll end up deleting it so you won’t be paying storage charges for unreadable data.</p>
<p>So far all of the encryption methods we’ve covered, including default encryption, Cloud KMS, and CSEK have been examples of server-side encryption. This is where your data is encrypted after Google Cloud receives your data. The only major difference between the 3 methods is where the key comes from. But there is another way. It’s client-side encryption. This means that you encrypt the data before you send it to Google Cloud. Google won’t even know that it’s already encrypted and it will encrypt it again. When you read your data back, Google Cloud will decrypt it on the server side first and then you’ll decrypt your own layer of encryption on the client side. The same warning applies - if you lose your keys, your data will effectively be gone.</p>
<p>Since our case study includes credit card information, we’ll need to be PCI DSS compliant, so we should use Cloud KMS to manage our keys. I’ll talk more about PCI compliance in the next lesson.</p>
<h1 id="Legislation-and-Compliance"><a href="#Legislation-and-Compliance" class="headerlink" title="Legislation and Compliance"></a>Legislation and Compliance</h1><p>Google Cloud Platform has passed annual audits for some of the most important security standards, including SOC 1, 2, and 3, ISO 27001, and PCI DSS. It also complies with HIPAA, CSA STAR, the EU-US Privacy Shield Framework, and MPAA controls, none of which require annual audits.</p>
<p>So if your organization is required to comply with any of these standards, then you know that Google has done its part. But this is a shared responsibility because <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">your security processes and applications</a> running on top of Google’s infrastructure also need to comply.</p>
<p>You’ll notice that Network is listed for both Google and the customer. That’s because Google takes care of some parts of networking and the customer takes care of the rest. One of the most interesting areas of shared responsibility for network security is protecting against distributed denial of service (or DDoS) attacks.</p>
<p>Google provides many features to help deal with DDoS attacks, but it’s up to the customer to use them properly. Here are some of the techniques.</p>
<p>Reduce the attack surface by</p>
<ul>
<li>Isolating and securing your deployment with firewall rules</li>
<li>Google also provides anti-spoofing protection by default</li>
</ul>
<p>Isolate your internal traffic from the external world by</p>
<ul>
<li>Deploying instances without public IPs unless necessary</li>
</ul>
<p>Use Load Balancing</p>
<ul>
<li>Because a load balancer acts as a proxy that hides your internal instances</li>
</ul>
<p>Use Cloud Armor</p>
<ul>
<li>This service is specifically designed to provide DDoS defense</li>
<li>And it works with Load Balancing</li>
<li>It protects against layer 3 and layer 4 DDoS attacks</li>
</ul>
<p>Google Cloud also enforces API rate limits and resource quotas to prevent a spike in one customer’s activity from affecting other Cloud Platform customers.</p>
<p>Now it’s time to get back to the PCI DSS standard and how to comply with it. If your organization accepts credit card payments, then you need to comply with this standard or you could be fined. More importantly, if you have security flaws that allow hackers to steal credit card information from your systems, then it would be very damaging to both your customers and your reputation.</p>
<p>In the case study, GreatInside provides an interface for collecting credit card information, but it passes the validation and processing of the information to a Certified Payment Processor. This makes the company an SAQ A-EP merchant in PCI lingo. I’ll go over Google’s recommendations for how this type of merchant could comply with PCI DSS.</p>
<p>First, you have to check that the other parties involved (that is, Google Cloud and the payment processor) are certified for your volume of transactions (since there are different PCI DSS merchant levels based on the number of transactions). Google Cloud Platform has the highest level of PCI DSS certification, so that’s not a concern, but you’ll have to check your payment processor’s certification level because your volume might exceed their certification level.</p>
<p>Here’s a suggested architecture to handle the company’s credit card processing. Here’s how it works. A customer enters their credit card information in a form on your website. Then your payment-processing application sends the information to the external payment processor. Now the payment processor tells your application whether the card was accepted or declined. After that your payment processing application sends some or all of the response data to your core application, so it knows how to proceed with this customer.</p>
<p>You also need to log and monitor all of these interactions. Every instance involved in payment processing sends its logs to Stackdriver Logging and its alerts to Stackdriver Monitoring.</p>
<p>Now let’s move on to how you would set this up. To reduce the number of systems that need to be PCI-compliant, you have to fully isolate your payment-processing environment from the rest of your production environment. The best way to do this is to use a separate Google Cloud account, rather than just a separate project within your main account.</p>
<p>Then use IAM to grant access only to people who absolutely need to work on the payment-processing environment, such as people who will be deploying new versions of the application or managing the systems. These people must also pass a background check first.</p>
<p>To create the instances, you should first create your own Linux image that’s based on one of the preconfigured boot disk images and that contains the bare minimum of additional software needed to run your application. Then use this custom image when creating all of your VM instances.</p>
<p>To secure the network, create firewall rules that only allow three types of inbound traffic:</p>
<ul>
<li>HTTPS traffic from the load balancer to the payment form servers, so that customers can reach your payments page</li>
<li>Credit card authorization responses from the external payment processor to your internal payment authorization servers, and</li>
<li>VPN traffic from your internal office network to the VPN Gateway, so your authorized people can manage and audit the application and systems.</li>
</ul>
<p>Then create firewall rules for outbound traffic. There’s only one type of outbound traffic you need to allow – HTTPS traffic from the payment form servers to the external payment processor, so they can send credit card authorization requests.</p>
<p>Now all of the traffic in and out of the network is locked down, but you’ll also have to open up internal traffic, such as:</p>
<ul>
<li>From all of the instances to Google’s NTP servers for time synchronization, and</li>
<li>SSH traffic from the VPN Gateway to all of the instances, so authorized people can access the systems for maintenance</li>
</ul>
<p>OK, let’s move on to deploying your application. To be compliant, you have to make sure you’re deploying the correct application every time, that it’s deployed securely, and that no other software packages are installed during the deployment. If you don’t already have an automated deployment tool, then you might want to use Cloud Deployment Manager, which could automate the creation of everything in your payment-processing environment, even the firewall rules. It could also help you create an audit trail of deployments.</p>
<p>Since you’ve used the same custom Linux image for all of your instances, you’ll need to install additional software on each instance. For example, some instances may need a web server, while others don’t, and each instance should only have the software it needs, which will reduce your security risks. To make this process consistent and reliable, it should be automated as well. The easiest way to automate software installation and configuration is to use a configuration management tool such as Chef, Puppet, or Ansible. Cloud Academy has courses on all three of these tools, so check one out if you’re not familiar with how to use any of them. </p>
<p>There are a few packages that you’ll want to install on all instances. First there’s iptables. You can set it up to log all network activity to and from each instance. This data is required for PCI DSS compliance audits.</p>
<p>Second, each instance needs the Stackdriver Monitoring and Logging agents so it can send logs and alerts.</p>
<p>Third, each instance should run an Intrusion Detection System (or IDS) to alert you to suspicious activity.</p>
<p>Finally, your configuration management tool needs to securely retrieve and launch the latest version of your application. </p>
<p>Even with an automated deployment, you’d still need to verify the integrity of the software being deployed. You could do this by running an automated checksum comparison against each package as it’s installed. You could also run an automated code analysis tool to check for security flaws.</p>
<p>Now let’s move on to logging. To be compliant, every step in the payment-processing environment has to be monitored and recorded. All instance activity and all user activity must be logged. Stackdriver Logging is a great service for collecting logs. You can record network traffic to and from your instances by enabling VPC Flow Logs on each subnet in your VPC.</p>
<p>By the way, you might think that we need to assign a service account to the instances so they can write logs to Stackdriver, but the default service account for VM instances already grants write access to Stackdriver, so you don’t need to configure that yourself.</p>
<p>I mentioned that user activity needs to be logged, but you also need to log the activity of people who have administrative access to the environment. The easiest way is to log all shell commands.</p>
<p>The amount of log information generated by all of this is likely to be very large, so you might want to export your Stackdriver logs to BigQuery if you need to do some complex analysis.</p>
<p>In addition to logging, you also need to set up real-time monitoring alerts, such as when your IDS detects any intrusion attempts.</p>
<p>After your environment is implemented, but before any production traffic flows through it, you have to validate the environment, either by contracting a Qualified Security Assessor if you’re a Level 1 merchant or by filling out the Self Assessment Questionnaire if you’re not a Level 1 Merchant.</p>
<p>Wow, that was a lot of work, wasn’t it? Well, if you’re going to be handling credit card information, you’ll be happy when your rigorous security design prevents damaging incidents.</p>
<h1 id="Disaster-Recovery"><a href="#Disaster-Recovery" class="headerlink" title="Disaster Recovery"></a>Disaster Recovery</h1><p>In an earlier lesson, we covered how to design a highly available architecture that will keep running even if an instance fails, by using load balancers, instance groups, and redundant databases. However, there are more catastrophic events that might occur. I’m not talking about an entire city getting destroyed or anything like that (although it would be good to have an architecture that could handle that). But much smaller incidents can be disastrous too. For example, one of your databases could become corrupt. This is actually worse than the database server going down because it may take a while before you realize there’s a problem, and in the meantime, the corruption problem could get worse.</p>
<p>To recover from this sort of disaster, you need backups along with transactional log files from the corrupted database. That way you can roll back to a known-good state. Each type of database has its own method for doing this.</p>
<p>If you’re using Cloud SQL to run a MySQL database (which we are for the interior design application), then you should enable automated backups and point-in-time recovery. Then if your database becomes corrupt, you can restore it from a backup or use point-in-time recovery to bring the database back to a specific point in time. </p>
<p>If you’re using Cloud SQL for SQL Server, then you should enable automated backups. At this time, Cloud SQL does not support point-in-time recovery for SQL Server, so you can only restore a database to the point when a specific backup was taken. For both types of databases, Cloud SQL retains up to 7 automated backups for each instance.</p>
<p>If you’re hosting a database on Compute Engine instances directly, then you’ll have to configure backups and transaction logging yourself. For example, suppose that instead of using Cloud SQL for SQL Server, we ran SQL Server on a Compute Engine instance. Then we’d need to set up our own disaster recovery solution for it. Luckily, Google has a very detailed white paper on this topic. I’ll give you the highlights.</p>
<p>First, set up an automated task that copies the SQL Server database backups to Google Cloud Storage. This is where we would finally need a service account because instances can’t write to Cloud Storage by default. The SQL Server instances need to have a service account with the Storage Object Creator role. Another way to do it would be to set a Cloud Storage access scope for the instance, but service accounts are more flexible.</p>
<p>Once the database is being backed up, then if disaster strikes, you would spin up a new SQL Server instance. Either use one of Google’s preconfigured SQL Server images or your own custom disk image. It doesn’t mention this in the whitepaper, but it’s the sensible thing to do and I’ll talk about it more in a minute. Next, you can use an open-source script to restore the database and re-execute the events in the log files up to the point in time desired.</p>
<p>When you’re designing a disaster recovery solution, you need to consider RPO and RTO. RPO stands for Recovery Point Objective. This is the maximum length of time when data can be lost. It affects your backup and recovery strategy because, for example, if it’s acceptable to lose an entire day’s worth of work, then you can just recover using the previous night’s backups. If you have a short RPO, which is usually the case, then you need to make sure you are constantly backing up your data, and when recovering from database corruption, you have to carefully consider which point in time to recover to.</p>
<p>RTO stands for Recovery Time Objective. This is the maximum length of time that your application can be offline and still meet the service levels your customers expect (usually in a service level agreement).</p>
<p>In the SQL Server example, I suggested using either one of Google’s preconfigured SQL Server images or your own custom disk image that has SQL Server installed and configured. The advantage of having a custom disk image is that it helps you meet your recovery time objective because it reduces the amount of time it takes to get a new SQL Server instance running. If you have to configure SQL Server manually, that could significantly impact how long it takes to recover from a disaster.</p>
<p>As with everything, though, there are tradeoffs. If your SQL Server implementation is customized, then you’ll have to weigh the benefits of fast recovery time against the maintenance effort required to keep your custom image up-to-date . If you have a very short RTO, then you may have no choice but to maintain a custom disk image. You might be able to ease the maintenance required, though, by using a startup script to perform some of the customization. Since the startup script resides on either the metadata server or Cloud Storage, you can change it without having to create a new disk image.</p>
<p>In some cases, you may want to run an application from your own data center or from another cloud platform and use Google Cloud as a disaster recovery solution. There are many ways you could do this, but I’ll go over a couple of common designs.</p>
<p>The first way is to continuously replicate your database to an instance on Google Cloud. Then you would set up a monitoring service that would watch for failures. In the event of a disaster, the monitoring service would trigger a spin-up of an instance group and load balancer for the web tier of the application. The only part you would need to do manually is to change the DNS record to point to the load balancer’s IP address. You could use Cloud DNS or another DNS service for this.</p>
<p>This is already a low-cost solution because the only Google Cloud resource that needs to run all the time is the database instance. But you can reduce the costs even further by running the database on the smallest machine type capable of running the database service. Then if there’s a disaster, you would delete the instance, but with the option to keep the persistent disk, and spin up a bigger instance with the saved disk attached. Of course, this solution would require more manual intervention and would lengthen your downtime, so you wouldn’t want to do this if you have a short RTO.</p>
<p>If you want to reduce your downtime as much as possible, or even keep running in the event of hardware failures, you could serve your application from both your on-premises environment and your Google Cloud environment at all times. That way if you have an on-premise failure, the Google Cloud environment would already be running and serving customers. It would just need to scale up to handle the extra load, which would be automatic if you use an autoscaling instance group.</p>
<p>To make this hybrid solution work, you would need to use a DNS service that supports weighted routing, so it could split incoming traffic between the two environments. In the event of a failure, you would need to disable DNS routing to the failed environment.</p>
<p>And that’s it for disaster recovery.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>I hope you enjoyed learning how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">design a Google Cloud infrastructure</a>. Now you know how to map <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/compute-1/">compute</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/storage-2/">storage</a>, and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/networks-1/">network</a> requirements into Google Cloud, and secure your infrastructure with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/authentication-2/">authentication</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/roles-1/">roles</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/service-accounts-1/">service accounts</a>, ACLs, and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/data-protection-and-encryption-1/">encryption</a>. You also know some of the ways to design <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/high-availability-1/">high availability</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/disaster-recovery-1/">disaster recovery</a>, and PCIDSS compliance into your solution.</p>
<p>To learn more about Google Cloud platform, you can read Google’s online documentation. You can also try one of the other Google courses on Cloud Academy, and watch for new ones, because we’re always developing new courses.</p>
<p>If you have any questions or comments, please let me know on the Cloud Academy community forums. Thanks and keep on learning.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Working-with-Google-Cloud-Storage-from-the-Console-6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Cloud-Engineer-Working-with-Google-Cloud-Storage-from-the-Console-6/" class="post-title-link" itemprop="url">GCP-Cloud-Engineer-Working-with-Google-Cloud-Storage-from-the-Console-6</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:42" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:42-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:57:00" itemprop="dateModified" datetime="2022-11-22T20:57:00-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Working-with-Google-Cloud-Storage-from-the-Console-6/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Working-with-Google-Cloud-Storage-from-the-Console-6/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/35/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/35/">35</a><span class="page-number current">36</span><a class="page-number" href="/page/37/">37</a><span class="space">&hellip;</span><a class="page-number" href="/page/274/">274</a><a class="extend next" rel="next" href="/page/37/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
