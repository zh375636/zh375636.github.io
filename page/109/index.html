<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hang&#39;s Blog">
<meta property="og:url" content="https://example.com/page/109/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/page/109/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/gcp-digital-leader-exam-Knowledge-Check-Cloud-Fundamentals-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/gcp-digital-leader-exam-Knowledge-Check-Cloud-Fundamentals-2/" class="post-title-link" itemprop="url">gcp-digital-leader-exam-Knowledge-Check-Cloud-Fundamentals-2</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 12:30:07 / Modified: 12:30:08" itemprop="dateCreated datePublished" datetime="2022-11-14T12:30:07-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/gcp-digital-leader-exam-Knowledge-Check-Cloud-Fundamentals-2/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/gcp-digital-leader-exam-Knowledge-Check-Cloud-Fundamentals-2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/gcp-digital-leader-exam-Cloud-Fundamentals-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/gcp-digital-leader-exam-Cloud-Fundamentals-1/" class="post-title-link" itemprop="url">gcp-digital-leader-exam-Cloud-Fundamentals-1</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 12:27:06 / Modified: 12:27:08" itemprop="dateCreated datePublished" datetime="2022-11-14T12:27:06-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/gcp-digital-leader-exam-Cloud-Fundamentals-1/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/gcp-digital-leader-exam-Cloud-Fundamentals-1/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Cert-Prep-Developing-Solutions-for-Microsoft-Azure-37/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Cert-Prep-Developing-Solutions-for-Microsoft-Azure-37/" class="post-title-link" itemprop="url">AZ-204-Cert-Prep-Developing-Solutions-for-Microsoft-Azure-37</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 11:57:29 / Modified: 19:30:36" itemprop="dateCreated datePublished" datetime="2022-11-14T11:57:29-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Cert-Prep-Developing-Solutions-for-Microsoft-Azure-37/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Cert-Prep-Developing-Solutions-for-Microsoft-Azure-37/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><object data="4.pdf" type="application/pdf" width="100%" height="600"></object></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Resource-Required-Reading-for-Microsoft-AZ-204-Exam-36/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Resource-Required-Reading-for-Microsoft-AZ-204-Exam-36/" class="post-title-link" itemprop="url">AZ-204-Resource-Required-Reading-for-Microsoft-AZ-204-Exam-36</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:56:50" itemprop="dateCreated datePublished" datetime="2022-11-14T11:56:50-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 10:02:48" itemprop="dateModified" datetime="2022-11-15T10:02:48-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Resource-Required-Reading-for-Microsoft-AZ-204-Exam-36/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Resource-Required-Reading-for-Microsoft-AZ-204-Exam-36/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Required-Reading-for-Microsoft-AZ-204-Exam"><a href="#Required-Reading-for-Microsoft-AZ-204-Exam" class="headerlink" title="Required Reading for Microsoft AZ-204 Exam"></a>Required Reading for Microsoft AZ-204 Exam</h1><p><strong>Before taking Microsoft’s AZ-204 exam, please read the pages at the following links because these specific topics were not covered anywhere else in this learning path:</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/learn/modules/configure-web-app-settings/5-enable-diagnostic-logging">Enable diagnostic logging</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/azure/active-directory/develop/authentication-vs-authorization#authentication-and-authorization-using-the-microsoft-identity-platform">Authentication and authorization using the Microsoft identity platform</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/azure/azure-app-configuration/use-key-vault-references-dotnet-core">Use Key Vault references in an ASP.NET Core app</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/graph/overview">Overview of Microsoft Graph</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/azure/architecture/best-practices/caching#considerations-for-implementing-caching-in-azure">Considerations for implementing caching in Azure</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Exam-Preparation-Additional-Topics-35/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Exam-Preparation-Additional-Topics-35/" class="post-title-link" itemprop="url">AZ-204-Exam-Preparation-Additional-Topics-35</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:55:51" itemprop="dateCreated datePublished" datetime="2022-11-14T11:55:51-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 10:01:48" itemprop="dateModified" datetime="2022-11-15T10:01:48-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Exam-Preparation-Additional-Topics-35/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Exam-Preparation-Additional-Topics-35/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Additional-Topics"><a href="#Additional-Topics" class="headerlink" title="Additional Topics"></a>Additional Topics</h1><p>Congratulations on making it all the way through this learning path. There are a few topics that you’ll need to know for the exam that weren’t covered yet, so I’ll go over them now.</p>
<p>First up is Azure Container Instances. Although Kubernetes is usually the preferred system for running container-based applications, it would be overkill if you just need to run one container. For example, suppose you want to deploy a simple web application that’s in a single Docker container. Using Azure Container Instances, you can deploy it very easily.</p>
<p>All you have to do is run the <code>az container create</code> command and specify the resource group, the name you want to give the container, the image it should use to build the container, the DNS name to assign to its public IP address, and the ports you want to open. This single command will spin up your container. I should point out that the name parameter is technically for the name of the container <em>group</em> because it’s possible to spin up more than one container at the same time, but in most cases, you’ll probably use this command to spin up only a single container.</p>
<p>If you want to check the status of your container, you can use the <code>az container show</code> command. This will give you lots of details about your container, such as its IP address, its operating system, and its current state.</p>
<p>It’s also possible to create and manage Azure Container Instances using PowerShell or the Azure Portal.</p>
<p>The next topic is a feature of Azure Functions called Durable Functions. Typically Azure functions are stateless, meaning when a function runs, it doesn’t know anything about previous runs of that function. A classic example of an Azure function is one that waits for an image file to be uploaded to a particular container in Blob storage and then creates a thumbnail version of that image. It’s stateless because it doesn’t matter what images it processed in the past, it runs in exactly the same way every time. Furthermore, it doesn’t care what other Azure functions are doing either. It only cares about its own job.</p>
<p>This approach is fine for simple applications, but if you try to build a more complex application out of stateless functions, you’ll probably have to write a lot of code to try to coordinate the actions of these functions.</p>
<p>For example, suppose you’re writing an order processing system that needs to execute four different functions in the same sequence every time. To make that happen, you’d have to write code to ensure that the output of the first function triggers the execution of the second function, and so on. It is possible to do this by creating events, but it’s much easier to use the Durable Functions library. Here’s what the C# code for this would look like.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[FunctionName(&quot;ProcessOrder&quot;)]</span><br><span class="line">public static async Task &lt; object &gt; Run([OrchestrationTrigger] IDurableOrchestrationContext context) &#123;</span><br><span class="line">	try &#123;</span><br><span class="line">		var x = await context.CallActivityAsync &lt; object &gt; (&quot;Function1&quot;, null);</span><br><span class="line">		var y = await context.CallActivityAsync &lt; object &gt; (&quot;Function2&quot;, x);</span><br><span class="line">		var z = await context.CallActivityAsync &lt; object &gt; (&quot;Function3&quot;, y);</span><br><span class="line">		return await context.CallActivityAsync &lt; object &gt; (&quot;Function4&quot;, z);</span><br><span class="line">	&#125;</span><br><span class="line">	catch(Exception) &#123;</span><br><span class="line">		// Error handling or compensation goes here.</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Here are the four functions. You just need to put them in the order you want. Also notice the error handing section down here. This is another reason why it’s way easier to orchestrate a workflow using Durable Functions than to try to do it yourself. Here, your error handling code can deal with multiple components in the workflow, which would be very difficult to do with stateless functions.</p>
<p>This is actually one of the simplest use cases for Durable Functions. A more complicated example is called fan-out &#x2F; fan-in. The first function splits the work into multiple tasks that will be executed in parallel by the second function. Then the output from these parallel tasks needs to be aggregated and sent to the third function. This is much more challenging than the previous example because the third function needs to know when all of the parallel functions have completed. Using the Durable Functions extension, the code for this is still relatively straightforward.</p>
<p>The next topic is how to implement web tests using Application Insights. Once you’ve deployed a web application, you’ll want to monitor its availability so you’ll know if it ever goes down. Application Insights provides a great tool to do that.</p>
<p>Go to Application Insights, and then select Availability from the menu. Now click Add Test. The only parameters you have to set are the name of the test and the URL of the website. But there are lots of options.</p>
<p>The default test type is a URL ping test, but you can configure a multi-step web test if you want. This is a recording of a series of requests to send to your website. To create it, you have to use Visual Studio Enterprise.</p>
<p>Parse dependent requests means request all of the images, scripts, and other files in the web page instead of just the one file at the URL you specified.</p>
<p>When this is checked, the test won’t fail until it has tried to connect three times with a 20-second delay between retries. You can also change how often the test is run.</p>
<p>Here, you can set which locations to test from. Microsoft recommends testing from at least five locations.</p>
<p>When you’ve set all of the options, click the Create button. Here’s the web test.</p>
<p>There’s one more step that’s really important. You need to tell it where to send alerts when there’s a problem with the website. But it’s not obvious where to do that. In the context menu for the web test, select Edit alert. Under Action Groups, click Create. Give the action group a name. Then you have to give it a short name that’s a maximum of 12 characters.</p>
<p>You can put it in an existing resource group or just leave it so it’ll create this default resource group. Give the action a name. Under Action type, select Email&#x2F;SMS&#x2F;Push&#x2F;Voice (or one of the other options if you want to send the alerts somewhere else). I’ll tell it to send an email to this address. Click OK, and click OK again. Now click Save.</p>
<p>It’s also possible to set up a web test using an ARM template. Here’s a <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/azure/azure-monitor/platform/alerts-metric-create-templates#template-for-an-availability-test-along-with-a-metric-alert">link</a> to an example of how to do that. OK, that’s it for additional topics for the AZ-204 exam. Please give this course a rating, and if you have any questions or comments, please let us know. Thanks and good luck on the exam!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Lab-Azure-API-Management-Policies-and-Security-34/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Lab-Azure-API-Management-Policies-and-Security-34/" class="post-title-link" itemprop="url">AZ-204-Lab-Azure-API-Management-Policies-and-Security-34</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 11:55:04 / Modified: 11:55:06" itemprop="dateCreated datePublished" datetime="2022-11-14T11:55:04-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Lab-Azure-API-Management-Policies-and-Security-34/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Lab-Azure-API-Management-Policies-and-Security-34/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Configuring-Azure-API-Management-33/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Configuring-Azure-API-Management-33/" class="post-title-link" itemprop="url">AZ-204-Configuring-Azure-API-Management-33</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:54:25" itemprop="dateCreated datePublished" datetime="2022-11-14T11:54:25-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 10:00:30" itemprop="dateModified" datetime="2022-11-15T10:00:30-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Configuring-Azure-API-Management-33/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Configuring-Azure-API-Management-33/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to configuring Azure API Management. My name is Matthew Quickenden, and I am going to be guiding you through some of the key features and aspects of configuring the Azure API Management resource. I have over 20 years industry experience and have recently been working with cloud and hybrid cloud technologies, with a specific focus on <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> and Azure Stack. If you have any questions, feel free to connect with me on LinkedIn, or send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. </p>
<p>This course is intended for people who want to become a certified Azure developer, or who are tasked with creating and managing an Azure API Management resource. To get the most out of this course, you should have a general understanding of Microsoft Azure and be able to deploy and manage resources. Being familiar with restful APIs and having some experience using Postman and an understanding of OAuth token flow would be useful, but not essential. For this course, you do not need any knowledge of any specific development languages. </p>
<p>We are going to look at what Azure API Management is and what it can do, and we will create an instance in Azure. Once we have this instance, we will look at various ways we can secure the APIs and apply policies during different stages of an API request. We will use Postman to help access and consume the service external to the Azure Portal. </p>
<p>By the end of this course, you should be able to set up an instance of Azure’s API Management, secure it using OAuth endpoints, apply policies to alter API requests and responses and be able to troubleshoot and trace policies being applied. Your feedback on this course is important, so please give it a rating when you’re finished. Let’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/getting-started/">get started</a>.</p>
<h1 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h1><p>Because <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/introduction/">Azure API Management</a> takes a while to deploy and become usable we’re going to go to the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> portal and kick off the provisioning process immediately. There is only one blade you need to complete to start the creation of your service which we can review now. </p>
<p>In this case, we can see a screenshot, where I’ve named it clouddemo which is appended with the .azure-api.net suffix. I’ve select a subscription and a resource group. I’ve chosen a location and given the company name. I’ve also entered an email address, this needs to be a valid email as you will receive emails to this based on the service and selected a pricing tier which is Developer. </p>
<p>If we look at the pricing details we can see that the Developer tier costs around 33 dollars a month and contains all the features we need to develop. This includes AAD Integration, virtual networks, the things you are short on, the things like redundancy. You’re only in a single region and you can’t scale. However, all the features you need to develop are there for any of the other tiers. Once you go into production you can change the skew of your API very easily by selecting a new skew. So with all this done, let’s click create and we can let the service provision. Once the service is ready, you will receive a notification email.</p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>While that’s provisioning, let’s take a look at what the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/introduction/">Azure API Management</a> is. On the Microsoft website if you look up what is API Management, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a> defines it as API Management helps organizations publish APIs to external, partner, and internal developers to unlock the potential of their data and services. Businesses everywhere are looking to extend operations as a digital platform, creating new channels, finding new customers, and driving deeper engagement with existing ones. API Management provides the core competencies to ensure a successful API program through developer engagement, business insight, analytics, security, and protection. You can use Azure API Management to take any backend system and develop a fully-fledged API on top of it. </p>
<p>So what does that mean? Using an API is a very common way to communicate over the internet, allowing your organization to provide services in a secure manner. You can consider APIM as a gateway service that provides a developer portal, a publisher portal, and allows developers, publishers, and applications and users to access all the content and data securely hosted in your own backend systems. </p>
<p>Using API Management allows developers to easily consume APIs in different formats, including open API, which is an open standard and language agnostic, WADL XML representation of APIs, WSDL, which is SOAP representation of APIs, and other Azure-hosted services like Logic Apps, Function Apps, and API Apps. </p>
<p>Once you have ingested these APIs, you can create different products, which allows you to deliver parts of these APIs to different user groups with different restrictions and options. When a user or company connects to the API Management service, they obtain a subscription. This subscription is used to help manage incoming requests. Azure API Management also offers a flexible way to version, test, and publish APIs to internal and external users. </p>
<p>Some of the benefits of the Azure API Management are freedom of language choice, scalable, limit access or the number of calls, offloading security, insights for performance and troubleshooting. </p>
<p>Now that we have an idea of what the Azure API Management is and can do and before we proceed with configuring the service, let’s discuss the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/scenario-outline/">scenario</a> of what we’re going to try and achieve over the length of this course.</p>
<h1 id="Scenario-Outline"><a href="#Scenario-Outline" class="headerlink" title="Scenario Outline"></a>Scenario Outline</h1><p>There are a lot of components that make up the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/configuring-the-service/">configuration of the service</a>. Here we are going to explain what we are going to work through. We have already started the creation of the Clouddemo API in our subscription. Once this completes we are going to ingest an API provided by <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a>. This API contains a number of API operations around getting conference data. We will then create a simple API request in Postman. From there we can create the required applications in Azure AD, I’ve already provisioned an Azure AD called Cyber Labs for this demo. And will expect you to have your own Azure AD or if you don’t have one to configure it now. In the Azure AD we will create a backend app, a front end app along with a secret key. We will also grant the front end application permission to access the backend app. We will use the Azure Portal, the Developer Portal, and Postman to query the import of Microsoft Demo APIs using these applications. We will then add API policies and look at how we can scope and understand effective policy and how to trace these policies. Finally we will make sure that our API is secure and that requests to the API require a valid access token or bearer token from our Azure AD tenant which in this case is Cyber Labs. </p>
<p>There are a lot of configuration items throughout this demo I record into Notepad To help you here is all the text. You may just want to copy it from the transcript and fill it out with your specific data as you go through the demos.</p>
<p><a target="_blank" rel="noopener" href="https://conferenceapi.azurewebsites.net/?format=json">https://conferenceapi.azurewebsites.net?format=json
</a>https:&#x2F;&#x2F;{name}.azure-api.net&#x2F;sessions<a target="_blank" rel="noopener" href="https://clouddemo.azure-api.net/sessions">
</a>Starter Subscription Key: 76c24a0abeb94104809b0810f74a20e5<br>Subscription Header: Ocp-Apim-Subscription-Key</p>
<p>Azure AD Tenant: mycyberlabs.onmicrosoft.com<br>Azure AD Tenant GUID: fc9f98a5-2d78-4a13-afa4-2ccfe88db15a</p>
<p>Apps<br>myFrontEndApp ID: 902eef25-668f-4e58-8398-f72a5da893ea<br>myFrontEndApp Secret Key: QZdqqvNXBxm466IvJd5ociARYInUwNyPbXJuJLP3IyE&#x3D;<br>myBackEndApp ID: f9a45df4-6102-4f5c-a855-e2a2cbbab627</p>
<p>Call Back URLs<br>Postman Call back URL: <a target="_blank" rel="noopener" href="https://www.getpostman.com/oauth2/callback[](https://www.getpostman.com/oauth2/callback)">https://www.getpostman.com/oauth2/callback[](https://www.getpostman.com/oauth2/callback)</a></p>
<p>https:&#x2F;&#x2F;{name}.portal.azure-api.net&#x2F;signin<a target="_blank" rel="noopener" href="https://clouddemo.portal.azure-api.net/signin"></a></p>
<p>https:&#x2F;&#x2F;{name}.portal.azure-api.net&#x2F;docs&#x2F;services&#x2F;cyberlabs&#x2F;console&#x2F;oauth2&#x2F;authorizationcode&#x2F;callback<a target="_blank" rel="noopener" href="https://clouddemo.portal.azure-api.net/docs/services/cyberlabs/console/oauth2/authorizationcode/callback"></a></p>
<p>https:&#x2F;&#x2F;{name}.portal.azure-api.net&#x2F;signin-aad<a target="_blank" rel="noopener" href="https://clouddemo.portal.azure-api.net/signin-aad"></a></p>
<p>Endpoints<br>OAuth 2.0 (v1) Authorization Endpoint: <a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/oauth2/authorize[">https://login.microsoftonline.com/{aad-tenant}/oauth2/authorize[</a><br>](<a target="_blank" rel="noopener" href="https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/oauth2/authorize)OAuth">https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/oauth2/authorize)OAuth</a> 2.0 (v1) Token Endpoint: <a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/oauth2/token[">https://login.microsoftonline.com/{aad-tenant}/oauth2/token[</a><br>](<a target="_blank" rel="noopener" href="https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/oauth2/token">https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/oauth2/token</a>)</p>
<p>OpenID Connect meta document: <a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/v2.0/.well-known/openid-configuration[](https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/v2.0/.well-known/openid-configuration)">https://login.microsoftonline.com/{aad-tenant}/v2.0/.well-known/openid-configuration[](https://login.microsoftonline.com/fc9f98a5-2d78-4a13-afa4-2ccfe88db15a/v2.0/.well-known/openid-configuration)</a></p>
<p>V1<br><a target="_blank" rel="noopener" href="https://login.microsoftonline.com/mycyberlabs.onmicrosoft.com/.well-known/openid-configuration">https://login.microsoftonline.com/mycyberlabs.onmicrosoft.com/.well-known/openid-configuration</a></p>
<p>postman Oauth<br><a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/oauth2/authorize?resource=%7Bresource">https://login.microsoftonline.com/{aad-tenant}/oauth2/authorize?resource={resource</a> ID}</p>
<p><a target="_blank" rel="noopener" href="https://login.microsoftonline.com/%7Baad-tenant%7D/oauth2/authorize?resource=%7Bresource">https://login.microsoftonline.com/{aad-tenant}/oauth2/authorize?resource={resource</a> ID}&amp;response_type&#x3D;code&amp;client_id&#x3D;{client ID}&amp;redirect_uri&#x3D;https:&#x2F;&#x2F;{name}.portal.azure-api.net&#x2F;docs&#x2F;services&#x2F;cyberlabs&#x2F;console&#x2F;oauth2&#x2F;authorizationcode&#x2F;callback&amp;state&#x3D;{state ID}</p>
<h1 id="Configuring-the-Service"><a href="#Configuring-the-Service" class="headerlink" title="Configuring the Service"></a>Configuring the Service</h1><p>If we go to our clouddemo API management service and we see the overview, we can see we have the clouddemo.azure-api.net. We can see we’ve got a virtual IP address, the developer tier for this queue that we selected, and the region and the status is currently online. So, this is all the information we expected, which is great. If we go to the APIs, we can see the add API and the different types we looked at earlier. We need to find an API we can import. If you go to your favorite search engine and enter democonference api, you should be able to find the Import and publish your first API from Azure Management. We can see it’s an OpenAPI Specification and it’s conferenceapi on Azure websites in the format of JSON. So I’m gonna copy this URL. I’m also gonna record all these links in just a Notepad for my own reference. So, save that there. And if we actually open this in a browser, we can see the API definition here with the different operations. So this has the GetSessions, GetTopics.</p>
<p>If we return to the API Management service, if we go into the Add API and OpenAPI, we’re gonna add here, and we paste in this URL, we can see that it recognizes the URL and calls it Demo Conference API. The products, and add the Starter and the Unlimited products, which are already defined when the service is created. And click Create. And now that’s imported. So we can see we’ve got the Demo Conference API now in this portal, and we can see a number of operations. I’m just gonna minimize displayed so that we can see more real estate and look at one of these operations itself. </p>
<p>So, can we actually get some sessions back from the Demo Conference API we’ve just imported? We’re just gonna click Test and test it within the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> portal, and click on the GetSessions. We can see here there’s a number of parameters you can pass to it. We’re not so interested in that at the moment. We just wanna see the Request URL gets us some data. So if we press Send, we can see we get the HTTP response back, 200 OK, which is good, it’s green, green is good. And if we look down, we can see a collection of items. So there’s a session here, 100, keynotes with Dan North. We can see another record, time slots. So, this looks correct. </p>
<p>We wanna test this outside of the Azure portal ‘cause we’re likely gonna be building other applications or interacting this with another way. So I’m gonna grab this Request URL here for the sessions. I’m just gonna paste that into my Notepad over here. And we’re gonna go to the Postman application. If you haven’t used Postman before, it’s a free app to download. There is a paid subscription which allows you to share your APIs with different team members. It’s a very useful tool for orchestrating and creating API requests and troubleshooting problems with APIs. </p>
<p>I’d like to go through and make sure that we can access our Azure API services that we’re creating using Postman as well. We’ve just copied in the URL for these sessions. I’ve done nothing more here than create a workspace and a collection called demo. Again, paste that URL in and we’ll just save that, and that’s gonna be called sessions. Select the collection and Save. So now, if we click the Send button, we get an Access denied due to missing subscription key. Make sure you include a subscription key when you make an API request. If we go back to the portal, when we clicked this, we went okay, so we need to understand the difference between what’s happened here and what we need to do to access this externally. </p>
<p>So, what we did do when we first added the API, we added the product Starter and Unlimited. That’s where we’re gonna get our subscription keys from. We’re gonna open up the Developer portal, so you see the link here on the API Management service. That will open another web browser for us. We can see there, it’s Cloud Company. That was the name that we had entered in originally when we created the system. And we can see we’ve got an Administrator log in here. So this is the portal which was created by the API service. You don’t have to create anything. You can customize this. </p>
<p>This is supposed to be the Developer portal on how developers would interact with your API. We wanna create a user. We don’t wanna use the Administrator. So, we’re just gonna sign out. This will allow us to go through the sign up experience. Sign up right away. And I’m just gonna pause the video and enter in some details. </p>
<p>I’ve entered an email, a password, first name, last name, and the characters we see here. And we click Sign up. We’ll save that for ease of use. And we’re told we get a verification email we need to go check. Got that email in my inbox. It’s over here. We can see we’ve got the link, welcome to Cloud Company API account, and we just need to activate this. So, it’s asking me for the password again. And sign up. Just gonna copy this out of that Chrome browser and put it in our Firefox browser here. There’s the user we’re gonna sign back in with. And we can see we have the Cloud Company API Developer portal. We have no subscriptions. So, we need to go to Products and in this case, we wanna sign up for the Starter subscription. Along with the Starter subscription, we can see we get access to the Echo API and the Demo Conference API. Just gonna click Subscribe. And we get to give that a name. Starter is fine. Confirm. </p>
<p>We can see now for Matt Quickenden, we have a subscription for Starter and we started on this date. We have a primary and secondary key. I’m gonna just click Show here and see that key. We’re gonna use this key a couple times, so I’m gonna bring this over to my Notepad and we’re gonna call this MQ Starter Subscription Key, and save. From here, let’s go back to the clouddemo API and we wanna go to the Settings for the Demo Conference API. These settings are around the import for this app, so we can see, here’s the URL we put in. Both the URL scheme are allowed or required. Here are those products we selected. We can see we have Subscription, Subscription required. The header name is this, and the query parameter subscription key. Now that we have the subscription ID and we know what the header is we need to provide, we will go back to the Postman app and add in this information. So, let’s copy out this header name here. This is Subscription Header. Bring up Postman. And we can see we have Headers over here, so let’s click header. Let’s add in the key name, which is the subscription key. And then we’re gonna wanna add in the key itself. So, we take this number we copied, put it in the value, and Send. </p>
<p>We’ve now actually created the appropriate headers to access the information for sessions using that key. We can now do in the Postman portal what we’ve seen happen in the Azure portal. So during this process, we created a subscription. Let’s go back to the API and have a look at what this actually means. Expand displayed, click on Subscriptions. We can see here that this Administrator has access to each of these products. The built-in service has a product. And there’s a Starter product subscribed to Matt Quickenden. If we wanna look at the different products, we have the Product displayed over here. By default, there’s a Starter and an Unlimited, and the access control here for different groups. So, you can create your own subscriptions for different access controls, different levels of permission, different customers, different end users, different developers. They’ll have different access and different levels and that very much depends on how you wanna utilize and segregate your APIs. We’re gonna be just using the Starter for our demo. </p>
<p>So, let’s review what we’ve done. We’ve created the API Management service in the Azure portal. We have imported a Demo Conference API from Microsoft. We’ve created a user in the portal called Matt Quickenden, and we’ve captured our subscription key. We’ve tested a call for GetSessions in the Azure portal itself. And we’ve created a GetSessions request with our subscription key in Postman. We’re gonna pause the demo session here and go back and look at some of the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/authentication/">authentication theory</a>.</p>
<h1 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h1><p>What does offloading security actually mean? It means the built-in APIM is the ability to consume other authentication services, which means you don’t have to deploy and maintain your own security layer. You can allow a range of different public identity services, so that your users can connect to your APIM portal. These services can be Azure AD, Azure B2C, Facebook, Google, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a> and Twitter accounts can all be used to protect and access your APIM. </p>
<p>With regards to securing the APIs directly, APIM has some native features to help secure APIs using OpenID Connect or OAuth 2.0. We are going to be working through the process of setting up and securing an API using OAuth 2, and our Azure AD tenant, Cyberlabs.</p>
<h1 id="What-is-OAuth"><a href="#What-is-OAuth" class="headerlink" title="What is OAuth?"></a>What is OAuth?</h1><p>Let’s review the OAuth authentication protocol. OAuth allows a user to prove their identity without having to share their secure password. It covers authorization, it does not cover <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/authentication/">authentication</a>. A user can obtain a token, which they give to an application to use as proof of that user’s identity. This token is often referred to as a bearer token. Using bearer tokens means third party services, once configured, can validate a user with their identity provider, and provide access to privileged or secure resources. </p>
<p>What is the difference between OAuth and OpenID Connect? The OAuth 2.0 protocol was designed to allow authorization to occur over HTTP. OpenID Connect was designed to be an additional layer on top of the OAuth 2.0 protocol, and adds authentication. For our scenario, we will be focusing on the OAuth 2.0 protocol.</p>
<h1 id="Oauth-Grants"><a href="#Oauth-Grants" class="headerlink" title="Oauth Grants"></a>Oauth Grants</h1><p>There are different types of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/what-is-oauth/">OAuth</a> grants: authorization code, implicit, password, client credentials, device code, and refresh token. We will be taking a look at the authorization code grant, which is what we are setting up for our scenarios. Having an understanding of the code flow is very useful when implementing and troubleshooting. </p>
<p>An authorization code flow is when a client obtains a user’s approval and gets an authorization code that can be exchanged for an access token which is used to gain access to privileged resources. </p>
<p>Let’s take a closer look at the OAuth flow for authorization code. Here we can see we have a user and their browser, a client application, the user’s authorization server, and a privileged resource server. </p>
<p>Let’s walk through the eight steps. First, the process will be initiated by the user trying to get into a client application. Second, the client will redirect the user to an authorization server that they trust. Third, the user will log into the authorization server with their username and password. Fourth, the authorization server will validate the user’s credentials and redirect them to the client application to the reply or callback URL with an authorization token. Fifth, the browser hands the authorization token to the client application. Sixth, the client application will send the authorization token to the authorization server, to the token endpoint, and get an access token. It will also gain a refresh token. Seventh, the application will submit the access token to the resource server. Eighth, the resource server will validate the access token and will allow the client application access to the resource. </p>
<p>With an authorization code grant, at no stage does the user give their credentials to the app. They enter their credentials into a server they know and trust. The other benefit of this flow is the access token does not pass through the browser, which makes it harder to be compromised. </p>
<p>Next, we are going to set up the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/oauth-prerequisites/">AAD applications and delegated permissions</a> that are required to implement this.</p>
<h1 id="OAuth-Prerequisites"><a href="#OAuth-Prerequisites" class="headerlink" title="OAuth Prerequisites"></a>OAuth Prerequisites</h1><p>This demo will be focused on setting up the prerequisites, which are critical to creating the configuration items for our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/what-is-oauth/">OAUTH</a> and making sure we have everything we need to set up the configuration. We’ll be creating two applications in Azure ID, and we will be setting this OAUTH token flow request up into Postman. </p>
<p>So the first thing we need to do is gather some information. Here is our cyber labs domain, we can see the name, there, Cyber Labs on microsoft.com, and it’s also helpful to grab sometimes the directory ID. So if you’ve got a properties, you can see the directory ID here. I’ve recorded this information in my notepad, so we have the My Cyber Labs and the Tenant ID. </p>
<p>Next we wanna create the applications. And it’s important to note here that you need to use the application registrations, not DV-2 application registrations, which are currently in preview. So if we’ve got APP registrations and we create a new application registration. We gonna call this API back end, and for the sign on URL, we want to use for now just a HTTPS on our local host. So we’ll create that and click okay. </p>
<p>Now we wanna record the application ID, so we can click this copy button here, and take that to our notepad, and turn here and we need to create the next application. So new application again, API front end, and for the sign on URL here, we want to use the API’s developer portal. If we click copy here, and return to our application creation, with forward slash sign in. And if we wanna look, I’ve recorded that information here as well, dot sign in. And click okay for create. </p>
<p>We also want to grab this application ID, so that’s API front end, and we wanna put that in our API front end text.</p>
<p>The next thing we’re going to do is create a secret key, that we’re going to use in the front end application to allow us to communicate and exchange the authorization token, to get an access token. We need to go to the settings and go to keys. Here we have no keys. So we’re gonna call this secret. And duration never expires and save. Now you’ll only get to see this value once. So it’s important that you do copy it. This is a secure key and it’s important that you keep it secret. In this case for this demo, we’re just gonna save it on this text file. We have now created the two applications. </p>
<p>The last step is we need to grant the appropriate permissions on the front end application. So under here under required permissions, we need to select the required permissions and add, select an API and we wanna grant the access to the API back end APP which is here. So we select that and we wanna say this application is allowed to access the API back end. We select okay and done. And that has added that delegated permission to this front end application. Something we can use the preview APP registrations for is getting the end points. So if we go over here and select API, we can see a API front end, and if we select in points, we can see all our OAUTH in points. There’s a V two and a V one, currently the API management service only works with the V one end points. So you’ll notice that the URL is slightly different. So in this case we wanna copy the OAUTH two authorization end point version one, and OAUTH two token end point version one. Also copying the open ID connect metadata document, would be useful later. So I’ve copied all these into this document here. </p>
<p>The next step is we wanna configure Postman to utilize all these end points in this application. If we bring up the postman application and go to authorization, under type, select OAUTH two. And we wanna add the authorization to request status, and we need to get the access token. So get new access token. We can see here, this form is blank, we gonna go through and give this a name. We’ll call this our token, the code <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/oauth-grants/">grant</a>, we can see the different types here. We had this mentioned earlier, we want to add a callback URL, as we’re using this in Postman, the callback URL will be postman. So this is copied into this callback URL, paste that in, the authorization URL we’re trying to authorize at our end point, which is the Tenant for Cyber Labs and we’re wanna authorize a particular resource which happens to be our back end application. That’s where we wanna actually get access to. We look at this is the fully constructed URL. So if you can see we’ve got the login from <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a>, the tenant ID, OAUTH and authorize, and after that we do a question mark, resource equals and then the ID of our back end APP. So we’ve already constructed that. I’m gonna copy that and put it under the authorization URL. </p>
<p>Next, we wanna go to the access token URL. So this comes from the OAUTH two V one token end point, copy that and let’s paste that in. And we wanna use the client ID and client key from the front end application. So the front end application had this ID here, and we want the secret for that application, which is here. Paste that in, and let’s try get that authentication token. Now you can see here, I’m currently logged in as mat at cyber labs, which is the administrator for this Azure ID domain and we’ve been given the option to authorize API front end, to access back end up, and sign it and read your profile. So this is what we talked about originally, with the OAUTH flow, and we can see in particular the permissions that does want to access. So we gonna accept that, and we can see the reply URL does not match what’s configured. So when we configured the application, we didn’t add the URL for Postman. So that’s fair that that won’t respond. So in this case, we can close this down, we can see there’s the callback URL we want to allow. So let’s copy that and return to our Azure ID applications, Azure ID application registrations, and we wanna look for API front end under labs. </p>
<p>In the front end app we wanna change the settings and the reply URL. So we can see we enabled the cloud demo portal sign in page, but we haven’t allowed Postman. So if we add the Postman URL to this, we can then save that information. Let’s return to Postman and try to request token again, refresh request, and here we have a token. So we can see we’ve got an APP token, and the token information, what type is it bare, is a bunch of information. We also have the refresh token, so that’s great. </p>
<p>So to review what we’ve done, in the Azure ID, we’ve set up two API applications, a front end and a back end application, we’ve created a secret key on the front end application and we’ve delegated permission to access the back end APP. We’ve also captured the end points for that, and put that information into Postman, which has allowed us to now get a new token from that end point. We also approved access for the API APP to access My Data from the Cyber Labs domain.</p>
<h1 id="Front-and-Back-Channels"><a href="#Front-and-Back-Channels" class="headerlink" title="Front and Back Channels"></a>Front and Back Channels</h1><p>You might be wondering the reason we <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/oauth-prerequisites/">create two applications</a>. Let’s look at the OAuth diagram again. When talking about OAuth, there is the concept of front channel and back channel. The front channel could be a browser on a user’s computer. A browser is very good at interacting with users. For example, presenting the user with a login screen and asking for user approvals. However, we don’t control the browser, and we can’t trust it with sensitive information. The back channel is considered servers or code we control or, more importantly, we can trust with sensitive information. </p>
<p>This is why we get an access token in two phases. First, we get an authorization token through the browser or front channel. We can then exchange this <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/oauth-grants/">authorization token</a> over the back channel using the client ID and secret we have already configured. OAuth utilizes the best things about the front channel and the best things about the back channel in order to obtain the access token or bearer token securely.</p>
<h1 id="Registering-the-Client-Application"><a href="#Registering-the-Client-Application" class="headerlink" title="Registering the Client Application"></a>Registering the Client Application</h1><p>Before a client application can present a token to an authorization server to gain access to privileged information on behalf of a user that application must be registered with an authentication server. To do this the application owner must provide a name, a callback or reply URL to represent the application. We can use this information in Azure AD to create a registered application. When we create the application we get a Client ID which is a public and unique identifier and we create a Client Secret. We give this Client ID and Client Secret back to the client application. With this combination, Azure AD knows who is sending the request and has a list of valid reply URLs stored for that application and will direct the OAuth request to the requested URL as long as it is valid. We saw this earlier with Postman when we tried to get an access token, the request failed because Postman’s callback URL was not on the list of valid reply URLs stored with the Azure AD application.</p>
<h1 id="Decoding-the-Token"><a href="#Decoding-the-Token" class="headerlink" title="Decoding the Token"></a>Decoding the Token</h1><p>Tokens are encoded data, and if we decode that data, we can see that a token is made up of a header, a payload, and a signature. Decoding the data we retrieved from Postman can help us validate we have set up the AAD applications and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/what-is-oauth/">OAuth</a> and Postman correctly. </p>
<p>We can use jwt.io to decode the token and take a look at the payload. If you’d like to do this yourself, copy the token out of Postman, go to jwt.io, and paste it into the encoded field. And you can take a look at the payload yourself. In this case, we can see in the image the aud is the audience for this token, which is the back end application. And we can see the app which is in the application requesting the token is the ID of the front end application. Using this tool, we can see we have validated that our application and OAuth flow are configured correctly. Next, let’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/configuring-oauth-authentication-service/">configure this in our APIM service</a>.</p>
<h1 id="Configuring-OAuth-Authentication-Service"><a href="#Configuring-OAuth-Authentication-Service" class="headerlink" title="Configuring OAuth Authentication Service"></a>Configuring OAuth Authentication Service</h1><p>For our example we’re going to be using OAuth 2.0, so let’s configure the appropriate endpoints. Under the management API service we go to security, OAuth 2.0, and we can see there’s no results here, we click add. I’ve already pre-populated this page here so we’re just going to talk through what the results are. So we have the CyberLabs for a display name. We have a client registration URL. I’ve just made up this URL. The type of grant is the authorization code. The authorization endpoint is the same authorization endpoint we used in Postman. </p>
<p>So if we go back to our document here, we can see that this was the code we used. The next piece of information we need is the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/decoding-the-token/">token</a> URL, again, this is the same as we’ve already used and the token endpoint is here. If we keep scrolling down we can see we need the client credentials, front-end client ID, and the secret. Which we can see here is that same secret key that we’ve put in the text file. And if we click create, we can see that OAuth service is added. </p>
<p>The next step is to use this auth service with our API. So let’s go to the APIs, Demo Conference, and we look at the settings for the Demo Conference API. If we scroll down, we can see security. So let’s select OAuth and we will get a list of all the configured OAuth 2.0 servers. So we’ve only got one, that’s fine, we’ll click save. We’ve now connected this API to the OAuth server. </p>
<p>Next step is we wanna try and view this authorization code. What we’re going to do is launch an incognito browser just so that we make sure we end up with the correct user. I’m gonna go log into portal.azure, and I’m going to use a user that I’ve already configured in the Azure AD. Which is in the onmicrosoft and keep Jessica signed in, yes. So now we’re signed in as a user in the CyberLabs domain. And we want to take the developer portal and log in here. So I’m gonna use my other user. This would probably be Jessica as well, but this is the way we’ve set it up for now. And if we go to the Demo Conference API, and let’s go to the GetSessions, and click try it. </p>
<p>We can see now we’ve got the subscription key, it’s already picked up the primary subscription. But we have a CyberLabs authorization. So if I select authorization code, we’re getting a request here from CyberLabs for the app API to get access to the backend app and read the profile. So we’re gonna accept that. And what we can see here is expected, this is saying that again, the reply URL isn’t valid. </p>
<p>So I wanted to show you a way you can grab this information to try and understand what it’s doing. If you select this header here to Notepad, we’ll just do a quick replace here to help make this readable. 3a becomes a colon and the percent 2f becomes a forward slash. </p>
<p>We can now see that this application is looking for a redirect to cloud portal docs authorize callback. So this is the URL now that we need to authorize again against our application. We go to Reply URLs, we’ve already got it loaded. Paste that in there and save. cloud portal demo docs CyberLabs console, which is the complete URL for us to get to this developer portal. So let’s just give this a hard refresh. </p>
<p>Let’s go to the get authorization token again, and we can see that Bearer Token’s come through. So if we just show that token, let’s just validate what we’ve got there. Copy that token, we’ll go to the JWT.io. And we’ll paste that into our debugger, and we can see we’ve got the backend application, the front-end application, and we’re logged in as Jessica. Oh if we try and execute our request, we’re getting the response 200 back, which is great. Successfully set up the OAuth server. We have successfully connected that OAuth server to our API, collected an authorization code through the browser. </p>
<p>Let’s just try this through Postman, see what we get. So if we put this in, now we don’t have any token here, but we’ve still got the data back. So what we actually need to do is apply a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/api-policies/">policy to check for valid token</a>, which we will do in the next section.</p>
<h1 id="API-Policies"><a href="#API-Policies" class="headerlink" title="API Policies"></a>API Policies</h1><p>A key strength of APIM is that it allows you to apply policies to change the behavior of the API. The policies can be applied on different attributes, like the subscription or data types returned and much more. The policies allow publishers to control or manipulate the requests or the various data at different stages. This screenshot is from the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> Portal and shows us where we can add policies. The Frontend, Inbound, Backend, or Outbound again. </p>
<p>The policy definition is a simple XML document that describes the order that the policies are executed in. This policy can be added directly in the Azure Portal. The portal offers a range of code snippets that you can add to each area to perform a range of functions to a request. Here we can see the XML document with the inbound, backend, outbound, and on-error sections.</p>
<p>Some examples of policies are securing your API by requiring an OAuth token, converting XML to JSON or JSON to XML, rate limiting the number of requests based on the specific subscription, or simply changing header values and callback URLs. Many of these policies can be applied through the UI experience by filling in the form and applying the policy in the right area. You can also code these policies by hand. The solution is very extensible. </p>
<p>Policies can be configured at different levels. You can set an API policy globally or at the scope of a product, a specific API, or individual operation. Before creating a policy, you should decide at what level you want to apply the policy. Policy scopes are evaluated in the following order: Global scope, which is all APIs, product scopes, like starter, API scope, which is like the Demo Conference API or all operations, and operation scope, which is an individual operation. </p>
<p>The statements within the policies are evaluated according to the placement of the base element if it is present. Global policy has no parent and using the base has no effect. We will take a look at what tools we can use to help us understand effective policies and troubleshooting policies during execution.</p>
<h1 id="Adding-API-Policies"><a href="#Adding-API-Policies" class="headerlink" title="Adding API Policies"></a>Adding API Policies</h1><p>Let’s look at configuring <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/api-policies/">policies</a> against the API requests. First thing let’s look for an existing policy. So as we’ve said we’ve got different scopes. If we go to the products and we go to starter, we can see those are policies listed here. We can see there’s an inbound policy which limits the number of calls and renewal period. If we go to Postman and we just run this one, two, three, four, five, this time should fail and indeed it does. So we see the rate is limited, try again in 54 seconds with the 429 request and 47 seconds. So that’s counting down for us. That was an easy way for us to see how this policy has been applied to our particular subscription. </p>
<p>Next thing we do is we want to look at perhaps changing some other policies, maybe an outbound policy. So let’s go back here and look at the API and we want to change the Demo Conference API. This is specific to this API. We want to change all operations, and we want to add some outbound processing. We’re going to try to use the UI here to change some headers. We’ve got the outbound policy and we want to choose set header. So let’s go find a header to change. </p>
<p>If we rerun this request here, and look at our headers, let’s say we don’t want anyone to know what the version of AspNet is. So let’s grab that, there. And we want to delete it. We also want to delete the powered by ASP NET. Add header, delete, delete, and save. Cannot have values, sometimes these get populated with a value. You just need to delete it. If we go and write our query again that’s already saved, we can see those headers have disappeared. So that was very easy to manipulate or control the data coming back from the API. </p>
<p>Let’s say we want to try something a little different. We want to go and edit this policy manually. So rather than choosing this we can choose this button here, choose expand, and we want to do a find and replace. We want to basically replace all the URL CORS that reference this conference API website and send them back to our website. If we scroll down here we can see all the different types of policies we have. In our case we wanna do the find and replace string. So what do we want to find? We want to find anything that says conference, API, azurewebsites, and we want to replace it with our URL. We’ll click save.</p>
<p>So if we go and run the Postman call again, we can see that’s now changed. So we’ve applied two policies, three policies, to the outbound processing of the API request and we’ve applied this to all operations. So let’s say we want to change one particular operation. If we go to get sessions and we want to add a new policy, you can see here we can choose other policies. We want to add an outbound policy here and we’re going to look for JSON TO XML. So we’d like to convert the JSON output to XML for this particular function. So if we click save and go to Postman, let’s try to run that again. </p>
<p>We’re still getting back the JSON version of the code. If you wanted to troubleshoot this, there’s a method for doing that. If we go over to the test, select get sessions, and send the query, we can then click the trace button here. So as much as we’ve got this response, we want to know why that policy hasn’t applied. So we can see the total response time, and we have different sections we can jump to.</p>
<p>So let’s look at the outbound section. The reason that we can see that here, is the content type. It’s not applied. We can see the other policies that we did apply worked. All we need to do in this case is go to the design for that item, and we’re going to change these two values to false, and save. Now if we try this operation and test, click send, we will look at the trace again and we’re hoping to see that the JSON to XML has been applied. Outbound, and we can see that it was set to XML which is exactly what we want. We can validate this by resending the request, and we can see we’ve got a different style of return. </p>
<p>If we save this query, and let’s duplicate it. We’re going to call this one speakers. Change the COR there to speakers. We can see we’re getting JSON from the speakers still, and we’re getting XML from sessions. Effectively applied policy at different levels to manipulate the API request in different ways. The very next thing we want to do is apply the policy to look for the correct token. We’ve seen that we can validate the token, but we’re not applying that to our session. </p>
<p>So again on the Demo Conference API, all operations, I would like to add a new policy. We’re going to go into the code editor for this one and expand. On the inbound policy I would like to validate the JWT token. We need to delete some of this code. We’re going to delete the issuers, audience, the claim, the particular claim we’re going to match as audience and the audience value is the backend application. In the token it will decode it, and we’re looking for this value. We’re going to call this auth, and let’s just change the message here so we know that it’s us, and we need the endpoint that we’re going to validate that token against. We captured this earlier from Microsoft here. </p>
<p>Now there’s only one problem with the endpoint that we got, and that’s it’s version two. We just need to remove the version two and you may also know that you can swap out these values here. If it wants to be more readable, instead of the tenant ID, you can put in your cyberlab’s name there. So let’s grab this openid connect inpoint for validation and put it in here. Don’t forget to leave the html closed, and save. </p>
<p>Now we’ve applied a lot of policies here and we’re maybe not sure exactly what order they’re happening in. What we can do is calculate effective policy. If we choose a particular product, you can see the effective policy view. Here we can see the rate call limited, which was on the product. Different versions are there. If we go and check this against the sessions and we edit this one we should see that particular policy for the JSON to XML call as well. So there’s our oauth, check, jwt token, check, the rate limit, and outbound policy. We’re doing the final replace JSON to XML and removing the headers, so this helps you view all the different policies in one place. </p>
<p>Now let’s test if our policies worked. We’ll try the developer portal first. Jessica let’s give it a refresh. We’re in the get sessions authorization code. Let’s have a look at the token just to make sure we’ve got the right user. So we have Jessica@mycyberlabs, and we’re going for the backend application. Let’s click send. We get a 200 response okay. So we’ve successfully applied that validation code there. If we turn auth off we get the authorization failure, you are not allowed in. Which is good. </p>
<p>Let’s go to the Postman application, and we’ve got our speakers and sessions. We’re gonna say get new access token. We’re gonna call this Jessica, and request a token. Let’s grab this token and prove that we are Jessica, no slight of hand going on. Jessica@cyberlabs on <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft</a> and our audience is the backend application. </p>
<p>If we go back to Postman, we can then choose the token Jessica and preview the header. We’ve then added this token to this header here and we click send so we get a result. Let’s take this to the sessions header. We’re gonna send as well. You’re not allowed in. So make sure we’ve got the latest Jessica token and send, and we get our result. So if we were to remove this token from the header, and send, you are not allowed in. So we’ve successfully secured our API with a validation policy and we’ve tested that and validated that token for that user works. </p>
<p>This concludes the course, and the demos. I hope you’ve found this useful. I’ve tried to include steps here that help with troubleshooting. The oauth token flow is definitely difficult and without some of these tools it’s difficult to troubleshoot.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/introduction/">Azure API Management</a> provides a rich set of features to manage, control, and publish your content. During this presentation, we have published our own API using an existing API from Microsoft. We have focused on using <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/configuring-azure-api-management/what-is-oauth/">OAuth</a> as a method to protect your API. Using Postman has allowed us to set up and consume this service external to the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> portal tooling. And finally, we used Azure API policies to manipulate responses. </p>
<p>There are many other areas worth investigating, from using your own custom domains, using revisions and a Git repository to version and control the release of API functionality, using application insights to help track and troubleshoot performance, also creating alerts. I hope you found this content useful and it helps you create and consume your own APIs.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32/" class="post-title-link" itemprop="url">AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-14 11:52:52 / Modified: 11:52:54" itemprop="dateCreated datePublished" datetime="2022-11-14T11:52:52-04:00">2022-11-14</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Lab-Monitoring-Resources-with-Azure-Monitor-32/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Designing-for-Azure-Operations-31/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Designing-for-Azure-Operations-31/" class="post-title-link" itemprop="url">AZ-204-Designing-for-Azure-Operations-31</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:51:25" itemprop="dateCreated datePublished" datetime="2022-11-14T11:51:25-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 09:48:10" itemprop="dateModified" datetime="2022-11-15T09:48:10-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Designing-for-Azure-Operations-31/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Designing-for-Azure-Operations-31/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Greetings! Welcome to Design for Azure Operations with Cloud Academy! I am delighted to have you join me on what is bound to be an educational and delightful adventure into the world of Microsoft Azure.</p>
<p>First I will let you know a bit about myself before I get into the course outline. My name is Jonathan. I am one of the course developers with Cloud Academy. I work professionally as a technical consultant specializing in DevOps, data engineering, and security. Long ago in another life I was a public school teacher, so I love educating people and I am thrilled to be doing it again only now with technology.</p>
<p>So enough about me, let’s get into this course. Who is this course for exactly? This course is for anyone looking to improve their infrastructure engineering abilities with Microsoft Azure. If you are a DevOps engineer, sysadmin, or security specialist and plan to work with Microsoft Azure at your next job, then this course will be very helpful to you.</p>
<p>So what exactly are the prerequisites for this course then - what do I expect you to know in order to understand the material? Well, not much actually. This is not a programming intensive subject. You do not need any deep knowledge of computer science or software development. The course will focus mostly on explaining Microsoft Azure systems and how to use the Azure user interface. You should know some basic concepts, like what a virtual machine is, or what software application logs are. You should also know some basic networking concepts, like SSL and TCP. If these sort of rudimentary cloud and software concepts are new to you, then you probably don’t need this course anyway.</p>
<p>The course will cover a lot of information given its short length. We are going to go into detail on a number of Azure services and practices. You will learn all about Azure monitoring and automation systems - the kinds of things DevOps engineers would need to worry about in their day to day work. We are going to talk about log aggregation, software application instrumentation, and network security.</p>
<p>There are three core learning objectives for this course. Number one is learning how to use Azure for application monitoring. Number two is how monitor Azure resources and infrastructure. Number three finally, is about task automation in Azure, including instance autoscaling. If you finish the course with a solid understanding of these three things, you will have gotten your money’s worth.</p>
<p>Lastly I want to encourage everyone to leave feedback. Email <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a> if you have any questions, comments, suggestions, or concerns. We always appreciate people taking the time. Now without further ado, let’s get started.</p>
<h1 id="The-Big-Four-Priorities-of-Microsoft-Azure"><a href="#The-Big-Four-Priorities-of-Microsoft-Azure" class="headerlink" title="The Big Four Priorities of Microsoft Azure"></a>The Big Four Priorities of Microsoft Azure</h1><p>For section 1 of this course we have four priorities: System monitoring, application monitoring, log monitoring, and alerting. System monitoring refers to monitoring of cloud resources and hardware with a focus on things like CPU, memory, and network. Application monitoring refers to instrumentation of your own service code - anything you deploy on top of your servers. Log monitoring, as you can probably guess, is focused on analyzing logs generated by your system. Finally alerting is the process by which we automate a variety of alarms triggered by your application getting into an unhealthy state. The fourth priority, alerting, is made possible by the first three - system and application monitoring along with log analysis.</p>
<p>For system monitoring you will need to learn about the Azure Monitor service. For logging you will get acquainted with Azure Log Analytics. For application monitoring Azure offers its Application Insights service, which we will also be using for alerting in the last part of the section. So if you’re ready, we’ll get started now in the next lesson with an introduction to Azure Monitor.</p>
<h1 id="Monitoring"><a href="#Monitoring" class="headerlink" title="Monitoring"></a>Monitoring</h1><p>One of the nice things about Azure is that there are a lot of default metrics automatically reported for different services. For Azure VM’s, system level metrics are enabled by default and viewable in the dashboard. You can see a lot of these metrics right from the Azure compute interface by just clicking on the relevant VMs.</p>
<p>Azure Monitor is sort of your ‘base camp’ for metrics in Microsoft Azure. Azure Monitor, ‘provides base level infrastructure metrics and logs for most services in Microsoft Azure. The service has evolved over time, gradually subsuming more and more types of metrics from other Azure services. We are going to focus on Azure Monitor as our solution for system level monitoring.</p>
<p>In the Azure Monitor interface we can casually browse different system metrics. By default all Azure resources report basic information about network and system state. It is analogous to Amazon’s Cloudwatch. Azure Monitor is meant to be used primarily with Azure resources, however individual components can be used with non-Azure servers. For example the Application Insights component, which we will address in more detail later, can be installed on on-premise servers or virtual instances in another cloud. You could then use Azure Monitor to collect metrics about your Google Cloud or Amazon servers. This is not a very common use case though.</p>
<p>Azure also has a diagnostics extension that can be used for application performance monitoring. For this course we will be using Application Insights for this sort of monitoring, but it is cool to know that Monitor is also getting into this use case. In the future the two systems may become more tightly integrated, so it’s good to be aware of it.</p>
<p>By default Azure Monitor will store metrics for 30 days. If you need to keep metrics for longer than that you will need to store them somewhere. You can easily import metrics into Azure storage by using the console. If you wish to store metric data elsewhere, you can also export everything to some other system.</p>
<p>Now that we have a good understanding of Azure Monitor’s capabilities and how to get started, our next priority is looking at log aggregation. In the next lesson we’ll talk about Azure Log Analytics and learn how it can be your one-stop shop for logs. Let’s get to it.</p>
<h1 id="Log-Analytics"><a href="#Log-Analytics" class="headerlink" title="Log Analytics"></a>Log Analytics</h1><p>Having application and system level metrics is a minimum requirement for a proper monitoring system. However log aggregation is a similarly important but often overlooked part of an overall monitoring strategy. Many companies do not even think about proper log management until some disaster comes along and they find they cannot properly identify the root of the problem. Being able to collect and quickly analyze large numbers of logs is extremely helpful for any forensic investigation.</p>
<p>Companies spend large amounts of money and development on solutions like Splunk or ELK. With Azure, you get a baked in solution with Azure Log Analytics. It gives you an easy way to search a variety of types of event logs and has simple quickstart guides for Linux, Windows, and Azure VM server types.</p>
<p>The setup for Azure VM’s is easiest. All you will have to do is enable to log analytics extension from the console. With just a few clicks you can immediately start collecting event data for analysis. For Linux and Windows servers you will need to obtain a set of credentials - specifically a workspace ID and key. These will be used to set up the log analytics agent that will run on your server. The actual agent installation is pretty straightforward. You can do it with a few terminal commands in Linux. For Windows, you can download the agent from Azure directly and set it up with a few clicks on the relevant server. In both cases, you will need to configure the agent with the workspace ID and key so that the log data is sent to your Azure portal.</p>
<p>From the Log Analytics portal you will do most of your setup using the ‘Advanced Settings’ tab. There you can type in the name of the relevant logs to set as event logs. You can enable OS performance data for Linux or Windows with a separate option and configure severity levels WARN and ERROR for isolating potentially serious events. Once you are done with configuration, you can freely search and view log data by clicking on ‘Log Search.’ There you can type in any arbitrary pattern and find matches among all of your events.</p>
<p>One final cool feature to note about Azure Log Analytics is the ecosystem of additional plugins, known as ‘management solutions’ that you can add to your workspace. Management solutions are additional data acquisition rules and visualizations that let you really customize your log analysis needs to your specific use case. There are dozens of them available. Just to name a few examples, there is a management solution specifically for container monitoring, a solution for tracking specific events in your activity log, and a solution for automated real-time server mapping and graphing. If you want to really get the most out of your log data then it is definitely worth your time to browse these additional features for Azure Log Analytics.</p>
<p>In the alerting section we will discuss how to use Log Analytics for automatically catching dangerous conditions in your system. For now, you should have a basic understanding of how to set up Log Analytics and use it for investigating your systems. Next, we move on to application monitoring with Application Insights. See you there.</p>
<h1 id="App-Monitoring"><a href="#App-Monitoring" class="headerlink" title="App Monitoring"></a>App Monitoring</h1><p>Now that we have a solid understanding of log analysis and system monitoring in Azure, we can proceed to the final and most critical component of our instrumentation: Application monitoring. This is a deeper level of monitoring that goes beyond just tracking the state of the hardware. When we talk about application monitoring, we really mean monitoring everything we actually put into our infrastructure - all of our own unique business logic, internally developed software, and external libraries.</p>
<p>The general way to do this is to use a monitoring library with your code. There are many such libraries as frameworks for different languages, such as dropwizard metrics or ERMA for Java. Application Insights is similar in that you will need to add it to your code base before you can start getting metrics. Like many such frameworks the library is pretty lightweight and should not cause much performance overhead. Tracking calls are non-blocking, batched, and sent in a separate thread.</p>
<p>Application Insights can be used to monitor applications running <em>anywhere</em>. You can use it to monitor applications hosted in another provider like AWS or Digital Ocean. You can use it to monitor applications hosted on premise or even on your personal computer. All that Azure needs is for your application to have the Insights library installed and sending metrics to an endpoint in Azure.</p>
<p>Now, the Azure Portal has some great quickstart guides for a few languages including Java, Node.js, and .Net. It starts by having you create the Application Insights resource in the portal. You will need to set an app name, a region, an application type (usually just the language or framework name), and a resource group name, which is just the name for the resource actually hosting the metric data.</p>
<p>Once you have the Application Insights resource defined, step two is installing the library in your app. The quickstart guide shows how to do this very quickly using an IDE like Eclipse. It can also be done manually if you carefully follow the Azure documentation. There are some useful code examples that show how to actually get your application code to send data.</p>
<p>Once you have solid application and system monitoring in place, you need to make use of all that data. You need to empower your systems to send you actionable alerts when metrics suggest that something is wrong. In the next lesson we will discuss how to create meaningful alerts using application and system metrics.</p>
<h1 id="App-Alerting"><a href="#App-Alerting" class="headerlink" title="App Alerting"></a>App Alerting</h1><p>A key principle with alerting is ensuring that alerts are actionable and relevant. If you set up a large number of irrelevant alerts that fire constantly, you will train your team to ignore all alerts. Maintaining a good signal to noise ratio is critical with alerts that may require human intervention. It is similarly important that you try to make sure all alerts are actionable. This is not always possible - sometimes you may have to configure an alert for a situation that is not easily resolved. To the extent possible, you want to try to have documented responses to alerts so that the majority of your alerts are actionable.</p>
<p>For system level alerts - things like low disk space or high cpu load - we can use Azure Monitor. In the Azure Monitor portal we can configure notifications to fire when specific metric thresholds are met. From the monitoring dashboard click on the ‘Add metric alert’ button and create a name for your alert. You will then pick a relevant metric and set a condition such as ‘greater than’ or ‘less than’ some specific value.</p>
<p>You also will have to set a time period for the condition such as ‘5 minutes’. This would mean that the alert condition must be sustained for five minutes in order for the alert to trigger. It is crucial to think very carefully about the time period parameter. Configuring it incorrectly can lead to false positives or false negatives. For example, let’s say we set an alert for CPU load. We set it to alert whenever load is above 2.0 for more than 3 minutes. This may be too sensitive, as perhaps your application regularly has short periods of high load that are expected. In such case the alert would just end up being noise and training your response team to not take alerts seriously.</p>
<p>For Azure metric alerts be sure to add the right email address under the ‘Additional administrator email(s)’ section. This way you can ensure that the right people are notified when an alert is triggered.</p>
<p>Application Insights alerts are similarly easy to set up for your application performance metrics. From the Insights dashboard just click on ‘Alerts’ and then ‘Add alert’ to get the setup menu. From there you will define the alert rules in much the same way as we did with system metrics. You will pick a metric, a time period, a threshold, and a condition. You can set contact emails or a webhook address if you wish to integrate your Insights alerts with another system.</p>
<p>Finally it is possible to set up alerts based on queries run by Azure Log Analytics. From the Analytics dashboard you can create the alert rules by defining a time window and query. If the query returns the expected result within the time window, and alert can be generated. This can be used for example to catch serious ERROR messages that were output to an event log within some time frame.</p>
<p>And that about wraps it up for alerting using Azure Monitor and Application Insights. As we have seen, we can create a variety of alerts based on system metrics and application performance stats. Keep in mind the importance of minimizing noise with your alerts - make sure that when an alert is triggered it really means something. With this in mind, let’s move on to the next major section of course.</p>
<h1 id="Network-Security-and-Access-Management-with-Azure"><a href="#Network-Security-and-Access-Management-with-Azure" class="headerlink" title="Network Security and Access Management with Azure"></a>Network Security and Access Management with Azure</h1><p>Now that we have a solid understanding of application monitoring and alerting with Azure, we need to think about how to properly monitor Azure resources at a higher level. While Azure Monitor is a pretty flexible system for getting basic metrics about Azure VM’s, we need to think about how to monitor other Azure components. We also need to think about Azure network security and access management.</p>
<p>Section two will address these priorities in three parts. In part one, we’ll look at how to actually monitor all of the different Azure components using Azure Health, Azure Advisor, and the Activity Log. In part two we will focus on network security the Network Watcher Service and Azure Log Analytics. Finally in part three take a detailed look at the Azure Security Center and see how it can help ensure our Azure infrastructure is not compromised.</p>
<p>So without further ado, let’s begin.</p>
<h1 id="Monitoring-Platform-Resources"><a href="#Monitoring-Platform-Resources" class="headerlink" title="Monitoring Platform Resources"></a>Monitoring Platform Resources</h1><p>Out first monitoring priority is just tracking the health of Azure itself. Azure Health is your first line of defense for identifying problems with Azure platform resources. It is the most high level view of your cloud system and is generally the best place to start if you are experiencing problems and have no other leads.</p>
<p>Azure Health offers three basic levels of information about your infrastructure. At the highest level is Azure Status, which is simply a dashboard with information about the health of all of Azure’s different components. This information is not specific to your account; rather it will tell you if there is a global issue with a particular Azure service, such as virtual machines or storage. A quick check of the Azure Status dashboard is the fastest way to rule provider level problems when debugging failures.</p>
<p>The next level is Azure Service Health. It is similar to Azure Status but focused only on Azure resources in your account. Like Azure Status it is a dashboard only this one is customizable. You can arrange elements to focus on specific Azure products and regions.  Also like Azure Status, it will give you a general health check for each product category and inform you of issues that need your attention. Azure Service Health will notify you of planned maintenance that may affect your system. It will also warn you if you are approaching a resource quota or if a feature you use is about to become deprecated. After a quick check of the Azure Status dashboard, Azure Service Health is often the next best place to quickly examine when you are in the middle of responding to some kind of system failure.</p>
<p>Finally you have Azure Resource Health, the most granular level of inspection in the Azure Health suite. With Azure Resource Health you can get the status of specific instances of Azure resources, such as a single VM. It will let you know if a given resource is unavailable and it keeps a very useful log of platform events. You can see if an Azure platform SLA was violated at any point. With its very simple status messages and historical data, Azure Resource Health is the simplest way to monitor individual resources from the Azure platform’s perspective.</p>
<p>The Azure Health set of services gives us a lot of information to track our system’s health over time. However we often need to more than just data; we need some analysis and a more granular view of system events. To address these two issues we will use Azure Advisor and Azure Activity Log respectively.</p>
<p>Azure Advisor, as the name implies, is a personalized cloud consultant. It automatically examines all of your Azure resources and identifies ways to optimize them. It will spit out tons of recommendations automatically focusing on security, availability, performance, and cost. The nice thing about Advisor is that it’s really simple to use. Literally all you do is click “Advisor” in the left pane menu and you’ll get a summary of recommendations. You can then drill down to one of the four categories I just mentioned. So for example, you might get a cost recommendation telling you to scale down your storage provisioning if you are not actually using much of it.</p>
<p>So Azure Health has given us copious amounts of information about our system and Advisor continually helps us optimize. The final component is tracking system changes over time. For this we have Azure Activity Log.</p>
<p>Azure Activity Log is a subscription log that records events using event data from Azure Resource Manager. It records eight specific types of events: Administrative, Service Health, Security, Alert, Autoscale, Recommendation, Policy, and Resource Health.</p>
<p>Now, Azure Activity Log is accessible from a wide range of tools. You can get event data from the console, Powershell, CLI tools, and the Azure Monitor REST API. You can do a lot of useful things aside from just viewing system event data in the dashboard. You can store the data offline and query it programmatically with scripts. You can set alerts against specific types of event. You can also stream Activity Log data to external event hubs such as a third party analytics tool or monitoring system.</p>
<p>Activity Log is a very flexible tool and is very simple to use. That said, it is important to understand its limitations. It is not a replacement for proper application logging and monitoring. Activity Log is primarily concerned with Azure Resource Manager events. Some of the older “classic” type resources will not by default send events to Activity Log. You will need proxy resource providers to make the operations appear in Activity Log.</p>
<p>So now we are at the end of our dive into platform resource monitoring. You should have a basic understanding now of how Azure can monitor its own assets, track events over time, and automatically help us use resources most efficiently. So next we move onto all of that space in between our Azure resources: the network. In the next lesson we will learn how to properly monitor our network infrastructure in Azure.</p>
<p>Let’s get to it.</p>
<h1 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h1><p>We have spent a good deal of time covering how to monitor the physical infrastructure of our system. We have covered application level monitoring and Azure resources from the smallest levels up to the entire set of Azure datacenters. Our priority now is to fill in the gaps - to track what happens in between all of those resources at the network level. Our main tool to accomplish this will be the Azure Network Watcher service. We will also revisit Azure Log Analytics as it plays a role here too.</p>
<p>Network Watcher is a comprehensive network topology monitoring and analytics solution. It is comprised of several features. A full list is presented here in the slides. I will not dive deeply into every single one so it is a good idea to pause the lesson and read through each description. I will cover three of the more important Network Watcher tools so that you know how to handle basic network level monitoring.</p>
<p>It starts with the Topology app. This gives you a network level view showing the various interconnections between network resources within a given resource group. This will be your go-to tool when you need to get a clear picture of your network infrastructure.</p>
<p>Next up is the Variable Packet Capture tool. This lets you capture packets flowing in and out of virtual machines, much as you might do with tcpdump or wireshark. You can filter the capture tool to set size and time constraints and then store the packets in the Azure blob store or on the VM disk. This is a really useful surgical tool for analyzing very low level network events.</p>
<p>Thirdly there is the Next Hop tool. This is a personal favorite because it can identify unexpected behavior. Basically it just determines the next hop for packets routed in the Azure Network Fabric. It is great for identifying problems with user-defined routes.</p>
<p>There are eight other great tools to look at in Network Watcher. It’s worth giving a quick mention to the NSG Flow Logging, Security Group View, and IP Flow Verify tools, all of which are really great for identifying where exactly packets are permitted to go and not go. Again, be sure to take a deeper look at the documentation to learn about the other Network Watcher tools.</p>
<p>Azure Log Analytics adds a few useful supplemental feature  to your overall network monitoring system. They are activated through the Log Analytics UI and so need to be addressed separately. Most are just additional levels of instrumentation. For example there are the DNS Analytics and Traffic Analytics components. The former is for DNS administrators and aggregates DNS logs. The latter is for aggregating and visualizing public internet traffic against Azure systems.</p>
<p>Two larger pieces of the Log Analytics network monitoring feature set, are the Network Performance Monitor and the Application Gateway analytics solution. We’ll start with the Network Performance Monitor. At a high level, all it is meant to do is track performance between various parts of your infrastructure. The power comes from the versatility and the web interface. Network Performance Monitor can track loss and latency across  various subnets and set alerts. It can track connectivity between user locations, multiple data centers, on-premise locations, and other endpoints, all while visualizing everything in an intuitive UI.</p>
<p>The Application Gateway analytics solution will provide you with an additional level of network logging, specifically firewall logs, performance logs, and access logs for application gateways. It is quick to set up too. Simply enable the Azure Application Gateway analytics solution from Azure Marketplace and then enable diagnostics logging for the desired application gateways.</p>
<p>Whew! So this was pretty thorough. As you can see, Azure gives you A LOT of tools for monitoring your network infrastructure. If you are the type that likes to be able to audit every single packet, then Azure is going to be a lot of fun for you.</p>
<p>Our final priority in this section is going to be security. We have covered in depth how to track everything that happens in our system both in transit and at rest, so now we need to think about how to harden the system from threats. We’ll dive in in the next lesson. See you there space cowboy!</p>
<h1 id="Securing"><a href="#Securing" class="headerlink" title="Securing"></a>Securing</h1><p>Properly securing your cloud infrastructure is a multi-faceted effort. It includes a lot more than just using the tools provided by your hosting solution. It takes employee training, secure coding practices, properly maintained facilities, regular auditing, and a number of other important practices. That said, Microsoft Azure does of good job of simplifying the task of securing its own resources. Thanks to the Azure Security Center service you have one full-featured centralized solution for hardening your entire Azure infrastructure.</p>
<p>Security Center is automatically included with your Azure account at no additional charge. By default it can only be used with your Azure systems. If you upgrade from the free tier to the ‘standard’ tier, you can have Security Center work with non-Azure resources in a sort of hybrid infrastructure model. The upgraded ‘standard’ tier also adds a number of useful features not available to the free tier. These include advanced threat detection systems for Azure systems, customizable alerting, security event collection and search, and a threat intelligence module.</p>
<p>Security Center’s core functionality, available in both the free and standard tiers, is its security policy system. Security policies let you defined the configuration of your workloads such that they satisfy specific company or regulatory security requirements. When you access the Security Center UI you will discover that there are default policies for all Azure subscriptions. These policies include recommendations that can be turned on or off. A good place to start looking is at your computer resources. On the Security Center dashboard, click ‘Overview,’ and then select ‘Computer.’ It will display a color-coded list of recommendations for your entire computer infrastructure.</p>
<p>The security policy and recommendation services are the bulk of what the free tier of Azure Security Center does. It might seem simple, but it is actually quite powerful, particularly if you are <em>only</em> using Azure for your cloud environment. You get tons of free recommendations and a central location for auditing and adjusting security policies to suit company compliance requirements. When combined with all of the other monitoring, event logging, and alerting systems in Azure that we have already covered, you have all the tools you need to maintain a hardened, transparent, self-optimizing infrastructure.</p>
<p>We strongly recommend digging into the Security Center documentation to learn about some of the additional features at the standard tier. In particular VM access management and customizable alert systems can be very helpful for complex cloud systems. One cool thing is you can actually use the standard tier with all of its additional features completely free for 60 days. It’s a great way to see if you actually need any of its advanced capabilities.</p>
<p>So with that, we come to the end of section two. We have thoroughly covered platform monitoring, network monitoring, and security for your Azure systems. Congratulations on making it this far. You’re ready to really do some great operational work for any Azure environment now. Our final section will focus on operation automation. See you there!</p>
<h1 id="Automation-Overview"><a href="#Automation-Overview" class="headerlink" title="Automation Overview"></a>Automation Overview</h1><p>This is a very broad topic that could easily be its own course. For our purposes we will focus on Azure-specific technologies and introduce a few third-party tools that integrate well with the platform.</p>
<p>We will again divide our subject into three parts. We will start by just introducing the relevant automation technologies, namely, Chef, Puppet, PowerShell, Desired State Configuration, Event Grid, and Azure Logic Apps. The next two sections will be about using these technologies to address the challenges mentioned above: Autoscaling, and task automation. By the end of this unit you should have a solid understanding of how to automate operations in Azure.</p>
<p>So without further ado, let’s get started.</p>
<h1 id="Automation-Technologies"><a href="#Automation-Technologies" class="headerlink" title="Automation Technologies"></a>Automation Technologies</h1><p>When it comes to automation with Azure we have a lot of different options. The three basic categories are Azure web console tools, PowerShell scripts with Azure SDK, or a third party tool like Chef. Which approach we take will be a function of our expertise and the nature of the work we want to automate.</p>
<p>We will start by focusing on Azure’s built-in tool set. Azure Automation is comprised of two core pieces: Runbooks and Configurations, both built on top of PowerShell. Before you do anything you will need to set up an Azure Automation  account in the UI. Once done you are ready to start writing PowerShell runbooks and PowerShell Desired State Configurations (DSC). A runbook is a simply a collection of scripts. These scripts use the Azure SDK API to execute changes to your Azure system. It takes some programming knowledge to use it properly. The upside is that Powershell is far more flexible than simply using the web gui.</p>
<p>Desired State Configurations are special methods within PowerShell that let you predefine a configuration state for your servers. For example you can enforce that specific ports are open or that only a specific set of software is installed. DSC greatly simplifies the process of writing scripts by letting you work from the end state. The Azure documentation and console make it very easy for non-programmers to generate and import basic PowerShell DSC scripts in their Azure Automation account. It lets you define a specific end state for your Azure systems and let Azure do the work of getting things there. Be warned that DSC Configurations sometimes do tasks in a manner or order you don’t expect. If you have very delicate requirements regarding how and when things change in your system it may be better to write more explicit PowerShell code instead of relying on DSC.</p>
<p>Azure also has a service for intelligent event routing. It is called Azure Event Grid and it lets you automate responses to relevant events across both Azure and non-Azure services. Event Grid uses a publish-subscribe model and is configurable in the portal or by using Azure CLI or Powershell scripts. To use Event Grid you need to create an event subscription. This is done by selecting ‘Add Event Grid subscription’ to the relevant app in the Azure portal. The Azure documentation includes a number of handy examples of how you can make use of this. In one it shows how you can use Event Grid to automatically resize images uploaded to your Azure storage. It can be done in minutes and save you a great deal of time and money that would be spent on manually fixing images.</p>
<p>Let’s turn our attention to some non-Azure tools. Chef and Puppet are two cloud infrastructure automation tools. Both have open source offerings that have integrations with not only Azure, but other providers like Google Cloud and AWS. Chef and Puppet have different names for their different pieces. For example in Chef, modules are described as ‘cookbooks’ with scripts called ‘recipes.’ In Puppet these things are called ‘manifests’ and ‘modules.’ One thing to note is that both are fairly complex tools. If your automation needs are very simple, then it is likely not a great idea to try to set up Chef or Puppet; better to just stick with Azure’s built-in tools such as PowerShell with DSC or Event Grid.</p>
<p>So we he have discussed Chef, Puppet, Powershell with DSC, Runbooks, and Event Grid. As you can see, we have a lot of options when it comes to automating work in Azure. In our next lesson we will focus in on a specific use case: autoscaling. Let’s get started.</p>
<h1 id="Autoscaling"><a href="#Autoscaling" class="headerlink" title="Autoscaling"></a>Autoscaling</h1><p>Azure has multiple systems for automatically scaling computer resources. Our focus will be on horizontal scaling - namely, adding additional compute resources instead of trying to switch to a larger instance.</p>
<p>The simplest approach with Azure is to use Azure Monitor’s built-in autoscale feature. This lets you automatically scale up and down compute resources based on metrics.</p>
<p>Azure VM’s also have a concept known as ‘Scale Sets.’ A Scale Set is simply a group of VM’s that can be given autoscaling rules. They are similar to AWS autoscale groups and make for a handy way to organize and think about your VM’s in terms of large groups instead of individual machines. Scale Sets can also be configured through Azure Service Fabric. Each node type in a Service Fabric cluster can be a separate VM scale set, thus allowing each node type to scale up or down independently.</p>
<p>Azure autoscaling is also available for the Azure App Service. Autoscaling is actually built right in as an app-level setting. It will allow you to scale based on a designated metric. You select a value and also use a slider to set your maximum and minimum number of instances. Similarly, Azure Cloud Services have a setting for autoscaling. The difference here is that scaling is based on number of cores being used. Depending on your subscription you may have a limit for a maximum number of cores for autoscaling. You can set this up in the portal by clicking on the scale tab in the portal and setting it to ‘automatic.’</p>
<p>Finally, probably the most bleeding-edge approach to autoscaling, would be to cut out VM’s and containers entirely and just use Azure Functions. If you can adopt a serverless paradigm wherein your app logic is defined using Azure Functions, then you won’t need to think about autoscaling at all. The Azure platform automatically allocates computer resources as necessary to any code running as an Azure Function in your account.</p>
<p>We won’t focus much on non-Azure autoscaling systems. I’ll instead just take a quick second to remind you that such systems exist. Kubernetes, for example, has support for horizontal scaling of ‘pods’ based on metrics. You can also integrate your configuration management tools like Chef with your monitoring to create autoscaling logic.</p>
<p>So now that we have a good understanding of what autoscaling looks like in Azure, it is time to broaden our automation scope. In the next lesson we will discuss how to automate arbitrary tasks in Azure using a variety of different approaches. See you there.</p>
<h1 id="Task-Automation"><a href="#Task-Automation" class="headerlink" title="Task Automation"></a>Task Automation</h1><p>Azure is very flexible when it comes to arbitrary task automation. In this short lesson we will introduce a few common maintenance tasks and explain how we can fully automate the work using different tools.</p>
<p>As we have seen in earlier lessons, Azure integrates well with management tools such as Chef and Puppet. If, for example, you are already very comfortable with Chef, then it trivial to automate any task defined in your Chef code on subsets of your servers. There is an easy to use cron Chef cookbook that lets you define cronjobs. One common use-case is to automate the chef-client run itself to run every few minutes. This ensures that configuration changes are automatically propagated quickly.</p>
<p>Another common need is automated resource deletion and re-creation. For example a business may want to save money by not running Azure VM’s during non-work hours. Automating this safely requires ensuring you have a reliable way of preserving the environment’s state and then recreating and deleting resources easily. This is do-able using Chef and Puppet if you have your infrastructure well-defined in your config management code. A perhaps easier approach, however, is to use a runbook with a Powershell Workflow.</p>
<p>As mentioned in the previous lesson, runbooks are just collections of Powershell scripts. An Azure Powershell Workflow uses runbooks to execute a series of tasks. Workflows add a number of useful features to your Runbooks. For one, they can be scheduled, and they can include automated failure recovery and retry logic. Workflows can help automate many simple maintenance tasks. For example, you can create workflows that save your environment state every day at 8 pm and then delete unneeded resources. Then you can have another workflow that executes a runbook to recreate everything the next day at 8 am. This would cut your Azure hourly costs in half.</p>
<p>You might need several different scripts to do all of the work of snapshotting your environment, deleting everything safely, and then recreating everything in the right order with proper tests to ensure environment health. You could combine the scripts into multiple runbooks and multiple workflows.</p>
<p>Powershell workflows are great for people comfortable writing scripts. For people that prefer to focus on GUI tools, Azure has its Logic Apps system. Azure Logic Apps let you automate and schedule workflows. Logic Apps are similar to Powershell scripts in that they can include conditional statements, switches, loops, and branches. All of this is definable in the GUI, so if you have ever done any coding using a GUI you will have a sense of what to expect.  You can define a logic app in the Azure portal. You will have to define a resource group to let the logic app know what Azure components it will access, and then you define a schedule trigger, which lets you set the exact time interval for when to execute the app.</p>
<p>So that’s basically all you need to know about task automation in Azure. You have your third party services like Chef and Puppet. These integrate well so if you’re familiar with them you can continue to lean on them with Azure. If you prefer writing scripts perhaps because you like checking them into version control and being more transparent, Powershell works great with Azure runbooks and workflows. If you are not as confident about writing scripts, you’ve got Azure Logic Apps, and that will let you automate pretty much anything involving Azure resources.</p>
<p>So keep those core three approaches in mind and congrats on making it through this final section of the course. We will finish up with a final course summary in the next lesson. See you there.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Congratulations on completing the Microsoft Azure Design for Operations course. For a relatively short course there is a lot of material crammed in here, and you made it through, so kudos. We covered a lot of ground.</p>
<p>We started by talking about application monitoring and alerting. We learned how to thoroughly instrument applications using Azure Application Insights and we learned how to aggregate log data using Azure Log Analytics. We explored the numerous features in the Azure Monitor system.</p>
<p>We then learned all about how to monitor the Azure platform itself. We went over how to use Azure Status and Azure Health to quickly assess the state of both our own Azure resources and the wider Azure platform. We learned about how to optimize our resource usage with Azure Advisor. We covered how to use the Activity Log for forensic investigations and resource tracking. We also covered the Azure Network Watcher service and Azure Security Center to handle network and platform security respectively.</p>
<p>Finally we did a deep dive on Azure automation. We learned how to autoscale resources using Azure Autoscale, and we learned how to automate various tasks by using Powershell and Runbooks. We also reviewed configuration management technologies like Chef and Puppet to see how they integrate with our Azure systems.</p>
<p>By combining all of this knowledge we have a skill set for thoroughly modernizing our cloud infrastructure. We can instrument, monitor, configure, automate, and secure our Azure systems as well as a professional DevOps engineer. That’s pretty darn cool for a class like this. Of course remember that practice makes perfect. We have described a lot of technology in this course. It is up to you to actually play around with things in Azure and develop some intuition.</p>
<p>Now that you are done I’d like to invite you to send any feedback you have about the course to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. We greatly appreciate your comments, questions, and suggestions. Congratulations again on fighting through the whole course and good luck in your future endeavors.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/14/AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30/" class="post-title-link" itemprop="url">AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:49:44" itemprop="dateCreated datePublished" datetime="2022-11-14T11:49:44-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 09:38:44" itemprop="dateModified" datetime="2022-11-15T09:38:44-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Integrating-Redis-Cache-and-CDN-on-Azure-30/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>- [Thomas] Welcome to Integrating Redis Cache and CDN on Azure. My name is Thomas Mitchell and I’ll be taking you through this course on key caching and content delivery concepts. I’m an Azure content author at Cloud Academy and I have over 25 years of deep IT experience, several of those with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn or send an email to <a href="mailto:&#x73;&#x75;&#x70;&#112;&#x6f;&#114;&#x74;&#64;&#x63;&#x6c;&#111;&#x75;&#100;&#x61;&#x63;&#97;&#100;&#x65;&#109;&#121;&#x2e;&#99;&#111;&#109;">&#x73;&#x75;&#x70;&#112;&#x6f;&#114;&#x74;&#64;&#x63;&#x6c;&#111;&#x75;&#100;&#x61;&#x63;&#97;&#100;&#x65;&#109;&#121;&#x2e;&#99;&#111;&#109;</a>. </p>
<p>This course is intended for IT professionals who are interested in earning Azure certification and those who need to incorporate Redis Cache or CDN with their solutions. To get the most from this course, you should have at least a moderate understanding of what caching is and why it’s used. We’ll kick off the course with an overview Redis Cache, and then we’ll create a Redis Cache instance in Azure. With Redis Cache deployed in Azure, we’ll then connect an application to the cache. Next, we’ll walk through the process of storing and retrieving data in Redis Cache. After covering Redis Cache, we’ll walk through an overview of what CDN is and what it’s used for. We’ll then develop some code for leveraging CDN. As we wrap up the course, we’ll cover the process for invalidating date in both Redis Cache and in a CDN. </p>
<p>By the end of this course, you should have a good understanding of what Redis Cache and what CDN are and what purposes they serve. You’ll also know how to connect to each from applications and how to purge or invalidate data in both. We’d love to get your feedback on this course, so please give it a rating when you’re finished. </p>
<p>If you’re ready to start learning about integrating Redis Cache and CDN on Azure, let’s get started!</p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>- [Instructor] Azure Cache for Redis is usually used to improve performance and scalability of systems and applications that rely on back end data-stores. Leveraging Redis cache improves performance by temporarily copying frequently accessed data to fast storage that’s located close to the application that’s being run. Azure Cache for Redis provides the storage and memory instead of loading data from disc via a database. </p>
<p>In addition to providing caching services, Azure Cache for Redis can also be used for other purposes. For example, it can be used as an in-memory data structure store or even a distributed non-relational database. By taking advantage of the Redis engines high throughput and low latency, application performance is improved. </p>
<p>Leveraging Azure Cache for Redis provides organizations with access to a cache that’s managed by Microsoft. Because it’s hosted in Azure, Azure Cache for Redis is accessible to all applications, whether they reside within Azure or outside of it. </p>
<p>There are several typical patterns where Azure Cache for Redis comes in handy for supporting application architecture or to improve application performance. </p>
<p>Common patterns include things such as cache-aside, content caching, user session caching, job and message queuing and distributed transactions. </p>
<p>Because databases can be quite large, they should never be loaded in their entirety into a cache. That said, a common strategy would be to use the cache-aside pattern to load data items into the cache only as needed. When the back end data is updated by the system, the cache can also be updated. Such updates are then distributed with other clients. Through expiration settings or by using an eviction policy, the system can cause data updates to be reloaded into the cache. </p>
<p>Because most web pages are generated from templates that contain static headers, footers, toolbars, et cetera, they don’t change all that often, as such, generating them dynamically isn’t recommended. By using an in-memory cache like Azure Cache for Redis, you can speed up access to web content by providing your web servers with quicker access to this type of static content when compared to back end data-stores. The content caching pattern reduces processing time and server load that would otherwise be necessary to generate content dynamically. What this does, is allow web servers to be more responsive. As such, this results in the ability to actually reduce the number of servers that are needed to handle similar loads. Azure Cache for Redis provides the Redis output cache provider to help support this pattern with asp.net. </p>
<p>User session caching is typically used with shopping carts. It’s also used in other applications that deal with user-history types of information that make use of cookies. Because storing too much in a cookie can negatively affect performance, you can instead use the cookie as a key to query the data that’s stored in a back end database. Using Azure Cache for Redis to associate information with a user is far faster than interacting with a full relational database. </p>
<p>Any time an application receives a request, there’s a chance that the operations that are associated with that request, might take additional time to execute. A common way to deal with these types of longer running operations is to add them to a queue, which is then processed later and maybe even by a different server altogether. This type of deferment strategy is called task queuing and Azure Cache for Redis serves this purpose well by acting as a distributed queue. </p>
<p>An application will often need to be able to execute multiple commands against a back end data-store in a single operation. If all commands don’t succeed, then they must all be rolled back to the initial state. </p>
<p>Azure Cache for Redis provides support for executing a batch of commands in a single operation. It does so in the form of transactions. Azure Cache for Redis is available in three different tiers. These tiers include basic, standard and premium. The basic tier offers a single node cache. It supports multiple memory sizes from 250 megabytes all the way up to 53 gigabytes. </p>
<p>The basic tier is a good fit for development environments, testing and non-critical workloads. It’s important to note that the basic tier offers no service-level agreement. The standard tier offers a replicated cache in a two-node, or primary, secondary configuration that’s managed by Microsoft. </p>
<p>The standard tier offers a high-availability SLA of 99.99% or four nines. </p>
<p>The premium tier is enterprise ready. Caches in the premium tier offer more features, higher throughputs, and lower latencies than standard or basic. Premier tier caches are deployed on more powerful hardware than the other tiers, which in turn obviously offers better performance than basic or standard. </p>
<p>It’s important to note that a cache can be scaled to a higher tier after it’s already been created, but it can’t be scaled down to a lower tier. So with that in mind, when you’re deploying a cache make sure that you don’t over-provision, because if you do, you may find yourself in a spot where you can’t go backwards. It’s always better to slightly under-provision and then scale higher if necessary.</p>
<h1 id="Create-a-Redis-Cache-Instance"><a href="#Create-a-Redis-Cache-Instance" class="headerlink" title="Create a Redis Cache Instance"></a>Create a Redis Cache Instance</h1><p>- [Instructor] In this demonstration, we’re going to create an Azure Cache for Redis on Azure. To do so, I’ve logged in to my Azure portal, as you can see on your screen. </p>
<p>To create our Azure Cache for Redis, I browse over to the left pane and click Create a resource. From here, I can browse to Databases, and then, in the list of featured services, I can scroll down to Redis Cache and select it. I need to provide a globally unique name for my Redis Cache. Now, basically, what that means is the name that I give my cache needs to be unique across the entire Azure landscape. So, I’ll call it myredis9878. The green check box tells me that my name is valid. Then, of course, I need to select a subscription, so I’ll select the Microsoft Azure Sponsorship subscription that I have, and then, I need to specify a resource group. </p>
<p>I don’t have an existing resource group, so I’ll create a new one. And I’ll just call it Redis and okay it. I typically deploy my resources in the east region, so I’ll go East US, and for this demonstration, I’m going to select the basic pricing tier. </p>
<p>Now, if I click on View full pricing details, I can see all of the different options that are available to me for my Redis Cache pricing. If we scroll back up here, we can see Premium. We scroll down, we see the standard. And then, at the bottom, we can see our basic tiers. I’m using the C0 Basic tier. You can see further down here that some features or options, I should say, are not available because I’m not using a premium tier. </p>
<p>So, now, what I’ll do is I’ll create my cache, and this can sometimes take a few minutes to complete. We can see up here we get the Deployment in progress status. And what I’ll do is I’ll switch over to my resource group here, and if I select my cache here, we can see that the status is creating. This status will change to running once it’s completed. </p>
<p>We’ll refresh it here. And we can see it’s still creating. And while we’re waiting for this to create, what I’m going to do is switch over to my dashboard and create a new one for my Redis Cache lab here. And then, I’ll switch back to my resource group, and then, I’ll pin my Redis to my dashboard here. And if we select my cache, we can see it’s still creating. And let’s give it one more refresh. </p>
<p>So, we can see now that our cache is in the running state. So, in the next demonstration, we’re going to retrieve our access keys and connect a Python app to our cache.</p>
<h1 id="Installing-Redis-PY"><a href="#Installing-Redis-PY" class="headerlink" title="Installing Redis PY"></a>Installing Redis PY</h1><p>- [Narrator] In this lesson, we’re going to create a Python application and connect it to our Redis cache. However, before doing so we need to install redis-py, which is a Python interface to the Azure cache for Redis. I’m goin to install redis-py through Microsoft Visual Studio, which you see on your screen. To perform the installation I simply click on tools and then Python. From here I go to Python Environments. In my packages search I can search for Redis. In my list of commands that are returned I can see install redis here installs redis-py. So we’ll go ahead and click this command, and we need to run it in an elevated prompt, so we’ll go ahead and elevate it, and you can see on the bottom here that it was successfully installed. In the next demonstration we will test the read and write access to our cache from Python.</p>
<h1 id="Test-Read-and-Write"><a href="#Test-Read-and-Write" class="headerlink" title="Test Read and Write"></a>Test Read and Write</h1><p>- [Instructor] What we are going to do in this demonstration is connect to our Redis cache via Python through an interactive window in Microsoft Visual Studio. Once we connect to our cache, we are going to use the set command to store some data in the cache and then use the get command to pull that data out and display it. It’s a basic demonstration, but it shows how to connect to the ready cache and how to store and retrieve data. </p>
<p>Before connection to our cache, we need to import the readis-py package. And what I am going to do is copy and paste some of these commands and explain them as we go. </p>
<p>So on the screen we have my Python interactive window open and what I am going to do is paste in this import command and essentially what this does is pull in that ready cache package, so we can use it to connect to our ready cache. We’ll hit enter here, doesn’t give us any feed back, but it doesn’t give us an error either. So we know we are good. </p>
<p>And what we are going to do here is connect to our cache. So this is the connection string we are going to use to connect to our cache. We are storing this in a variable. You can see here that we have to specify the complete host name for our cache. And this is our host name that we give it when we deployed it earlier on. We need to specify the port we are going to connect over. And sixty-three eighty, by the way, is the default port number. The Db equals zero command here tells us that we are connecting to the zero data base. Remember, there are sixteen databases that comprise the data cache. So we are just specifying which database we are working with. The password here that we are specifying is actually the access key that we copy from our cache after we deployed it in Azure. And then lastly, we are just telling the command that we are going to use SSL to connect. </p>
<p>So with this command we hit enter and again there is no real feedback to tell us anything. What we are going to do now is perform a set command to store some data in the cache. So essentially performing this set against our variable. And we are put in some data in our cache and we can hit enter. So finally, we get some feedback true tell us that our storage set was successful. So now, what I am going to do here is to perform a get against our variable to pull the data back out. And on the screen here we can see that the get was successful. </p>
<p>What we will do on our next demonstration is create an actual Python script that goes out and communicates with our ready cache.</p>
<h1 id="Test-Read-and-Write-Access-to-Cache"><a href="#Test-Read-and-Write-Access-to-Cache" class="headerlink" title="Test Read and Write Access to Cache"></a>Test Read and Write Access to Cache</h1><p>- What we’re going to do here is create a basic Python script or application in Visual Studio. What this script is going to do is connect to the cache, set a message into the cache, and then retrieve it and display it. </p>
<p>To create our new project in Visual Studio, you can go up here and click file and then new project. We’re going to select a Python application and we’ll call it my Python app. We’ll leave it in the default location and what this does is open an editor window. Now what I’m going to do is I’m going to copy some of the lines for this code into the window rather than just type everything out. Essentially what we’re going to do is import the redis and then we’re going to set two variables. The redis host name and the access key. The host name is the FQDN of the cache that we configured in Azure and the access key is the access key to access it. </p>
<p>What we’ll do is we’ll open a connection to the cache we’ll ping it to confirm it’s accessible and then we’ll set a message, confirm that the message was set and then we’ll access and display that message. I’m going to start here by importing redis and then I’m going to pull in my two variables the redis host name is the FQDN of my cache and the access key is the key to access that cache. What I’m going to do now is open up the connection to the cache on port 6380 and then what I’m going to here is ping the cache we’ll do the ping store it in result and then print the result so we can see it. What we’ll then do is set a message in our cache we’re essentially setting a string here in a message that says hi Tom. </p>
<p>Python can access the cache and then what we’re going to do is we’ll print that result out and then what we’ll do here I have one more command or two more commands I wanna paste in here and after we’ve set that message, what we’re going to do is retrieve that message and display it. </p>
<p>So what this simple little Python script does is verify that we can connect to the cache that we can ping the cache, that we can set data to the cache, and that we can retrieve data from the cache. So to run our little test Python application here, we can simply click debug and then start without debugging. And the basic feedback we get is that the ping returns a true statement so we were in fact able to ping the cache. We were able to set the message in the cache which means we can store data in it, and then we were able to retrieve that data which is represented by the message that’s returned, Hi Tom, Python can access the cache. So we’ll hit enter to continue and exit back out. </p>
<p>So what we’ve done with 10 lines of code is confirm that we can connect to our cache and at the same time we’ve also demonstrated that we can store data in that cache as well as retrieve that data.</p>
<h1 id="Flushing-Redis-Cache"><a href="#Flushing-Redis-Cache" class="headerlink" title="Flushing Redis Cache"></a>Flushing Redis Cache</h1><p>- [Instructor] You will sometimes find yourself in a spot where you need to invalidate the data in your Redis cache. Doing so is pretty straightforward right from the Azure Portal. So, what I wanted to do in this really, really brief demonstration is show you how to open the console for the Redis cache in Azure Portal and issue a flushall command to empty out the Redis cache. On the screen here, you see that I’m in my Redis resource group and I have my Redis cache here. What I’m going to do is open my Redis cache and then click on Console. From here, I can simply flush my cache by issuing a flushall command. And that’s it. It’s a rather straightforward process that you can do right from the Azure Portal.</p>
<h1 id="Azure-CDN-Overview"><a href="#Azure-CDN-Overview" class="headerlink" title="Azure CDN Overview"></a>Azure CDN Overview</h1><p>- [Narrator] A content delivery network, which is also known as a CDN, is a network of distributed servers that’s used to more efficiently deliver content to end users. What CDNs do is store cached content on what are called edge servers that are located in specific point-of-presence locations that are near the end users who are consuming the content. What this does is minimize latency. </p>
<p>The Azure Content Delivery Network provides a global solution for organizations and developers that need to deliver high-bandwidth content to end users by caching that content on strategically-placed nodes all over the world. While a CDN is useful for delivering static content, Azure CDN can even accelerate delivery of non-cacheable, dynamic content by leveraging many different network optimizations using CDN POPs, or points of presence. </p>
<p>Using Azure CDN to deliver web content offers better performance and an improved end user experience for those who are consuming the content. This is especially true when the end users are using applications that require multiple round-trips to load that content. </p>
<p>Azure CDN also offers large scaling. What this does is allow it to better handle high loads, which is something that you would expect to see maybe during a product launch. </p>
<p>By distributing user requests and serving content directly from the edge servers, Azure CDN ensures that less traffic is actually sent to the origin server, which further improves performance and responsiveness of the origin server.</p>
<h1 id="How-Azure-CDN-Works"><a href="#How-Azure-CDN-Works" class="headerlink" title="How Azure CDN Works"></a>How Azure CDN Works</h1><p>- [Narrator] On the screen here, you can see a diagram of exactly how CDN works. Let’s put a little context behind it. In step one, User A requests a file or an asset via a URL with a special domain name. Such a domain name might be mydomain.azureedge.net. The domain name can actually be an endpoint hostname or even a custom domain. DNS then routes that request to the best performing point-of-presence, or PoP, which is often the point-of-presence that is geographically closest to the user requesting the content. </p>
<p>Now, if there are no edge servers in the point-of-presence that have the requested file in their cache, the POP, or point-of-presence, requests the file from the originating server. The originating server could be an Azure Web App, an Azure Cloud Service, an Azure Storage Account, or essentially any other publicly accessible web server. Next, the originating server returns the requested file to one of the edge servers in the PoP. The edge server in the PoP then caches the file and returns it to the original requester, which is User A in this case. The file will then remain cached on that edge server in the PoP until the time to live, or TTL, that’s specified by its HTTP headers, expires. The default TTL is seven days, unless the origin server provides a specific TTL. Other users can then request the same file by using the same URL that User A used, and can also be directed to the same PoP. If the TTL for the file hasn’t expired, the PoP edge server returns the file directly from the cache instead of going back to the originating server. What this does is result in a far faster, more responsive end user experience.</p>
<h1 id="Adding-Azure-CDN-to-an-Azure-Web-App"><a href="#Adding-Azure-CDN-to-an-Azure-Web-App" class="headerlink" title="Adding Azure CDN to an Azure Web App"></a>Adding Azure CDN to an Azure Web App</h1><p>- [Instructor] In this demonstration, we’re going to add an Azure CDN to an existing Azure web app. What we’re going to do is deploy a CDN profile in Azure, along with an endpoint for our web app. The web app that we’re going to use is a basic static HTML page that we’re going to use to demonstrate the functionality of the CDN and how to purge CDN content. </p>
<p>On the screen, you can see my dashboard for my CDNLab. We already have a basic web app deployed. It’s a static HTML page, and it’s essentially a picture of a cat, because I like cats, and a little bit of text at the bottom. The website in its starting form displays a sentence called “This is a cat!!” in red text. We’re going to use the color of this text to demonstrate how a CDN caches content from a web application. So let’s bounce back over into my dashboard here. </p>
<p>The first thing I need to do is create a CDN profile and an endpoint. So let’s go ahead and click Create a resource here, and search for CDN. We’ll deploy a CDN, and create it. And we’ll call it mycdnlabdemo. And we’ll put this in our CDNLab Resource group. And for the Pricing tier, we’re going to use the Standard Akamai. This is because we need to be able to configure custom rules later on. </p>
<p>Now to create our CDN endpoint, which points to our application, we’ll click the checkbox, and then give our CDN endpoint a name. This needs to be unique across the entire Azure landscape. So I’ll just call it mycatendpoint.azureedge.net. And what we’re going to do is specify an Origin type of Web App, since it’s a web app we’re pointing to. And we’ll browse to the Origin hostname, which is themywebapp1973, which you saw up here. So we’ll go ahead and create that CDN profile and endpoint. </p>
<p>So now that we have our CDN profile created, what we can do is browse to our CDN and see that our endpoint is running. If we click on our endpoint here, we can get the hostname. So we’ll copy this and paste it into a new tab. Now the name of our file here, our HTML page, is CDNDemo.htm. So we’ll append that to our cache. So as you can see, our CDN cache is the same as our application, our web app. So now that we’ve confirmed that our cache and our live site both match, what we’re going to do is make a change to the website itself. So to do this, I’m going to drop down into my FTP client here, which is already connected to my web app. If I open up my CDNDemo page on my live site, I can see that I’m specifying a red color for the text. We’re going to go ahead and change this to blue, and we’ll save it. </p>
<p>Now if I bounce back up to my web app itself, which is denoted by mywebapp1973.azurewebsites.net, if I refresh my page here, I now have blue text. However, if I go to my endpoint in my CDN, which is denoted by my endpoint name with an azureedge.net attached to it, and refresh, the text is still red. This is because the cache content hasn’t been updated yet. Now the CDN, in and of itself, will periodically refresh its content from the origin webpage. This is based on the TTL configuration. That being said, the default TTL is seven days. </p>
<p>So there will be times when content is updated on a website that we may wish to purge the cached content from our CDN. This is one of those cases. So what we’re going to do is purge the content from our CDN by browsing over, back into our Azure portal, and into our endpoint here. If we roll back out into our demo here, we can see our endpoint listed. What we can do is click Purge at the top here. And I’m going to purge the CDNDemo. And we’ll purge it. Now this takes a minute or so to do, but once this happens, we’ll go back up and refresh our endpoint here to see if it’s updated. So let’s bounce back up into our endpoint here and do a refresh. </p>
<p>And there you have it. So by purging the CDN cache, we’ve allowed it to recache the new content from the source website. So now you know a little bit about how to deploy your CDN profile, how to create that endpoint that references the production website, and how to purge your CDN content to ensure it pulls down the latest version of the content so that it can serve it up properly.</p>
<h1 id="Using-Query-Strings-to-Version-Content"><a href="#Using-Query-Strings-to-Version-Content" class="headerlink" title="Using Query Strings to Version Content"></a>Using Query Strings to Version Content</h1><p>- [Instructor] In this demonstration we’re going to see how the cache in an Azure CDN can be manipulated using query strings. On your screen you can see I’m in here with my CDN in Azure. On your screen here you can see I’m in my CDN. If I click on my end point that we created in our previous demonstration, I can browse over to caching rules to see what rules are set up for this end point. We can see that we have global caching rules and custom rules. What we’re going to do here in this demonstration is change the query string caching behavior. If I select this drop-down you can see there’s three options. We have ignore query strings, bypass caching for query strings and cache every unique URL. What we’re going to do here is change the default caching behavior to cache every unique URL. And then we’ll save it. While this is saving, we’ll go out to our web app and we’ll refresh here and see that our text is blue. If we go into our cache, we can also see that our text is blue. Now what I’m going to do here is copy my end point URL and open a new tab. I’ll paste this URL in, but I’ll specify a query string. So we can see here even with a query string of one we still have blue text, which makes sense, we haven’t made any changes yet. And I’ll just refresh this to make sure it gets committed to cache. And now what I’m going to do is go down into my ftp client and I’m going to edit my web app and I’ll change the color to green. So on my production web app this text is now green. So what I’ll do next is open up my end point again this time with a query of two. We can see my query two shows green text, my query one shows blue. If I refresh, I still have blue text. So what this demonstrates is how each query string is treated differently based on the fact that I have the query string caching behavior set to cache every unique URL. If we bounce back down to my editor here, and change it to black, I can then open another tab, so another query and now I get black text. So as you can see, you can control what content is cached and how, based on how you configure your caching rules, and how you access the content itself.</p>
<h1 id="Invalidating-CDN-Cache-With-a-Custom-Rule"><a href="#Invalidating-CDN-Cache-With-a-Custom-Rule" class="headerlink" title="Invalidating CDN Cache With a Custom Rule"></a>Invalidating CDN Cache With a Custom Rule</h1><p>- While we’re in here looking at caching rules for our CDN cache, let’s take a look at a custom caching rule. What we’re going to do in this demonstration is define a custom caching rule that invalidates our CDN cache after a specified amount of time. What we’re going to do in this demonstration is use a custom caching rule to set a cache duration of one second on our cdndemo.htm file. What this will do is override any cache control or expires http headers that are sent by the originating server. </p>
<p>So to create our custom caching rule, we’ll browse down here, down to the custom caching rule section. So to define our custom caching rule, we’ll go down to the bottom here where it says custom caching rules. So to create our custom caching rule, what we’re going to do is go down to the bottom here where it says custom caching rules. What we’re going to do for the match condition field is set it to path. The value we’re going to match on is our cdndemo.htm file. The caching behavior we’re going to set is override and we’re going to tell it that we want a cache duration of one second. We can go ahead and save our new rule. </p>
<p>With our new rule in place, what we’ll do is go up to our web app and we’ll refresh it. And we can see we have black text. If we switch over to our end point, we can refresh and we see we have black text. Now what I’m going to do is go into my FTP client again and I’m going to edit the text color back to red. Now if I go back up to my application and refresh, we can see I get red text. Now what I would expect in my end point is that a refresh also displays red text. This is because the custom rule down here should override the default cache expiration of seven days because I’m focused on the cdndemo.htm match. So let’s go up here and do a refresh and as you can see here, the text is in fact red. So what this demonstrates is that I can control individual caching with custom caching rules. Our custom rule here that matches on the cdndemo.htm file overrides the default caching expiration duration of seven days. And if you read closely under the custom caching rule section, Microsoft will tell you that these rules override the default settings above and that they’re evaluated from top to bottom. That being said, rules that are lower in this list can override rules that are further above it. So keep that in mind when you start creating custom caching rules.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>- [Instructor] I hope you’ve enjoyed learning about integrating Redis Cache and CDN on Azure. Let’s review what you’ve learned. </p>
<p>Early on in this course, you learned about Azure Cache for Redis and what it offers. You learned about several patterns where Azule Cache for Redis comes in handy and about different service tiers. After learning what Azure Cache for Redis is, you learned how to create a cache instance in Azure and how to access it. You then learned how to test, read, and write access to the cache and how to access the cache with a Python application via Visual Studio. We then moved on to the Azure Content Delivery Network or Azure CDN where you learned what it is, what it offers, and how it works. Later in the course, you learned how to add an Azure CDN to an Azure App Service web app and how to invalidate CDN content as well as Redis Cache content. </p>
<p>To learn more about integrating Redis Cache and CDN on Azure, you can and should read Microsoft’s published documentation. Be sure to also watch for new Microsoft Azure courses on Cloud Academy because we’re always publishing new ones. Please give this course a rating and if you have any questions or comments, please let us know. As always, thanks for watching and happy learning.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/108/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/108/">108</a><span class="page-number current">109</span><a class="page-number" href="/page/110/">110</a><span class="space">&hellip;</span><a class="page-number" href="/page/244/">244</a><a class="extend next" rel="next" href="/page/110/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2432</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
