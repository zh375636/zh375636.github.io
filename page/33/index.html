<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hang&#39;s Blog">
<meta property="og:url" content="https://example.com/page/33/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/page/33/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Designing-a-Google-Cloud-Infrastructure-11/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Designing-a-Google-Cloud-Infrastructure-11/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Designing-a-Google-Cloud-Infrastructure-11</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:14:08" itemprop="dateCreated datePublished" datetime="2022-11-19T00:14:08-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:35:56" itemprop="dateModified" datetime="2022-11-20T19:35:56-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Designing-a-Google-Cloud-Infrastructure-11/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Designing-a-Google-Cloud-Infrastructure-11/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Course-Introduction"><a href="#Course-Introduction" class="headerlink" title="Course Introduction"></a>Course Introduction</h1><p>Welcome to designing a Google Cloud infrastructure. I’m Guy Hummel, and I’ll be showing you how to build an enterprise IT solution in Google platform.</p>
<p>To get the most from this course, unless you already have a lot of experience using Google Cloud, you should take the Google Cloud Platform Fundamentals and Systems Operations courses to get a solid understanding of the different components of Google Cloud. In this course, I’ll be showing you how to use these building blocks to construct an enterprise class application architecture.</p>
<p>We’re going to use a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/case-study-1/">case study</a> as an example of how to apply enterprise principles to a design. I’ll start by explaining how you would take an organization’s requirements, and translate them into the appropriate <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/compute-1/">compute</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/storage-2/">storage</a>, and network components in Google Cloud. I’ll also show you how to make it a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/high-availability-1/">high availability</a> design.</p>
<p>Then I’ll cover how to secure the environment, including how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/authentication-2/">authenticate</a> and give permissions to people as well as to applications using <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/service-accounts-1/">service accounts</a>, how to encrypt your data, and how to comply with a rigorous security standard like PCI DSS.</p>
<p>Finally, we’ll wrap up with how to design a solution that can recover from <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/disaster-recovery-1/">disasters</a>.</p>
<p>All right, if you’re ready to learn how to create an enterprise class architecture for your Google Cloud infrastructure, then let’s get started.</p>
<h1 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h1><p>Suppose you’ve been hired to help a company called Great Inside, which offers interior design software as a service.</p>
<p>Great Inside makes its money by selling subscriptions to its web-based interior design application. It also has a free version that’s supported by advertising. Their customers are primarily in North America, but they hope to expand in Europe and Asia at some point in the future.</p>
<p>The company has grown slowly for five years, but recently closed a venture capital round, brought in experienced executives, and is now growing more quickly. The company’s existing infrastructure is not capable of scaling up quickly enough, so they would like to move to the cloud.</p>
<p>Great Inside started off with a Microsoft-centric infrastructure and then migrated to a LAMP stack. The only Microsoft infrastructure left is the payment processing system and an Active Directory server. They would like to retire their Microsoft servers in the future, other than Active Directory. But that isn’t a priority right now, and the company would like to move both types of servers to the cloud. They’ve also started a pilot project using a NoSQL database.</p>
<p>Since they accept credit cards, they need to be PCI DSS compliant. Since their volume is increasing, they need to ensure that their payment processing environment meets a higher level of compliance. Note that Great Inside passes the validation and processing of credit card information to a certified payment processor.</p>
<p>They would like to improve their disaster recovery solution. At the moment, they’re backing their data up to a cloud service, but it would take them a long time to recover from a disaster.</p>
<p>Their existing technical environment is all in a single data center.</p>
<p>They have three types of databases. MySQL for the interior design application, Microsoft SQL Server for payment processing, and a NoSQL database in the development environment.</p>
<p>They have two types of web and application servers. Apache and Tomcat are running on six servers, each with 2 dual-core CPUs, 24GB of RAM, and two mirrored 200GB disks. These servers are for their interior design application. IIS is running on four servers- two customer-facing and two internal, each with a dual-core CPU, 16GB of RAM and two mirrored 250GB disks. These servers are for payment processing.</p>
<p>They have a variety of infrastructure servers, including Active Directory and a file server for internal documents, etc.</p>
<p>Here are their business requirements. Scale easily to handle rapid growth, move as much of the development, test, and production infrastructure as possible to the cloud, and increase performance, reliability, and security while reducing management overhead.</p>
<p>And their technical requirements are: connect the data center’s network with the cloud environment’s network, encrypt all data, design <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/high-availability-1/">high availability</a> into all tiers, and create a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/disaster-recovery-1/">disaster recovery</a> solution that will reduce recovery time to a few hours, rather than a day.</p>
<p>I should mention up front that some aspects of this case study may not be completely realistic. It’s simplified so we can go through it in a reasonable amount of time, but it has just enough complexity to allow us to cover the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">key topics</a>.</p>
<h1 id="Compute"><a href="#Compute" class="headerlink" title="Compute"></a>Compute</h1><p>Although most Google Cloud designs include virtual machine instances, that doesn’t mean VMs are your only option for compute resources. Before you start designing a solution using only Compute Engine instances, you should consider App Engine and Kubernetes Engine.</p>
<p>App Engine is designed for people who don’t want to manage an application’s underlying infrastructure. App Engine provisions and scales all of the resources your application needs behind the scenes, without any human intervention required. That sounds great, doesn’t it? So why wouldn’t you use App Engine?</p>
<p>The main reason is that it is much easier to develop a new application on App Engine than it is to migrate an existing one to it. So if you’re developing an application from scratch, then App Engine may be a good choice. If you have an existing application, then you’ll need to check if App Engine supports the programming languages your app is written in and if your app has any operating system dependencies (such as only being able to run on Windows, which isn’t supported by App Engine).</p>
<p>You’ll also need to look at your application’s architecture to see if it would be able to run on App Engine without having to re-architect it. App Engine is designed for microservices-based apps, so if your existing application has a monolithic architecture, then it might require some work to migrate it.</p>
<p>For all of these reasons, it’s usually advisable to use App Engine only for new applications rather than existing ones.</p>
<p>The next option is Kubernetes Engine. It provides many of the benefits of App Engine, in that you don’t have to worry about the underlying operating system running your application. It also handles scaling, although you have to configure that yourself first. It does require more management than App Engine, but it doesn’t require as much management as Compute Engine.</p>
<p>The ideal case for using Kubernetes Engine is, of course, if your application already runs in containers, especially Docker containers, since that’s what Kubernetes Engine supports. On the other hand, if your application will only run on certain operating systems, especially Windows, then it won’t run in Kubernetes Engine.</p>
<p>If you have an existing app that does not currently run in containers, then you might want to see if it’s possible to containerize it so you can take advantage of Kubernetes Engine.</p>
<p>If your existing application runs on virtual machines, then the easiest way to migrate it to Google Cloud is to use Compute Engine instances. If it doesn’t run on virtual machines, then you’ll have to virtualize it before you can run it on Google Cloud.</p>
<p>Although Compute Engine requires more management than App Engine or Kubernetes Engine, it does give you ultimate flexibility. For example, you could run an application that requires Windows, a specific network driver, and high-performance GPUs.</p>
<p>Since our case study involves an existing application that doesn’t currently run in containers, we’re going to choose Compute Engine for our design.</p>
<p>The case study company, GreatInside, currently has 6 machines running Apache and Tomcat, and 4 machines running IIS. Let’s have a look at Google’s predefined machine types . We need to decide how many vCPUs and how much memory to use. Memory is pretty straightforward. Our existing machines have 24GB for the Tomcat servers and 16GB for the IIS servers. VCPUs are more complicated, though.</p>
<p>The existing Tomcat servers have two dual-core CPUs and the IIS servers have one dual-core CPU. How does that translate into vCPUs? Some people say that cores and vCPUs are equivalent, but that’s not quite true. A vCPU on a Compute Engine instance is implemented as a single hyper-thread on an Intel Xeon processor. Since each Xeon processor has 2 hyperthreads, that means you need to multiply the number of cores by 2 to get the number of threads, and thus the number of vCPUs.</p>
<p>So our Tomcat servers have the equivalent of 8 vCPUs (4 cores times 2) and our IIS servers have the equivalent of 4 vCPUs (2 cores times 2). Of course, if we really wanted to be accurate, we’d need to take into account things like the clock speed of the CPUs, but we’re not going to go that far.</p>
<p>So, we need 8 vCPUs and 24GB of RAM for the Tomcat servers and 4 vCPUs and 16GB of RAM for the IIS servers. Do any of the predefined machine types match these requirements? Well, the n1-standard-4 is almost identical to the IIS server requirements. It has 4 vCPUs and 15GB of RAM. Having one less gig of RAM is probably fine, but you can monitor it in production to make sure it’s sufficient.</p>
<p>The Tomcat servers are another story, though. The closest match is the n1-standard-8, which has 8 vCPUs and 30GB of memory. That’s 6GB more than we need, so we should consider a custom machine type. We can select the exact size we need. With this custom configuration, it says it will cost $190.54 per month. Let’s see how that compares to the n1-standard-8. That costs $194.58 per month, which is more expensive, but only 2% more.</p>
<p>I should mention that there are a couple of ways to reduce those costs: sustained-use discounts and committed-use discounts. If you know that you’re going to be running an instance continuously for a long period of time, then you can pay much less by purchasing either a one-year or three-year contract, which is called a committed-use contract. This will typically reduce the cost by up to 57%. However, that’s a pretty big commitment, so Google provides a way to reduce costs without signing a long-term contract. You start getting an automatic discount after an instance runs for more than 25% of a month, and the discount increases the longer the instance runs during that month. For most machine types, you’ll receive a sustained-use discount of 30% if you run the instance for the entire month.</p>
<p>Okay, let’s get back to our case study. Since IIS and SQL Server run on Windows, we’ll need to figure out how to license them. Let’s start with IIS. For Windows Server itself, you can either use Google’s pay-as-you-go Windows licensing or you can bring your own license. </p>
<p>There are two ways to use Google’s pay-as-you-go Windows licensing. The first way is to create a new instance with one of the pre-configured Windows Server boot disks . The second way is to import a Windows VM. There are two options for importing a VM. The first option is to import a virtual disk and turn it into an image that you can use to create a Compute Engine instance. That’s quite simple to do, but it’s not meant for migrating mission-critical applications or migrating a large number of VMs in an automated fashion.</p>
<p>A more sophisticated option is to use Cloud Migrate for Compute Engine. This service makes replicas of existing VMs you have running on-premises or on another cloud platform. It will take care of the many steps that are needed to migrate important applications. </p>
<p>If you want to bring your own Windows licenses, then you can run your Windows VMs on sole-tenant nodes, which are dedicated physical servers that are not shared with other customers.</p>
<p>If you need to run any Microsoft applications, then you’ll need licenses for those too, of course, but Microsoft is more flexible with its application licensing than with Windows licensing. If your organization has active Software Assurance contracts for its Microsoft applications, then you can move those licenses to either Compute Engine instances or sole-tenant nodes.</p>
<p>Now let’s move on to SQL Server. You can use any of the options I just mentioned, but fortunately, there are also easier options for SQL Server. One option is to create instances with pre-configured SQL Server boot disks . These include pay-as-you-go licenses for both Windows Server and SQL Server. The second option is to use Cloud SQL, which is a managed service. I’ll tell you more about it in the next video.</p>
<p>For premium Linux OSs (such as Red Hat or SUSE), licensing is much simpler. You can either create an instance with a pre-configured boot disk or you can import your Linux VM. In both cases, you can either use a Google pay-as-you-go license or bring your own license.</p>
<p>I should mention one other Compute Engine option – preemptible VMs. They’re up to 80% cheaper than regular instances, but since Google can remove them with only 30 seconds’ notice, you would usually only use them as disposable instances for things like big data batch jobs. That doesn’t fit our use case, so we’ll stick with regular instances.</p>
<p>And that’s it for this lesson.</p>
<h1 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h1><p>Each of the instances for the Tomcat and IIS servers will come with a standard persistent boot disk by default, but we might need something different. There are many options for instance storage, including Standard Persistent Disk, SSD Persistent Disk, Local SSD, RAM Disk, and Cloud Storage.</p>
<p>Standard Persistent Disks are magnetic drives. Their main advantage is low cost. SSD Persistent Disks (or solid state disks) have up to 4 times the throughput and up to 40 times the I&#x2F;O operations per second of a Standard Persistent Disk, so if you need high performance, SSDs are a must.</p>
<p>But SSD Persistent Disks aren’t even your fastest option. Local SSDs are up to 600 times as fast as Standard Persistent Disks in IOPS and up to 15 times as fast in throughput.</p>
<p>Why are Local SSDs so much faster than SSD Persistent Disks, which are obviously both using SSD technology? Well, it’s because Local SSDs are not redundant and are directly attached to an instance. That gives them major speed advantages, but with high risk because if they suffer a hardware failure, then your data will be gone. Furthermore, Local SSDs disappear when you stop or delete an instance, so you should only use them for temporary data that you can afford to lose, such as a cache.</p>
<p>There are a couple more disadvantages of Local SSDs too. First, they are only available in one size – 375GB, which is kind of an awkward number. Second, they can’t be used as boot disks.</p>
<p>If you need even faster storage, then you can use a RAM disk, which essentially makes a chunk of memory look like a filesystem. Although RAM disks are the fastest option, they’re even less durable than Local SSDs, so they’re only suitable for temporary data. It’s also an expensive option because RAM is much more expensive than SSDs.</p>
<p>One more option is Cloud Storage. This is kind of a weird way to add storage to an instance because a bucket is object storage rather than block storage. That means it can’t be used as a root disk and it may be unreliable as a mounted filesystem. So why would you ever use it? The first advantage of using Cloud Storage is that multiple instances can write to a bucket at the same time. You can’t do that with persistent disks, which can only be shared between instances in read-only mode. The danger is that one instance could overwrite changes made by another instance, so your application would have to take that into account.</p>
<p>The second advantage is that an instance can access a bucket in a different zone or region, which is great for sharing data globally, especially if it’s read-only data, which would avoid the overwriting problem.</p>
<p>However, Cloud Storage usually isn’t a good option for instance storage. It is good for general-purpose file serving, though, so it would be a potential choice for replacing GreatInside’s internal file server if they want to move it to the cloud. To do this, you’d need to use Cloud Storage FUSE, which is open source software that translates object storage names into a file and directory system. Essentially, it makes Cloud Storage buckets look like network file systems. A better choice, though, would be Cloud Filestore, which is a fully-supported file sharing service that’s designed specifically for this purpose. It’s compatible with NFS version 3.</p>
<p>So, which instance storage option should we use for our instances? Since performance is important, we should use something faster than Standard Persistent Disks. SSD Persistent Disks are many times faster than standard ones, so they’d be a good choice. Should we consider Local SSDs or RAM disks? Well, neither of those can be boot disks, so we would have to use them in addition to a persistent boot disk. The higher performance wouldn’t outweigh the extra cost and complexity of using one of these options, though, so we should just stick with SSD Persistent Disks. Furthermore, since persistent disks are redundant, we don’t need to have two mirrored disks on each instance like GreatInside does in its existing data center. We can just have a single persistent boot disk on each instance.</p>
<p>As for the size, we can specify the exact amount we need, so for the Tomcat servers, we should use one 200GB disk on each instance, and for the IIS servers, we should use one 250GB disk on each.</p>
<p>Next, we need to look at our database options. Google Cloud has 5 different database services: Cloud SQL, Cloud Datastore, Bigtable, BigQuery, and Cloud Spanner.</p>
<p>Cloud SQL is a relational database. It’s a managed service for MySQL, PostgreSQL, or Microsoft SQL Server. It’s suitable for everything from blogs to ERP and CRM to ecommerce.</p>
<p>Cloud Datastore is a NoSQL database service. Unlike a relational database, such as Cloud SQL, it is horizontally scalable. A relational database can scale vertically, meaning that you can run it on a more powerful VM to handle more transactions, but there are obviously limits to the size of a VM. You can also scale a relational database horizontally for reads by using read replicas, but most relational databases can’t scale horizontally for writes. That is a major problem that is solved by NoSQL databases.</p>
<p>Because of this and because it’s an eventually consistent database, Cloud Datastore is faster than Cloud SQL. It’s best suited to relatively simple data and queries, especially key-value pairs. Typical examples include user profiles, product catalogs, and game state. For complex queries, Cloud SQL is a better choice.</p>
<p>Cloud Bigtable is also a NoSQL database. It’s designed to scale into the petabyte range with high throughput and low latency. It does not support ACID transactions, so it shouldn’t be used for transaction processing. It’s best suited for storing huge amounts of single-keyed data. If you have less than one terabyte of data, then Bigtable is not the best solution. It can handle big data in real-time or in batch processing. Typical examples are Internet of Things applications and product recommendations.</p>
<p>BigQuery also handles huge amounts of data, but it’s more of a data warehouse. It’s something you use after data is collected, rather than being a transactional system. It’s best suited to aggregating data from many sources and letting you search it using SQL queries. In other words, it’s good for OLAP (that is, Online Analytical Processing) and business intelligence reporting.</p>
<p>Google’s newest database service is Cloud Spanner, which seems to combine the best of all worlds. It’s a relational database that also scales horizontally. That is, it combines the best features of traditional databases like Cloud SQL and the best features of NoSQL databases like Cloud Datastore. So why wouldn’t you use it for all of your database needs? Well, mostly because it’s more expensive than the other options. Also, if your application is written specifically for a particular database, such as MySQL, then Cloud SQL would be a better choice, unless you can rewrite it to work with Cloud Spanner. </p>
<p>So use Cloud Spanner when you need a relational database that is massively scalable. Typical uses are financial services and global supply chain applications.</p>
<p>Now, which database services should GreatInside use? It currently has two production databases – MySQL for the interior design application and SQL Server for payment processing. There are two ways you could migrate the MySQL database to Google Cloud. You could use Cloud SQL or run MySQL on a regular instance. Considering that GreatInside wants to reduce system management tasks, Cloud SQL would be the best choice since it’s a fully managed MySQL service, with automatic replication and backups.</p>
<p>For SQL Server, you have the same two options. You could use Cloud SQL, or you could run it on a regular instance. Again, Cloud SQL is the best choice.</p>
<p>GreatInside does have one more database – their experimental NoSQL datastore. Since the development team is still evaluating this technology, you should talk to them about trying Cloud Datastore. They should also try App Engine because Cloud Datastore works best when used with App Engine.</p>
<p>And that’s it for storage and databases.</p>
<h1 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h1><p>Before we talk about networks, we need to talk about how we can make our applications highly available.</p>
<p>If you have an application that’s running on only one VM instance, then, of course, it’s a single point of failure, and if it goes down, your application goes down. So, at a minimum, you should always have at least two VMs for every component of your solution. But where should those instances be located?</p>
<p>When you create a VM instance, it gets created in a particular zone, such as us-central1-a. A zone is an isolated location. You can think of a zone as a data center or an isolated portion of a data center.</p>
<p>If you put both instances in the same zone, then both of them could potentially go down if there’s a problem in that zone. So, you should put the instances in different zones. For performance reasons, you may need to put them in zones that are in the same region, such as us-central1. Notice that the zone name is just the region name with a dash and a letter at the end. All of the zones in a region have high-bandwidth, low-latency network connections between them, so if instances that are spread across a region need to mirror data with each other, then they can do this quickly.</p>
<p>Although “region” sounds like a geographic area, it’s just a data center campus in one location. For example, all of the zones in the us-central1 region are in Council Bluffs, Iowa. So, for maximum availability, you may also want to distribute your instances across different regions.</p>
<p>For a higher level of availability, you can use autoscaling instance groups. This was covered extensively in the “Google Cloud Platform: Systems Operations” course, so I’ll just go over the highlights.</p>
<p>An instance group consists of identical instances that perform processing for your application. If one of the instances fails, then a health check will notice this and replace the instance with a new one. If the load on the instance group gets too high, then the autoscaler will add more instances to maintain good application performance.</p>
<p>To ensure availability even if an entire zone fails, you should distribute the instances across multiple zones. Luckily, this is very easy to do. You just have to select “Multizone” when you’re creating the instance group.</p>
<p>If you want to make sure you’ll still have enough instances to handle the load if an entire zone goes down, then you should overprovision by 50%. For example, if your instances are spread across 3 zones and you need 6 instances to handle your normal traffic load, then you should provision 9 instances. That way if one of the zones goes down (which would take out 3 of the instances), you’ll still have 6 instances left in the two remaining zones.</p>
<p>You can either overprovision by 50% at all times or you could save money by just setting the upper limit on your autoscaler to at least 50% more than the normal number of instances. If you decide to depend on the autoscaler during a zone failure, then the instances in your remaining two zones will be very heavily loaded until the autoscaler provisions additional instances, so only choose this option if you can tolerate this temporary performance degradation.</p>
<p>Since GreatInside has 6 web tier instances for its main application, this is how it should be set up. For the 2 customer-facing IIS instances in the payment processing system, you’d set an upper limit of 3 instances, which is 50% more than the 2 instances that it normally needs.</p>
<p>To make the instance group work as a high availability solution, you’ll need a couple of other components. First, the instance group has to be behind a load balancer that will distribute incoming requests to different instances. Second, the instances cannot have any stateful data. Otherwise, the same instance would have to handle all requests from a given user. Although you can enable the “session affinity” option in this situation, it will ruin your high availability since a failed instance will impact all of the users on it.</p>
<p>Since most applications do have stateful data, you have to put it on other components, such as a database or Cloud Storage. Unfortunately, that just moves the availability issue to a different layer, but fortunately, Google Cloud has good ways to handle storage availability.</p>
<p>If Cloud Storage is sufficient for your stateful data needs, then you’re covered because Cloud Storage is automatically replicated either across zones in a region (for the Regional type) or across regions (for the Multi-Region type).</p>
<p>If you need a database for your stateful data, then there are different availability solutions depending on the data service.</p>
<p>With Cloud SQL, you can simply check the “High availability” box when you create a Cloud SQL instance. This will create a failover replica in another zone. In the event of a failure, Cloud SQL will automatically fail over to the replica. This option is available for MySQL, PostgreSQL, and SQL Server.</p>
<p>Since Cloud Datastore is a NoSQL database, it scales horizontally, which makes high availability easier than with Cloud SQL. Cloud Datastore automatically replicates data across zones in a region. When you create a Datastore instance, you specify which region and it does the rest.</p>
<p>Bigtable is also a NoSQL database that scales horizontally, but if you want it to replicate across multiple zones, then you’ll have to configure it to do that. You can even configure it to support replication across regions if you need that. But in its simplest configuration, it only stores data in a single zone, which gives it higher performance. It’s still stored redundantly in that configuration but within the same zone.</p>
<p>BigQuery automatically replicates data within a region, but it’s a data warehouse, so it’s not suitable for real-time stateful data storage.</p>
<p>Cloud Spanner also automatically replicates data within a region, so it’s highly available out of the box, and unlike Cloud SQL, it doesn’t need a failover replica, which is a less available solution.</p>
<p>In summary, if a NoSQL database is sufficient for your application, then Cloud Datastore is your best choice for storing stateful data. If you need to use a relational database, then either use Cloud SQL and enable high availability or use Cloud Spanner for even higher availability if you’re willing to pay a higher price.</p>
<p>Since GreatInside is going to use Cloud SQL for both MySQL and SQL Server, then we just need to enable the high availability option when we create those databases.</p>
<p>And that’s it for this lesson.</p>
<h1 id="Networks"><a href="#Networks" class="headerlink" title="Networks"></a>Networks</h1><p>Now we know all of the components we want to use and we just need to connect them together with networks. Google provides what are called Virtual Private Clouds, or VPCs, but I’m just going to call them networks.</p>
<p>There are 5 layers in <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">Google Cloud</a> you can use to isolate and manage resources: organizations, folders, projects, networks, and subnetworks.</p>
<p>You aren’t required to have organizations or folders, but they can be useful, especially for large companies.</p>
<p>Projects are required, though. You use them to provide a level of separation between resources. Not only are resources in different projects unable to communicate with each other, but they’re even in different billing accounts. Projects also have separate security controls, so for example, you could give Bob in QA the highest level of access in the Test Environment project, but a lower level of access in the Production Environment project.</p>
<p>Each project has one default network that comes with preset configurations and firewall rules to make it easier to get started, but you can customize it, or you can create up to 4 additional networks (for a total of 5). If 5 networks per project isn’t enough for you, then you can request a quota increase to support up to 15 networks in each project.</p>
<p>A network belongs to only one project, a subnet belongs to only one network, and an instance belongs to only one subnet.</p>
<p>Instances in the same subnet or even different subnets within the same network can communicate with each other. Subnetworks are used to group and manage resources.</p>
<p>A network spans all regions, but each subnet can only be in one region. A subnet allows you to define an IP address range and a default gateway for the instances you put in it. The IP address ranges of the different subnets must be non-public (such as 10.0.0.0) and must not overlap, but other than that, there are no restrictions on them. For example, they can be different sizes. They must be IPv4 addresses, though, because Compute Engine doesn’t support IPv6 yet.</p>
<p>A network can have either automatic or custom subnets. With automatic, the subnets are created for you, one in each region. With custom, you create them yourself. If you discover that you need to customize a network with automatic subnets, then you can convert it to custom mode, but once you do, you cannot convert it back to automatic mode.</p>
<p>On the default network, instances within the same subnet can communicate with each other over any TCP or UDP port, as well as with ICMP. Instances in the same network can communicate with each other, regardless of which subnets they’re in, because Google Cloud creates routes between all of the subnets in a network. However, the default network’s firewall rules only allow ssh, rdp, and icmp traffic between subnets.</p>
<p>If you don’t want instances in different subnets to be able to reach each other, then you can change the firewall rules to deny traffic between them.</p>
<p>Note that only the default network comes with predefined firewall rules. When you create a new network, it doesn’t have any firewall rules. However, the instances in that network will still be able to communicate with the Internet, assuming they have external IP addresses, because all outgoing traffic from instances is allowed. Only incoming traffic is blocked. And when an instance sends a request over the Internet, the incoming response is allowed, so two-way traffic is enabled at that point.</p>
<p>Each network includes a local DNS server so VM instances can refer to each other by name. The fully qualified domain name for an instance is [HOSTNAME].c.[PROJECT_ID].internal. This name is tied to the internal IP address of the instance. An Instance does not know its external IP address and name. That translation is handled elsewhere in the network.</p>
<p>To reach Internet resources, each VM needs an external IP address. An ephemeral external IP address is created for each VM by default, but an ephemeral address gets replaced with another one if you stop and restart the instance, so if you want an instance to always have the same IP address, then you need to assign a static IP address to it.</p>
<p>Since IPv4 addresses are a scarce resource, Google doesn’t want customers to waste them. So you’re not charged for having static IP addresses as long as you’re using them. But if a static IP address is not associated with a VM instance or if it’s associated with an instance that’s not running, then you’ll be charged for it.</p>
<p>Normally, if a VM needs to send requests to other Google services, such as Cloud Storage, then by default, it has to do so using a public IP address rather than an internal one. This is problematic if you don’t want any of your internal network communications to go over the Internet. However, if you enable the Private Google Access option in a subnet, then VMs in that subnet can connect to Google services using internal IP addresses, so their requests will go over Google’s network rather than the Internet.</p>
<p>If you want instances in different projects to communicate with each other, then you have three options: the Internet, VPC Network Peering, or a Shared VPC. Connecting over the Internet is slower, less secure, and more expensive than the other two options, so it’s not usually the best choice.</p>
<p>The simplest alternative is VPC Network Peering. This allows two VPCs to connect over a private RFC 1918 space, that is, using non-routable internal IP addresses, such as 10.x.y.z. In other words, they don’t need public IP addresses, and they communicate over Google’s network. Not only can you do this for VPCs in different projects, but you can even use it to connect VPCs in different organizations. To make this work, both sides have to set up a peering association. If only one side sets up a peering association with the other VPC, then the networks won’t be able to communicate with each other. Also bear in mind that there can’t be any overlapping IP ranges in the two networks. You’ll notice in this example that the two ranges are not overlapping.</p>
<p>A more complicated option is to use a Shared VPC. The idea is that instances in different projects can share the same network. This is kind of a weird idea. If you’ve put resources in different projects, you probably want them to be managed separately, so why would you get them to use the same network? In most cases, it’s to enforce security standards. For example, if you want to use the same firewall rules across all of your projects, then this is a good way to do that.</p>
<p>To set up a Shared VPC, you need to designate one of the projects as the host project and the others as service projects. The host project is the one that contains the Shared VPC. Instances in the service projects can use subnets in the Shared VPC. This is made possible by giving Service Project Admins the authority to create and manage instances in the Shared VPC but nothing more. Meanwhile, the Shared VPC Admins have full control over the network. Note that all of the projects in this arrangement have to be part of the same organization.</p>
<p>OK, we’ve gone over a lot of networking topics. Now how should we apply these concepts to GreatInside?</p>
<p>At a minimum, we should create separate projects for the Development, Test, and Production environments. Inside each project, we should stick with the default network. There’s no need to add any additional ones. We should also stick with automatic subnetworks. The only subnetwork we need right now is one in the US, such as us-central1, since we don’t currently have any plans to expand into other parts of the world. When GreatInside decides to add instances overseas, then they can be added to the other regional subnets.</p>
<p>The default firewall rules should also be fine, since they only allow internal traffic plus ssh, icmp, http, and https. We should remove the rule that allows rdp traffic in the Production network, though, since we don’t have any Windows instances in it.</p>
<p>We don’t want the Production, Development, and Test environments to be part of the same network, so we don’t need a Shared VPC. In fact, we don’t want them to communicate with each other at all, so we don’t need to use VPC Network Peering either.</p>
<p>By the way, you probably noticed that everything I’ve shown so far is only for the interior design application. I’m going to get into the details of how to set up the payment processing environment in the Legislation and Compliance lesson.</p>
<p>One last item is that we have to decide which components need external IP addresses. That’s easy in this case because the load balancer is the only one that needs an external IP address (and ideally it should be a static address). Users will connect to the web instances through the load balancer, so the web instances only need internal IP addresses, and for security reasons, that’s all they should have.</p>
<p>That does raise the question of how a system administrator could connect to them for troubleshooting, though. One way is to give your administrators access to the internal network by interconnecting it with the company’s on-premises network. That’s something that GreatInside has already requested, so let’s see how to do that. There are three ways: Cloud VPN, Cloud Interconnect, and Direct Peering.</p>
<p>Cloud VPN lets you set up a virtual private network connection between your own network and Google Cloud. To do this, you need to have a peer VPN gateway in your own network and it needs to use IPsec to connect to the Cloud VPN Gateway and encrypt traffic. You can have multiple tunnels to a single VPN gateway.</p>
<p>By itself, Cloud VPN requires you to make changes to static routes on your tunnels manually. But if you use Google Cloud Router, then the routes will be updated dynamically using BGP (that is, Border Gateway Protocol). Network topology changes are propagated automatically.</p>
<p>The second way to connect is called Cloud Interconnect. Instead of connecting over the Internet, you can use an enterprise-grade connection to Google’s network edge. There are two ways to do this: Dedicated Interconnect and Partner Interconnect. If your internal network extends into a colocation facility where Google has a point of presence, then you can connect your network to Google’s. This is called Dedicated Interconnect. It’s a great solution that provides higher bandwidth and lower latency than a connection over the public internet. It’s a bit expensive, though, because the minimum bandwidth is 10 Gbps.</p>
<p>If you don’t have a presence in a supported colocation facility or you want to pay for a connection that’s smaller than 10 Gbps, you can use Partner Interconnect. With this option, you connect to a service provider that has a presence in a supported colocation facility. You can purchase a monthly contract for connections as small as 50 Mbps and as large as 10 Gbps. </p>
<p>The third way is to use Peering. This is similar to Cloud Interconnect because you connect your network to Google’s network at a point of presence either directly (which is called Direct Peering) or through a service provider (which is called Carrier Peering). One big difference with peering is that it doesn’t cost anything. So why would anyone pay for Cloud Interconnect when they could peer with Google for free? Well, because with Cloud Interconnect you get a direct connection between your on-premises network and one of your VPCs in Google Cloud. You have full control over the routing between your networks. If you want to change a route, you can change it on your on-premises router, and it will be picked up by BGP. Although the peering option uses BGP, too, it’s done at the most basic level. It doesn’t create any custom routes in your VPC network.</p>
<p>Since we don’t have requirements for low latency and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/high-availability-1/">high availability</a> between the company network and Google Cloud, we should go with Cloud VPN to connect. We should also use Cloud Router so network routes will be updated dynamically.</p>
<p>And that’s it for networks.</p>
<h1 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h1><p>The first step in giving secure access to your <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">Google Cloud infrastructure</a> is to decide how to authenticate your users. By default, Google Cloud Platform requires users to have a Google account to access it. But if you have more than a handful of users, then you’ll want to find a centralized way to manage your user accounts. The solution is to use the G Suite Global Directory. You don’t have to use G Suite products like Google Docs, you can just use G Suite for user management.</p>
<p>Most organizations already have a user directory, so the best policy is usually to manage users in your existing directory, and then synchronize the account information in G Suite. There are three ways to do this: Google Cloud Directory Sync or GCDS, the Google Apps Admin SDK, or a third party connector.</p>
<p>Google Cloud Directory Sync is the easiest solution if you have either Active Directory or an LDAP server. It synchronizes users, groups, and other data from your existing directory to your Google Cloud Domain Directory. GCDS runs inside your <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/networks-1/">network</a> on a machine that you control.</p>
<p>It’s a one-way synchronization, so GCDS doesn’t modify your existing directory. Of course the synchronization can’t be a one-time event. It has to happen on a regular basis to keep your Google Directory up-to-date.</p>
<p>To make authentication even easier for your users, you can implement single sign-on or SSO. Google Cloud Platform supports SAML 2.0-based SSO. If your system doesn’t support SAML 2.0, then you can use a third party plugin.</p>
<p>Once you’ve implemented SSO, then when a user would normally have to login, Google will redirect your authentication system. If the user is already authenticated in your system, then they don’t have to login to Google Cloud separately. If they aren’t already logged in, then they’re prompted to login.</p>
<p>In order for this to work, your users must have a matching account in Google’s Directory. So you still need to use GCDS or one of the other synchronization options.</p>
<p>In our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/case-study-1/">case study</a>, since we have an active directory server, we’ll use GCDS for synchronization and also implement single sign-on.</p>
<p>And that’s it for authentication.</p>
<h1 id="Roles"><a href="#Roles" class="headerlink" title="Roles"></a>Roles</h1><p>To give a user permission to access particular Google Cloud resources, you assign a role to them. Basic roles act at the project level. There are 3 basic roles available: Owner, Editor, and Viewer. There are also fine-grained roles for individual resources. These are called predefined roles. (They were previously known as curated roles.) For example, the Cloud SQL Viewer role gives read-only access to Cloud SQL resources.</p>
<p>You can assign roles at different levels of the hierarchy, that is, at the organization, folder, project, and resource levels. If you assign roles to the same user at different levels, then their effective permissions are the union of the permissions at the different levels.</p>
<p>For example, if you granted Marie the Viewer role at the organization level and the Editor role at the project level, then she would have Editor permissions for all of the resources in that project. The Viewer role at the organization level would not override the Editor role at the project level. Similarly, if you assigned them in the opposite way, with the Editor role at the organization level and the Viewer role at the project level, Marie would still have the Editor role for all of the resources in that project because the project-level permissions would not override the organization-level permissions.</p>
<p>There are a few principles you should apply when setting roles and permissions. </p>
<p>First, use the principle of least privilege when granting roles. That is, assign roles with the least permissions required for people to do what they need.</p>
<p>Second, whenever possible, assign roles to groups instead of to individuals. Then, when you need to grant a role to a user, you can just add them to the group. Not only is this easier to manage, but it also ensures consistent privileges among members of a particular group. You can also use a descriptive group name that makes it clear why group members need those permissions.</p>
<p>Third, keep tight control of who can add members to groups and change policies. If you don’t, then people could give themselves or others more privileges than they should have.</p>
<p>Fourth, to make sure that inappropriate policy changes aren’t made, audit all policy changes by checking the Cloud Audit Logs, which record project-level permission changes.</p>
<p>Now let’s apply these principles to GreatInside. First, you would grant the project owner role to a few key system administrators. Owners are the only ones who can change policies (unless you grant users the Organization Administrator role). You should always have more than one owner. Otherwise, if that person is unavailable or leaves the organization, it would be difficult to for someone else to take their place as owner. So avoid that situation by giving the owner role to several people, but choose wisely because owners can do just about anything. </p>
<p>Similarly, you would have a small number of G Suite administrators who could add users to groups.</p>
<p>Obviously, there would be a large number of users who would need permissions, so I’m not going to talk about every type of user, but I’ll give a couple of examples. One example would be a network administration group that you would grant the Compute Network Admin role to.</p>
<p>Another example would be a QA team. You could grant their group the editor role on the Test Environment project and the viewer role on the Production Environment project. Alternatively, if the QA people don’t need full access to the Test Environment, then you could grant them several predefined roles, such as Compute Instance Admin, Cloud SQL Admin, and Compute Storage Admin.</p>
<p>Regarding audit logs, someone would need to take on the responsibility of checking for policy changes. The Admin Activity audit logs are viewable by all project members, so you wouldn’t need to grant access to the person who does the checking.</p>
<p>And that’s it for roles.</p>
<h1 id="Service-Accounts"><a href="#Service-Accounts" class="headerlink" title="Service Accounts"></a>Service Accounts</h1><p>Now that you have user authentication and permissions figured out, it’s time to plan how your applications will access the Cloud Platform services it needs to use. To avoid embedding credentials in an application, you need to use service accounts. For example, if an application uses Cloud Datastore as a database, then it needs to have authorization to use the Datastore API.</p>
<p>You would accomplish this by enabling Datastore API access on any VM instances that will be involved in the part of the application that uses the database. By default, all VM instances run as the Compute Engine default service account. If you want something different, then you can create your own.</p>
<p>A service account has an email address and a public&#x2F;private key pair that it uses to prove its identity. Your instances use that identity when communicating with other Cloud Platform services. However, by default, an instance running as the Compute Engine default service account has limited scope in how it can interact with other services. For example, by default an instance can only read from Cloud Storage and can’t write to it.</p>
<p>To give an instance more permissions, you need to set the scope when you’re creating the VM. So, in the case of interacting with Datastore, you have to enable access to the Datastore API. You also have to enable the Datastore API at the project level, but you only have to do that once.</p>
<p>Then your application code has to obtain credentials from the service account whenever it uses the Datastore API. Google Cloud Platform uses OAuth 2.0 for API authentication and authorization. There are two ways to do it: Application Default Credentials and access tokens.</p>
<p>The easiest way is to use Google Cloud Client Libraries. They use Application Default Credentials (or ADC) to authenticate with Google APIs and send requests to those APIs. One great feature of ADC is that you can test your application locally and then deploy it to Google Cloud without changing the application code. </p>
<p>Here’s how it works. To run your code outside Google Cloud Platform, such as in your on-premise data center or on another cloud platform, create a service account and download its credentials file to the servers where the code will be running. Then set the environment variable GOOGLE_APPLICATION_CREDENTIALS to the path of the credentials file.</p>
<p>So while you’re developing locally, the application can authenticate using the credentials file and when you run it on a production instance, it will authenticate using the instance’s service account. This works because ADC allows applications to get credentials from multiple sources.</p>
<p>The second way is to use OAuth2 access tokens to directly connect to the API without going through a client library. One reason you’d have to use this method is if your application needs to request access to user data.</p>
<p>The way it works is the application requests an access token from the metadata server and then uses the token to make an API request. Tokens are short-lived, so your application needs to request new ones regularly.</p>
<p>If you need to write shell scripts that access other Cloud Platform services, then you can use gcloud and gsutil commands to make API calls. These two tools are included by default in most Compute Engine images and they automatically use the instance’s service account to authenticate with APIs.</p>
<p>So what service accounts would you need to create for GreatInside? The load balancer and the web instances communicate over HTTPS, so you don’t a service account for that. Since the Tomcat instances communicate with the MySQL database in Cloud SQL, you would need a service account for that. Similarly, the IIS instances communicate with SQL Server in Cloud SQL, so you’d need a service account for that, too. There may be a need for other service accounts when we add more features to our architecture, such as disaster recovery, but we’ll cover that later.</p>
<p>And that’s it for service accounts.</p>
<h1 id="Data-Protection-and-Encryption"><a href="#Data-Protection-and-Encryption" class="headerlink" title="Data Protection and Encryption"></a>Data Protection and Encryption</h1><p>Protecting data is critical in any organization. Google Cloud Platform is very strong in this area because of its default encryption policies. Before we get into encryption, though, let’s look at Access Control Lists (or ACLs).</p>
<p>ACLs specify who has access to Cloud Storage buckets and objects in buckets. I’m not going to cover this topic in depth, but there are a few things to keep in mind when you’re deciding what ACLs to apply to your Cloud Storage.</p>
<p>First, there are actually five different mechanisms for controlling access to Cloud Storage: IAM permissions, ACLs, Signed URLs, Signed Policy Documents, and Firebase Security Rules. With so many different ways to control access, you have to be careful not to create conflicting permissions. Start with the first two: IAM permissions and ACLs.</p>
<p>IAM permissions work at the project level. For example, you can specify that a user has full control of all the objects in all of the buckets in your project, but cannot create, modify, or delete the buckets themselves. So they’re a nice way to grant broad access to buckets and objects, but if you want to set fine-grained access, such as which buckets or objects a particular group can read, then you need to use ACLs.</p>
<p>The confusing thing about using these two mechanisms is that you have to look at both of them to get a complete picture of access permissions. For example, you could list the ACLs for a bucket and see that only Bob has been granted write access, but it wouldn’t show that Jill has also been granted write access to all buckets by IAM. For this reason, whenever possible, you should try to use either IAM or ACLs, but not both.</p>
<p>Another potential source of confusion is that bucket and object ACLs are independent of each other. The ACLs on a bucket do not affect the ACLs on objects inside that bucket. For example, you might think that Jane doesn’t have access to the objects in a bucket because she hasn’t been granted access to the bucket itself, but she could have been granted access to any of the objects in the bucket.</p>
<p>So you should keep a couple of principles in mind. First, apply the principle of least privilege. Grant users and groups only as much access as they need. Second, keep your access control as simple as possible. Try to use as few control mechanisms as you can.</p>
<p>If GreatInside decides to replace its internal file server using Cloud Storage, then the best way to secure the files would be to use ACLs. You would create groups to match the teams in the company and create ACLs that give those groups access to the appropriate resources. For example, you could create a bucket for each group. Then for each bucket, you would make the associated group a writer of the bucket. Finally, you would set the object default permissions so that any new objects uploaded to the bucket would get the same permissions and everyone in the group would have full access. If the company’s needs aren’t that simple, then you would set more complex ACLs.</p>
<p>Now let’s move on to encryption. To ensure that your data is encrypted at all times, it needs to be encrypted when it’s in storage (also known as “at rest”) and when it is being sent over a network (also known as “in flight”). Google Cloud Platform takes care of both of these situations.</p>
<p>Encryption in flight is handled very simply. All of the Cloud Platform services are accessible only by API (even when you’re using other methods, such as the Cloud Console or the gcloud command, they’re making API calls under the hood). And all API communication is encrypted using SSL&#x2F;TLS channels. Furthermore, every request has to include a time-limited authentication token, so the token can’t be used by an attacker after it expires. Of course, for any communications between your Google Cloud infrastructure and outside parties, such as website visitors, you have to use SSL&#x2F;TLS yourself to encrypt the traffic.</p>
<p>Encryption at rest is just as simple if you’re willing to leave it to Google because Cloud Platform encrypts all customer data at rest by default.</p>
<p>So without you having to do anything, all of your data will be encrypted both at rest and in flight. Then why isn’t this the end of this lesson? Well, because your organization might want to take on some of the encryption responsibilities itself.</p>
<p>There are actually two layers of encryption for data at rest. First, the data is broken into subfile chunks, and each chunk is encrypted with an individual data encryption key (or DEK). These keys are stored near the data to ensure low latency and high availability. The DEKs are then encrypted with a key encryption key (or KEK). The keys are AES-256 symmetric encryption keys.</p>
<p>Google always manages the data encryption keys, but your organization can manage the key encryption keys if that’s your preference. There are two options for doing this: Customer-managed encryption keys or Customer-supplied encryption keys.</p>
<p>With the customer-managed option, you use the Cloud KMS service to create, rotate (or automatically rotate), and destroy your encryption keys. The keys are hosted on Google Cloud. You can have as many keys as you want, even millions of them if you actually need that many. You can set user-level permissions on individual keys using IAM and monitor their use with Cloud Audit Logging.</p>
<p>Cloud KMS is a nice service, but why wouldn’t you just let Google manage your key encryption keys and not have to deal with it yourself? The biggest reason is compliance with standards or regulatory requirements, such as HIPAA (for health information) or PCI (for credit card information).</p>
<p>If your organization requires that you generate your own keys and&#x2F;or that they’re managed on-premises, then you have to use Customer-supplied encryption keys. Be aware that this option is only available for Cloud Storage and Compute Engine.</p>
<p>With CSEK, Google doesn’t store your key. You have to provide your key for each operation, and your key is purged from Google Cloud after the operation is complete. Here’s how to do it from the command line with each of the two supported services. To encrypt the disk on a Compute Engine instance, you add the csek-key-file flag and point it to a file that contains the key. To encrypt data you’re uploading to Cloud Storage, you have to do it a bit differently. Rather than adding an encryption flag to the gsutil command, you need to add the encryption key to your .boto file, which is the configuration file for the gsutil command. Then all of your gsutil commands will use that key.</p>
<p>It only stores an SHA256 hash of the key as a way to uniquely identify the key that was used to encrypt the data. When you make a request to read or write the data in the future, your key can be validated against the hash. The hash cannot be used to decrypt your data.</p>
<p>There’s a big risk in using this method, though. If you lose your keys, you won’t ever be able to read your data again, and you’ll end up deleting it so you won’t be paying storage charges for unreadable data.</p>
<p>So far all of the encryption methods we’ve covered, including default encryption, Cloud KMS, and CSEK have been examples of server-side encryption. This is where your data is encrypted after Google Cloud receives your data. The only major difference between the 3 methods is where the key comes from. But there is another way. It’s client-side encryption. This means that you encrypt the data before you send it to Google Cloud. Google won’t even know that it’s already encrypted and it will encrypt it again. When you read your data back, Google Cloud will decrypt it on the server side first and then you’ll decrypt your own layer of encryption on the client side. The same warning applies - if you lose your keys, your data will effectively be gone.</p>
<p>Since our case study includes credit card information, we’ll need to be PCI DSS compliant, so we should use Cloud KMS to manage our keys. I’ll talk more about PCI compliance in the next lesson.</p>
<h1 id="Legislation-and-Compliance"><a href="#Legislation-and-Compliance" class="headerlink" title="Legislation and Compliance"></a>Legislation and Compliance</h1><p>Google Cloud Platform has passed annual audits for some of the most important security standards, including SOC 1, 2, and 3, ISO 27001, and PCI DSS. It also complies with HIPAA, CSA STAR, the EU-US Privacy Shield Framework, and MPAA controls, none of which require annual audits.</p>
<p>So if your organization is required to comply with any of these standards, then you know that Google has done its part. But this is a shared responsibility because <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">your security processes and applications</a> running on top of Google’s infrastructure also need to comply.</p>
<p>You’ll notice that Network is listed for both Google and the customer. That’s because Google takes care of some parts of networking and the customer takes care of the rest. One of the most interesting areas of shared responsibility for network security is protecting against distributed denial of service (or DDoS) attacks.</p>
<p>Google provides many features to help deal with DDoS attacks, but it’s up to the customer to use them properly. Here are some of the techniques.</p>
<p>Reduce the attack surface by</p>
<ul>
<li>Isolating and securing your deployment with firewall rules</li>
<li>Google also provides anti-spoofing protection by default</li>
</ul>
<p>Isolate your internal traffic from the external world by</p>
<ul>
<li>Deploying instances without public IPs unless necessary</li>
</ul>
<p>Use Load Balancing</p>
<ul>
<li>Because a load balancer acts as a proxy that hides your internal instances</li>
</ul>
<p>Use Cloud Armor</p>
<ul>
<li>This service is specifically designed to provide DDoS defense</li>
<li>And it works with Load Balancing</li>
<li>It protects against layer 3 and layer 4 DDoS attacks</li>
</ul>
<p>Google Cloud also enforces API rate limits and resource quotas to prevent a spike in one customer’s activity from affecting other Cloud Platform customers.</p>
<p>Now it’s time to get back to the PCI DSS standard and how to comply with it. If your organization accepts credit card payments, then you need to comply with this standard or you could be fined. More importantly, if you have security flaws that allow hackers to steal credit card information from your systems, then it would be very damaging to both your customers and your reputation.</p>
<p>In the case study, GreatInside provides an interface for collecting credit card information, but it passes the validation and processing of the information to a Certified Payment Processor. This makes the company an SAQ A-EP merchant in PCI lingo. I’ll go over Google’s recommendations for how this type of merchant could comply with PCI DSS.</p>
<p>First, you have to check that the other parties involved (that is, Google Cloud and the payment processor) are certified for your volume of transactions (since there are different PCI DSS merchant levels based on the number of transactions). Google Cloud Platform has the highest level of PCI DSS certification, so that’s not a concern, but you’ll have to check your payment processor’s certification level because your volume might exceed their certification level.</p>
<p>Here’s a suggested architecture to handle the company’s credit card processing. Here’s how it works. A customer enters their credit card information in a form on your website. Then your payment-processing application sends the information to the external payment processor. Now the payment processor tells your application whether the card was accepted or declined. After that your payment processing application sends some or all of the response data to your core application, so it knows how to proceed with this customer.</p>
<p>You also need to log and monitor all of these interactions. Every instance involved in payment processing sends its logs to Stackdriver Logging and its alerts to Stackdriver Monitoring.</p>
<p>Now let’s move on to how you would set this up. To reduce the number of systems that need to be PCI-compliant, you have to fully isolate your payment-processing environment from the rest of your production environment. The best way to do this is to use a separate Google Cloud account, rather than just a separate project within your main account.</p>
<p>Then use IAM to grant access only to people who absolutely need to work on the payment-processing environment, such as people who will be deploying new versions of the application or managing the systems. These people must also pass a background check first.</p>
<p>To create the instances, you should first create your own Linux image that’s based on one of the preconfigured boot disk images and that contains the bare minimum of additional software needed to run your application. Then use this custom image when creating all of your VM instances.</p>
<p>To secure the network, create firewall rules that only allow three types of inbound traffic:</p>
<ul>
<li>HTTPS traffic from the load balancer to the payment form servers, so that customers can reach your payments page</li>
<li>Credit card authorization responses from the external payment processor to your internal payment authorization servers, and</li>
<li>VPN traffic from your internal office network to the VPN Gateway, so your authorized people can manage and audit the application and systems.</li>
</ul>
<p>Then create firewall rules for outbound traffic. There’s only one type of outbound traffic you need to allow – HTTPS traffic from the payment form servers to the external payment processor, so they can send credit card authorization requests.</p>
<p>Now all of the traffic in and out of the network is locked down, but you’ll also have to open up internal traffic, such as:</p>
<ul>
<li>From all of the instances to Google’s NTP servers for time synchronization, and</li>
<li>SSH traffic from the VPN Gateway to all of the instances, so authorized people can access the systems for maintenance</li>
</ul>
<p>OK, let’s move on to deploying your application. To be compliant, you have to make sure you’re deploying the correct application every time, that it’s deployed securely, and that no other software packages are installed during the deployment. If you don’t already have an automated deployment tool, then you might want to use Cloud Deployment Manager, which could automate the creation of everything in your payment-processing environment, even the firewall rules. It could also help you create an audit trail of deployments.</p>
<p>Since you’ve used the same custom Linux image for all of your instances, you’ll need to install additional software on each instance. For example, some instances may need a web server, while others don’t, and each instance should only have the software it needs, which will reduce your security risks. To make this process consistent and reliable, it should be automated as well. The easiest way to automate software installation and configuration is to use a configuration management tool such as Chef, Puppet, or Ansible. Cloud Academy has courses on all three of these tools, so check one out if you’re not familiar with how to use any of them. </p>
<p>There are a few packages that you’ll want to install on all instances. First there’s iptables. You can set it up to log all network activity to and from each instance. This data is required for PCI DSS compliance audits.</p>
<p>Second, each instance needs the Stackdriver Monitoring and Logging agents so it can send logs and alerts.</p>
<p>Third, each instance should run an Intrusion Detection System (or IDS) to alert you to suspicious activity.</p>
<p>Finally, your configuration management tool needs to securely retrieve and launch the latest version of your application. </p>
<p>Even with an automated deployment, you’d still need to verify the integrity of the software being deployed. You could do this by running an automated checksum comparison against each package as it’s installed. You could also run an automated code analysis tool to check for security flaws.</p>
<p>Now let’s move on to logging. To be compliant, every step in the payment-processing environment has to be monitored and recorded. All instance activity and all user activity must be logged. Stackdriver Logging is a great service for collecting logs. You can record network traffic to and from your instances by enabling VPC Flow Logs on each subnet in your VPC.</p>
<p>By the way, you might think that we need to assign a service account to the instances so they can write logs to Stackdriver, but the default service account for VM instances already grants write access to Stackdriver, so you don’t need to configure that yourself.</p>
<p>I mentioned that user activity needs to be logged, but you also need to log the activity of people who have administrative access to the environment. The easiest way is to log all shell commands.</p>
<p>The amount of log information generated by all of this is likely to be very large, so you might want to export your Stackdriver logs to BigQuery if you need to do some complex analysis.</p>
<p>In addition to logging, you also need to set up real-time monitoring alerts, such as when your IDS detects any intrusion attempts.</p>
<p>After your environment is implemented, but before any production traffic flows through it, you have to validate the environment, either by contracting a Qualified Security Assessor if you’re a Level 1 merchant or by filling out the Self Assessment Questionnaire if you’re not a Level 1 Merchant.</p>
<p>Wow, that was a lot of work, wasn’t it? Well, if you’re going to be handling credit card information, you’ll be happy when your rigorous security design prevents damaging incidents.</p>
<h1 id="Disaster-Recovery"><a href="#Disaster-Recovery" class="headerlink" title="Disaster Recovery"></a>Disaster Recovery</h1><p>In an earlier lesson, we covered how to design a highly available architecture that will keep running even if an instance fails, by using load balancers, instance groups, and redundant databases. However, there are more catastrophic events that might occur. I’m not talking about an entire city getting destroyed or anything like that (although it would be good to have an architecture that could handle that). But much smaller incidents can be disastrous too. For example, one of your databases could become corrupt. This is actually worse than the database server going down because it may take a while before you realize there’s a problem, and in the meantime, the corruption problem could get worse.</p>
<p>To recover from this sort of disaster, you need backups along with transactional log files from the corrupted database. That way you can roll back to a known-good state. Each type of database has its own method for doing this.</p>
<p>If you’re using Cloud SQL to run a MySQL database (which we are for the interior design application), then you should enable automated backups and point-in-time recovery. Then if your database becomes corrupt, you can restore it from a backup or use point-in-time recovery to bring the database back to a specific point in time. </p>
<p>If you’re using Cloud SQL for SQL Server, then you should enable automated backups. At this time, Cloud SQL does not support point-in-time recovery for SQL Server, so you can only restore a database to the point when a specific backup was taken. For both types of databases, Cloud SQL retains up to 7 automated backups for each instance.</p>
<p>If you’re hosting a database on Compute Engine instances directly, then you’ll have to configure backups and transaction logging yourself. For example, suppose that instead of using Cloud SQL for SQL Server, we ran SQL Server on a Compute Engine instance. Then we’d need to set up our own disaster recovery solution for it. Luckily, Google has a very detailed white paper on this topic. I’ll give you the highlights.</p>
<p>First, set up an automated task that copies the SQL Server database backups to Google Cloud Storage. This is where we would finally need a service account because instances can’t write to Cloud Storage by default. The SQL Server instances need to have a service account with the Storage Object Creator role. Another way to do it would be to set a Cloud Storage access scope for the instance, but service accounts are more flexible.</p>
<p>Once the database is being backed up, then if disaster strikes, you would spin up a new SQL Server instance. Either use one of Google’s preconfigured SQL Server images or your own custom disk image. It doesn’t mention this in the whitepaper, but it’s the sensible thing to do and I’ll talk about it more in a minute. Next, you can use an open-source script to restore the database and re-execute the events in the log files up to the point in time desired.</p>
<p>When you’re designing a disaster recovery solution, you need to consider RPO and RTO. RPO stands for Recovery Point Objective. This is the maximum length of time when data can be lost. It affects your backup and recovery strategy because, for example, if it’s acceptable to lose an entire day’s worth of work, then you can just recover using the previous night’s backups. If you have a short RPO, which is usually the case, then you need to make sure you are constantly backing up your data, and when recovering from database corruption, you have to carefully consider which point in time to recover to.</p>
<p>RTO stands for Recovery Time Objective. This is the maximum length of time that your application can be offline and still meet the service levels your customers expect (usually in a service level agreement).</p>
<p>In the SQL Server example, I suggested using either one of Google’s preconfigured SQL Server images or your own custom disk image that has SQL Server installed and configured. The advantage of having a custom disk image is that it helps you meet your recovery time objective because it reduces the amount of time it takes to get a new SQL Server instance running. If you have to configure SQL Server manually, that could significantly impact how long it takes to recover from a disaster.</p>
<p>As with everything, though, there are tradeoffs. If your SQL Server implementation is customized, then you’ll have to weigh the benefits of fast recovery time against the maintenance effort required to keep your custom image up-to-date . If you have a very short RTO, then you may have no choice but to maintain a custom disk image. You might be able to ease the maintenance required, though, by using a startup script to perform some of the customization. Since the startup script resides on either the metadata server or Cloud Storage, you can change it without having to create a new disk image.</p>
<p>In some cases, you may want to run an application from your own data center or from another cloud platform and use Google Cloud as a disaster recovery solution. There are many ways you could do this, but I’ll go over a couple of common designs.</p>
<p>The first way is to continuously replicate your database to an instance on Google Cloud. Then you would set up a monitoring service that would watch for failures. In the event of a disaster, the monitoring service would trigger a spin-up of an instance group and load balancer for the web tier of the application. The only part you would need to do manually is to change the DNS record to point to the load balancer’s IP address. You could use Cloud DNS or another DNS service for this.</p>
<p>This is already a low-cost solution because the only Google Cloud resource that needs to run all the time is the database instance. But you can reduce the costs even further by running the database on the smallest machine type capable of running the database service. Then if there’s a disaster, you would delete the instance, but with the option to keep the persistent disk, and spin up a bigger instance with the saved disk attached. Of course, this solution would require more manual intervention and would lengthen your downtime, so you wouldn’t want to do this if you have a short RTO.</p>
<p>If you want to reduce your downtime as much as possible, or even keep running in the event of hardware failures, you could serve your application from both your on-premises environment and your Google Cloud environment at all times. That way if you have an on-premise failure, the Google Cloud environment would already be running and serving customers. It would just need to scale up to handle the extra load, which would be automatic if you use an autoscaling instance group.</p>
<p>To make this hybrid solution work, you would need to use a DNS service that supports weighted routing, so it could split incoming traffic between the two environments. In the event of a failure, you would need to disable DNS routing to the failed environment.</p>
<p>And that’s it for disaster recovery.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>I hope you enjoyed learning how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/course-introduction-8/">design a Google Cloud infrastructure</a>. Now you know how to map <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/compute-1/">compute</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/storage-2/">storage</a>, and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/networks-1/">network</a> requirements into Google Cloud, and secure your infrastructure with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/authentication-2/">authentication</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/roles-1/">roles</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/service-accounts-1/">service accounts</a>, ACLs, and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/data-protection-and-encryption-1/">encryption</a>. You also know some of the ways to design <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/high-availability-1/">high availability</a>, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/designing-a-google-cloud-infrastructure/disaster-recovery-1/">disaster recovery</a>, and PCIDSS compliance into your solution.</p>
<p>To learn more about Google Cloud platform, you can read Google’s online documentation. You can also try one of the other Google courses on Cloud Academy, and watch for new ones, because we’re always developing new courses.</p>
<p>If you have any questions or comments, please let me know on the Cloud Academy community forums. Thanks and keep on learning.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-10/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-10</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:14:07" itemprop="dateCreated datePublished" datetime="2022-11-19T00:14:07-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:39:32" itemprop="dateModified" datetime="2022-11-20T19:39:32-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-10/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Scaling-an-Application-Through-a-Google-Cloud-Managed-Instance-Group-10/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-9/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-9</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:14:05" itemprop="dateCreated datePublished" datetime="2022-11-19T00:14:05-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:39:54" itemprop="dateModified" datetime="2022-11-20T19:39:54-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-9/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Create-a-Network-Infrastructure-with-Google-Virtual-Private-Cloud-9/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Define-and-Deploy-Resources-with-Google-Cloud-Deployment-Manager-8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Define-and-Deploy-Resources-with-Google-Cloud-Deployment-Manager-8/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Define-and-Deploy-Resources-with-Google-Cloud-Deployment-Manager-8</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:14:04" itemprop="dateCreated datePublished" datetime="2022-11-19T00:14:04-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:40:06" itemprop="dateModified" datetime="2022-11-20T19:40:06-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Define-and-Deploy-Resources-with-Google-Cloud-Deployment-Manager-8/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Define-and-Deploy-Resources-with-Google-Cloud-Deployment-Manager-8/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Command-Line-7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Command-Line-7/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Command-Line-7</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:14:02" itemprop="dateCreated datePublished" datetime="2022-11-19T00:14:02-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:40:46" itemprop="dateModified" datetime="2022-11-20T19:40:46-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Command-Line-7/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Command-Line-7/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Google-Cloud-Platform-Systems-Operations-6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Google-Cloud-Platform-Systems-Operations-6/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Google-Cloud-Platform:-Systems-Operations-6</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:14:01" itemprop="dateCreated datePublished" datetime="2022-11-19T00:14:01-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:35:44" itemprop="dateModified" datetime="2022-11-20T19:35:44-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Google-Cloud-Platform-Systems-Operations-6/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Google-Cloud-Platform-Systems-Operations-6/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Course-Introduction"><a href="#Course-Introduction" class="headerlink" title="Course Introduction"></a>Course Introduction</h1><p>Welcome to the Google Cloud Platform: Systems Operations course. I’m Ben Lambert and I’ll be your instructor for this course. The goal of the course is to cover some of the services that are part of Google Cloud’s infrastructure as a service options.</p>
<p>Here’s what you’ll get out of this course. By the end of the course, you should understand how to Compute Engine to create virtual machines, as well as how to create disk snapshots, how to create images, how to create instance templates and groups. And you’ll learn how to create networks and how to use the auto scaler and load balancer.</p>
<p>Before you start, there are some assumptions that I’ve made about you. I assume you’re familiar with general IT concepts. Maybe you’re a systems administrator or operations engineer looking to expand your skill set to Cloud platforms. I assume you’re familiar with the basics of cloud computing as well. If you’re not, I recommend that you check out the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/what-is-cloud-computing-introductory/introduction-8/">What is Cloud Computing?</a> course by Stuart Scott. Then follow it up with the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-fundamentals/course-introduction-1/">Google Cloud Platform: Fundamentals</a> course before continuing.</p>
<p>Okay, here’s our agenda for this course. We’ll start off with an overview of the platform. We’ll move on to cover Compute Engine instances. We’ll talk about networking, then we’ll talk about disks and images. After that, we’re going to cover authorization and IAM. Then, we’re going to talk about snapshots. After that, we’ll follow it up a review of cloud storage. Then we’ll talk about instance groups. We’ll cover a crash course on Cloud SQL. Then we’ll go through metadata and startup and shutdown scripts. We’ll follow that up by auto scaling and load balancing. Then our final lesson is going to put some of these components together into a single demo.</p>
<p>So if this course has piqued your interest, then let’s get started with the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/getting-started-4/">first lesson</a>.</p>
<h1 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h1><p>Welcome back. In this lesson we’re going to be talking about projects. If you completed the Google Cloud platform fundamentals course then this lesson is going to be a bit of a review. However since projects are the starting point for all of our work, it’s worth going over again.</p>
<p>Projects are used to create isolated environments. It’s used to create different applications or different environments for a single application. As an example, if we had an application called pizza-time then we might have a project for development named dev-pizza-time and another for staging called staging-pizza-time and one for production named production-pizza-time. So, we can enable services and resources that are linked to a specific project and each project is billed separately. Though it can use the same billing account, if we want to.</p>
<p>Once we have a project, we’ll need to be able to identify it and we’ll have different mechanisms to do that. Projects have three identifiers. We have the name, which is the human friendly identifier. There’s the ID, which is kind of the developer’s ID. It’s the identifier that we used on the command line tools, or passed into any URLs. And then we have the project number. And this is a Google generated number used behind the scenes to identify our projects. Keep in mind some of the automated emails that Google sends out are going to use this number as the project reference.</p>
<p>We can find these different identifiers on the settings tab of the IAM &amp; Admin page. Let’s imagine you received an automated email from Google informing you that your project is violating the terms of service and they provide you with the project number. Well, for most of us we don’t pay attention to that number. So, if you have a lot of projects then going through each of them to find that can be a pain and this where the G cloud command line tool comes in. You can run the G cloud projects list command to get a listing of all of the projects and it will show the name, ID, and number for each of them. And this is going to make it easier to zero in on the correct project.</p>
<p>Okay now that we can find projects by name, number, or ID, let’s move on to talk about project resources. First, what do I mean, when I say resources? In this context, resources are things such as virtual machine images, disk snapshots, networks, and other components that we use to create our infrastructure and applications. And resources have different types depending on where they can be accessed from. Let’s list off the different types of resources and then let’s go into them each a bit more. We have global resources, regional resources, and zone-based resources.</p>
<p>Just in case you need a quick refresher about regions and zones. A region is a geographic area in the world and regions have zones inside of them. And those zones are basically data centers that are physically inside of that geographic region.</p>
<p>So, starting at the bottom of our list. If a resource belongs to a zone then it lives in just one zone. And it can interact with other zone-based resources that live in that same zone. Some example of zone-based resources are things such as instances and disks. This makes sense when you consider that a single running VM is only running on one server and while it could be moved to another server it runs on one at a time. So, zone-based resources are things that aren’t likely to be distributed across multiple servers.</p>
<p>Moving up the list we have regional resources, which are resources that are accessible inside of a given region. As an example, a static external IP address is a regional resource. You can assign it to any instance that’s running in the same region. And recall that instances are zone-based meaning zone-based resources can interact with resources that have a broader scope.</p>
<p>And then we move to the top of the list and we have global resources. Global resources are accessible by any resource in any zone within the same project. These global resources are things such as virtual machine images, or persistent disk snapshots. Being global means that we have these resources to use in any zone. So, if we create a custom image then we can use that in any zone that we choose.</p>
<p>Like I mentioned at the beginning, we’re going through this stuff again even though we’ve covered it in the fundamentals course because this is important to understand. Understanding the resource types will help us to make conscious decisions about how we allocate them and where we allocate them. For example, if we’re going to use a VM image, which is a global resource, to create a virtual machine instance and we need to choose which zone that instance is going to run in. And depending on the application and architecture that could impact latency for some users. So we need to understand where resources will run and what they’ll have access to.</p>
<p>Okay, so we have projects that will serve as an isolated environment for us to enable and use different resources in. And once we start using different resources we need to think about potential quotas and limits that we may run into. Quotas determine the amount of a given resource that we create per project or region. And limits determine things such as, how many requests we can make against a given API in a certain time frame. For the most part the quotas are to protect us from accidentally allocating let’s say a million VMs and going broke. Or from those same million VMs causing latency issues for the rest of the Google Cloud Platform customers. Now of course that’s an exaggerated example to make a point, however the quotas are there to help us. So, if you need a quota cap increased you can create a support ticket because most of the quotas can be increased.</p>
<p>Let’s move on from projects and resources now to talk about how we interact with the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a> as a whole. We have three options. We can use the Cloud Console, the SDK, and the rest API. We can use the Cloud Console, which is the web user interface and it will allow us to do just about everything we need, however some tasks need to be done in code or on the command line. An example of this is, we can look at the different Cloud data store indeces, however we can’t create them from the console. We need to upload an index configuration on the command line.</p>
<p>And that leads us to our second way of interacting with the Google Cloud Platform and that’s the Cloud SDK. That’s a suite of command line tools and that extends to Cloud Shell, which is a Google provided web-based terminal that has the Cloud SDK pre-loaded. It’s basically a Debian VM that you can access through you web browser and this is a very cool feature to me. Actually this one saved me a weekend. I was visiting some family and I was a couple hours away from home and I was without my laptop. I got an IM from a coworker letting me know that some of the users for our product were getting an 500 error on the profile page. However, my father-in-law let me use his Mac and I was able to log into the console, launch Cloud Shell, and then use it to pull the latest code from source control. I skimmed through the logs, I noticed the problem, and used nano to fix the issue. And then committed it back to Git. And then from there the CI process kicked off and deployed the code. This resolved the issue for the users thankfully and saved my weekend.</p>
<p>Cloud Shell has Git and several programming languages pre-loaded in addition to the Cloud SDK. So, it also gives us five gigs of persistent storage mounted to our home directory. And that allows us to install any tools that we may need to use. And now there’s a new update that Cloud Shell even has a web based code editor. So, that’s really cool. Not needing to install a bunch of things locally or for me driving two hours home was just fantastic, so I’m rather partial to Cloud Shell.</p>
<p>The third way to interact with Google Cloud is through the Rest API. Just about all of the functionality of the platform is exposed via Rest API and these different APIs are gaining functionality on a regular basis. Google provides us with a tool as well to test out this functionality and it’s the aptly named API Explorer. It’s going to give us a simple to use interface for testing things out.</p>
<p>Let’s actually check it out. Check out here we have this list of all of the different APIs. So, we scroll through you can see there’s quite a bit. And now let’s pick something. Let’s go with the translate API cause that’s a nice one to show as a demo. And we can translate some texts from English to let’s say Italian. So if we try translating Hello, and let’s just set these variables here. Okay great. Now let’s run this. And we scroll down and we can see the output of Ciao. So we can use this to test out all kinds of APIs and I like to use this when I’m learning a new API, to kind of figure out the mechanics of it.</p>
<p>Alright let’s wrap up the lesson here. We’ve covered projects, we talked about resources and how to interact with them, and now these are going to be the basis for all of the things that we’re going to do with the Google Cloud Platform from here on out in the following lessons. In our next lesson we’re going to talk about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/compute-engine-instances/">Virtual Machine Instances</a>. So, if you’re ready to keep learning then let’s get started.</p>
<h1 id="Compute-Engine-Instances"><a href="#Compute-Engine-Instances" class="headerlink" title="Compute Engine Instances"></a>Compute Engine Instances</h1><p>Welcome back. In this lesson, we’re going to talk about virtual machine instances. We’ll talk about Compute Engine and creating instances and then once we have our instances running, we’ll need to connect to them, so we’ll talk about that as our closing topic.</p>
<p>Sometimes, we’re building something like a web application and using hosted platforms like AppEngine makes a lot of sense. It abstracts away the need to think about individual virtual machines and that can make life easier on developers and operations. However, there are still plenty of applications and workloads that are better suited for running on VM instances. Things such as batch processing jobs as well as lifting and shifting legacy applications to the Cloud. And this is the rule of Compute Engine. And it’s one of Google’s compute offerings. It allows us to create networks and virtual machines and structure things just the way we need to.</p>
<p>Now, maybe you need something like a fairly simple small Ubuntu VM to run some legacy application or maybe you’re working with something larger and more complex like a multi-player video game backend. Either way, Compute Engine has the ability to make all of that happen.</p>
<p>So what does Compute Engine offer in the way of features? It provides pre-configured machine types such as high CPU and high memory as well as standard or shared-core machine types. We’ll cover these more in-depth in just a bit. It also provides persistent disks and these can be in the form of standard or SSD and even local SSD. And we can take snapshots of these disks as well and that will allow us to make back-ups or to create a base image.</p>
<p>Compute Engine also provides a metadata server which is really cool. The way it works is that we can get and set metadata related to the project or a running instance. The metadata server also holds things such as the startup and shutdown scripts. So whenever a server starts up, which includes a reboot, the startup script can run and initialize things. It’s going to allow us to bootstrap our code or a configuration management client. And besides all of this good stuff, we also get APIs for auto scaling, we get per-minute billing, and custom machine types. And we’ll be talking more about this stuff as we progress throughout the course.</p>
<p>Compute Engine is classified as infrastructure as a service, which is ideal for general computing workloads. And that means it takes more effort to create and manage the environments we need. However, it also means we have fewer limitations. You can select the tools and languages that work for you.</p>
<p>Now that we’ve talked about some of the cool features that Compute Engine offers, let’s dive into actually creating instances. I want to make a quick point of clarification between image and instance. An image is basically a snapshot of a disk. And an instance is a copy of an image that contains a boot disk and it’s one that can be started and stopped and deleted. It’s an actual bootable VM.</p>
<p>Google provides us with several images based on common operating systems, though we can also create our own images if the existing ones don’t work for us. Instances are created under a project and require a unique name. An instance needs a boot disk and a machine type. And when we create a VM instance, it will use other Compute Engine resources as needed, and that’s things such as persistent disks, IP addresses, et cetera. Both instances and pre-defined machine types are zone-based resources.</p>
<p>Pre-defined machine types determine the hardware configuration. We mentioned it previously; there are four major types of pre-defined machine type. We have high memory, high CPU, standard, and shared-core. High memory machine types are ideal for tasks that require more memory relative to virtual CPUs. High memory machine types have 6.5 gigs of RAM per virtual CPU. High CPU machine types are ideal for tasks that require more CPU relative to memory. They have .9 gigs of RAM per virtual CPU. Standard machine types are good for tasks that need that balance between CPU and memory. Standard machine types have 3.75 gigs of RAM per virtual CPU. And then finally we have shared-core machine types which provide one virtual CPU and it’s allowed to run for a proportion of time on a single hardware hyperthread on the host CPU that’s running your instance. These are really designed to be cost-effective for running very small applications that aren’t really resource-intensive. Now, if you skim over the list and none of these pre-defined machine types are what you need, then you can also use a custom machine type.</p>
<p>A custom machine type can be very cost-effective because it uses just the resources that you want. So if you need a machine that has one virtual CPU and one gig of RAM, you can do that. There are, however, some rules that you need to follow when creating a custom machine type. For example, anything over one CPU needs to be an even number and memory needs to be between .9 gigs and 6.5 gigs per virtual CPU. The total memory needs to be a multiple of 256 megabytes and also the maximum number of virtual CPUs allowed depends on the zone. Some processors can support more than others.</p>
<p>Okay, earlier I mentioned that instances need a machine type and a boot disk, and we’ve just talk about machine types. So let’s cover boot disks. You can create an instance boot disk from the pre-defined images Google provides, or from a custom image which you could store on Cloud Storage or from a snapshot. So imagine you create an instance using a pre-defined image such as Debian, and then you install your web server software and get it all configured. You can then take a snapshot of that and use that to create new instances. And those new instances will have the same configuration and set-up of the instance the snapshot was based on at the time the snapshot was taken. Now this is a simple but very powerful mechanism because we can use it to set up base images or to restore an instance from back-ups and other uses. Now if you’re using Linux, you can import an image from a raw disk image from existing Amazon AMIs or from a virtual box image. So this allows us to create our own custom virtual machine image. This can be really useful if we need control over the base image or if the public base images don’t fit our needs. This is often useful when you need an OS that isn’t already in the public images. However, it’s also useful if you have very strict security requirements.</p>
<p>Let’s see what it looks to actually create an instance through the console. Okay, you can see that once we get to the creation form, we have some options we need to fill out. We have the instance name, and recall that this needs to be unique to the project. And then we have the zone that we want this to run in. And we have the boot disk and we can base it on public images, we can use a snapshot, or if we have an existing disk that isn’t already attached to a running instance, we can use that. We’re just going to select Debian. And while there’s more we could fill out here, we’re not going to be talking about those features ‘til later on in the course, so we’re going to leave these as the default and we’re going to select create. Okay, now if we look at the instances list, we can see our new instance is there. Let’s use the command line interface so that we can describe the instance on a command line and you can see what it looks like to interact with it through the SDK.</p>
<p>So we’ll use the gcloud compute command and we’ll use the describe instances subcommand. And we get back all of this info. Now, this is the same basic info that you’d see if you were to interact with a rest API, the SDK is just using the rest API on our behalf. Now you can probably imagine the potential here from programmatically creating instances and returning data about them, or maybe programmatically identifying instances that aren’t using a specific operating system that maybe you require for compliance reasons.</p>
<p>So we’ve just created a default Debian instance, which we could use for whatever we need. It’s just a standard instance, but there are times when maybe we want to run complex batch tasks. And things such as this tend to do well with more computing power, and so Google offers what they call a pre-emptible instance. These are virtual machine instances that are less expensive and they run for a maximum of 24 hours. And the catch is that if the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud platform</a> needs the resources back from these instances, they can terminate them without notice. Because of all this, we’re able to use shutdown scripts to gracefully close out of any running tasks that we had. Now again, this isn’t going to be suitable for all workload types, however, batch processing typically will stay running as long as we have the batch controller up and running. So in this case, pre-emptible instances will allow us extra less-expensive horsepower.</p>
<p>Okay, once we have an instance such as our Debian instance, we’re going to need to connect into it. To connect to a Linux VM, we can use SSH. To connect to a Windows VM, we use RDP. For SSH, the simplest method is to connect via the gcloud command because gcloud will automatically handle the SSH keys, though it’s also possible to generate SSH keys on our own that we can use with other tools.</p>
<p>Before we connect in, we need to make sure we have port 22 open, and the default network will create a firewall rule automatically for us that opens that port up. Once the port’s open, we can connect in. If we’re either an editor or an owner, as a role for that project, we can use the gcloud compute SSH command and it will copy down the keys required to connect in without any effort on our part. Non-project members will need to use an SSH client other than the gcloud compute command because they won’t have access to pull down those keys.</p>
<p>Let’s connect into our instance. We’ll run the gcloud compute SSH command and it needs to know the instance name and the zone. Okay, now once it connects in, we get our command-line interface that we’re used to when connecting in via SSH. Again, because I’m an owner of this project, I can easily this gcloud compute command to connect in, but if you weren’t, you would need to generate the keys yourself and use just the standard SSH command.</p>
<p>Okay, so imagine we’ve created our instance, we connect in, and we’re setting things up and we’re finding that the servers that we’re expecting to see just aren’t on that network. What happens is, we look around and find out that we’re in the wrong zone. And sometimes this happens, so when that happens, we have a few methods for moving an instance to another zone. We can use the gcloud command, calling the gcloud compute instances move command, and that’s going to allow us to move an instance to a new zone. And since the gcloud commands are based on the REST API, then that means we could also use the API directly and optionally, we could take a snapshot of the disk and then use that to start up a new instance in the correct zone.</p>
<p>Once we have an instance or instances up and running, we’ll end up needing to stop them at some point. And that’s made simple again with the REST API, the gcloud command, or through the console. And we can also use the shutdown command from inside of the operating system. However there are issues with shutting down this way if you have a local SSD attached. So if you’re planning on using the local SSD, make sure you look into the limitations first.</p>
<p>Now, between our startup process and the shutdown process, there are a few different statuses or states that an instance could be in. An instance has the provisioning state where resources are reserved for the instance, and then the instance moves into the staging status, where resources are acquired and the instance is being prepared and after that, we’re in the status that we call running, and this just means that the VM instance is running. However, it doesn’t mean that the operate system has fully booted, it just means that the instance has started up. And then if we shut down our instance or there’s some sort of failure, we enter the stopping status. And then once it’s completely stopped, we change to the terminated status, which sounds ominous, but terminated doesn’t mean it’s completely gone, what it means is it’s just shut down until we start it up again.</p>
<p>Okay, now that we know about instances and we know about how to start one up, how to shut one down, let’s talk about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/networking-2/">networking</a> and that’s going to be the subject of our next lesson so if you’re ready to learn more about how Google Cloud platform handles networking, then let’s get started with the next lesson.</p>
<h1 id="Networking"><a href="#Networking" class="headerlink" title="Networking"></a>Networking</h1><p>Welcome back. In this lesson, we’ll talk about networking on the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a>. We’ll start with a high-level overview of network fundamentals, and then we’ll move on to cover firewall rules. We’ll talk about network management, and finally, we’ll take a look at how to connect to instances without an external IP address. </p>
<p>So we have a lot to cover in this lesson, and let’s start off by talking about network fundamentals. Networks on Google Cloud Platform are a global resource, which means they’re visible to all of the resources in our project. There are three supported protocols, TCP, UDP and ICMP, and for most applications, this will probably be all we need. </p>
<p>Also, they only support IPv4 at the moment. Every VM instance that we create belongs to a network. Now, you may be thinking back to when we created that Debian instance and you’re trying to recall when we selected a network. In that example, we didn’t explicitly select a network. By default every project that has the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/compute-engine-instances/">compute engine</a> API enabled has a Google-created network, and if we don’t specify a network for our instances that Google-created default is used. </p>
<p>The networks for the Google Cloud Platform have evolved over time so we have two different types of networks currently. We have the Legacy networks which use globally allocated IP addresses and then we have the newer and recommended subnetworks, which regionally control the IP addresses available for instances in that subnet. </p>
<p>So if subnetworks are the recommended way of doing things what are the benefits? Here are just a few. First, subnetworks allow you to regionally segment the networks IP address space into prefixes, and control which prefix an instance’s internal IP address is allocated from. Also, when using a VPN, subnetworks allow you to target VPN tunnels to a particular region. And this allows you additional control over how VPN routes are configured. </p>
<p>This also results in lower latency in cases where the VPN would previously have assumed the IP address range span across all regions. Another benefit, the overall network IP address space doesn’t have to be determined when you first create the project. And that’s just three of the many benefits. Subnetworks are going to allow for more control and for breaking out environments in a more defined way. </p>
<p>When we use subnetworks, we have two options for assigning an IP address range. We can use the Auto Subnetwork networks or the Custom Subnet networks. And once we’ve selected which type we want for a given subnet network we can’t change it. The automatic will select the IP address prefixes automatically and the custom will allow you to select any private IP address range that you want. </p>
<p>So, with the subnetworks, we can create regional networks each with their own IP address prefix. Now once we have instances up and running, and even instances across different subnets, we’ll need a way to control the flow of packets within our network. And that’s what routes provide. With routes, we can specify where packets that are addressed to a specific range should be directed to. </p>
<p>Routes will allow us to very easily to control the flow of outgoing traffic from instances, allowing us to route everything through a proxy if we wanted to or somewhere else. For the most part, the default routes will handle our outgoing traffic. So unless we need something more advanced we really won’t need to create new routes. </p>
<p>Okay, so once we have instances and networks we’ll need to start thinking about securing the perimeter. Firewall rules are global resources, and they enable us to allow or deny incoming or outgoing traffic on our network, which include three open ports one for ICMP, one for SSH, and one for RDP. And it also allows traffic between instances to flow unrestricted. </p>
<p>Next up, let’s shift gears and talk about identifying instances by hostname or IP address. Each instance has a Metadata server that will act as a DNS server. </p>
<p>The Metadata server is something that we will be talking about in depth in a later lesson. For now just now that it stores the DNS entries for all network IP addresses on the local network and calls Google’s Public DNS server for entries outside of the network. If you want to communicate between servers using the fully qualified domain name it follows the pattern of Hostname.c.projectid.internal. Now the side using the fully qualified domain name we also have an internal and external IP address. Internal IP addresses can either be ephemeral which means they don’t stick around after they are no longer needed or they can be set up by a user when the instance is created. </p>
<p>When instances talk to each on the network they use the internal IP address. External IP addresses are used for addressing the instance from outside of the network. They can be reserved as a static IP address or can be created beforehand and attached to instances as well as being ephemeral. </p>
<p>Alright, by this point we know a bit about networking on the Google Cloud Platform. We know about Networks and Subnetworks and we talked about routes and firewall rules. And we just talked about hostnames and internal and external IP addresses. Now let’s talk a bit about how to manage that. It starts with enabling the Compute Engine API and doing that will create the default Automatic Subnet Network and the firewall rules associated with it for allowing ICMP, SSH, and RDP traffic as well as internal network traffic. </p>
<p>Once that’s enabled you can create additional subnet networks up to the quota limit and you can also delete subnet networks except for the last one. There needs to be at least one at all times. And you can also create firewall rules and routes which like subnet networks are subject to quota limits. </p>
<p>At a certain point you may end up with a lot of firewall rules and to help make management easier you can use tags. Now, this is a great feature. You can assign tags to a firewall rule and you can assign them to virtual machine instances and that enables us to have our firewall rules apply to any instances that are tagged with the same tags used for firewall rules. </p>
<p>Here’s an example. Imagine you have an instance running an FTP server so you need port 21 open. You could create a tag and you can name it whatever you want however in our example we’ll name it FTP Server. Now if you create a rule that opens up port 21, then you can tag that rule with the same value of FTP Server. </p>
<p>And because the instance and the rule share the same tag, that rule is gonna apply to that instance. And if we create a new instance or new instances then all we need to do to open up Port 21 is apply that tag. So, while we’re talking about Firewall rules it’s worth pointing out, they’re not just limited to a single port. </p>
<p>Firewall rules allow us to filter traffic to a single network and we can specify IP addresses as well as the ports we want to filter for that single rule. OK. In a previous lesson, we created a Linux VM we connected to via SSH. Now, that worked because we had an external IP address and we had firewall rules that opened up port 22. </p>
<p>If you only have the one instance then this works out just fine. However, if you have multiple instances, and even multiple networks, this is no longer optimal because you don’t want to expose all of your instances to the outside world if it’s really not required. This is a common scenario. So, there are options to allow us to connect into our instances without external IP address for those instances. </p>
<p>The first option is to create a bastion. And this serves as a gateway allowing us to connect into it via SSH and then from there, we can kind of springboard to the other servers we want to connect to, and this works because we give that bastion host an external IP address and we open up port 22 to it. </p>
<p>This workflow requires that we keep that bastion host hardened from the outside so that it’s secure. Though, it is a good solution when we have cloud-native infrastructure. Now what I mean by that is if we already have a company network, then using a site to site VPN makes more sense. It would allow us to connect a company network to the cloud network. So, a site to site VPN is our second option. </p>
<p>The third option is a NAT gateway. If an instance doesn’t have an external IP address, it can’t communicate with anything outside its network. So what a NAT gateway does is allow traffic from those instances to flow through it. Allowing traffic from the instances on the network to communicate with the outside world through it. </p>
<p>This option requires a fair bit of setup and the NAT gateway becomes a single point of failure. However, it’s an option that may work in some cases. And the final option for connecting to an instance is via the Serial Console. This option allows us to use the web Console, the GCloud command-line, or the SSH client to connect to an instance via its serial port. </p>
<p>Using this does require that we enable the feature with a metadata key-value setting. However, should you need to connect to a single instance for troubleshooting those one-off issues, this could be useful. </p>
<p>Alright, that’s gonna wrap up this lesson. In our next lesson, we’re going to cover <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/disks-and-images/">Disks and Images</a>. So, if you’re ready to keep going, then let’s get started with the next lesson.</p>
<h1 id="Disks-and-Images"><a href="#Disks-and-Images" class="headerlink" title="Disks and Images"></a>Disks and Images</h1><p>Welcome back. In this lesson we’ll be talking about persistent disks, SSDs, RAM disks, boot disks, and virtual machine images. Let’s jump right into it.</p>
<p>Persistent disks are important because they allow us to store the operating system and&#x2F;or any persistent data that we’ll need to run our server and applications. Persistent disks are zone based resources and they are encrypted by default. Each instance can have a maximum of 16 persistent disks and up to 64 terabytes of storage. And while typically disks would be attached to a single instance, it is possible to attach one to multiple instances in read only mode and that’s kind of cool.</p>
<p>Let’s head in to the console and check out how to actually create a new disk. So we start on the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/compute-engine-instances/">compute engine</a> page and we click on the disks section on the left-hand side navigation and it starts with a name. And we’re going to call ours app-disk. We’ll skip the optional description. We don’t need it for this demo. And then let’s select a zone. We’re going to leave the disk as a standard disk though we could use it as a SSD, but again for a demo that’s not really needed. Then let’s pick an image. We don’t have any snapshots so we can’t select that anyway. Let’s use a ubuntu image. Okay, we need a size. That 10 gigs by default is going to be fine. Then we’ll also leave the encryption set to automatic. Now the other option’s for customer supplied where the customer can supply their own encryption key. The abilities to use your own encryption keys are going to be important for some companies for compliance reason, however, having <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google</a> automatically manage and rotate the keys is pretty valuable so I’m going to leave this by default. Okay and now we’re going to create it and it’ll take just a second. Okay there it is.</p>
<p>The question is what did we just do? We just created a boot disk that we can use for new instances. If we create an instance and we use this disk as its boot disk it’s going to have ubuntu 1604 and it’s going to be up and running with 10 gigs of space.</p>
<p>Okay. We’ll get back to taking about disks and images, however, I want to take a quick detour and I want to talk about Solid State Drives which are abbreviated SSD. Sometimes you’re going to need higher IOPS than the standard disks provide. IOPS stands for Input Output Operations per Second. So for this we can use SSDs. If you find that solid state drives aren’t enough random IOPS and there’s also an option for local SSDs.</p>
<p>Now local SSDs are physically attached to the server that hosts your virtual machine instance. Local SSDs have higher throughput and lower latency than standard persistent disks and SSDs. Though the data that you store on local SSDs persist only until you stop or delete the instance. They offer sub-millisecond latency with up to 680,000 read IOPS and up to 360,000 write IOPS. Local SSDs will be great when you need to do some caching operations and you don’t want to use the system memory.</p>
<p>So if local SSDs aren’t fast enough for you then there’s always RAM disks. They’re extremely fast, however, they’re not persistent. So as soon as you reboot or shut down, anything that you have in that disk is going to be lost.</p>
<p>So if we look at the disk types in this comparison we can see that both standard and SSD disks offer all of the functionalities such as snapshotting, and as you know the SSD are great for random IOPS. And then when we move to the local SSDs and the RAM disks we lose most of the features in favor of speed. So you need to consider these trade offs when selecting which type you want to use and for which type of applications you want to use them for.</p>
<p>Okay. Let’s jump back to talking about disks and images. Do you recall when we created that persistent disk we had to select an image? We touched on it previously, but what exactly is that image? That was an operating system image and what that means is it was the disk with a boot loader and operating system and a block device containing our file system. The specific image we used was for an ubuntu image and it came from the public images that Google provides, though if we had our own image we could also use that to create instances and it would be considered a private image because it’s only accessible to our projects. We can create an instance based off of any images that we have access to, public or private.</p>
<p>Let’s check out how to actually create an instance on the command line. Okay, so here’s what we’ll do, we’ll use the gcloud command to create and instance so we’ll use the compute instances create subcommand and we just need to pass them the name of our image, and it’s going to take a moment to run. Okay. Now that it’s done we’ve created an actual instance. It’s up and running. We can connect to it and use it as we need to and if we look in the console we’re going to see that this same image exists and there it is. We can create instances with the console just as easily as we can create them on the command line.</p>
<p>Here’s a few other options we can use when creating instances. Now we can create an instance from an image within the project and we’ve seen that, from an image in an alternate project, from a URI for a tar file that’s hosted on cloud storage. We could use an alias for the latest version of an image, and finally we have the option of specifying a specific version of an image. So we have a few different methods that we can choose from when selecting the images that we want to use for our instances.</p>
<p>Now we can also create our own images. If we need to create an image, we can create it based on a running instance. We’d use an existing base, as our example unbuntu, and then install whatever we need to before we delete the instance and use the keep disk option and that’ll leave us with a boot disk image. There’s also documentation to create something from scratch if we don’t want to use one of the existing images.</p>
<p>Images are used for things such as a bootable “gold master” image for deployment, an image with standard tools for the development teams, an image with approved production software and libraries, or even a foundation for cluster deployments. And so having images with everything we need loaded on there is incredibly valuable, however, there are alternatives to doing it this way.</p>
<p>We could configure instances at boot time with start up scripts. And start up scripts are something we’re going to cover later in the course. We can configure with provisioning tools such as Ansible, Chef, and Puppet. We could use docker and container images. So we have options for how we would get our images production ready and due to the effort involved in setting up custom images as golden images I tend to recommend some sort of boot time configuration. Now that depends on the circumstances because sometimes you’re going to have a boot time configuration that adds too much boot time and so it’s going to slow down the actual process of getting that instance into the load balancer and if you’re seeing heavy traffic that might be a blocker. However, if your traffic increases fairly evenly then boot time configuration will allow you to get everything installed and configured on startup. And that’ll make it more flexible to implement changes because once our configuration management code has been tested and deployed we can easily run it against the targets of our choosing.</p>
<p>Okay, let’s wrap up this lesson by summarizing what we’ve covered so far. We talked about persistent disks and different disk types. We talked about standard hard disk drives and how they support things such as snapshots and encryption, however it won’t be as fast as solid state drives or random IOPS. We talked about local and RAM disks which are very fast, however, don’t support things such as snapshots. And we talked about how to create and use disk images that can be used as a base image. And then we wrapped up the discussion by talking about methods that would allow us to use a standard image and configure it at boot time.</p>
<p>Okay, in our next lesson we’re going to talk about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/authorization-and-iam/">authorization and IAM</a>. If you’re ready to keep going then let’s get started with the next lesson.</p>
<h1 id="Authorization-and-IAM"><a href="#Authorization-and-IAM" class="headerlink" title="Authorization and IAM"></a>Authorization and IAM</h1><p>Welcome back. In this lesson we’ll cover authorization as well as identity and access management. Since we’re talking about authentication and authorization we’ll start with talking about how to get a user authenticated and then once they are authenticated, how do we make sure they only access the things that they’re allowed to.</p>
<p>And then, let’s jump into talking about a special type of account which is the server-to-server communication mechanism called Service Accounts. Okay, let’s dive into getting users authenticated. Imagine you’re in charge of managing the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a> for your company. You’ve just signed up and you need to get people access to the system.</p>
<p>You’ve probably noticed that in the console you can invite users that have a Google account. Now, this is perfect, it manages a couple of users. You can add the user, set up their roles and then you’re on to other things. However, let’s imagine that you have two hundred users. So, sending two hundred requests via the user’s personal gmail account is not going to be the best option here.</p>
<p>So, this is where using G Suite, which was formerly called Google Apps for Work, will be ideal. It has session activity tracking, security alerts, suspicious activity detection and more. And, this will allow you to manage all of the users in one place. However, if you have two hundred users then, you probably already have an LDAP server which is why Google provides a tool called GCDS, which stands for Google Cloud Directory Sync, and it’s a one way sync that allows you to sync users from your existing LDAP server to G Suite.</p>
<p>And, this allows you to sync users pretty easily. Again, it’s one way syncing, so changing something in G Suite isn’t going to change in your existing directory. It’ll also allow you to apply roles to the mapping of things like users and groups. It works by running as a utility in your environment. Okay so, things are starting to shape up.</p>
<p>You don’t need to manually import two hundred users and you’ll be able to continue managing your users via your existing LDAP server, which is awesome. Remember your initial task was to get your users access to the services inside of the Google Cloud Platform that they need. And, with G Suite and the directory sync, you’ve done that, however we haven’t talked about single sign on just yet.</p>
<p>Importing users is great and with single sign on it’s even better. If you have your own authentication system you can use SAML for single sign on. The configuration is simple. You fill out three URLs, you upload your certificate and Google will do the rest. The user name is the only assertion that’s used which makes it a pretty lightweight and easy to use setup.</p>
<p>Okay, now you’re done. Your task was to get users set up with accounts inside of the Google Cloud Platform and with the use of G Suite, GCDS to sync from your LDAP server to Google and with single sign on with SAML, you have an authentication setup based on your existing infrastructure. Now, once we have users we need to be able to make sure that we can lock things down so that they only access the things they’re allowed to.</p>
<p>And, for that we can use Identity and Access Management, which we typically abbreviate IAM. IAM allows you to have two types of roles. There’s Primitive Roles and Predefined Roles. Primitive roles are project based roles and there’s only a handful. We have owner, editor and viewer. And, using primitive roles you can set fairly simple project based permissions.</p>
<p>Owners can add and remove users from a project and they can basically do just about anything they want with a specific project. Editors are a bit more restricted. They can deploy applications, modify code and configure services and things like this. They have a lot of power so anyone with an editor role is basically what we would consider an admin.</p>
<p>The viewer role, as the name suggests, is a bit more restricted than the editor. It’s just a view only access into the console. Now, these primitive roles can be great for small teams, however in our example earlier, we had a two hundred employee company and these roles are either going to be too restrictive or too permissive.</p>
<p>So, that’s what Predefined Roles solve. They allow us much more granular roles. The Predefined Roles are a collection of common permissions related to a specific resource. As an example, the instance admin role allows a user to administer the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/compute-engine-instances/">compute engine instance</a> and it’s basically a combination of permissions for get, list, delete, start, stop, et cetera.</p>
<p>So, there are a lot of predefined roles that are geared towards common tasks like this. So, using these granular roles it’ll make sure that users only have access to what they need. The Google Cloud Platform has a resource hierarchy and it starts with an organization and then it goes down to the project level, and then the resources that are inside of that project.</p>
<p>And, this hierarchy impacts permissions. For example, if you set the user as an editor for a project and you have them set as a view only role for something like logs, then the editor role at the parent level takes priority and they’re going to be an editor for the logs. So, it’s best practice to start with the least amount of permissions for a given user and increase it at the granular level.</p>
<p>Also, you’re going to want to use groups whenever you can. It simplifies policy changes. Along the same lines, make sure you control who can make policy changes and you’ll probably want to audit any changes. Alright, so we’ve talked about getting users into the system and authorizing them which is great, however sometimes you need to have an application running under a specific set of credentials and that’s what we use service accounts for.</p>
<p>Service accounts authenticate applications running on your virtual machine instances to other Google Cloud Platform services. As an example, if you have an application that uses Cloud Storage, it first needs to authenticate to the Cloud Storage API. If you have a service account that has permissions to read and write files using the Google Cloud Storage API, then you could use that account in your application code to read and write files on Cloud Storage and doing it this way you don’t need to pass credentials around.</p>
<p>There are three types of service accounts available to compute engine instances. We have user managed service accounts, built-in service accounts and the Google API service accounts. The user managed accounts allow you to create your own service accounts and then set the roles that you want it to have and this is going to allow you to break down the service accounts based on the very granular roles that you need.</p>
<p>The built-in accounts are Google created. There’s one for compute engine and there’s one for app engine. The compute engine default service account is created on a per project basis and it’s going to have its own unique email address for each project. And, it’s the default service account for new instances.</p>
<p>And, these built-in service accounts, by default, have editor permissions. However, you can change that if you want to and even use the curated roles if you need. Okay, and the one final type is the Google API service account. You may have noticed that this doesn’t show up in the list of other service accounts and that’s to prevent people from editing the permissions and breaking functionality for things such as auto scaling.</p>
<p>This is also an editor role by default and while you could change it, you probably shouldn’t. Service accounts work by using encryption keys and the built-in service accounts will have their keys automatically managed by Google which means that Google will rotate the keys as a security measure, however, you can also do it manually should you choose to.</p>
<p>Okay, if you’re going to use the service accounts that you created then you can use the IAM permissions to set just the roles you want. However, if you are going to use the default service account as an instances service account then, you may want to limit the accounts access with scopes. Access scopes are a way to determine what APIs the service account can interact with and more specifically, which actions it can execute for a given API.</p>
<p>Let’s check it out in the console. If we start to create a new instance and then we scroll down to the service account we can see the options for access scopes and if we select this option here to set the scopes for each API you can see that we have a list of several different services that we have enabled for this project.</p>
<p>And, each has the ability to edit the options. Here’s what you need to remember. Whatever scopes that we set here aren’t going to be changeable unless we recreate the instance. Okay so, service accounts allow us to interact with the Google APIs from our code and run under whatever permissions this service account has.</p>
<p>And, this is a great way to avoid hard coding credentials in our application. Alright, let’s wrap up here. In our next lesson we’re going to be talking about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/snapshots-1/">Disk Snapshots</a>. So, if you’re ready to keep learning then let’s dive in with our next lesson.</p>
<h1 id="Snapshots"><a href="#Snapshots" class="headerlink" title="Snapshots"></a>Snapshots</h1><p>Welcome back, in this lesson, we’re going to talk about disk snapshots. This is going to be a fairly quick lesson. Snapshots are a very useful tool; however, there really isn’t that much to say about them. Let’s start with what are snapshots? Snapshots are going to allow you to create a copy of a disk, and that can be either a hard disk drive or a solid state drive, and store just the data that exists.</p>
<p>What I mean by that is that if you have a disk with 100 gigabytes of space allocated, but it’s only using 10 gigabytes of space, then the snapshot will be for 10 gigabytes. Because you can snapshot a running instance, you’ll be able to create a point in time back up. Snapshots are considered differential, which means subsequent snapshots will only store the changes between that moment and the previous snapshot.</p>
<p>This is great for backups because we don’t need to store the full amount for each snapshot. The snapshots you create are considered a global resource, which means that you’ll be able to use them in any zone, regardless of which zone it was created in. Though, they are confined to the project that they are created in.</p>
<p>Besides disk backups, commonly used cases for snapshots include things such as migrating data between zones and swapping disk types, for example, between a standard hard disk and a solid state drive. Here are some things to keep in mind. Snapshots are data only. They don’t store any information about machine types or its tags, and you can’t move data to a local SSD with snapshots.</p>
<p>Okay, so how would you go about actually creating a snapshot? Well, first you’ll want to either unmount the disk in question or prevent writes to it, and the reason is, so that we don’t end up with the data being in an inconsistent state. So assuming the use of a Linux operating system, you can run the umount command, and this is going to ensure that no new writes happen while you’re creating the snapshot.</p>
<p>If you’re snapshotting a boot disk, then it’s best practice to shut down the server. Again, it’s to ensure that we don’t end up with inconsistent data. Now if you can’t unmount the disk for some reason, then the next best option is to use the sync command to flush any pending writes to disk, and then use the fsfreeze command to halt any writes to the disk until we’re done with the snapshot process.</p>
<p>Afterwards, the -u flag can be passed into the fsfreeze command to unfreeze the disk. Okay, like I mentioned at the start, this is going to be a quick lesson. Snapshots are very powerful; however, not complex enough to go in any more detail on it. So, in our next lesson, we’re going to talk about cloud storage.</p>
<p>Alright, so if you’re ready, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/cloud-storage-1/">let’s get started</a>.</p>
<h1 id="Cloud-Storage"><a href="#Cloud-Storage" class="headerlink" title="Cloud Storage"></a>Cloud Storage</h1><p>Welcome back. In this lesson, we’ll talk about Cloud Storage. We’ll recap the basics and then we’ll talk about how to access Buckets and Objects and we’ll wrap up by talking about Security.</p>
<p>By default, Cloud Storage encrypts our data both at rest and in flight and and the way Google Storage is set up allows us to store data using the same service and same APIs, but with different access pricing.</p>
<p>There are three options for where your data gets stored. To maximize an application’s performance, you can choose to store your data in the same region as the services that are going to consume that data. Even though it’s only stored in one region, it still does have a fairly high level of availability because it’s replicated across multiple zones in that region.</p>
<p>If you wanna have the same performance benefits, but you also wanna increase your data’s availability, you can choose the dual region option and that will give you geo-redundancy. </p>
<p>Now finally there’s the multi-region option which is the best way to make your data available around the world with very low latency and it’s great for using with website content distribution, video streaming and those sorts of things. </p>
<p>If you wanna learn more about cloud storage basics, I recommend you check out the documentation. Check it out at cloud.google.com&#x2F;storage&#x2F;docs.</p>
<p>Okay. Let’s shoot from the overview to actually accessing and interacting with Cloud Storage. Like most everything else, you can use the Console, the REST API, or the SDK. If you need to do something that’s simple, such as creating a Bucket or uploading a file, then the Console is great. If you need to do something programmatically, then you’ll want to use the REST API. You’ll be able to use the JSON or XML APIs, though the XML option only supports a limited subset of what the JSON API allows.</p>
<p>And if you want to use the Command line, you can use the gsutil command, which offers commands that will be similar to the UNIX file manipulation commands. These are commands such as mv, rm, cp, and rsync, as well as a few others that handle things like access control and removing Buckets.</p>
<p>And recently, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google</a> released the beta version of Cloud tools for PowerShell. This is cool because we can mount Storage as a drive, allowing us to use standard commands such as dir, to interact with Cloud Storage. And just like the gsutil command, we can use the PowerShell command list to edit the Access control list.</p>
<p>So, speaking of Access control lists, this leads us to our next topic. Access control lists allow us to determine who can access Buckets and Objects. And Access control lists consists of a scope or grantee, and a set of permissions. In plain English, a list of people and what they’re allowed to do. Each Bucket or Object can have up to 100 Access control list entries.</p>
<p>The allowed permissions are Read, Write, and Full Permission. Full Permission means that the user or users can read, write, and delete. Write access, as the name implies, means they can write, but it also means that they can read. And Read, well, it means that they can read.</p>
<p>To make it easier, Google has created predefined Access control lists for some of the most common operations, and these are things such as Public Read, which allows anyone to read the file, and that’s useful for static assets of a website. Here are some of the supported roles for setting up permissions. Now, we’re not going to go through them all, however, if you want to check them out, I recommend that you pause and kind of skim through the list.</p>
<p>Even with all of these Access controls, sometimes you’ll want to allow a random Internet user to be able to upload a file. Maybe it’s for something such as uploading an image to your site, or something similar. Now, yes, you can handle this in code if you have your application process the file and write it to Cloud Storage. However, if you allow users to upload directly to Cloud Storage, then it’s going to save your servers from needing to handle it. So, Cloud Storage offers what’s called a Signed URL, which is a time-limited URL that anyone that has access to that specific URL can use to invoke whatever operations you’ve allowed when you created that URL. Here’s a basic example of a Signed URL that allows a get request for a limited amount of time. This will allow anyone with that URL to read that object until the token expires.</p>
<p>Okay, that’s going to wrap up our topic of Cloud Storage. We’ve covered most of this in the Fundamentals, so again, this was just a recap.</p>
<p>In our next lesson, let’s cover <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/instance-groups/">Instance Groups</a>. So, if you’re ready to keep going, then let’s get started with the next lesson.</p>
<h1 id="Instance-Groups"><a href="#Instance-Groups" class="headerlink" title="Instance Groups"></a>Instance Groups</h1><p>Welcome back. In this lesson we’ll be covering instance groups. We’ll do an overview, and then we’ll talk about the use cases, and then we’ll wrap up with some examples.</p>
<p>Let’s start with, what are instance groups? As the name suggests, instance groups are about creating a grouping of instances. And once we have a group, we can monitor all of the servers in that group, or we could reboot them all at the same time, and we can do other similar tasks like this. And we can do that with two different types of groups. We have managed and unmanaged groups.</p>
<p>Unmanaged groups are pretty simple. The concept is that you can take instances that already exist and add them together into an unmanaged group and then you can do some simple admin tasks. Those are things such as rebooting, you can monitor, et cetera. And that’s about it. They’re designed to make it easier to manage existing infrastructures.</p>
<p>Managed groups, on the other hand, are the Google recommended form of instance groups. And the reason is that they have a lot more functionality than the simple administration that they share with unmanaged groups. With managed groups, we don’t need to manually add instances, hence the managed part of the name.</p>
<p>Let’s cover some of the features that managed groups offer and then we’ll dive into how they actually work. Managed groups will ensure that the instances in that group are all running. And we can resize the group as needed, which means if we want to add 10 new instances, we can do that rather easily by increasing the minimum number of instances and they’re going to be automatically added. Managed groups also make autoscaling possible because we can use metrics to determine if we need to add or remove instances. By the way, we’ll cover autoscaling in a later lesson.</p>
<p>Now, you may be wondering how managed groups are able to automatically add instances. How do they know which instances to add? Managed groups require that you specify an instance template which allows you to define the machine type, image, zone, and other instance properties for the instances that will be created. An instance template is basically all of the info you’d supply if you were to create an instance, however it doesn’t actually create it at that time, it just saves those settings for you. And that includes things such as startup scripts.</p>
<p>Let’s check out how to create an instance template and a managed group. We start out on the instance template page, and click create. And this page will look familiar. It’s the same form we use when creating an instance. We’ll give our template a name. Since this will be a template for a web application, I’m going to call it webapp-template. And now, let’s change the machine type. We’ll use a small for this demo, since we really aren’t expecting any traffic. And let’s change the boot disk to use Ubuntu 16.04 LTS. That’s just the preference I have. Notice there are a lot of other options here.</p>
<p>Under identity and access, I’m going to change the scope to full scope. I don’t recommend this for production systems, this could end up being a security nightmare if just one server is compromised, because the attacker could use all of the APIs that <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud</a> has to offer with no restrictions. And you can imagine the implication of that. I’m using it here to make it easier to interact with some of the different APIs from my startup script, but again this is just for a demo.</p>
<p>Now, I’m going to select allow HTTP and HTTPS and that will automatically apply some tags to allow the traffic to flow through the firewall. And I want to actually provision the instance on startup, so I’m going to add a startup script. We’ll be covering startup scripts in a later lesson, so I’m not going to go in depth now. So we’ll just click on the management link here and we’ll paste in our startup script. There we go.</p>
<p>Now let’s take a moment. I just want to briefly show you what’s going on with this startup script in the code editor. This is a pretty vanilla Bash script, and what it’s doing is, it’s going to fetch the project ID from the metadata server and then it grabs the latest code from the web app Cloud repo, and inside that repo is a shell script to build the application. In this example, I’m building the code out on the web server directly. This isn’t something you’d do in production. You’d use a build server and you’d run your code through the complete continuous delivery pipeline. However, again this is just an example so I’m just going to build it on the server.</p>
<p>So if you look at that script, we see that it installed some dependencies; it installed some logging code, and then it’s going to deploy our actual .net application behind engine X.</p>
<p>Okay, let’s go back to the Google Cloud console, and since everything looks good with the rest of the default, we’re going to create this. Now, to use this, we need to create a group. So we’ll click on the instance groups and fill out the form. Like everything else, it’s going to need a name, and we’re going to skip the optional description, however, you should use this in your environments to clearly define what the group is for. We’ll leave it as a single zone, however if you need high availability, you could use multi-zone. I’ll use east1-d just to stay consistent with the rest of the services that I have running.</p>
<p>And then, in this section here, for the create method, this is where we’d select managed or unmanaged. Now notice that isn’t what it’s called on the form. The term Google uses here are use instance template or select existing. So, we know that managed groups use instance templates so we’re going to use the “use instance template” option. And it wants us to select our template, we only have the one, so it’s a really easy decision here. And we can also enable autoscaling. For this demo, I’m not going to show how to use that, that’s something we’re going to cover in a later course, so I’ll save that.</p>
<p>Now let’s create this group. It’ll take a few minutes, and let’s just jump to the end. And there we go, it’s complete and we can click into it and we can see that it has one running instance. And if we browse to the IP address for that instance, we can see that our web application is actually running.</p>
<p>Okay, so creating these is fairly easy, and we’ll expand on managed groups in a later lesson when we cover autoscaling which means that’s going to wrap up this lesson.</p>
<p>In our next lesson, we’ll look at <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/cloud-sql/">Cloud SQL</a>. So, if you’re ready to keep learning, then let’s get started with the next lesson.</p>
<h1 id="Cloud-SQL"><a href="#Cloud-SQL" class="headerlink" title="Cloud SQL"></a>Cloud SQL</h1><p>Welcome back. In this lesson we’ll talk about Cloud SQL. We’ll start with an overview, and we’ll follow it up with administration. And then we’ll compare the difference between Cloud SQL and MySQL. And we’ll talk about how to connect to SQL instances from <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/compute-engine-instances/">Compute Engine</a>.</p>
<p>Cloud SQL is a Google-managed version of MySQL. It allows us all the benefits of using MySQL databases without having to deal with the time-consuming management tasks or security patches. Like most systems in the cloud, Cloud SQL needs to be scalable. And so it offers vertical scaling for reads and writes, and horizontal scaling for reads.</p>
<p>Cloud SQL has evolved since its first release, and so now we have two versions. We have the first and second generations. The first generation had some limits on the size, and that didn’t work for a lot of applications, so the second generation changed that. The second generation offers more storage, higher performance, and lower cost in most cases. The rough numbers suggest that the second generation has something like seven times the throughput and 20 times the storage capacity.</p>
<p>I mentioned a few times that Cloud SQL is a Google-managed version of SQL, but what does Google actually manage? That would be stuff such as patches and updates to MySQL, daily backups, cross-zone replication, allowing for higher durability, that means that should the primary zone become unavailable, the secondary zone will automatically take over and start handling requests. And Google will also handle instance pausing. This is a feature of the first generation instances, and one that you can optionally disable. It allows you to have the instance stopped if there are no requests for a period of time. This can make running the databases less expensive, though the second generation instances offer a sustained-use discount which should compensate.</p>
<p>So, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google</a> will manage a lot of the time-consuming stuff for us, however there are still things that we’ll need to manage. That’s things such as user management, which covers creating users, assigning permissions, and setting passwords; SSL configuration; data import and export; configuring external read replicas, which will increase our read performance. And then the typical SQL management tasks, such as schema migrations and schema management.</p>
<p>The first generation version of Cloud SQL has a limit of 500 gigabytes. The second generation also has limits, however those are related to the machine type that you use. Though even the smallest instance supports over 3,000 gigabytes of storage. Cloud SQL is basically just a managed version of MySQL. However, it doesn’t allow the use of any statement or function that allows for file access. So there are some differences there.</p>
<p>Let’s jump into the console and create a SQL instance, and then show how to connect to it. We’ll start on the Cloud SQL page. We don’t have any existing databases, so we start with the option to create an instance. And then it wants to know whether we’ll be using the first or second generation. We’ll use the second generation. It’s the better option in most all cases.</p>
<p>And now we’re presented with a form. We need to fill out the details here. We’ll need a name. And we’re going to leave it as MySQL version 5.7. I’m going to set the region, this is just the one that’s close to where I live. I’ll use the eastern region. And we also need to change the machine type. Since this is just a demo, I’ll use the small instance. We’ll leave the drive as an SSD for the higher IOPS. And we have some options for high availability. You can see that we can easily add a failover replica, which will add a read-only copy of our database that will be promoted to the primary database in case the current primary fails. By default the backup and logging are enabled. This is an automatic backup that’s kicked off for us. And the binary logging is used for replicating data to read-only copies. We’ll leave the rest as the defaults, and let’s just click on the Create button. Okay, it’s going to take a minute, so we’re going to fast-forward to when it’s complete.</p>
<p>And if we click into the instance we have a dashboard for viewing and editing the instance. On the Overview tab there’s some general info. And if we click the Access Control we can add networks that’ll be able to access the instance. For the sake of an easy demo, I’m just going to open this up to the world. And we can use the Backups tab to create manual backups, or change our backup window. And then we have a Replicas tab, and this is where we’d create read-only or failover replicas.</p>
<p>Okay, and back on the Overview page we have some quick links that show you how to connect to SQL from different places. All right, let’s actually try and connect. We’ll start with opening up Cloud Shell. And it’s just going to take a moment. Okay, there we are. We can now connect with any MySQL client. And this will work because we’ve opened it up to the world. So we’re going to paste in the password here. Great, and we’re connected. And now if we run Show Databases we can list off the databases that exist. And we just get the default databases back.</p>
<p>Now for connecting we can also use the gcloud command-line tool to connect. And it will add the instance to the SQL instances network whitelist. And that will allow us to connect without needing to first open up the ports. Once we’ve connected in with the gcloud command-line tool, it’s just a standard MySQL client. There’s really nothing else after that. Now after you have an instance up and running, it’s pretty much the same as any other MySQL instance. So there’s really not much else to say about it. So, that’s going to wrap up our lesson here.</p>
<p>In our next lesson, we’re going to cover <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/metadata/">metadata</a>. So if you’re ready to keep going then let’s get started with the next lesson.</p>
<h1 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h1><p>Welcome back. In this lesson, we’ll be talking about metadata. We’ll talk about the metadata server and how to get and set metadata.</p>
<p>Let’s start with a quick explanation of what metadata is in this context. Metadata is a set of key value pairs containing information related to running instances or our project. This can be stuff such as project-level settings. Maybe things like API keys for external services. And instance-level information are things such as tags or the zone that we’re running in or the hostname or whether the instance is pre-emptible or not.</p>
<p>So, as I mentioned, there are two types of metadata: instance and project. And they’re accessed through the same base URL. Now we have three URL options and they’re all going to direct you to the same place. There’s the full URL, that’s metadata.google.internal&#x2F;computeMetadata&#x2F;v1. There’s the short URL which is metadata&#x2F;computeMetadata&#x2F;v1. And then the final option is to use the IP address. And then, you’ll either append project or instance to the end of the URL to access the metadata specific to those topics.</p>
<p>Let’s look at how to actually get and set data. Like most everything else, we can use the API, the SDK or the console to get and set metadata. However, to get metadata from a compute engine instance, using these options would add extra steps that we just don’t need. From a running instance, all we need to do is call the URLs and add these specific values to the end of the URL. You could do it in code, or you could use a tool such as curl or Wget.</p>
<p>Let’s connect in to an instance that we have running and see how to use these. We’re connected via SSH to a compute engine instance. So, we’re going to use cURL and we can start getting data from the metadata server. If we start with the base URL, we have two options here. You can see we have instance and project. And these values are what we use to append to the end of the URL and this allows us to drill-down in to the different keys. So, if we append instance to the end of this, you can see we have some additional things that we can drill in to here.</p>
<p>Let’s check out tags. So, all we have to do is add tags to the end of the URL and you can see we get some tags back here. These ones allow us to have http and https traffic through the firewall. We can query for things such as the zone that we’re in. And, in this case, we’re in east1-d. And if we edit the URL, we can query for project-wide settings as well. We can see here that we have just two attributes. One is a Google-supplied and the other is a value that I’ve added. So, if we want to read the value for the dotnet environment, we’d append that string. And we can see that we have a value there.</p>
<p>Now, to change it, if we jump in to the console on the compute engine page, in to the metadata section, we can change that value. Let’s change it to staging. Okay, and then we’ll save it. Great, now, if we jump back in to the command line, we can refetch that and see if it says staging. So, there it is. It’s changed to staging. It’s a project-wide setting.</p>
<p>So, metadata will make our script more dynamic, because we don’t need to hard-code any values. And, we don’t need to know, at the time that we write our code, some of these values. For example, we don’t need to know the project ID because we can fetch it dynamically. And it’s not uncommon to use environment variables to store things such as API keys, connection strings, access tokens, etc. So, if we use project metadata for those sort of things, we can ensure that instances will have access to the data they need and have it in a centralized location for us to easily manage. Okay, that’s gonna wrap up this lesson.</p>
<p>In our next lesson, we’ll talk about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/startup-and-shutdown-scripts/">startup and shutdown scripts</a>. So, if you’re ready to keep going, then let’s get started.</p>
<h1 id="Startup-and-Shutdown-Scripts"><a href="#Startup-and-Shutdown-Scripts" class="headerlink" title="Startup and Shutdown Scripts"></a>Startup and Shutdown Scripts</h1><p>Welcome back. In this lesson, we’ll talk about startup and shutdown scripts. We’ll talk about what they are and how to us them.</p>
<p>We’ll begin with startup scripts, which are pretty well-described by their name. These are scripts that run when an instance is started. Started here means that any time the operating system is booted up, so that covers the initial creation of an instance as well as reboots. Startup scripts are used for things such as installing and configuring software, running operating system updates, enabling services, and other tasks along these lines.</p>
<p>When you create or edit an instance, you can add or change a startup script. Startup scripts are added as <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/metadata/">metadata</a>. Then we have options for where they’ll live. For example, if you want to store a startup script in a Cloud Storage bucket, then you can use the metadata key named “startup-script-url.” And assuming that the service account has access to it, it’ll pull the startup script from there. You could also upload the script from a local file as well as assign it to the startup script metadata key on the command line.</p>
<p>You can use startup scripts with Windows and Linux. Linux is going to use Bash scripts and if you run into any problems, you can check the logs located at &#x2F;var&#x2F;log&#x2F;startupscript.log.</p>
<p>Windows is a bit different. You can use a batch file or PowerShell script and if you want to store the script on Cloud Storage, it needs to be in a publicly accessible URL. Optionally, you can upload the script directly to metadata, just as you can with Linux. Although unlike Linux, Windows has different types of startup scripts. We have a pre-sysprep and a post-sysprep option and there are different keys that we use for each.</p>
<p>Let’s test this out with an Ubuntu VM. We’ll install an Apache web server and then we’re just going to write some contents to an index.html file. So we’ll go through the same VM process as usual. And there’s nothing special here, however the important thing is when we get to the metadata section where we can add our startup script. I already have this copied to my clipboard so I’m just going to paste this in and what this is going to do is install Apache and then it’s going to dump the contents here into the index.html, which will render on the page once we load it in the browser. So we’ll create the image and we’ll jump forward to once it’s complete. Great, now we’re back, we’re going to browse to this via the IP address. And there it is, it’s nothing fancy, however I’m sure you can imagine the possibilities for this.</p>
<p>Alright, here’s what we’re going to do, we’re going to stop the instance and then we’re going to make a change to the startup script, we’ll change the text that gets dumped into that index.html and then we’ll restart it so that you can see that this happens any time the instance is started. So we’ll edit the text and we’ll just add this line at the end here to restart Apache after this is all done. Okay, great. Now let’s jump forward to when this is started back up. And if we reload the browser, you can see that we have our new text in the paragraph. And there it is.</p>
<p>So those startup scripts are going to run anytime the machine is started, and you can use this for things such as installing a Chef client and that would allow you to have a newly-created instance provisioned by Chef. You can use it to run through a basic security checklist and ensure that all newly-added instances are locked down and if you’re using in the instance for batch processing, you could bootstrap whatever resources you need and have the instance register itself with the head note. Startup scripts are a simple but powerful part of compute engine.</p>
<p>Now, we also have shutdown scripts, which are similar to startup scripts. However, they run when an instance is shutdown, or more accurately, the shutdown script will be executed, however, if it runs for too long, it’s going to be terminated and then that instance is going to be shut down anyway. So shutdown scripts have no guarantee that they’ll complete. So try not to execute long-running processes inside of a shutdown script.</p>
<p>The shutdown script will be triggered by an instance being shut down due to an instances.delete request or instances.stop request to the API or when Compute Engine stops a pre-emptable instance as part of the pre-emptable stop process. Also, when an instance shuts down through a request to the guest operating system, such as sudo shutdown or sudo reboot. And also, when you shut down an instance manually through the console or SDK. Use cases for things like shutdown scripts include backing up logs, copying data to Cloud Storage, or cleanly terminating applications. Startup and shutdown scripts are useful for bootstrapping an app or starting up a process for a batch job as well as cleaning things up on shutdown.</p>
<p>Alright, that’s going to wrap up this lesson. In our next lesson, we’re going to cover <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/auto-scaling-3/">auto scaling</a>. So if you’re ready to keep learning more, then let’s get started with the next lesson.</p>
<h1 id="Auto-Scaling"><a href="#Auto-Scaling" class="headerlink" title="Auto Scaling"></a>Auto Scaling</h1><p>Welcome back. In this lesson we’ll talk about auto scaling. We’ll start with an overview and then we’ll move on to talking about policies, and then we’ll set up auto scaling.</p>
<p>So, what is auto scaling? Again, this is the case where the name is pretty descriptive. Auto scaling is the ability to add and remove instances automatically, as the workload demands, so that you don’t need to do it manually. This can help manage cost because you don’t need extra instances running when they’re not really required. Also, it will make for a better application, because users or processes aren’t waiting for the resources, or requests due to the servers being overtaxed. Autoscalers work with the managed <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/instance-groups/">instance groups</a> to add and remove instances, which are based on an instance template. And it will add and remove them down to the minimum and up to the maximum as needed.</p>
<p>In order to determine when new instances should be created we need to set up a policy. There are three different auto scaling policies that we can use. Those are CPU utilization, HTTP requests per second, and Stackdriver metrics.</p>
<p>For the CPU option, we can scale out. If the average usage of the total virtual CPU cores in the instance group exceeds the threshold that we’ve set. As an example, we can set a value of 70%. And if the average CPU usage hits 70% or higher, the autoscaler is going to add an instance, assuming that we haven’t already exceeded the maximum allowed instances for that group.</p>
<p>The HTTP load balancing serving capacity option will scale based on the requests per second per instance. This works because the loadbalancer allows us to specify the max request per second. And so we can tell the auto scaler to scale if the request go over a certain percentage of that.</p>
<p>If either of these CPU or HTTP options don’t work, we can also use Stackdriver custom metrics, and this allows us to specify the metric and the target range. We won’t be getting into Stackdriver because it needs to be its own course. However, it is a cross cloud monitoring tool that’s integrated with many of the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google cloud platform</a> services.</p>
<p>And if we need more in the way of options, we can use multiple metric options. And that allows us to add up to five policies based on the three above options. If you have more than one policy, the autoscaler will select the one that leaves the most amount of available servers.</p>
<p>Let’s jump into the console, so we can actually create an autoscaler. Let’s start off by editing the instance group we created in the previous lesson. And we’ll edit it to allow auto scaling. So from the instance group page, we’ll click on our group. And notice we have one server running. That’s because we set it to use just one in our previous lesson. Let’s click on the details tab, so we can see that auto scaling is disabled.</p>
<p>Alright, let’s edit this group by clicking on the edit link at the top of the page. And we’ll set auto scaling to on. And now, we can use the different auto scaling options that we talked about previously to determine how we’re going to scale out. You can see the default is for CPU, and it’s set to 60%. It has a default minimum of one instance, and a default max of 10. Looking at the HTTP option the form is identical.</p>
<p>Changing to metric base, you can see it’s a bit different. We have two text boxes and a drop down. This is where we select something like read or write ops. Whatever metric you select, this has to be a metric that quantifies how busy an instance is and it needs to be one that will change by adding or removing instances. And then we need to set a target, which is our measurement in this example of CPU it could be percent of utilization. And then the target type, this defines how the autoscaler computes the data collected from instances, and the possible target types are gauge. This is where the autoscaler computes the average value of the data collected in the last couple of minutes. Delta per minute is where the autoscaler calculates the average rate of growth per minute, and compares that to the target utilization. And then we have Delta per second, and that’s where the autoscaler calculates the average rate of growth per second, and compares that to the target utilization. So, it’s more advanced, however, it’s going to be useful if the other options don’t work for your use case.</p>
<p>And then we have the multiple metrics option, which allows us to build up something more complex than any single metric alone. For example, we can say 50% CPU utilization and high disk IO. We’re going to use CPU for this demo, and I’m going to set it to 75%. And while we’re at it, let’s change our min and max values. We’ll set the minimum to two instances, and the maximum to three. And let’s save this.</p>
<p>Okay, notice how it picked up on our new minimum, and it’s adding another instance. So if the average CPU across the existing instances increases to 75%, then the autoscaler is going to add another server. And after a few minutes of the instances being below that threshold, they’re going to start to be removed one at a time. Google determines the period of time to wait before removing machines and they try and ensure that these new instances stay around for as long as they need.</p>
<p>Alright, that’s going to wrap up our lesson on auto scaling. In our next lesson we’re going to cover <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/load-balancer/">load balancing</a>. So, if you’re ready to talk about load balancing, then let’s get started with the next lesson.</p>
<h1 id="Load-Balancer"><a href="#Load-Balancer" class="headerlink" title="Load Balancer"></a>Load Balancer</h1><p>Welcome back. In this lesson, we’ll be talking about load balancing. We’ll cover the different types of load balancers, and then we’ll create one to see how it’s actually set up.</p>
<p>There are three types of load balancer. We have TCP, UDP and the HTTP load balancer. Let’s start by talking about the options that <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google</a> classifies as network load balancers, which are the TCP and UDP load balancers.</p>
<p>Network load balancing allows you to balance the load of your systems based on the incoming IP protocol data, such as address, port and protocol type. They use forwarding rules that point to target pools, which list instances available for load balancing and define which type of health check should be used to determine if those instances are healthy. With network load balancing you have some options that you don’t have with HTTP. For example, you can load balance based on protocols, such as SMTP or FTP, and you can also perform packet inspection, which isn’t available for the HTTP load balancer. So, if you need to load balance an application that doesn’t run over HTTP, then you can use either TCP or UDP.</p>
<p>The network load balancer works by distributing traffic among pools of instances inside of a single region. It uses forwarding rules that you create to determine which pool to send traffic to, and the load balancer uses health checks to ensure that it only sends traffic to instances that are considered healthy. The health check is based on an HTTP request. So, you’ll need to ensure that your instance has at least a basic web server, even if the instance isn’t being used for web workloads. Network load balancing also supports a couple of additional features, namely session affinity and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/auto-scaling-3/">auto scaling</a>. Session affinity means that requests from a particular client will be continually directed to the same instance, and this is useful for applications that aren’t stateless.</p>
<p>So network load balancing is useful for use cases, such as multiplayer game servers over UDP, or maybe load balancing SMTP servers, or FTP servers, or even load balancing an application using your own protocol over TCP or UDP. And you could use it for HTTP if you wanted to. However, because HTTP is such a common use case, Google has created the HTTP load balancer, and it offers some features that the network load balancer doesn’t.</p>
<p>Let’s cover what it offers. The HTTP load balancer distributes traffic among groups of instances based on proximity to the user and the request URL routing rules. It requires an instance group and it supports managed and unmanaged groups. And that means it supports auto scaling, however it’s not required. It uses ports 80 and 8080 for HTTP and 443 for HTTPS. And, just like network load balancers, this one also supports session affinity, which is useful for legacy applications that aren’t stateless. The HTTP load balancer also supports connection draining, which ensures that no new connections are made and that existing connections are preserved as long as possible before an instance is removed from the group.</p>
<p>Let’s see how to create an HTTP load balancer from inside of the console. We already have an instance group and it has a web application in it. From the Networking page and on the Load balancer tab we can click on Create load balancer. And now, it wants to know which type of load balancer we want to create. We’re going to use the HTTP load balancer, as we talked about. So, we’re going to give it a name. We’ll call ours webapp-load-balancer.</p>
<p>And now, we need a backend service. Backend services direct incoming traffic to one or more backends. Each backend is composed of an instance group and an additional serving capacity. Backend serving capacity can be based on CPU or requests per second. Each backend service also specifies which health checks will be performed against the available instances. The form for backend service already has a sub-form for a backend. So, we just need to fill it out. And each backend requires us to select an instance group. We’re going to use the one that we’ve already created. And our backend runs on port 80. So, we’ll leave that there by default. And we can select the balancing mode, which will be either CPU utilization or requests per second. We can also set the capacity for the backend, and in this case it would be 100% CPU utilization.</p>
<p>And now, we need a health check. The health check pulls the instances attached to our backend service and makes sure that they’re available to handle traffic. And with that done we can move on to the host path rules. This is were we can map a path to a backend. We only have the one backend so we don’t have to edit anything here. Next is the frontend service. Here we can set HTTP or HTTPS. We can set up the type of the IP address: static, ephemeral, et cetera. We can change the port. And if we’re using HTTPS, then we would add our SSL cert, which gets terminated at the load balancer. Keep in mind if you want to have the load balancer also communicate with our backend service via HTTPS, then we need to have our cert loaded on each instance as well.</p>
<p>Now, we can review the setup and since everything looks good, let’s click on the Create. We’re going to jump forward to when it’s complete so we can try this out. So, we’re going to browse to the IP address of our load balancer. And there it is. There’s our application running and serving traffic from our backend service.</p>
<p>Unlike some device-based load balancers, the cloud load balancer is a massively scalable, software-defined solution that doesn’t require any pre-warming. Cloud load balancer is going to be a key component in any Compute Engine based, highly available workload, so take the time to test it out and get to know it.</p>
<p>In our next lesson, we’re going to put what we’ve learned throughout <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/course-introduction-5/">this course</a> in practice. So, if you’re ready to keep learning, then let’s get started with the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/putting-it-all-together-1/">next lesson</a>.</p>
<h1 id="Putting-It-All-Together"><a href="#Putting-It-All-Together" class="headerlink" title="Putting It All Together"></a>Putting It All Together</h1><p>Hello and welcome. In this lesson, we’re going to head into the console and create a cross-region load balanced web application. We’re going to use <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/load-balancer/">Google Cloud’s global load balancer</a> to distribute traffic between two regions. One of the regions is going to reside in the U.S. and the other in Europe. </p>
<p>Google Cloud’s load balancer is comprised of a few different components behind the scenes. Requests that are sent by users head to the frontend forwarding rules. A forwarding rule routes requests to a target proxy. A target proxy checks the URL map to determine the backend service for which it should route traffic. It’s the job of the backend service to forward those requests on to the instances themselves, and that’s based on the instance capacity and health. And instance health is determined by health checks. Once we’ve built this out, we’ll be able to make a request to a static IP address which is attached to the forwarding rule and then we’ll be able to receive the response from the most responsive region. </p>
<p>Here’s our requirements for this build. We’re going to create an instance template so that we can ensure every instance is created consistently. We’re going to create two instance groups based on the template. One will reside in US East, and the other in Europe West. We’re going to create a firewall rule that will allow HTTP traffic to the servers. We’ll create a static external IP address. And we’ll create and configure the load balancer. To top it all off, we’ll test the traffic flow using curl, and we’ll test that through two different machines, one in each region so that we can see how we actually will receive these requests from the region that is the most responsive. </p>
<p>All right, a few notes before we get started, some of the functionality in this demo does require the premium tier networking functionality, so keep that in mind, also we’re going to use HTTP rather than HTTPS, though HTTPS is fully supported. </p>
<p>All right, if you’re interested in building this out, then let’s get started. I’m here on the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/google/">Google Cloud Platform</a> dashboard and the first thing we need to do is create our instance group template. So let’s head over to the compute engine page and let’s drill into the instance templates sub-page, right here. Okay, and clicking create instance template. Okay, so remember this template is going to allow us to ensure that whatever instances we create will look exactly the same. So it’s going to provide us that consistency. We’re going to use a machine type of f1-micro and we’ll leave the Debian Linux default OS here set, and then let’s expand this management section, and we’re going to add a startup script. Now, this is going to be the thing that configures the Apache web server, and we’ll scroll over to networking. </p>
<p>Network tags allow us to dynamically lookup instances to have firewall rules applied to them. So, using a network tag, a firewall rule can basically say hey, show me any instances that have a tag of HTTP tag and that just makes things a bit more dynamic because anything with that tag will automatically have that rule applied, so it’s a nice easy way to apply firewall rules. We’ll specify this as HTTP dash tag, and we’ll have to remember that for later. And we’ll use an ephemeral IP address and then we can create this instance template. </p>
<p>Okay, with this complete we can create an instance group. So, we’re going to create two groups of instances, one in each region, and they’re going to based off this template. The first one will be the U.S. East region, and we’ll be using HTTP, so I just like to specify that as the name there, and we’ll set it to multiple zones, we don’t really need to worry about which zone, we’ll just have it pick for us, so we’ll use east four, and it’s already got our template there, perfect. It’s using auto-scaling, I’m going to use the default CPU usage, but feel free to change that for yourself. </p>
<p>The minimum number of instances is one, that’s fine. The max is 10, it’s a bit high, let’s set that to two. Okay, and let’s create this. So this is going to create instances inside of a group based on our template that are running inside of the U.S. East four region. So, now let’s just copy this name, we’re going to use the same basic naming convention, and create our European instance group. And so I’m going to just paste this and swap this over. Okay, perfect. </p>
<p>And let’s set the region. Actually, I didn’t set the multiple zones first, so let’s do that again. And set the region. Perfect, and it doesn’t have our instance template here so let’s set that. And again, let’s dial the maximum number of instances down to two. And let’s create this. </p>
<p>All right, with this complete, what we’ve actually done is we’ve set up our web server running in two different regions using the same instance template and created through instance groups. And those groups are going to allow this to auto-scale. That’s going to make it so that we can scale up and down based on the demand, and all of this is going to end up routed through just the one IP address, so there’s a lot of functionality here happening in the background, though it’s going to be seamless to the user, they’re going to be able to just hit that one IP address, and get routed to the region and instance that is the best qualified to handle the traffic. </p>
<p>Okay, so the next thing we need to do is create our firewall rule. Remember, we created our tag on the instance, now let’s create a firewall rule that recognizes that tag, and it’s going to apply to those instances that we just created. So, we’re going to click on create firewall rule. And we’ll give it a name. The most creative name you’ve ever seen, no doubt. And I’ll scroll down, this is an ingress rule, we’ll allow, and we need to specify the tag here, so HTTP dash tag. Okay, so that will apply to our instances. And we want this to be accessible from everywhere so we’ll use zero dot zero dot zero dot zero slash zero. Is there an extra zero in there? I can’t tell. Anyway, we’re going to specify the port of port 80. And click create. </p>
<p>Okay, so now we have our firewall rule. In theory, because we’ve linked this together with the tags, these instances are accessible from the internet. We should be able to hit these on port 80 and see the webpage that is running. So let’s test this out by copying the URL. Oops, I deleted the five here, there we go. </p>
<p>Okay, so this is running, you can see it’s running in U.S. East four, let’s try this again with the other region. And we’ll drill into Europe. And copying this external IP address, pasting it in here, yeah, there it is, Europe West three. Okay, so our instances are up and running, they are accessible over the internet on port 80, so, so far things are looking good. </p>
<p>The next thing we need do is create our external IP address because we don’t wanna have to actually go to the individual instances to view our webpage. So, let’s click on the navigation menu and let’s go to the external IP address section. Okay, so once this loads, we can click this reserve static address here. And I’m going to select this name from the list, as you can tell I’ve done this off camera before. I’ll make sure it’s IPv4, and we’re going to set this as a global type. And we’ll click reserve. </p>
<p>Notice in the network tier column in a second here, it should pop up, yeah, there it is, it says premium, so this is what I was mentioning earlier at the beginning, some of these features are actually premium network tier. </p>
<p>So, next let’s click on the load balancing section, we’re going to create the load balancer. And so we’ll click create here, and we’ll select HTTP, though notice you can use TCP or UDP. And I’ll just give this a name real quick. Let’s call this webserver map, and let’s set a backend. So, we’re going to select our backends, though now that I’m here, notice you can actually create a backend off of storage bucket, so that’s kind of cool, not really the purpose of this demo, but it’s still cool. </p>
<p>So we’ll go back to create our backend service, and I’ll give this a name, we’ll call it web server map backend. Okay, and we need to set our instance group, this is the group of servers that it’s going to route traffic to, and we’ll now set another one, we’re gonna grab the European one. </p>
<p>So now I’ve added the two backends, I’ve added the two different groups of web servers, the one in the U.S. and the one in Europe, next thing we need to do is make sure we have a health check. We need to know that the instances are healthy, and so for that, we’ll click on this health check and create. And we’ll just give this a name of web server map backend, that’s probably not the best name since I think I already used that, but we’ll go with it for this demo. Okay, and we’ll click create. </p>
<p>Notice on this host path and rules page, we can actually specify different rules for how to direct traffic to the different backends. Clicking on this add rule here is going to allow us to specify a host and a path, so maybe you wanna do something like some URL-based routing, you wanna send anything that mentions images, based on this little example here, anything that says images in the URL you wanna send to a specific location, that could be a storage bucket or someplace else, this gives you the functionality to do that. We’re not going to do it, we’re going to send all the traffic by default to the backend that we’ve just created. Though keep in mind that you can use content-based routing, which is pretty cool. </p>
<p>The frontend configuration, let’s give this a name. And perfect, so we’re gonna make sure it’s HTTP. It’s the premium tier, that’s fine, and we wanna use our static IP address, that way it’s always the same IP address, we’ll be able to use that in DNS if we want to. Clicking on review and finalize, everything looks good here, this is all that we expect, so let’s click create. And perfect. </p>
<p>So let’s drill into this. It’s going to provide for us the IP address for the frontend and let’s copy that and paste that in another tab. And we get a 404. Now, don’t worry, this is actually expected, this is working as designed. It just takes a little while for some of this stuff to propagate out. So, we’re working with some global rules here, it takes a little while for that to get sent all over the globe and wherever it is it needs to be. So don’t worry, this can take a few minutes, I think the last time I did this I waited about 10 minutes. So I’m gonna pause here and I will catch you in 10 minutes. </p>
<p>Okay, I’m back, and it’s been about 10 minutes, let’s click on the refresh button and see if this is working now. And it is. Notice this is running in U.S. East four B. If I was to keep mashing this refresh button, it’s really not going to change. I have two regions, yes that is true, I’m distributing the traffic between them, that is also true, however, it’s tough to tell because Google is going to route me to the best possible instances that it finds. And now it determines that in different ways, but basically since I am physically close to U.S. East, I’m actually in East US, it’s going to send me to that server. </p>
<p>The way we’re going to test this is I actually started up two instances earlier, one of them is in the U.S., one of them is in Europe, and we’re going to use those as springboards to test this out. I’ve used the Cloud Shell functionality to SSH into them, and so I’m going to just pivot to that screen and show you them side-by-side. And so here they are. I’m going to add a little space here so that it doesn’t overlap with these icons up in the top right. And I’m going to use curl to actually see if this works. </p>
<p>So, this page on the left-hand side is East four, over on this let’s do curl, and I paste that in, notice it says this server is running in zone, and then there’s a project ID, not gonna read that off, but then it’s followed by zone U.S. East four B. So, because this one is the best option it’s going to send us to East four, and if we try from this European instance, and again I’ll add a little space here, and curl, oops extra period there, and there it is, so Europe West three B. So it actually works. </p>
<p>Okay, with this complete let’s stop here and summarize what we’ve done in this lesson. We built a cross-region web application using compute engine instances which were created based on instance templates and they were created inside of an instance group. Then, we created a firewall rule that allowed IPv4 traffic to port 80 from anywhere and it mapped to our instances using network tags. We created a static IP address that we then linked to the frontend forwarding rule. We also created the backend service which contained the instance groups, that’s those two instance groups the U.S. East and Europe West. Then we tested this by sending traffic to our static IP address from different servers, those springboard servers that were located in the U.S. and Europe, and we noticed that we received our traffic from the closest region. So, all things considered, I think this was a successful build-out. </p>
<p>All right, that’s going to do it for this <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-systems-operations/course-introduction-5/">course</a>, I hope it has helped you to further your understanding of the Google Cloud Platform. Thank you so much for watching, and I will see you in a future course.</p>
<p><strong>Note: The startup script shown in this video is at</strong> <a target="_blank" rel="noopener" href="https://gist.github.com/whelmed/9b688aa4bf7d1d7d55900753f023d0ae">https://gist.github.com/whelmed/9b688aa4bf7d1d7d55900753f023d0ae</a>.</p>
<h1 id="1Course-Introduction"><a href="#1Course-Introduction" class="headerlink" title="1Course Introduction"></a>1<strong>Course Introduction</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/what-is-cloud-computing-introductory/introduction-8/">Course: What is Cloud Computing?</a></p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/google-cloud-platform-fundamentals/course-introduction-1/">Course: Google Cloud Platform: Fundamentals</a></p>
<h1 id="15Putting-It-All-Together"><a href="#15Putting-It-All-Together" class="headerlink" title="15Putting It All Together"></a>15<strong>Putting It All Together</strong></h1><p><a target="_blank" rel="noopener" href="https://gist.github.com/whelmed/9b688aa4bf7d1d7d55900753f023d0ae">Startup Script</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Inspecting-and-De-Identifying-Data-With-Google-Cloud-Data-Loss-Prevention-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Inspecting-and-De-Identifying-Data-With-Google-Cloud-Data-Loss-Prevention-5/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Inspecting-and-De-Identifying-Data-With-Google-Cloud-Data-Loss-Prevention-5</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:13:59" itemprop="dateCreated datePublished" datetime="2022-11-19T00:13:59-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:39:00" itemprop="dateModified" datetime="2022-11-20T19:39:00-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Inspecting-and-De-Identifying-Data-With-Google-Cloud-Data-Loss-Prevention-5/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Inspecting-and-De-Identifying-Data-With-Google-Cloud-Data-Loss-Prevention-5/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Starting-a-Windows-Virtual-Machine-on-Google-Compute-Engine-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Starting-a-Windows-Virtual-Machine-on-Google-Compute-Engine-4/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Starting-a-Windows-Virtual-Machine-on-Google-Compute-Engine-4</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:13:58" itemprop="dateCreated datePublished" datetime="2022-11-19T00:13:58-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:40:16" itemprop="dateModified" datetime="2022-11-20T19:40:16-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Starting-a-Windows-Virtual-Machine-on-Google-Compute-Engine-4/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Starting-a-Windows-Virtual-Machine-on-Google-Compute-Engine-4/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Console-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Console-3/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Console-3</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:13:56" itemprop="dateCreated datePublished" datetime="2022-11-19T00:13:56-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:41:06" itemprop="dateModified" datetime="2022-11-20T19:41:06-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Console-3/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Working-with-Google-Cloud-Storage-from-the-Console-3/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Professional-Architect-Knowledge-Check-Overview-of-Google-Cloud-Platform-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/GCP-Professional-Architect-Knowledge-Check-Overview-of-Google-Cloud-Platform-2/" class="post-title-link" itemprop="url">GCP-Professional-Architect-Knowledge-Check-Overview-of-Google-Cloud-Platform-2</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:13:55" itemprop="dateCreated datePublished" datetime="2022-11-19T00:13:55-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 19:38:20" itemprop="dateModified" datetime="2022-11-20T19:38:20-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Professional-Architect/" itemprop="url" rel="index"><span itemprop="name">GCP-Professional-Architect</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Professional-Architect-Knowledge-Check-Overview-of-Google-Cloud-Platform-2/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Professional-Architect-Knowledge-Check-Overview-of-Google-Cloud-Platform-2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>
<p><object data="Knowledge-Check-Overview-of-Google-Cloud-Platform.pdf" type="application/pdf" width="100%" height="600"></object></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/32/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/32/">32</a><span class="page-number current">33</span><a class="page-number" href="/page/34/">34</a><span class="space">&hellip;</span><a class="page-number" href="/page/274/">274</a><a class="extend next" rel="next" href="/page/34/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
