<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hang&#39;s Blog">
<meta property="og:url" content="https://example.com/page/21/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/page/21/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/PHP-CLI-Create-Command-Line-Interface-Scripts-with-PHP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/PHP-CLI-Create-Command-Line-Interface-Scripts-with-PHP/" class="post-title-link" itemprop="url">PHP-CLI-Create-Command-Line-Interface-Scripts-with-PHP</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-19 09:47:16 / Modified: 09:55:30" itemprop="dateCreated datePublished" datetime="2022-11-19T09:47:16-04:00">2022-11-19</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/PHP-CLI-Create-Command-Line-Interface-Scripts-with-PHP/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/PHP-CLI-Create-Command-Line-Interface-Scripts-with-PHP/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><object data="PHP-CLI-Create-Command-Line-Interface-Scripts-with-PHP.pdf" type="application/pdf" width="100%" height="600"></object></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/ccda-official-exam-certification-guide/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/ccda-official-exam-certification-guide/" class="post-title-link" itemprop="url">ccda-official-exam-certification-guide</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 09:47:14" itemprop="dateCreated datePublished" datetime="2022-11-19T09:47:14-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-27 20:55:36" itemprop="dateModified" datetime="2022-11-27T20:55:36-04:00">2022-11-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CCDA/" itemprop="url" rel="index"><span itemprop="name">CCDA</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/ccda-official-exam-certification-guide/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/ccda-official-exam-certification-guide/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><object data="ccda-official-exam-certification-guide.pdf" type="application/pdf" width="100%" height="600"></object></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Linux-LPIC-102-Amazon-Linux-2-Playground-11/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/Linux-LPIC-102-Amazon-Linux-2-Playground-11/" class="post-title-link" itemprop="url">Linux-LPIC-102-Amazon-Linux-2-Playground-11</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 01:11:56" itemprop="dateCreated datePublished" datetime="2022-11-19T01:11:56-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 20:11:00" itemprop="dateModified" datetime="2022-11-20T20:11:00-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LPIC-1-102/" itemprop="url" rel="index"><span itemprop="name">LPIC-1-102</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Linux-LPIC-102-Amazon-Linux-2-Playground-11/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Linux-LPIC-102-Amazon-Linux-2-Playground-11/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Linux-LPIC-102-Linux-Terminal-Playground-Red-Hat-10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/Linux-LPIC-102-Linux-Terminal-Playground-Red-Hat-10/" class="post-title-link" itemprop="url">Linux-LPIC-102-Linux-Terminal-Playground-Red-Hat-10</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 01:11:54" itemprop="dateCreated datePublished" datetime="2022-11-19T01:11:54-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 20:09:52" itemprop="dateModified" datetime="2022-11-20T20:09:52-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LPIC-1-102/" itemprop="url" rel="index"><span itemprop="name">LPIC-1-102</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Linux-LPIC-102-Linux-Terminal-Playground-Red-Hat-10/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Linux-LPIC-102-Linux-Terminal-Playground-Red-Hat-10/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Security-6-of-6-9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Security-6-of-6-9/" class="post-title-link" itemprop="url">Linux-LPIC-102-LPIC-1-102-Linux-certification---Linux-Security-6-of-6-9</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 01:11:53" itemprop="dateCreated datePublished" datetime="2022-11-19T01:11:53-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 21:30:44" itemprop="dateModified" datetime="2022-11-20T21:30:44-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LPIC-1-102/" itemprop="url" rel="index"><span itemprop="name">LPIC-1-102</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Security-6-of-6-9/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Security-6-of-6-9/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>This is the final course in Cloud Academy’s 11-part series preparing you for the LPIC1, Linux Server Professional 101 and 102 exams.</p>
<p>With this course, you’ll hopefully have everything you need to fly through the exams. But more importantly, to more productively and more profitably make use of the many opportunities Linux provides.</p>
<p>This course will focus on security. There’s more than one way to secure your servers and their data.</p>
<p>You can look at it from the perspective of user access, network connectivity, and both file and connection encryption.</p>
<p>We’ll learn about securing your local system resources against misuse, maintaining safe and secure network connections, using OpenSSH to encrypt, and thereby secure your remote terminal sessions, and about encrypting individual files so they can be safely sent across insecure channels.</p>
<h1 id="System-Security"><a href="#System-Security" class="headerlink" title="System Security"></a>System Security</h1><p>To keep the servers and PCs under your care secure, you will have to have control over the users who login both locally and remotely. You will also need to find ways to intelligently monitor the system processes themselves so you can spot strange activities and dig deeper. We’re going to discuss some of the tools available to Linux SysAdmins. It’s possible, by the way, that some of these tools aren’t installed by default on your system, but apt-get or yum can quickly fix that. If you’re not sure where to find a package, on a Debian-based system including Ubuntu, you can use apt-cache search and then the name of the program you’re after. In this case, we can see the netstat is part of the net-tools package. One of the simplest things you can do to prevent unauthorized control over your servers is to limit who gets administrative rights and when.</p>
<p>Your first job, therefore, is to make sure that users who don’t need admin rights don’t get them. To protect against legitimate admin users carelessly leaving their root sessions unwatched, discourage your admin users from using root sessions via sudo su.</p>
<p>Instead, they should use sudo. Sudo invokes root powers, but only for that particular command. Once the command is done, the shell session returns to non-admin permissions. This makes it much less likely that some kind of account hijacking will cause all that much damage.</p>
<p>As we previously seen, users can use sudo to invoke root if they’ve been added to the sudo group in etc&#x2F;group, or in some Linux distributions, to the wheel group.</p>
<p>Behavior of the sudo group is controlled through the etc&#x2F;sudoers file, which by the way, requires sudo just to view. Note the user privilege specification line, which in my case gives full root authority to members of the sudo group. As you can see, sudoers should never be edited directly, but through the visudo command.</p>
<p>You can add or remove a user from the sudo group either by editing the etc&#x2F;group file or by using usermod. The -a -G will add Steve to the group called sudo.</p>
<p>It’s no secret that passwords are among the weakest links in the security chain. Most people choose short passwords that are easy to remember, and then use them over long periods of time for multiple accounts, which is exactly what makes them the easiest to guess or crack. And the more accounts people have, the more likely it is that they’ll compensate with even fewer and weaker passwords.</p>
<p>We simple system administrators can’t be expected to solve all the world’s problems, but we can use Linux tools to enforce some password standards.</p>
<p>Although this isn’t an LPIC exam requirement, you should at least be aware of packages like PAM or APG that force users to use longer and more complex passwords. What is part of the LPIC exam is chage, which stands for change age.</p>
<p>We’ve seen this in a previous video, but let’s have a quick review. We’ll run chage against my own user Ubuntu. We’re shown the last time I changed my password, expiry settings and minimum and maximum days between password changes. Meaning that as an admin, I can force the Ubuntu user, who happens to be me in this case, to change the login password every X number of days.</p>
<p>You set the maximum with the uppercase M, and the number of days you’d like to force the new password; 30 in our case.</p>
<p>Let’s review. Sudo, which invokes root powers only for a single command, is far preferred over starting a root shell using sudo su.</p>
<p>Sudo can be used by members of the sudo or Wheel group which is controlled by the etc&#x2F;sudoers file. You use usermod to add sudo to the sudo group.</p>
<p>Chage can be used to force users to regularly change their passwords. Besides controlling system access, you should also regularly monitor the system itself for unusual and suspicious behavior. For the remainder of this lecture, we’re going to explore some tools and techniques for doing that.</p>
<p>However, it’s unreasonable to think that you’re actually going to do all these things regularly enough to make them useful. It’d be much more realistic to include them in scripts run automatically by cron that will issue notifications of anomalies.</p>
<p>At any rate, here’s how you can effectively monitor your servers. As we discussed way back in the Linux partitions and filesystems course, you can, if necessary, provide non-root users full access to system binaries, even to binaries that will act with root privileges through SUID and SGID.</p>
<p>This way, for instance, as we’ve explained, regular users will change their passwords using usr&#x2F;bin&#x2F;passwd even though passwd works by updating the etc&#x2F;shadow file which belongs to root.</p>
<p>We can see this by looking at the passwd file in the usr&#x2F;bin directory. Notice the S in the first set of permissions, signifying that the SUID bit is set. We could remove the bit using chmod -s, but then you’d need to be root in order to update your password.</p>
<p>As you can probably guess, chmod +s will add the SUID bit. Using the SGID bit, you can do the same thing for binary files group permissions. Now all this is very nice, I hear you saying.</p>
<p>But what does it have to do with system security? Good question. The point is that while SUID and SGID bits are really useful, they’re are also a huge security hole, since any user can exploit them to effectively get full root access. If you want to maintain control of these permissions, you should regularly audit your system to make sure that there aren’t any files that through accident or malice have been left improperly open.</p>
<p>You can do this using find. A slash followed by -type f tells find to search for and list files in every directory below root whose user permissions include the SUID bit.</p>
<p>We could run the same command using -G to search for SGID bits. Now you can look through the output to see if there’s anything there that shouldn’t be.</p>
<p>Alternatively, you can create a script that checks the output of find against the files you know should be there, and then sends an alert if there is anything new.</p>
<p>You should also be able to keep track of processes running on your system to make sure nothing is being used without proper authorization. PS as we’ve seen, will list all running processes, and grep can help you find specific entries from out of the long list. But you might need to narrow down your search based on more specific rules. Fuser, which stands for file user, will return all processes running within a specified directory. In this case, we can see all the process IDs currently running within the root hierarchy. You will want to run fuser as sudo to make sure you’re accessing all system processes. For more information like the process user and the command, run fuser with the verbose argument. You can restrict your output to a specific executable like the Apache 2 Web server in this case. Or if you suspect that someone might be accessing a particular port without authorization, you can run fuser with -n specifying the TCP protocol and the HTTP port 80. In addition to netstat, which we discussed in the previous course, you can learn a great deal about the state of your network facing server using nmap. We’ll run nmap against the LXC container I’m on right now.</p>
<p>We can see that port 22 is open for SSH, port 25 for outgoing mail, and 80 because I have the Apache Web Server installed and working.</p>
<p>All that is what I would’ve expected taking into account the various ways I’ve been using this container. If there is anything I didn’t recognize, I would naturally want to investigate. By default, nmap looks for TCP activity. If I wanted to scan for processes using the UDP protocol, I would add -sU as an argument.</p>
<p>Note how UDP searches require sudo authority. It’s also important to keep track of who is logged onto your system.</p>
<p>Since Linux is by design built for multiple users, you can have all kinds of users logged in from remote locations without you even being aware of it. You’ll really want to keep an eye on login activity to make sure that there’s no one sneaking in behind your back. Linux has a few very similar tools that can do this, each with a subtle angle all its own. Last will print the login times of all users since the beginning of the month.</p>
<p>By default, it uses data from the file var&#x2F;log&#x2F;wtmp. Besides the Ubuntu user and root, we can see that Steve is logged in too. W will display a list of all users logged in along with information on their current activity. Who will also print the names of logged in users. When used with -b, it will also display the time of the last system boot. Now that we know whose accounts are logged into our system, and that Steve is one of them, we might like to find out what he’s been up to.</p>
<p>Since just about everything that happens in Linux is built on files, searching for files that are open and associated with a particular user can tell us a great deal.</p>
<p>Lsof which stands for list open files can do just that. A quick look through the data we get back shows that these are all normal processes associated with any normal SSH session. But if there was something funny going on, it wouldn’t be too hard to spot.</p>
<p>Let’s review. You can search for files with the SUID or SGID bit set using find. Fuser will print all processes running within a specified directory or file, or using a particular port. Netstat and nmap will both scan network addresses for open ports. Last, w and who will all display user login data. Lsof can tell us which files are currently open and who is using them.</p>
<h1 id="Network-Security"><a href="#Network-Security" class="headerlink" title="Network Security"></a>Network Security</h1><p>The previous video focused on system security, that is, maintaining the integrity of locally-running processes and resources. This lecture is about protecting your system from network-based threats. With that in mind, you might wonder why we’re going to start by talking about passwords and the files used to store them, when it would seem to be something we should already have discussed. I believe the LPI placed password files together with network security because securing key system data, like passwords, is an important part of maintaining control over network access.</p>
<p>How? Because, if a hacker manages to break into your system for various reasons, he’s more likely to do it as a regular non-admin user. But if he can easily access a file containing user passwords, even if they’re encrypted, then he’s a step closer to getting the keys to the castle. And it’s for that reason that many Linux distributions stopped keeping encrypted passwords in the &#x2F;etc&#x2F;passwd file. Let’s take a look. Notice first of all, that we can view the file without sudo, which is what makes it so vulnerable. Now take look at how the data is arranged. Each field is separated by a colon. The first field is the Username, Steve, in this case. The second field is just an X. Once upon a time, this would’ve been the encrypted version of Steve’s password. But that’s now been moved somewhere else, which we’ll get to in a minute. While we’re here however, we might as well explain some of the other fields.</p>
<p>The User ID and Group ID come next, followed by Steve’s Home directory, and finally, his default shell. So, where have all the passwords gone? If you can still log into the system, they’ve got to be somewhere. The answer is, they are now usually kept in &#x2F;etc&#x2F;shadow file. Note that we can’t read the file without sudo.</p>
<p>That, obviously, is to protect the contents from non-admin users. But with sudo, we’ve got full access. Now we can see the encrypted version of Steve’s password. With enough time and compute power, it might be possible to decrypt the string, but it’s not a trivial matter. And the fact that everything is here in the shadow file protected by admin permissions, makes it just that much more secure. If your system ever becomes vulnerable or unstable and requires emergency care, and you can bet that at some point it certainly will, you can easily shut down access to everyone but the root user by creating an empty file in the &#x2F;etc directory with the name nologin.</p>
<p>As long as this file exists, users won’t be able to login to new sessions. You should be careful with this. If you create the nologin file, then logout yourself, since you’re not the root user, even if you’re part of the sudo group, Linux won’t let you log back in. You may find yourself having to mount your filesystem from a different machine and removing the nologin file manually. Let’s review. Encrypted records of user passwords are usually kept in the &#x2F;etc&#x2F;shadow file which is restricted to access by admin users. The &#x2F;etc&#x2F;passwd file contains only basic user account details, but no passwords. Adding an empty file named login to the &#x2F;etc&#x2F; directory will prevent non-root logins.</p>
<p>Now we can turn our attention to some more obvious network security considerations. When a remote client requests a network connection, your server has to know how to respond. Normally, local requests for some services cause system daemons to start, and once a service is no longer needed, stop. However, it wouldn’t be very secure to allow remote requests to directly spawn local daemons. So, a class of daemon manager, or a super-daemon, was created.</p>
<p>Originally called inetd, for internet service daemon. Inetd manages local daemons on behalf of remote clients. By the way, be careful not to confuse the various inet files and directories with the similar sounding init and inittab files and directories that we discussed earlier. Those services control system boot and run levels, and had relatively little to do with security. What’s important for us right now is to be aware that inetd can be configured to accept or reject remote requests according to your instructions. On Debian systems, until very recently at least, inet configurations were kept in the &#x2F;etc&#x2F;inetd.conf file. Over time, security concerns caused most distributions to replace inetd with more sophisticated super-daemons like xinetd, which would be controlled by the &#x2F;etc&#x2F;xinetd.conf file, or by files in the &#x2F;etc&#x2F;xinetd.d&#x2F; directory. In this case, xinetd.conf contains nothing more than a pointer to the &#x2F;etc&#x2F;xinetd.d&#x2F; directory where individual service config files are kept.</p>
<p>Let’s take a look at an xinetd file, the one called time. The value of the service line is the service name, time, in our case. By default, network access to time is disabled as we can see from the yes value of the disabled line. We can also see both tcp and udp versions. To provide real-time protection, the tcp.d daemon, otherwise known as a TCP Wrapper, can be invoked before a requested service is actually started up. Tcp.d will then check the client host against lists of allowed or denied addresses, and if everything’s okay, drop out, allowing the service to start. The files tcp.d reads are both in &#x2F;etc, hosts.deny and hosts.allow.</p>
<p>Hosts.deny is a blacklist, meaning any host addresses listed will be blocked from making requests, while requests from everywhere else will be allowed.</p>
<p>Hosts.allow, on the other hand, is a whitelist, so that only those domains actually listed will be allowed access, and all others will be denied. If there are entries in both files, matches from hosts.allow will be acted on, and anything from hosts.deny will be ignored. To review, the super-daemon controls remote client requests according to configurations found in the &#x2F;etc&#x2F;inetd.conf or &#x2F;etc&#x2F;xinetd.conf, or files in the &#x2F;etc&#x2F;xinetd.d&#x2F; directory. The tcp.d daemon will check the origins of remote requests against the entries in the hosts.allow whitelist file and the hosts.deny blacklist file. As we’ve briefly seen in previous videos, a lot of the access control for resources living in Amazon’s AWS cloud is handled by security groups and access control lists, or ACLs.</p>
<p>You can therefore open up a port, like https port 443, for traffic from a specific range of sources, either using the ACL at the virtual private cloud level, or within the security group at the resource level. You can also precisely manage access by particular services using AWS’ Identity and Access Management service, IAM. In this example, network access to a DynamoDB database table is restricted to only IAM users whose name matches the name of the table. By the way, Cloud Academy has a number of courses that deal with a AWS security in much greater detail.</p>
<h1 id="Connection-Encryption"><a href="#Connection-Encryption" class="headerlink" title="Connection Encryption"></a>Connection Encryption</h1><p>Since managing network computers will often mean you’ll be spending plenty of time transferring resources back and forth among machines, and logging in and out of remote shell sessions, it’s hugely important that you should make sure that you’re not exposing passwords and sensitive data in the process. The best way to address this need is through encryption, which uses complex algorithms to convert your plaintext data into an unreadable mess of apparently random characters. For all practical purposes, the only way to decrypt such data is by using software that can apply the original algorithm in reverse. Linux employs a program called OpenSSH to ensure that remote communication is properly encrypted. As you’ve seen many times in the series, you initiate OpenSSH remote shell sessions using ssh, followed by the account name and address of the machine you want to access. By default, you will now enter the password for the user account on the host machine, then you’ll be in. As you’ll see in just a minute, OpenSSH can also be configured to permit passwordless remote sessions. And in fact, from a security perspective, those are much preferred. But let’s first learn a bit about how OpenSSH actually works.</p>
<p>When a login session opens, the ssh agent program launches to hold all private keys that will be used for public key authentication. The encryption is controlled by files in the etc&#x2F;ssh directory. Here, we can see eight ssh key files which are really four pairs of host key files. One of each pair is public, recognizable of course through their .pub extension, and the other is private. We’ll talk more about the differences between public and private files a bit later.</p>
<p>Each of the four pairs is built using a different encryption algorithm: DSA, RSA, Ed25519 and ECDSA. DSA stands for Digital Signature Algorithm. And RSA are the first letters of the names of the three MIT researchers who created the particular algorithm: Rivest, Shamir and Adleman.</p>
<p>It is these keys that will be used to authenticate and encrypt all incoming traffic from clients also using OpenSSH.</p>
<p>These keys, by the way, all use the SSH protocol 2. The way your machine will be allowed to host remote client sessions is controlled by the sshd_config file.</p>
<p>We can see that the file allows you to control many configuration details, including the session port, which is currently set to the SSH default port of 22.</p>
<p>Changing that value to a very high port, like say, 45123, would make unauthorized access to your system that much harder. But you’d have to make sure that all legitimate clients were configured properly. The file also points to four host keys we saw just before, and defines other behavior like logging and authentication. Since you could also use this machine as a client to access a different machine, OpenSSH will control client behavior. This time through the ssh_config file. The ssh_config file controls a long list of behavior variables, most of which are currently not enabled. Let’s review. OpenSSH encrypts data passing between machines using key pairs stored in the etc&#x2F;ssh directory.</p>
<p>SSH protocol 2 algorithms include RSA and DSA, with RSA being the stronger. SSH server or host behavior is controlled by the sshd_config file, while SSH client behavior is managed through the ssh_config file.</p>
<p>Now let’s explore the way OpenSSH allows remote sessions that work between trusted machines without the need to enter passwords each time.</p>
<p>Besides the key pairs we’ve already seen in etc&#x2F;ssh, OpenSSH can be told to create different key pairs in a &#x2F;.ssh directory, in a user’s home directory.</p>
<p>This machine doesn’t yet have any keys, or even a .ssh directory. So let’s create some. First of all, we should make sure that OpenSSH is properly installed. Now we’ll run ssh-keygen to automatically generate a new key pair.</p>
<p>We’ll create an OpenSSH 2 key pair using the RSA encryption algorithm. We could specify our own filename, or simply go with the default. For significantly stronger protection, we can add a passphrase to protect against the possibility of somebody stealing your private key, and then gaining access to your host from his own machine. Note however that if you do use a passphrase, you might want to avoid having to type it for each login, which kind of defeats part of the purpose of passwordless logins.</p>
<p>By providing your passphrase just once per session to the SSH agent program by way of ssh-add, you can both maintain control over your private keys, and simplify your login sessions.</p>
<p>You could also use DSA or not specify any standard at all, which would by default, create keys compliant with the SSH protocol version 1.</p>
<p>Specifying RSA or DSA will generate keys using the stronger protocol 2. Overall, the protocol 2 RSA is usually considered a more efficient and in some ways, stronger standard.</p>
<p>Notice how we don’t run keygen as sudo. Note that one file of each of these pairs has a .pub extension, which as you can guess, stands for public. Note also that the public keys permit other uses to read them, while the private keys are accessible only to their owner.</p>
<p>This is because you’re going to copy the contents of the public key to be stored in the authorized keys file in the hidden SSH directory on the host machine. By host, we mean the machine into which you plan to login from a remote location. But the private key will remain on your client machine and must be carefully protected as it effectively contains all the keys to your castle.</p>
<p>Now that we’ve got a new pair, we’ll have to copy the public key to the host server we want to access remotely.</p>
<p>There are all kinds of ways to do this, but the main thing is to be absolutely sure that you don’t make any changes to the file contents along the way.</p>
<p>We use SCP, Secure Copy, which works securely through the OpenSSH package. From the same directory that holds the file, run SCP, the filename, the login address, and the directory on the host machine where you’d like the file to go. SCP by the way, works on top of our OpenSSH infrastructure and takes advantage of both its encryption and connectivity.</p>
<p>Now you’ll need to ssh into the server, still using the less secure password access method just one last time.</p>
<p>Let’s view the key file we’ve just copied. CD to the &#x2F;.ssh directory. Confirm that an authorized keys file exists.</p>
<p>And add the contents of the key file to the authorized keys file. Now. just to make sure it’s set right, we’ll restrict permissions for the file to access only by its owner.</p>
<p>We’ll log out and try logging in again to make sure we’re not asked for a password. I’ll exit the host so we can take a look at the known host file in our &#x2F;.ssh directory where you can see a record of the machine we’ve just visited.</p>
<p>Should any of these details change in the future, and we try to log in again, we’ll be warned of the change, and advised to update this file if you want to proceed.</p>
<p>Let’s review. Key pairs to control passwordless remote shell sessions are usually kept in the &#x2F;.ssh directory in a user’s home directory.</p>
<p>Key pairs for passwordless access are created by ssh-keygen and if desired, defined using the -t argument.</p>
<p>If you create .ssh key pairs with the passphrase, you can pass the phrase just once to SSH agent using ssh-add.</p>
<p>The public key is added to the authorized keys files on the host machine while the private key is kept safely on the client. The known host file on the client machine contains references to each host machine that you’ve accessed using passwordless key pairs.</p>
<h1 id="SSH-Tunnels-and-File-Encryption"><a href="#SSH-Tunnels-and-File-Encryption" class="headerlink" title="SSH Tunnels and File Encryption"></a>SSH Tunnels and File Encryption</h1><p>Hi. This is going to be the very last video in our LPIC-1 Certification series so we’re going to wrap up just a few remaining encryption related details, and then say goodbye. We’ll talk about SSH tunnels, GPG file encryption, and using SSH key pairs on Amazon’s AWS. First of all, we’re going to use what we’ve learned about SSH connections to create and use an SSH tunnel, that is, once you’ve got a live SSH session between two machines, you can use the connection to carry other functions. For instance, suppose you need to securely open a GUI program on a remote computer. Perhaps someone you’re working with is having trouble configuring his or her own desktop and you’d like to help. To do this, we’ll have to make sure that two simple settings in the ssh_config files on both our host and client machines are set to allow X11 connections. On the host machine, or in other words, the machine into which we will be logging for our remote session, we’ll open up the etc&#x2F;ssh&#x2F;sshd_config file to make sure that X11 forwarding is set to yes, which happens to be true already. Now on the client machine, meaning the computer from which we’ll launch the SSH session, we’ll edit the etc&#x2F;ssh&#x2F;sshd_config file so that the value of the ForwardX11 option is yes.</p>
<p>Now let’s create a special XSSH session. We’re in. So let’s see if we can open a GUI program, say, gedit.</p>
<p>It works. Besides using encryption to protect the data transferred back and forth in the process of running remote sessions, we can also encrypt files and messages sent between systems. In this case, however, the tool of choice is GPG, which stands for GNU Privacy Guard. Here’s how it works. GPG will generate a random symmetric key that it uses to encrypt a message you’d like to transfer.</p>
<p>The symmetric key is itself then encrypted using the recipient’s public key, and then sent with the encrypted message. When the recipient gets the message, GPG will decrypt the symmetric key using his private key. GPG then uses that decrypted key to decrypt the actual message.</p>
<p>Let’s generate some GPG keys using gpg –gen-key. We’ll first be asked to select a key type. We’ll stick with the default value. The default of 2048 bits for the key length is also fine for us.</p>
<p>We are now asked to configure how long the key should be allowed to remain valid. Using 0 will allow it to remain indefinitely. Since it’s usually not a great idea to create a key without any limits, GPG will ask if you’re sure you want it done that way in this case.</p>
<p>We’ll add a username, email, and a comment; all of which will be used as part of the key creation process.</p>
<p>Next, we’ll add a passphrase, and of course, we’ll be very careful not to forget this phrase. Finally, we’ll be asked to generate as much random noise as possible.</p>
<p>I’ll open a second session on his virtual machine and create some serious but useless busywork using find and xargs.</p>
<p>Eventually that will satisfy GPG’s needs and we’ll have our new keys stored happily in the hidden .gnupg directory.</p>
<p>Now that we have our GPG keys, we can use them along with the username and password we created earlier to encrypt the file. As you can see, gnupg has created a new file with the gpg extension. We could now use any normal method to copy the file as an email attachment, for instance, without having to worry about security. Let’s see how we might decrypt our encrypted file.</p>
<p>We’ll run GPG with the –output argument, create an easily recognizable name for the output file, and use the name of our GPG file as a value for decrypt. We’ll enter the passphrase we specified when we created the keys, and we’ll have our new decrypted version of the file. Of course, since the original happens to be sitting in the same directory in our case, that’s not all that useful. But you can see how it would be if we’d received only the encrypted file through an Internet transfer. So that a real recipient can decrypt files you send them, we’ll have to know how to export and then import public keys.</p>
<p>To export your key, use gpg –export and the name you gave your key. Then pipe the key to a new file that should end with the .pub extension.</p>
<p>When he gets it, the recipient will have to import the key into his own GPG installation using gpg –import and the name of the file.</p>
<p>Of course, we’re not going to do that here since the key is already a part of our set. But this is how you would do it on a recipient system. We can view all of the public keys on a system using –list-keys.</p>
<p>Finally, there may be times when you’ll need to revoke existing GPG keys. Perhaps, for instance, a server where the public key has been compromised, and you can’t be sure that the key hasn’t fallen into unfriendly hands.</p>
<p>On a simple level, revoking is quite straightforward. You simply run –gen-revoke, followed by your key ID.</p>
<p>This will print some ASCII text which you should copy into a new file. This is something you can do at the time you create your keys in the first place.</p>
<p>In fact, considering that your own machine can be compromised, stolen or destroyed, it’s probably not a bad idea to keep your revoke text file somewhere safe. When you need to revoke the key, run gpg –import using the revoke text file as input.</p>
<p>Now, one last time, let’s review. To enable X11 connections, the value of the X11 forwarding setting in the host’s etc&#x2F;ssh&#x2F;sshd_config file must be yes, and the value of ForwardX11 in the client’s etc&#x2F;ssh&#x2F;ssh_config file must also be yes.</p>
<p>You open an xssh session using ssh -x. You generate GPG keys using gpg –gen-key supplying a username, a passphrase, and lots of noise in the background to provide food for the randomizing process.</p>
<p>You can decrypt files using gpg –output filename and –decrypt filename.gpg. You can export a key using gpg –export piping the output to a new file, and import a key to your system using gpg –import.</p>
<p>Gpg –list-keys will display the keys on your system. Gpg –gen-revoke followed by a key ID will output text that can then be used to revoke a key.</p>
<p>And gpg –import can be used to actually revoke a key. AWS has their own system for managing SSH key pairs.</p>
<p>From the EC2 dashboard, click on Key Pairs, then on Create Key Pair. Give your pair a name and click Create, and AWS will create the file with a .pem extension, and automatically offer you the option of opening or saving the file.</p>
<p>You might want to save it to your home directory so it will always be immediately available whenever you open your terminal.</p>
<p>You must edit the public key’s file permissions so that no one but the owner has access. If you don’t do this, you won’t be able to connect. Once you’re ready to access a resource, you use ssh followed by -i and the name of the .pem file, and then the resource address.</p>
<p>Bear in mind that AWS key pairs are tied to the region in which they are created. If you’d like to use a key pair that was created in one region to access, say, an EC2 instance that’s in a different region, it won’t work.</p>
<p>So that’s it. We really hope that this series of courses on Linux Server Administration has taught you a lot about the beauty and function of Linux, and has prepared you for both the LPIC-1 exams and for a career in Linux System Administration.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Networking-5-of-6-8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Networking-5-of-6-8/" class="post-title-link" itemprop="url">Linux-LPIC-102-LPIC-1-102-Linux-certification---Linux-Networking-5-of-6-8</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 01:11:51" itemprop="dateCreated datePublished" datetime="2022-11-19T01:11:51-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 21:24:06" itemprop="dateModified" datetime="2022-11-20T21:24:06-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LPIC-1-102/" itemprop="url" rel="index"><span itemprop="name">LPIC-1-102</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Networking-5-of-6-8/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Networking-5-of-6-8/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>This is the fifth of the sixth courses preparing you for the LPIC-1 Linux Server Professional certification exam 102. With this course we turn our attention to network management. We’ll learn about many of the basic of TCPIP, including configuring and maintaining effective IP addressing, network protocols and ports.</p>
<p>We’ll also learn about the IF config tool and it’s eventual replacement, IP, and learn to setup DNS client services, aliases and hosts. Finally, we’ll be introduced to some of Linux’s powerful network troubleshooting tools, like netstat, netcat and traceroute. Once you finish this course, there will be only one more to complete the LPIC-1 series, covering the hugely important topic of system security.</p>
<h1 id="Network-Addressing-Protocols"><a href="#Network-Addressing-Protocols" class="headerlink" title="Network Addressing Protocols"></a>Network Addressing Protocols</h1><p>Networking is about effectively identifying connected resources and controlling traffic between them, allowing what should be allowed and blocking what shouldn’t. Without accurate identification, reliable communications and secure routing would, of course, be impossible. TCP&#x2F;IP networks currently use one of two kinds of IP addresses for this identification, IPv4 and IPv6. IPv4 addresses, which are written in four numeric octets, each made up of numbers between 0 and 255, are divided into two sections, networks and nodes. The network section defines the address ranges a given network has available for individual devices like computers or smartphones, while the nodes section contains the endpoint addresses for these devices.</p>
<p>Since IP addresses can have different combinations of networks and nodes, we use network masks to communicate the format we’re using. Let me explain using an example. Here’s a sample IPv4 address.</p>
<h3 id="Network-addressing-with-IPv4-IPs"><a href="#Network-addressing-with-IPv4-IPs" class="headerlink" title="Network addressing with IPv4 IPs"></a>Network addressing with IPv4 IPs</h3><p>Let’s say that the first three octets, whose current values are 192, 168, and 0, are all going to be network addresses. And the final octet, the 1, is for nodes. This means that the network or, more accurately, the subnet, identified as 192.168.0 can have a theoretical maximum of 256 devices attached to it: 192.168.0.1, 192.168.0.2, 192.168.0.3 etc., all the way to 254 since 0 and 255 are normally reserved addresses.</p>
<p>Similarly, we could use 19.168.1 as an entirely different subnet able to assign device addresses between 192.168.1.1 and 192.168.1.254. The netmask to identify such a three-octet network will be 255.255.255.0. A zero always represents network nodes, while the 255s are notations representing networks. If we wanted to use only two octets as network addresses leaving the other two for network nodes, we would use a netmask of 255.255.0.0. This would allow more that 65,000 possible device addresses. That’s 256 squared, but limit us to only 65,000 possible subnets. Another way of describing such a network using CIDR, Classless Inter-Domain Routing notation, will be to add a slash 16 to the end of the address. In other words, keeping in mind that each octet is made up of 8 bits, 16 of the 32 total bits available will be network addresses, and 16 will be nodes.</p>
<p>Our earlier example, 255.255.255.0 could similarly be described as 192.168.0.0&#x2F;24. To make it just a bit more complicated, you can also reserve only part of an octet for network addresses. Suppose you know that you’ll never have more than a few devices attached to each of your subnets and you’d like to keep your options open for as many subnets as possible, you might want to reserve only, say, 128 nodes. In that case, you could define your subnet as 192.168.0.0&#x2F;28, where 28 is four bits higher than 24 and four lower than 32.</p>
<p>Incidentally, you can Google subnet calculator for helping figuring out the proper CIDR settings for your network.</p>
<p>Even though mathematically there are more than four billion usable IPv4 addresses available, the many billions of Internet-connected devices would by now have long exhausted the supply. The protocol that has kept us going for the past couple of decades of growth is the reserving of these three address ranges for private networks using NAT, Network Address Translation. NAT allows port forwarding of a single public facing IP address to be used to route incoming and outgoing traffic to many thousands of local devices that individually have no public face at all. Addresses within these three private ranges cannot be reached from the Internet, but they can be reused simultaneously within millions of private networks that don’t communicate directly with each other. IPv4 addresses are divided into classes. The value of the first octet of all Class A addresses will lie between 1 and 127. Class B addresses are between 128 and 191, and Class C falls between 192 and 223. If you’re still awake at this point, you’ll have noticed two interesting things. One, that those classes don’t cover the values between 224 and 256. This is because addresses above 223 are part of Class D and E ranges, which serve other functions. And two, that each of our three private NAT address ranges falls within a different one of the first three classes. I’m sure that there’s some very good architectural reason for this, but I’m afraid it’s beyond me.</p>
<h3 id="Network-addressing-with-IPv6-IPs"><a href="#Network-addressing-with-IPv6-IPs" class="headerlink" title="Network addressing with IPv6 IPs"></a>Network addressing with IPv6 IPs</h3><p>There’s a second solution to the problem of the diminishing supply of IPv4 addresses, IPv6. While IPv4 addresses are 32-bit, meaning they’re made up of four 8-bit octets, IPv6 addresses are 128-bit, meaning that there are two to the 128 possible addresses - enough to keep us going for a very long time. Once IPv6 is fully implemented, there’ll be no need for NAT addressing and avoiding address conflicts will be much simpler.</p>
<p>An IPv6 address is made up of eight hexadecimal numbers separated by colons. Multiple fields equaling zero can be represented by double colons. Therefore an address like this one could also be written this way.</p>
<p>Let’s review. IPv4 addresses consist of four octets divided between network addresses and device nodes. The netmask or the CIDR slash notation tells routing software which octets are for networks and which are for individual devices. You can reserve only some addresses within an octet for networks. Private net networks allowed no direct access to the Internet but have addresses in three ranges reserved for them. IPv6 addresses contain 32 bits in eight fields of hexadecimal numbers and therefore promise a virtually unlimited number of unique addresses.</p>
<h1 id="TCP-Networking"><a href="#TCP-Networking" class="headerlink" title="TCP Networking"></a>TCP Networking</h1><h3 id="Understanding-TCP-x2F-IP-networking-protocols"><a href="#Understanding-TCP-x2F-IP-networking-protocols" class="headerlink" title="Understanding TCP&#x2F;IP networking protocols"></a>Understanding TCP&#x2F;IP networking protocols</h3><p>In the previous video we learned about how IP addresses are used to identify network devices. While those addresses do point requests in the right direction, there are still two more things you’ll need to specify to ensure successful data transfers, the network protocol and network port. The network protocol defines how devices will communicate with each other, including how to establish connections, organize packets of data, and in some cases, how to compress or encrypt data. The three protocols the LPIC expects you to understand are TCP, UDP, and ICMP.</p>
<p>Perhaps the most common higher level protocol you will use is the Transmission Control Protocol TCP. In fact, the original Internet Protocol Suite, will often be referred to as TCP&#x2F;IP. Largely because of it’s built-in reliability, TCP is used to carry most web traffic, emails, and file transfers. Data is automatically broken down into small packets, transferred, and then reassembled at the target. TCP includes packet verification in its data stream deliveries.</p>
<p>For transfers that don’t require error checking, like streaming audio and video or VOIP, the quicker and connection-less User Datagram Protocol UDP is often used, while UDP has no delivery conformation or verification, it does provide checksums.</p>
<p>The Internet Controlled Message Protocol, ICMP, is a very simple way for network devices to quickly exchange some basic information. The ping tool uses ICMP to check if a host is online and available for connectivity. You point ping to an IP or DNS address and it will send small packages with a request that they be echoed back. ping will immediately report its results. Network ports allow a single IP address to be used for multiple purposes. They can also be used to make it harder for unauthorized users to gain access to your resources.</p>
<h3 id="Becoming-familiar-with-standard-and-non-standard-networking-ports"><a href="#Becoming-familiar-with-standard-and-non-standard-networking-ports" class="headerlink" title="Becoming familiar with standard and non-standard networking ports"></a>Becoming familiar with standard and non-standard networking ports</h3><p>There are, by accepted convention, three kinds of network ports. Well known ports, that we’ll explore in a minute; ICANN registered ports that have been reserved for specific commercial protocols; and dynamic ports that are available for anyone to use on an ad hoc basis. All well known ports fall between ports one and 1,023. ICANN registered ports can lie between 1024 and 49,151. Dynamic ports start at 49,152 and continue up to the highest port number, 65,535. You must be aware of these rules to avoid conflicts or security vulnerabilities. When you address traffic to a host using a non-standard port, they’ll need to specify the port after a colon that follows the address itself. If a single address is host to more than one service you may have to specify which service you’re after.</p>
<p>This host can be used for either HTTP or FTP access. Technically speaking you should have to add a port like 80 or 443 to web addresses that you visit, but your browser will usually do that for you invisibly.</p>
<p>As advertised, we’ll now look at some of the more common well known ports. The LPIC exam expects you to be familiar with the function of each of these. Port 20 is used for FTP file transfers, while 21 is for FTP data control. Port 22 is used by SSH, which is something you’ll definitely need to know if you plan to set up virtual private networks, VPCs, on Amazon’s AWS. 23 is used by Telnet, bear in mind that while Telnet is still useful for certain temporary and local functions it is inherently insecure and is not appropriate for most purposes. Port 25 is set aside for SMTP, the Simple Mail Transfer Protocol. 53, is a port used for domain name service, DNS. A fact that explains why AWS named its DNS service Root 53.</p>
<p>80, is for insecure HTTP traffic. The kind that for now at least makes up the majority of web traffic. There is currently a growing movement to convince all website administrators around the internet to switch their sites to secure HTTP or HTTPS, which as we’ll see in a minute uses Port 443. Port 110 is for the POP3 post office protocol for retrieving email messages over a TCP&#x2F;IP connection. 123 is used by NTP, Network Time Protocol. 139 is for NetBios, which controls local communications at the session layer. The Internet Message Access Protocol, IMAP, uses Port 143. IMAP, like POP3, allows for the retrieval of email messages. 161 is used by Simple Network Managing Protocol SNMP, a protocol for managing devices on IP networks. SNMP activity can be controlled by SNMP trap, which uses the next port up, 162. Port 389 is used for LDAP, Lightweight Directory Access Protocol. 443 is, as we mentioned earlier, for secure HTTP traffic and 465 is for Sysco’s URL Rendezvous directory. Port 514 when accessed using the UDP protocol is often monitored for system data by Syslog. Since UDP is unreliable its usage now recommends using TCP, supporting Transport Layer Security, TLS, on Port 6514. Port 514 can also be used over TCP for automatic authentication for shell session. Port 636 is used for secure LDAP using SSL. 993 is for secure IMAP, IMAP-S and 995 is for secure POP3.</p>
<h1 id="Network-Configuration"><a href="#Network-Configuration" class="headerlink" title="Network Configuration"></a>Network Configuration</h1><h3 id="Managing-network-interfaces-and-routes"><a href="#Managing-network-interfaces-and-routes" class="headerlink" title="Managing network interfaces and routes"></a>Managing network interfaces and routes</h3><p>Now that we’ve discussed network addressing and transfer protocols, we’ll have to learn how to configure and manage network interfaces and routes to ensure reliable connectivity. Most modern Linux distributions would do a pretty good job of automatically pointing a standard network interface device like an ethernet card to a DHCP server during the installation process. However, there will definitely be times when you’ll need a non-standard connectivity profile, and for that, you’re going to have to know both what to configure and how. First of all, it’ll be helpful to understand how Linux identifies network interfaces. Depending on the specific distribution you’re using, an ethernet interface might be called some variation of eth0, eth1, eth2, or em0, em1, and so on. While wireless interfaces are likely designated as wlan0 or wlan1. If you’d like to see which interfaces are currently active on your system, you could run ifconfig, or on newer systems, ip a. This shows us a device called eth0, its mac or hardware address, and IPv4 and IPv6 IP addresses. If the interface you’re looking for doesn’t show up, perhaps because something is keeping it from being loaded at boot time, you can search through dmesg greping for possible names. If you’re confident that your interface is properly configured, you can bring it up using either ifup or ip link set dev, which applies the set command to the object and type link specifying eth1 as the link and telling Linux to bring the device up. If your interface has not been configured, you can do that either from the command line, as we’ll see in a moment, or by editing a configurable file. On Ubuntu, for instance, the &#x2F;etc&#x2F;network&#x2F;interfaces file contains editable settings for each device. On Fedora, you’ll find individual files in the &#x2F;etc&#x2F;sys&#x2F;config&#x2F;network-scripts directory.</p>
<p>As I mentioned just before, you can also configure an interface directly from the command line. Using ip, you can add a static IP address and set its netmask using ip a add followed by the address, a slash, and then the netmask. In this case, that’s 255.255.255.0. You then specify the device name, eth1 in our case. Since I don’t actually have a device named eth1 in this system, this command will obviously fail. Assuming that eth1 did exist, you would now need to restart the interface using ip link set dev. If you’d like to shut an interface down, perhaps in order to change its configuration or to restart it if it’s not responding the way it should, you can use ip link set dev eth1 down. As we mentioned earlier, these last two functions can also be performed using a lot fewer keystrokes using ifup and ifdown. I would note that if you’re logged in remotely to a server through SSH, you’ve got to be very careful bringing interfaces up or down as it could easily kill your current session and force you to travel to the server to restart it.</p>
<p>Let’s review. ifconfig by itself will display information on all the network interfaces currently running on your system. ip a is a newer way of doing the same thing. ifup and ifdown or ip link set dev&#x2F;eth1 up or down will start or stop an interface.</p>
<h3 id="Configuring-network-routes-and-aliases"><a href="#Configuring-network-routes-and-aliases" class="headerlink" title="Configuring network routes and aliases"></a>Configuring network routes and aliases</h3><p>Interface information is kept in files like etc&#x2F;network&#x2F;interfaces on Debian systems and within the etc&#x2F;sysconfig&#x2F;networkscripts directory on others. You can use ip a add to set a value for a device from the command line. To be properly configured, a device needs an IP address and a subnet, both of which we’ve already discussed, but it also requires a default gateway router address so processes can find their way out of the computer and on to the wider network, and in some cases, an identifiable host name.</p>
<p>We’ll talk about both of those now. The route command will display the current system route table. In this case, we can see that the network gateway runs through 10.0.31 using eth0. If we wanted to manually change the default route, we would run the route add default command entering the IP address of the new route that we would like to use. GW, by the way, stands for gateway. Using ip, you would use route add default via followed by the new route IP address. If you’re trying to connect to a new router using DHCP, meaning you’d like the router to assign your computer a dynamic IP address, you might have to run dhclient from the command line to start that process off manually. dhclient, by the way, stands for dynamic host configuration protocol client. So that local processes and authorized network clients should be able to properly identify your computer, it should have a host name. This name, often the name you gave your computer during installation, is contained in a very simple file in the etc directory called host name. You can edit this file whenever you like, but you should also remember to update another file, &#x2F;etc&#x2F;host, which maps your host name to appropriate IP addresses. In this case, 127.0.1.1. You can add an alias name to the same line if you like. You can also add ip alias pairs to this file to make external connections easier. This example will make the letter G an alias for the IP address of Google.com. You can then simply run any local command, say, wget g and access the site. Finally, the etc&#x2F;nsswitch.conf file contains pointers to various system configuration files. It also tells you the order by which resources will be consulted by the system. So in our case, the system is looking for a mac address known here as ethers. We’d first look through a DB (files like &#x2F;etc&#x2F;passwd or &#x2F;etc&#x2F;shadow are considered DBs for this purpose), and then through system files. The “compat” method, will sync entries in a file like passwd by following inline instructions (usually a leading + or - sign).</p>
<p>Let’s do some review. Route will display your current routing information, while route add default gw or ip route add default via will edit it. dhclient can be used to manually establish your computer as a DHCP client. The &#x2F;etc&#x2F;hosting file contains your system’s host name, and &#x2F;etc&#x2F;host maps DNS names and aliases to IP addresses. The etc&#x2F;nsswitch.conf file points to various kinds of configuration data.</p>
<h3 id="Working-with-AWS-Virtual-Private-Clouds-VPCs"><a href="#Working-with-AWS-Virtual-Private-Clouds-VPCs" class="headerlink" title="Working with AWS Virtual Private Clouds (VPCs)"></a>Working with AWS Virtual Private Clouds (VPCs)</h3><p>Now is probably a good time to take a quick look at Amazon Web Services Virtual Private Clouds, VPCs. VPCs are AWS’s primary networking architecture and are designed to help you effectively and securely manage all a project’s compute resources. Any traffic moving within a VPC or to or from any external networks must successfully pass through a number of layers before it can reach its target, starting from the outer edge as an Internet gateway, which must be referenced by a route table before allowing anything through. Route tables in turn can be connected to individual subnets, whose access is controlled by access control lists, ACLs. Once past an ACL into a subnet, traffic will still fail to reach a computer database instance unless it’s allowed by the rules of that instance’s security group. And of course, as we’ve seen, you can further take advantage of various local security tools within an instance, which after all, is nothing more or less than a server.</p>
<h1 id="Network-DNS-client-side"><a href="#Network-DNS-client-side" class="headerlink" title="Network DNS (client side)"></a>Network DNS (client side)</h1><h3 id="Domain-Name-Service-DNS-mapping-IP-addresses-to-domain-names"><a href="#Domain-Name-Service-DNS-mapping-IP-addresses-to-domain-names" class="headerlink" title="Domain Name Service (DNS): mapping IP addresses to domain names"></a>Domain Name Service (DNS): mapping IP addresses to domain names</h3><p>As part of the last video we briefly discussed configuring a host name for your system. As we mentioned, host names make it possible to refer to individual computers by name without having to remember their IP addresses. If this is useful for your local system, it’s a thousand times more true for network resources. If you want to be able to use google.com in your browser or in scripts rather than having to remember its IP address, then you’ll need access to a good DNS server to perform your address translation for you. The first place we’ll have to visit is the &#x2F;etc&#x2F;resolv.conf file, resolv by the way is spelled without an E. This version contains only one of the two kinds of entries that are normally found. In our case it identifies two possible system name servers as 10.0.3.1 and 10.0.0.1, this means the DNS translation request will be sent to DNS servers on either of those two hosts.</p>
<p>In addition however you will often find a search entry which defines search domains to use for queries that don’t include their own fully qualified domain names. If for example there’s an entry search myplace.com in resolv.com, then searching for a simple text stream will return all matches from myplace.com. On Debian systems you can enter their DNS values in the appropriate entry from the &#x2F;etc&#x2F;network&#x2F;interfaces files. In this example we’re going to use 208.67.222.222 and 208.67.220.220, which are OpenDNS’s name servers. Host is a DNS lookup tool for converting domain names to IP addresses and IP addresses to domain names. We’ll use it to find out the IP address for gmail.com and the host name from my own systems IP address. DIG, which stands for domain information groper, will return much more information than host. The answer section in this dig operation shows us Gmail’s a record.</p>
<p>If there was an authority section in this response, it would contain the DNS name server with authority over this name. DIG also shows us some stats associated with this particular request. In case DIG is not installed by default on your system you can, at least on Debian systems, download it as part of the DNS Utils package. On first glance the getent tool might seem a bit redundant, running getent with passwd for instance, will return all the entries found in the local &#x2F;etc&#x2F;passwd file, but then running cat &#x2F;etc&#x2F;passwd would do exactly the same thing.</p>
<p>Why do we need a separate command like getent? I believe the real value of getent is in the fact that it will even return entries available only through network sources. Such as LDAP set ups.</p>
<h1 id="Network-Troubleshooting"><a href="#Network-Troubleshooting" class="headerlink" title="Network Troubleshooting"></a>Network Troubleshooting</h1><p>In previous videos from this course, we discussed how to identify, configure, and start network interfaces. Now it’s time to learn about troubleshooting connections when things don’t work. So we’ll assume that our interface shows up in dmesg, as it should, and that ifconfig or ip a reports that it has an appropriate IP address. We’ll also assume that the route command shows a working route to a live network gateway. But you’re still not sure that you’re properly connected. Does Linux offer any diagnostic tools? You bet it does. A whole whack of them.</p>
<h3 id="Using-ping-route-traceroute-tracepath-and-netcat-to-troubleshoot-Linux-network-problems"><a href="#Using-ping-route-traceroute-tracepath-and-netcat-to-troubleshoot-Linux-network-problems" class="headerlink" title="Using ping, route, traceroute, tracepath, and netcat to troubleshoot Linux network problems"></a>Using ping, route, traceroute, tracepath, and netcat to troubleshoot Linux network problems</h3><p>The first weapon you should pull out is the simplest, ping. As we’ve mentioned before, ping sends very small data packets to an address you specify, using the ICMP protocol, and requests that the packets are echoed back. When they are, then we’ll know two things: that the host you’re accessing is, in fact, available, but also that you have network connectivity, at least that far. You should first try an internet-based host, like Google.com. Or if you’re not sure you’ve got DNS service, and easy to remember IP address, like 8.8.8.8, which happens to be Google’s name server. If either of these work, then you’ll know that connectivity is not your problem. If they don’t work, then it’s time for plan B, identifying the shaky link in the network. You could try pinging your gateway address, meaning the address of the device, like a router linking you to the larger network. If you don’t know your gateway address, you can usually figure it out by looking at your own system IP address, using ifconfig or ip a.</p>
<p>In my case, if the IP address is 10.0.3.133, then the gateway is probably 10.0.3.1. You can run route to confirm this. Now let’s ping 10.0.3.1. If that works, then the problem most likely exists somewhere between the router and your internet provider.</p>
<p>If you can’t ping your router, then you should check the hardware connection, whether wired or wireless, that connects your PC to the router. It can’t hurt to confirm that the router is plugged in and powered on. Believe me, you wouldn’t be the first guy to miss that one. You can also use trace route against a network address to display information about each step packets take along their journey.</p>
<p>Traceroute, or its newer cousin, trace path will often show you exactly where connectivity breaks down. Incidentally, ping, traceroute, and tracepath all have special versions for handling IPv6 connectivity, called appropriately enough, ping6, traceroute6, and tracepath6.</p>
<p>Actually, getting your system ready for IPv6 can be a bit complicated, and is beyond the scope of the LPIC-1 exam. Now what if you’ve got all of the network and internet connectivity you need, but you’re having trouble accessing a particular host that’s supposed to be available. Or what if somebody’s having trouble accessing your service. You should test to make sure the necessary ports are open. From a different computer or network, you can use a terrific little tool called netcat.</p>
<p>While you should bear in mind that netcat, which can also be used as NC, is not at all secure, it can be used to create quick host client network connections for communications or even streaming files, but it can also be used to test for open ports. Here, we’ll run it with -Z and -V against Google.com to see if the http port 80 is open. If the port you need was not open, this test would fail and you’d be much closer to figuring out your problem.</p>
<p>You can also run netcat against a range of ports, but that can take a very long time. Netstat can check for listening and non-listening sockets, to confirm that the sockets you need are accessible. Finally, netstat -s can show you a really useful diagnostic data for each network protocol.</p>
<p>Let’s review. You can use ping to test for connectivity to specified hosts, route to display your gateway address, trace route or trace path to track packets along their network journey, netcat to check for open ports, and netstat to check for listening and non-listening sockets. You should be aware that ping6, traceroute6, and tracepath6 are all versions of those tools, meant for IPv6 systems.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-System-Services-4-of-6-7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-System-Services-4-of-6-7/" class="post-title-link" itemprop="url">Linux-LPIC-102-LPIC-1-102-Linux-certification---Linux-System-Services-4-of-6-7</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 01:11:50" itemprop="dateCreated datePublished" datetime="2022-11-19T01:11:50-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 21:20:34" itemprop="dateModified" datetime="2022-11-20T21:20:34-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LPIC-1-102/" itemprop="url" rel="index"><span itemprop="name">LPIC-1-102</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-System-Services-4-of-6-7/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-System-Services-4-of-6-7/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hi and welcome to the 9th course in Cloud Academy’s Linux Certification Preparations series. This course will cover Linux systems services, part of the requirements for the LPIC 102 exam. We’ll learn some of the basics of managing email accounts and directing email messages to individual and alias accounts. Although we won’t actually go into the process of configuring an email server, that’s not required for the LPIC 1 exams. We’re going to learn how to maintain an accurate system time for the computers you manage and how to sync your systems to Internet time through NTP, the network time protocol. We’ll explore the Linux logging system. You can, and in fact, must closely monitor your system performance and security through your log files, but you’ll also need to maintain the logs themselves, especially to make sure that log files don’t become unmanageably large.</p>
<p>And finally we’ll learn how to use the common Unix printing system, CUPS, to manage your printers and print jobs.</p>
<h1 id="System-time"><a href="#System-time" class="headerlink" title="System time"></a>System time</h1><p>Back in the localisation lecture from our Linux administration course, we discussed maintaining accurate timezone settings on Linux systems through the usr&#x2F;share&#x2F;zoneinfo, etc&#x2F;timezone, and etc&#x2F;localtime files. Here we’re going to discuss a critically important task of maintaining an accurate system time. While it’s always nice to know that the time displayed in the clock at the corner of your desktop is accurate, this will be especially important when you’re managing applications that require resource coordination across a network or over the Internet. If even one node is set to an incorrect time, you can expect to experience some really weird behavior.</p>
<h3 id="Controlling-Linux-system-clocks-using-hwclock"><a href="#Controlling-Linux-system-clocks-using-hwclock" class="headerlink" title="Controlling Linux system clocks using hwclock"></a>Controlling Linux system clocks using hwclock</h3><p>First of all, however, we’ll need to distinguish between two separate and often contradicting computer time values, the hardware clock and system time. The hardware clock, also known as the real-time clock or RTC or the bias clock or the CMOS clock, is a time and date setting maintained in your motherboard’s firmware and is often powered even when a system is off by a CMOS battery. While such a steady value is a necessary element of the boot process and basic hardware operation, it’s not particularly reliable.</p>
<p>It can quickly fall out of sync with more accurate network time sources. For that reason, your operating system will usually make use of system time, which ideally is continually updated from a network time protocol or NTP server. You can display your current hardware time with hwclock -r. hwclock –hctosys will take the current hardware time value and apply it to the system clock. Of course, you can also do the opposite. That is, apply the system value to the hardware time using hwclock –systohc. This can be useful to update a hardware clock value that’s fallen far out of sync with your network adjusted system time.</p>
<p>Remembering which of these two command arguments will set which value can be a bit confusing, but I’m afraid that the LPIC exam will simply expect you to know it. You can also set your hardware clock with either coordinated universal time, UTC, which is more or less simply changeable with Greenwich Mean Time, or local system time. hwclock –UTC or –localtime will control that setting, although either way, hwclock -r will continue to display a local time.</p>
<p>Finally, you can set the hardware time and date using hwclock –set –date following this format.</p>
<p>Let’s review what we’ve seen so far. Computers keep time in two ways, through the hardware clock and through system time. You can control the hardware clock with hwclock. -r displays the current time. –hctosys will apply the hardware time to the system time. –systohc will apply the system time to the hardware clock. –UTC tells a hardware clock to use coordinated universal time, while –localtime applies a local time. hwclock –set lets you manually set the time.</p>
<h3 id="Using-NTP-to-manage-your-Linux-system-time"><a href="#Using-NTP-to-manage-your-Linux-system-time" class="headerlink" title="Using NTP to manage your Linux system time"></a>Using NTP to manage your Linux system time</h3><p>When accurate timekeeping is important, you want to make use of an NTP server through the ntpd daemon. If you don’t need to install full NTP connectivity but want to manually update your time, you could use ntpdate from the command line. This can especially helpful for mobile devices that might not have regular access to real-time servers. ntpdate is also useful as a preparation for full NTP configuration to make sure that your current time isn’t too far off from the official value. In some cases, if you haven’t got an NTP server configured and assuming that you’re running a Debian-based Linux distribution, you may want to use ntpdate -debian, which will by default poll the ntp.ubuntu.com server. Since ntpd generally won’t be installed by default, you can run your distribution’s package manager to bring it on board. Let’s make sure that the service is actually running. ntpq will print out a list of peers currently available to NTP.</p>
<p>Now let’s take a look at &#x2F;etc&#x2F;ntp.com to make sure everything is configured the way we like. The entries that interest us most right now are the server lines. Each of these defines a single upstream NTP server, which our system will query for the current time. You’ll notice that each of the servers in our configuration is part of the pool.ntp.org system. Now will be a good time to explain what that’s all about. NTP servers are arranged in layers, each of which is called a stratum. An NTP server that gets its data directly from a time producer like the US Naval Observatory in Bethesda, Maryland, is considered stratum 1. A server that gets its data from a stratum 1 server is known as stratum 2 and so on until stratum 15. To make sure that too many NTP clients can’t overwhelm a single stratum 1 server, it’s highly recommended that you tell your client to make its request from a pool of servers. The pool will automatically distribute requests among its servers by random distribution.</p>
<p>By default, Ubuntu installations will point to ubuntu.pool.ntp.org servers, which you could replace with the address of local network NTP servers or other offsite servers that are nevertheless accessible to you with lower latency. Our configuration also provides a non-pool fallback server, in case pool servers are inaccessible. Many admins will also add a local hosting address for this setting. The drift file that might sometimes be found in &#x2F;var&#x2F;lib&#x2F;ntp is interesting as it contains a number that’s the result of tracking the milliseconds that your local time might have drifted from your time server over the past while. This can be useful for software with built-in algorithms compensating for potential discrepancies.</p>
<h3 id="NTP-and-slewing-stepping-and-insane-time"><a href="#NTP-and-slewing-stepping-and-insane-time" class="headerlink" title="NTP and slewing, stepping, and insane time"></a>NTP and slewing, stepping, and insane time</h3><p>There are three more terms you’ll really want to understand, slewing, stepping, and insane time. When NTP updates your clock, it’ll first check to see how far up it’s drifted from the true time. If it’s more than 128 milleseconds off, NTP will correct the time in relatively large steps called stepping. If the difference is smaller than 128 milliseconds, then NTP will make its adjustments in smaller gradients using the process called slewing. If your system time is more than 1024 seconds off, then it’s considered to be using insane time, and NTP will ignore this as source of accurate time.</p>
<p>Let’s review. You can update your system time using ntpdate or ntpdate-debian. ntpq will display available peers. The NTP settings are kept in the &#x2F;etc&#x2F;ntp.com file. Ideally we connect to a server that’s close to a stratum zero server with as low a latency connection to us as possible and part of a traffic distributing pool. &#x2F;var&#x2F;lib&#x2F;ntp can contain a numeric record of a historic drift between our system and a time source. Slewing is the process of gradually adjusting the time that’s not too far from the true time. Stepping is the process of more quickly making that adjustment using larger steps, and insane time is a system time that’s more than 1024 seconds off.</p>
<h1 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h1><p>Whether you are trying to figure out what keeps making your system crash, whether hackers have found their way inside, or why your PHP code isn’t working, logs can contain the answers you’re looking for. In this video, we’ll learn about some of the more common Linux system logs and how to configure them so that their precious data will be available when you need it. Most Linux logs will live in or below the &#x2F;var&#x2F;log directory.</p>
<h3 id="Configuring-and-managing-Linux-logs"><a href="#Configuring-and-managing-Linux-logs" class="headerlink" title="Configuring and managing Linux logs"></a>Configuring and managing Linux logs</h3><p>As you can see, there are log files specific to many system functions like boot, and on this Fedora system, Yum. How log messages are handled is on systems using systemd controlled by the journald service. You can query the contents of the systemd journal using journalctl. If you want to go right to the end of the file, which can be very long, add -e. You can also use journalctl to manage the journal files.</p>
<p>Journalctl –diskusage will tell you how much space the files are currently using. You can edit journal behavior through the &#x2F;etc&#x2F;systemd&#x2F;journald.conf file. System max use and system max file size will, for instance, control how large your system files will be allowed to grow. The logger tool is something that on first glance may seem a bit a silly. Using logger on the command line, you can manually send the text screen to a log file you specified, but since you are the one writing it, why would you need a record? Like anything else on Linux, whatever you do from the command line can also be done as part of a script. So imagine that you’ve written a script that executes some process. Since you may not be around when a script is ran to find out whether, say, the process exceeded or not, inserting a logger line into the script can create a record that will include not only your text string, but the process ID, user, and a timestamp.</p>
<p>Using -p , you can specify a facility name. Meaning, the name of the target log file, and level name, like alert, crit, and warn. This command will send this message to the printer log as an alert.</p>
<p>These are the valid facility names along with their numeric equivalents. And these are the valid level names.</p>
<p>Since just about everything that happens on a Linux system will generate log entries, you can easily imagine how the logs themselves can grow. I’ve seen log files approaching terabytes in size. You don’t want to lose any important data, but you also don’t want your drives to be choked by older logs. The accepted solution is to rotate your log files at set times, with older files being permanently deleted or moved into archive storage. Log rotation is controlled by a file in the etc directory called, appropriately enough, logrotate.conf. In this case, most logs will be rotated every week with expired files being kept for three weeks after that. As we can see, once a log is rotated out, meaning it is renamed with a suffix based on the current date, a new entry file will be created to receive new messages in its place. Files can also be compressed to save space.</p>
<p>The truth is that not all logs are controlled from logrotate.conf. Note the reference to the &#x2F;etc&#x2F;logrotate.d directory. That’s where the RPM package manager drops configuration files for the logs associated with its packages. The include statement pointing to this directory in logrotate.conf will ensure that these config files are read.</p>
<h3 id="Log-files-on-systemd"><a href="#Log-files-on-systemd" class="headerlink" title="Log files on systemd"></a>Log files on systemd</h3><p>Distributions not yet using systemd will often use syslog or rsyslog to control logging. Older Ubuntu systems, for instance, will have a file named etc&#x2F;rsys slash log.conf to control many logging parameters. That file also points to configuration files in the etc&#x2F;rsyslog.d directory that control log behavior. Syslog -ng is another logging control system that adds functionality like content-based filtering and TCP network transfers. On some systems, klogd will control kernel message prioritizing. The LPIC expects you to be aware of these alternate non-systemd systems.</p>
<p>Let’s review. Most log files are kept in the &#x2F;var&#x2F;log directory. Journalctl can be used to read entries in the systemd journal. Journal behavior can be controlled from the &#x2F;etc&#x2F;systemd&#x2F;journald.conf file. Logger will send a text message to a log file. Logger -p can specify facility and level names. You can control log rotation through &#x2F;etc&#x2F;logrotate.conf. Finally, you should be aware of alternate logging systems like syslog, rsyslog, syslog -ng, and klogd.</p>
<h3 id="Managing-logs-on-AWS-with-CloudWatch-and-CloudTrail"><a href="#Managing-logs-on-AWS-with-CloudWatch-and-CloudTrail" class="headerlink" title="Managing logs on AWS with CloudWatch and CloudTrail"></a>Managing logs on AWS with CloudWatch and CloudTrail</h3><p>Now we’ll talk just a bit about logging on AWS. The Amazon CloudWatch service allows you to monitor system activity from multiple resources. You can configure CloudWatch to track and generate alarms based on your usage metrics from your AWS account resources, or even monitor and manage the traditional log data produced by Linux instances running on EC2. Amazon’s CloudTrail tracks and records all API calls received by your AWS resources. CloudTrail logs are saved to Amazon’s Object Storage Service, S3. As these logs grow in size, you can rotate and archive them in much the same way we do with logrotate, using S3 bucket versioning accompanied by life cycle rules that archive older logs to Glacier, Amazon’s cheaper long-term storage service.</p>
<h1 id="Mail"><a href="#Mail" class="headerlink" title="Mail"></a>Mail</h1><p>Despite many earnest predictions over the years, email use doesn’t seem to be in any serious danger of disappearing any time soon. And despite the fact that just about everyone uses sophisticated web-based email servers like Gmail, there’s still plenty of demand for locally configured email services. That’s why the LPIC still requires that you’re at least generally familiar with the four main MTA packages: qmail, Postfix, Sendmail and Exim. Even though qmail is not currently maintained and Exim by reputation isn’t as secure as the others, they’re among those found in active deployments. MTA, by the way, stands for mail transport agent.</p>
<h3 id="Managing-email-on-Linux"><a href="#Managing-email-on-Linux" class="headerlink" title="Managing email on Linux"></a>Managing email on Linux</h3><p>The fact is that while there are many MTA programs available for Linux, for the most part, they’re all functionally quite similar. In fact, I believe that they all share a common mail framework, Mailutils. Don’t think that there aren’t significant differences in policy and behavior between these packages, but they’re certainly not important for the LPIC exam. As it happens, we’re going to work with Postfix, Ubuntu’s default MTA. We’ll assume that both the Postfix and mailutils packages have been installed. To send mail from the command line, you use, “sendmail -t” and the name of the recipient. Since in my case Postfix is configured to only work locally, I’ll send it to a local user, Tony. You could include a subject line using “Subject:”, and then as many lines of text as you need. To save and send your email, type a period on an empty line.</p>
<p>Let’s switch users and become Tony to see if the mail has arrived. By the way, all mail messages are kept in files in the &#x2F;var&#x2F;mail directory. You can also use aliases to address emails. A mail alias is really just a name that can be invoked to send a single email to multiple recipients. You can create a new alias by editing the &#x2F;etc&#x2F;aliases file. By default, you’ll generally already have one existing alias, Postmaster, that is mapped to the root user. Let’s add a new alias, Developers, which would include all the developers working for our company. To initialize the mail database, we’ll need to run “newaliases.” Now let’s send an email to the whole group.</p>
<p>To make sure it worked, we’ll switch users to a different user and check his mail. Well, that worked. By the way, on a normal system you obviously shouldn’t be doing quite so much poking around in user accounts. These are all fictional accounts on this LXE virtual machine I created especially for this video. If there is a guy named Frank on my system, I certainly haven’t met him.</p>
<p>Besides alias groups, you can also create automatic email forwarders using a “.forward” file in your home directory.</p>
<p>Let’s create one for Frank. Notice the dot before the file name. This adds the file attribute, “hidden.” We’ll now add an email recipient to the file, say, Ubuntu, and log out of Frank’s account and into Tony’s. There we’ll fire off a quick email to Frank, log back into Frank’s account to see if there was any mail. Nothing. Now we’ll exit a few shells until we get back to Ubuntu and check for new mail there. And he’s got new mail, just as we expected.</p>
<p>You should also be aware of the mailq command, which will list all pending messages still waiting to be sent. Our queue is currently empty.</p>
<p>Let’s review. You can send email using sendmail adding “-T” and the recipient address. Emails are stored in files in &#x2F;var&#x2F;mail. You can add an alias group to the &#x2F;etc&#x2F;aliases file and initialize the mail DB using “newaliases.” You can create a mail forwarder for an individual user by creating a “.forward” file in his home directory. And mailq will display all emails currently pending.</p>
<h3 id="SES-Amazon’s-SMTP-email-service"><a href="#SES-Amazon’s-SMTP-email-service" class="headerlink" title="SES: Amazon’s SMTP email service"></a>SES: Amazon’s SMTP email service</h3><p>Like just about everything else, Amazon also does email. AWS has an industrial strength SMTP server for large volumes of outgoing mail called SES, simple email service. SES can handle key tasks like message authentication and programming APIs.</p>
<h1 id="Printers"><a href="#Printers" class="headerlink" title="Printers"></a>Printers</h1><h3 id="Using-CUPS-to-manage-Linux-printers"><a href="#Using-CUPS-to-manage-Linux-printers" class="headerlink" title="Using CUPS to manage Linux printers"></a>Using CUPS to manage Linux printers</h3><p>Along with printers themselves, the way Linux manages printing has evolved over the last 20 years. We’ll look at the command line printing tools a bit later, but these days your primary connection to printer drivers and configuration comes through CUPS, the Common Unix Printing System, and your primary CUPS interface works through a browser via the address local host:631. Oddly enough, the CUPS package is managed by Apple. Yes, that Apple. Most Linux distributions have graphic software tools to manage printing, but they’re really just front ends to the CUPS server. The main CUPS configuration file, &#x2F;etc&#x2F;cups&#x2F;cupsd.conf can be viewed and edited in the command line, but it is also accessible through the Edit Configuration File link in the admin tab.</p>
<p>The admin tab also provides links to help you add and manage printers, and manage print jobs. Clicking on add class allows you to create and manage printer classes. A printer class is a group of printers that are all equally accessible. When a job is directed to the group, it’ll be sent to the first available printer.</p>
<h3 id="Managing-printers-from-the-Linux-command-line"><a href="#Managing-printers-from-the-Linux-command-line" class="headerlink" title="Managing printers from the Linux command line"></a>Managing printers from the Linux command line</h3><p>Should the need arise, you can actually print from the terminal either existing files or command line text itself. The good news is that the LP program draws its settings from your CUPS configuration and knows all about your printer and its drivers. Once again, if you’re not sure why you’d ever want to print from the command line, just remember that Bash scripts can come will all kinds of strange use cases. But even better, it can be a really fun way to scare the daylights out of some guy dozing off at his workstation a few offices down.</p>
<p>At any rate, you can print using LP or LPR followed by a filename. If you’ve got more than one printer associated with your computer, you can specify it by adding a -d switch followed by the name of the printer driver. This is a driver from my Brother laser printer. You can also print directly from the command line by leaving the filename out altogether. You enter the text you’d like printed on subsequent lines and complete the job with control+d.</p>
<p>To view the jobs pending in your print queue, use LPQ or lpstat. The jobs we just created are still in the queue because my printer happens to be turned off right now. If you’d like to delete a print job, note its job number from LPQ and use LPRM. To remove all jobs in the queue, type the minus sign in place of a job number. Running LPQ again shows us that the queue is now empty. You can use LPQ and LPRM to work with all system print jobs even those launched from GUI applications.</p>
<p>As is true of pretty much all Linux processes, your first front line tool for troubleshooting print jobs or printer drivers that aren’t working the way they should is logs. While the most current printer log files are available from the CUPS browser console, if you need to see older, backup versions, you’ll need to go to the &#x2F;var&#x2F;log&#x2F;cups directory. The two log types we’re interested in are access log and error log. Incidentally you can quickly view the older compressed .gc backup files without having to actually decompress them by using zcat or zless. If you want your printer to reject all new jobs sent to it, you can use CUPS reject.</p>
<p>If you want to open the printer up to new jobs, use CUPS accept. Let’s review. The Common Unix Printing System accessible through local host:631 is a browser interface for managing printers, printer classes, and jobs. You can also control your printer from the command line. LP and a filename will print a file.</p>
<p>LPQ will display the print queue. LPRM will delete a print job. Print-related logs are kept in the &#x2F;var&#x2F;log&#x2F;cups directory. CUPS reject will reject new jobs, and CUPS accept will reopen the printer to new jobs.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Linux-LPIC-102-Creating-an-EBS-Backed-Linux-AMI-6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/Linux-LPIC-102-Creating-an-EBS-Backed-Linux-AMI-6/" class="post-title-link" itemprop="url">Linux-LPIC-102-Creating-an-EBS-Backed-Linux-AMI-6</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 01:11:48" itemprop="dateCreated datePublished" datetime="2022-11-19T01:11:48-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 20:10:04" itemprop="dateModified" datetime="2022-11-20T20:10:04-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LPIC-1-102/" itemprop="url" rel="index"><span itemprop="name">LPIC-1-102</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Linux-LPIC-102-Creating-an-EBS-Backed-Linux-AMI-6/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Linux-LPIC-102-Creating-an-EBS-Backed-Linux-AMI-6/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Linux-LPIC-102-Expanding-EBS-Volumes-on-Linux-Instances-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/Linux-LPIC-102-Expanding-EBS-Volumes-on-Linux-Instances-5/" class="post-title-link" itemprop="url">Linux-LPIC-102-Expanding-EBS-Volumes-on-Linux-Instances-5</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 01:11:47" itemprop="dateCreated datePublished" datetime="2022-11-19T01:11:47-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 20:09:16" itemprop="dateModified" datetime="2022-11-20T20:09:16-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LPIC-1-102/" itemprop="url" rel="index"><span itemprop="name">LPIC-1-102</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Linux-LPIC-102-Expanding-EBS-Volumes-on-Linux-Instances-5/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Linux-LPIC-102-Expanding-EBS-Volumes-on-Linux-Instances-5/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Administration-3-of-6-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Administration-3-of-6-4/" class="post-title-link" itemprop="url">Linux-LPIC-102-LPIC-1-102-Linux-certification---Linux-Administration-3-of-6-4</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 01:11:46" itemprop="dateCreated datePublished" datetime="2022-11-19T01:11:46-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 21:18:12" itemprop="dateModified" datetime="2022-11-20T21:18:12-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LPIC-1-102/" itemprop="url" rel="index"><span itemprop="name">LPIC-1-102</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Administration-3-of-6-4/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Linux-LPIC-102-LPIC-1-102-Linux-certification-Linux-Administration-3-of-6-4/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>In this rather brief course, we’re going to explore some basic but critical Linux administration tasks. We’ll talk about organizing and protecting system resources through <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/lpic1-linux-administration/users-and-groups/">managing user accounts and groups</a>.</p>
<p>We’ll become familiar with the system files that track user and group configurations as part of that process.</p>
<p>We’ll also learn how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/lpic1-linux-administration/job-scheduling/">schedule</a> regular or one-time tasks so they can be reliably executed even if you’re not around to set them off. And we’ll see how the computers you administrate can be optimized for your particular geographic region by setting the proper time zone and system <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/lpic1-linux-administration/localisation/">localization</a> variables. Let’s get started.</p>
<h1 id="Users-and-Groups"><a href="#Users-and-Groups" class="headerlink" title="Users and Groups"></a>Users and Groups</h1><h3 id="Managing-Linux-user-accounts"><a href="#Managing-Linux-user-accounts" class="headerlink" title="Managing Linux user accounts"></a>Managing Linux user accounts</h3><p>Managing users and groups on your system is about as basic an administration task as you can imagine. So you may wonder why it took the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/lpic1-linux-administration/introduction-4/">LPIC</a> exam objective so long to get here. The answer? I haven’t a clue, but since we’re here, we might as well get the job done. We’re going to talk about managing both user accounts and groups, and also the system files to track user group configurations.</p>
<p>We’ll begin by using useradd to create a new user account. We use -m to tell Linux to create a new directory in the &#x2F;home directory, which by default will be given the same name as the user.</p>
<p>And Terry is the name we’d like to give this user account. That’s it. But if we leave it there, the account might not be very useful since it doesn’t yet have a password. For that, we’ll use the passwd command. Note that for some reason that there is no O or R in the command name, it’s passwd.</p>
<p>Passwd will prompt you to enter a new password once, and then a second time to ensure that you haven’t mistyped. There are other arguments you can add to the useradd command. -e will set a date by which the account will automatically expire. -G will add the new user to an existing group. You will often use -G sudo to add the user to the sudo group, assuming, of course, that he’s going to be an admin. -p allows you to add a password without the need to run passwd later. Note though that you can only add encrypted passwords using this argument. -s will specify the user’s default log in shell if you don’t want the system default to apply, and -u allows you to manually specify a user ID.</p>
<p>Naturally, there are many more arguments that are documented in the useradd command file. Removing the user is done through userdel, user delete. Adding the -r argument will also remove the user’s home directory along with his mail spool if there is one.</p>
<p>Usermod will, as the name suggests, modify a user’s account settings. Usermod -m and -d create a new home directory for an existing user. -e will set or change an account expiry date, while dash -G will change the status of the user’s group membership. That is to say if the user is not yet a member of the specified group, he’ll be added. If he is already a member, he will be removed. -l will allow you to change the log in name for your user. Dash -L will lock password access to an account preventing the user from using his password to log in. Dash -U will unlock the account, re-enabling the original password. Speaking of expiry dates, you can also control account best before dates directly from the command line using change age or C-H-A-G-E. chage –list Max, for instance, will return the time until Max’s account expires, which is never in this case, but also the current controls in his password when it was last changed, when it will expire, and then the minimums and maximums you’ve set for creating new passwords.</p>
<p>There’s obviously a security concern with users who keep old and usually weak passwords for years, so change age allows admins to force users to step up their game. You can set the minimum number of days between password changes using change age -m, followed by the number of days and the user name. Running change age with uppercase M as an argument will set the maximum number of days before a new password is required. Change age with -W will set the number of days before password expires that a user will receive a warning message. In this case, the default is already seven.</p>
<p>You may wonder why this kind of control is necessary. After all, we’re talking about accounts on a single computer. Just how many users are there likely to be? This might be a point if we’re talking about people sitting down in front of most home PCs, but for set ups where users need to log in via secure shell, SSH, remote sessions, it’s a different story. In that context, it shouldn’t surprise you to learn that it’s quite common for server profiles to host remote visits from all kinds of developers and admins. Properly organizing and securing their accounts is therefore a significant concern.</p>
<p>Let’s review. You can create a new user with a new home directory using useradd -m. Adding -g will allow you to add the new user to a group. -p lets you set up an encrypted password. -s will specify which shell the user will use, and -u allows you to manually set the user ID. You can add a regular password with passwd followed by the username. Userdel will delete the user. You can use usermod -m to change a user’s home directory, -e to set an account expiry date, -g to add the user to or from a group, -l to change his log in name, -L to lock the password, and -U to unlock the password. Change age –list will list the user’s account limits. -n and a numeric value will set the minimum time for password change. Dash -M will set the maximum time, and -w will set the warning time.</p>
<h3 id="Working-with-Linux-groups"><a href="#Working-with-Linux-groups" class="headerlink" title="Working with Linux groups"></a>Working with Linux groups</h3><p>Let’s discuss groups. Groups are treated by your system pretty much the same way as users, but their function is a bit different. When you create a group, you assign permissions over specific system resources, but that by itself is meaningless because groups never do anything on their own. Rather, by adding system or logging users to a group, they are automatically given all the powers of the group. To take an example we’ve already seen, when the user joins the sudo group, he or she is allowed all the administrative powers that come with sudo.</p>
<p>Interestingly, Amazon’s AWS controls resource access for users enrols in very much the same way through identity and access management IAM groups.</p>
<p>The Linux groups tool kit works a lot like the useradd and usermod commands. Groupadd will create a group. Groupdel will remove or delete an existing group, and groupmod will modify a group’s values. -n, for instance, allows you to change the group’s name. You enter the new name immediately after -n, and then the name of the existing group.</p>
<h3 id="Using-Debian’s-adduser-and-deluser-rather-than-useradd-and-userdel"><a href="#Using-Debian’s-adduser-and-deluser-rather-than-useradd-and-userdel" class="headerlink" title="Using Debian’s adduser and deluser rather than useradd and userdel"></a>Using Debian’s adduser and deluser rather than useradd and userdel</h3><p>While the LPIC wants you to understand the workings of useradd and groupadd and their command families, you should also be aware that Debian distributions, which include Ubuntu, also use the variants adduser, deluser, and addgroup. These commands are more than just the old useradd and userdel with different names. They’re much more simple to use. So for instance, adduser and addgroup will automatically create ID values in line with Debian policies, and adduser will automatically create a home directory for the new user, populated with your system scale for configuration, which we’ll discuss a bit later, and require that you create a password right then.</p>
<p>Nonetheless, don’t lose sight of the fact that the LPIC exam will only deal with the more universal useradd. And either way, useradd and its friends work on all Linux systems. Finally, let’s explore some of the files Linux uses to store user and group profiles. The &#x2F;etc&#x2F;password file contains key information on each user on the system. Considering that on currently any virtual LXC container that really only exists for demonstration purposes, there do seem to be a few more users than you’d expect. Most of these like daemon, bin, and sys are actually system users. You can tell them apart from regular users by their user IDs called UID. System users will have IDs below 1000, while regular user IDs are usually 1000 and above.</p>
<p>The &#x2F;etc&#x2F;shadow file, which requires admin permission to view, also contains information on regular and system users, but it’s different information. Primarily for our purposes, shadow contains an encrypted version of the user’s password and any date restrictions on his account. &#x2F;etc&#x2F;group contains basic information about all current groups including the group ID, GID, and a list of all members. You can manually add a user to a group by editing this file and adding the user name to a group. Just remember not to insert any space in the line because that will mess things up royally. You can display information from these files using the get end get entry command. This example will politely ask getend to read the password file and display the entry for the user Ubuntu.</p>
<p>We mentioned the skeleton directory a little bit earlier, so we should perhaps give it some flesh and explain just what it is. If you’d like every new user to automatically be created with certain common files and directories in his home directory, you can place them in the &#x2F;etc&#x2F;skel directory. Copies of any files down there will be placed in new users’ directories ready for use.</p>
<p>Let’s review what we’ve seen. Groupadd will create a new group, groupdel will delete a group, and groupmod -n followed by new name and then the existing name will change its name. The &#x2F;etc&#x2F;passwd file contains basic user data like user IDs. &#x2F;etc&#x2F;shadow contains encrypted versions of user passwords, and &#x2F;etc&#x2F;group contains information about all system groups. Getend displays data directly from any of its user data files, and the &#x2F;etc&#x2F;skel directory contains files you’d like to be automatically included with new user home directories.</p>
<h1 id="Job-Scheduling"><a href="#Job-Scheduling" class="headerlink" title="Job Scheduling"></a>Job Scheduling</h1><p>While you can certainly execute a Linux process directly from the command line or through a script, there will definitely be times when that’s not practical. Perhaps, for instance, you’d like to make sure that your server data is backed up late each night at a time when no one is likely to be logged in and working, for when you yourself are planning to be comfortably sleeping in bed or perhaps you just want to make sure that the regular backups actually happen and aren’t forgotten.</p>
<h3 id="Scheduling-Linux-tasks-with-cron-and-at"><a href="#Scheduling-Linux-tasks-with-cron-and-at" class="headerlink" title="Scheduling Linux tasks with cron and at"></a>Scheduling Linux tasks with cron and at</h3><p>Whatever the need, unattended jobs can easily be scheduled using either the cron system or the At command. But first we’ll talk about cron. The key file holding the whole thing up is crontab, which lives in the &#x2F;etc directory. crontab is basically a script that regularly checks the cron.daily, cron.weekly, and cron.monthly directories, all of which exist in &#x2F;etc for their own scripts. As you can easily guess on your own, scripts that have been saved to cron.daily are supposed to be run each day. Those in cron.weekly are to be run each week, and cron.monthly scripts are to be run once a month.</p>
<p>If you’d like your script to run once a day and you’re not particular exactly when it’s run, then you’d simply save the script to the &#x2F;etc&#x2F;cron.daily directory, make sure it’s executable using change mode, and crontab will do its magic from then on. Let’s take a closer look at the contents of my crontab file. You’ll notice that the first line is commented out with the hash symbol, but it provides the column headers. The first column, therefore, represents how many minutes into the hour you’d like the command that follows to execute. In the case of the first command, that would be 17 minutes. The second column, H, describes in which hour of the day you’d like it to happen. The second through fourth lines will all take place in the sixth hour of the day, but our first command, because it contains a star, will execute in the 17th minute of every hour of the day. DOM stands for Day of the Month. Again, the star means that it will happen every day. The MON column sets the month, and, again, the star tells cron that it should happen in every month. And the final scheduling column sets the day of the week, meaning even if you set the command to execute on every calendar day of the month, it will only happen if the calendar day happens to fall out on a specified day of the week.</p>
<p>As you can see, the cron.weekly job will only execute on day seven, which is Sunday. Note, by the way, that crontab expects minutes in an hour to be numbered from 0 to 59, hours in a day from 0 to 23, days of the month from 1 to 31, and days of the week from 0 to 6. In this last case, however, Sunday can be represented by either zero or seven.</p>
<p>Now let’s look at the commands themselves. In each case, the system will CD to the root directory, and run all the files in the indicated directory using run-parts. The –report parameter will output the results of the command. The final three lines will first test for the existence of executable status of the anachron file. Only if it does not exist will it then run the files in &#x2F;etc&#x2F;cron.daily, weekly, and monthly.</p>
<p>Although the LPIC exam in its current form doesn’t yet require this, you should probably be aware that crontab functions can now also be performed on computers running systemD by systemD timers.</p>
<p>You can’t completely understand the cron system without awareness of a few other configuration files. The files found in the &#x2F;etc&#x2F;cron.d directory, for instance, work much the same way as crontab entries, but they also have a user field, populated by Root in this case. This is because cron.d scripts are run as a particular user, rather than automatically as Root.</p>
<h3 id="Working-with-anacron-jobs"><a href="#Working-with-anacron-jobs" class="headerlink" title="Working with anacron jobs"></a>Working with anacron jobs</h3><p>Finally, the &#x2F;etc&#x2F;anachrontab file is the configuration file for Anacron. Anachron runs regular jobs pretty much the same way that cron does, but it doesn’t assume that your computer will always be on. So if, for example, you have a regularly scheduled cron task that’s meant to run in the middle of the night, but you often turn your computer off for the night, then cron won’t be very helpful for you. To deal with this, the Anacrontab file doesn’t offer you the option of scheduling tasks for specific times during the day, but rather once daily, weekly, or monthly. Anacron will take care of the rest. Each line in the Anacrontab includes two columns of numbers. The first number is the number of days between executions. One, obviously, would indicate that the job is to be executed each day, and seven that it should be run every week. The at monthly value is a special value indicating one execution per month.</p>
<p>The second column tells Anacron how long to wait after a system boot before executing the command. The third column is the job identifier, and the final column contains the command line itself, which, in this case, is no different from what we found in the crontab file.</p>
<p>It’s time to review what we’ve seen so far. Scripts can be executed on a schedule set in the &#x2F;etc&#x2F;crontab file, schedules are set by minute, hour, day of the month, month, and day of the week. Scripts found in the cron.daily, cron.weekly, and cron.monthly directories are traditionally executed either through crontab or the &#x2F;etc&#x2F;anacrontab file, which runs jobs a set time after system boot. Jobs associated with specific users besides Root can be executed through the &#x2F;etc&#x2F;cron.d directory.</p>
<p>Now let’s discuss At. If you need to run a process just once, but you’re not going to be around to start it manually, you can use the At command to schedule it. I should note that At is not always installed by default, but can be added to your system using apt-get install at.</p>
<p>At is set up in two stages. You must first set the time you’ll want the job to run, and then the job details themselves. Scheduling is actually completely intuitive. Your scheduling command begins with the word at, which can be followed by an execution time that’s relative to the current time. So, for instance, you can type in now plus 30 minutes, which will start the process exactly 30 minutes from now. You can also use absolute local system times like 1430 meaning 2:30PM, which will run the command the next time the system clock hits 1430, whether that’s today’s 1430 or today’s 1430 has already passed, tomorrow. Plain English expressions will also work. Thus, at noon will run at 1200 hours. At midnight, at 0000 hours, and at tea time, believe it or not, will run at 1600 hours, which is when those under the influence of her Britannic Majesty’s Commonwealth take their mid afternoon break. At will also understand 2:00PM tomorrow or 5:00PM today.</p>
<p>Now that we know how to set the schedule, let’s create an actual job. We’ll use at 1330 to order up a job for 1:30 this afternoon. Now, we’ll simply type a command, say, a script located in my home directory called logrotate.sh. You can hit enter if you’d like to add another line of code or, when we’re done, control+d to finish the job configuration. Now, if nothing changes and, assuming that my computer will actually be running at 1:30, my script will be executed.</p>
<p>We can list all pending jobs with their ID numbers using at q. And we could remove a job using at rm, followed by the job’s ID. Batch works much the same way as At, but will only execute if the system load levels permit it. Not that I suspect you ever would, but be careful not to confuse our Linux batch with the old DOS batch file scripts, which of course weren’t nearly as much fun.</p>
<p>The directories in &#x2F;var&#x2F;spool&#x2F;cron are where pending at or crontab jobs belonging to regular users are kept. We’ll need to be sudo to enter these directories, so I’ll run sudo su. You can control which users can submit At jobs through the at.allow, or at.deny files in the etc directory. at.allow is a white list, meaning that if it exists, then only those users listed will be permitted to use At. If at.allow does not exist, then the at.deny file will act as a black list, preventing any user listed from using At, permitting everyone else. You can see that my at.deny file contains a long list of mostly system users, but all normal users are not blocked. The cron.allow and cron.deny files provide similar control access for cron jobs.</p>
<p>Let’s review the At command. You first schedule a job using relative time designations like now plus 20 minutes or now plus 2 hours, or absolute designations, like today at 2:30PM, noon, or 1445. Once you’ve scheduled a job, you can enter just about any command or list of commands on the command line, and hit control+d to finish. At Q will list all currently pending jobs, while at rm and the job ID will delete a pending job. At or crontab jobs belonging to regular users are kept in &#x2F;var&#x2F;cron, and access to the At or cron systems can be controlled through the at.deny, at.allow, cron.deny, and cron.allow files.</p>
<h1 id="Localisation"><a href="#Localisation" class="headerlink" title="Localisation"></a>Localisation</h1><p>Whether you are responsible for an application server hosting Internet services or a PC designed for local use, part of your job as an administrator is to make sure your system settings are appropriate for your users and geographic location. In this video, we’re going to learn how to identify and manage your system time zone settings and how to make sure your environment variables known as your locale properly reflect your needs.</p>
<h3 id="Managing-system-time-zones-in-Linux"><a href="#Managing-system-time-zones-in-Linux" class="headerlink" title="Managing system time zones in Linux"></a>Managing system time zones in Linux</h3><p>We’ll start with your time zone settings. Your current system time zone is stored in the &#x2F;etc&#x2F;timezone file. In my case, I’m in the American region, and within that, Toronto. You can also see that by running the date command, which displays the full current date and time. All the data for all available timezone is stored in the user share zone info directory. You can CD into the particular region, like America in my case, and find the file matching your zone. If the time zone setting is wrong or if your trans-continental flight is just landing and you want to keep your laptop in the loop, you can update it by creating a symbolic link linking the &#x2F;etc&#x2F;localtime file to the appropriate file in this directory. In my case, it would look like this. Alternatively, you can run tzselect and work through the menus to select your location. There’s currently a bug affecting the tzselect on some systems. The alternative is to run sudo dpkg-reconfigure tzdata to have the same effect. A third method is to directly edit the &#x2F;etc&#x2F;timezone file. The LPI-C wants you to know about the time date CTL program, which controls time and time zone settings for Linux distributions running system D. As you can see, time date CTL by itself will display some useful information. You should be aware, however, that not all timedatectl features - like set-time or set-timezone - will necessarily work on all systems. If timedatectl isn’t available by default on your computer, you can install it to Debian-based systems like Ubuntu and Mint, using apt-get install systemd-services.</p>
<p>To review, the &#x2F;etc&#x2F;timezone file contains your current time zone setting files in the user share zone info directory or present all available time zone locations. You can set the value of your &#x2F;etc&#x2F;localtime file by linking to it from a file and user share zone info, or you can set your zone using tzselect. timedatectl manages time zones for systemd machines.</p>
<h3 id="Managing-Linux-system-locales"><a href="#Managing-Linux-system-locales" class="headerlink" title="Managing Linux system locales"></a>Managing Linux system locales</h3><p>Now let’s look at system locales. Where you live in a world, will often determine how you visually represent all kinds of things, including the way you spell certain words, display dates in short form, or even numbers in currency so that your system software should be able to more effectively respond to your specific needs. Linux needs to set environment variables either globally or for specific use categories. To list your current environment variables, you can run locale. The first value is LANG, L-A-N-G, which when populated, will override all other values. In my case, the language of LANG is set to English, the country to Canada, CA, and the character encoding is UTF 8.</p>
<p>Currency, numbers including decimals and dates will all be displayed according to Canadian standards, whatever those are. I believe that the default paper size of LC underscore paper refers to letter format, which is slightly different than the A4 size popular in Europe. LC measurement would refer to Canada’s metric system as opposed to various versions of imperial units. By the way, there are a number of alternative character encoding settings besides UTF 8, including ISO 8859 and the very simple but absolutely reliable ASCII. Locale -a will display all available locale settings. Using C as a value for LANG can be very useful in some server scripting environments as it provides an environment that’s very compatible with syntax from the C programming language, the language with which most operating systems were written.</p>
<p>That pretty much takes care of identifying the values you’ve got right now, but we’ll also need to know how to change them. Environment values are kept in the user bin locale file. But since that’s a binary file, they can’t be edited. You could use export to set a particular value for this shell session only. However, once you log out or reboot, you’ll find yourself back to your original default. One way to change the default value is to edit the locale file that’s in the &#x2F;etc&#x2F;default directory.</p>
<p>Let’s review. The locale command will display your current local settings. The LANG equals value, if populated, will override all other locale values. LANG equals C will set your environment to emulate the C language as closely as possible. Export will change your locale settings for the session, and the contents of &#x2F;etc&#x2F;default locale determines the system default values.</p>
<p>While we’re on the topic of locale, there’s a very annoying bug I’ve noticed when running an Ubuntu virtual machine instance on Amazon’s AWS. While executing certain operations like package management, you sometimes face a locale cannot set LC all to default locale, no such file or directory error. This won’t usually be a big deal, that it can be easily resolved although I can’t understand why it happens in the first place. To fix the problem, first make sure that the locale you’d like to use is available by running locale gen. Then edit the &#x2F;etc&#x2F;environment file so that it includes an LC all equals line with your particular locale choice.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/20/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/20/">20</a><span class="page-number current">21</span><a class="page-number" href="/page/22/">22</a><span class="space">&hellip;</span><a class="page-number" href="/page/274/">274</a><a class="extend next" rel="next" href="/page/22/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
