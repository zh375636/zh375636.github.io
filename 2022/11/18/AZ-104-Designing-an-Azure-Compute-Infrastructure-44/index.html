<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="IntroductionWelcome to “Designing an Azure Compute Infrastructure”. My name’s Guy Hummel and I’ll be helping you with the compute aspects of architecting an Azure solution. I’m the Azure Content Lead">
<meta property="og:type" content="article">
<meta property="og:title" content="AZ-104-Designing-an-Azure-Compute-Infrastructure-44">
<meta property="og:url" content="https://example.com/2022/11/18/AZ-104-Designing-an-Azure-Compute-Infrastructure-44/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:description" content="IntroductionWelcome to “Designing an Azure Compute Infrastructure”. My name’s Guy Hummel and I’ll be helping you with the compute aspects of architecting an Azure solution. I’m the Azure Content Lead">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-19T00:22:47.000Z">
<meta property="article:modified_time" content="2022-11-22T15:40:36.000Z">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/2022/11/18/AZ-104-Designing-an-Azure-Compute-Infrastructure-44/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>AZ-104-Designing-an-Azure-Compute-Infrastructure-44 | Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AZ-104-Designing-an-Azure-Compute-Infrastructure-44/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AZ-104-Designing-an-Azure-Compute-Infrastructure-44
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 20:22:47" itemprop="dateCreated datePublished" datetime="2022-11-18T20:22:47-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 11:40:36" itemprop="dateModified" datetime="2022-11-22T11:40:36-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AZ-104/" itemprop="url" rel="index"><span itemprop="name">AZ-104</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AZ-104-Designing-an-Azure-Compute-Infrastructure-44/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AZ-104-Designing-an-Azure-Compute-Infrastructure-44/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Welcome to “Designing an Azure Compute Infrastructure”. My name’s Guy Hummel and I’ll be helping you with the compute aspects of architecting an Azure solution. I’m the Azure Content Lead at Cloud Academy and I have over 10 years of experience with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn and send me a message, or send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>.</p>
<p>This course is intended for people who want to become Azure cloud architects.</p>
<p>To get the most from this course, you should have a general knowledge of IT architecture.</p>
<p>We’ll start with how to design solutions using virtual machines. Then I’ll go over Azure Backup and Azure Site Recovery, two essential services for business continuity and disaster recovery. Next, we’ll get into serverless computing, especially Azure Functions. After that, I’ll explain how to design microservices-based solutions. Then we’ll cover how to design web solutions using Azure App Service and other supporting services. Finally, I’ll show you how to run compute-intensive applications, especially with Azure Batch.</p>
<p>By the end of this course, you should be able to design Azure solutions using virtual machines, serverless computing, and microservices; design web solutions using Azure App Service; and run compute-intensive applications using Azure Batch.</p>
<p>We’d love to get your feedback on this course, so please give it a rating when you’re finished.</p>
<p>Now, if you’re ready to learn how to get the most out of Azure’s compute services, then let’s get started.</p>
<h1 id="Azure-Virtual-Machine-Availability-and-Scalability-Solutions"><a href="#Azure-Virtual-Machine-Availability-and-Scalability-Solutions" class="headerlink" title="Azure Virtual Machine Availability and Scalability Solutions"></a>Azure Virtual Machine Availability and Scalability Solutions</h1><p>Virtual machines have gone from being revolutionary to being a standard part of nearly every organization’s infrastructure. Now containers are the revolutionary technology, but VMs are still very important. Virtual machines give you full control over not only the software that you want to run but also the operating system. This is especially useful when you’re migrating existing servers to the cloud. When you use VMs to run mission-critical applications, you need to architect the solution so that it will keep running even if there’s a hardware failure, a system update, or a spike in demand.</p>
<p>First, let’s look at high availability, which means that an application will continue to run even if there’s a hardware failure or another event that would normally cause the application to go down. Microsoft offers a few different services to help with high availability. The first one is called an availability set. Microsoft doesn’t recommend using availability sets anymore because they have better offerings now, but I’ll still tell you about them because you’ll likely still see references to them.</p>
<p>An availability set is a group of virtual machines that’s designed to handle both planned and unplanned VM downtime. Planned downtime is when Azure updates the infrastructure underlying your VMs, and this update requires a reboot of the VMs. Unplanned downtime is when a VM goes down unexpectedly, such as when it has a critical hardware failure.</p>
<p>To handle planned downtime, an availability set groups its VMs into what are called update domains. Azure will only perform planned maintenance on one update domain at a time. That way, while the VMs in a particular update domain are being rebooted, the VMs in the other update domains will keep running. You can configure up to 20 update domains when you create an availability set.</p>
<p>Unplanned downtime is handled in a similar way by using fault domains. Each fault domain has a separate power source and network switch. This limits the downtime caused by hardware failures. For example, if there’s a power failure in one fault domain, the VMs in the other fault domains should keep running because they don’t use the same power source. The maximum number of fault domains you can use depends on the region where your VMs reside. In many regions, the maximum is three, but in some, it’s only two.</p>
<p>Each VM is in both an update domain and a fault domain. Azure will distribute your VMs into these domains automatically. To qualify for Microsoft’s 99.95 percent uptime guarantee under its service level agreement, you need to have at least two VMs, at least two fault domains, and at least two update domains. </p>
<p>Using availability sets will give your applications a high level of availability, but they won’t protect against a data center failure. That’s where availability zones come in. They’re an alternative to availability sets. An availability zone is a physically separate zone within an Azure region. So, if one zone goes down, the other zones will likely stay up. Not every region offers availability zones, but in the ones that do, there are always three of them.</p>
<p>To take advantage of this capability, you should deploy multiple replicas of your application’s VMs in different availability zones. You can specify a particular availability zone when you create each VM.</p>
<p>However, even this level of redundancy won’t protect you against an outage that affects an entire region. Regional outages aren’t common, but they can happen. So, if you need higher availability than a single region can provide, you’ll have to use multiple regions. In most cases, it’d be sufficient to simply back up your VMs to another region. Then if the region where your VMs are deployed goes down, you can temporarily bring up replacement VMs in the second region by using your backups. If you can’t tolerate almost any downtime, then you could have VMs running in the backup region all the time.</p>
<p>When choosing a backup region, you should take into account regional pairs. Nearly every one of Azure’s regions is paired with another region. Some <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> services replicate their data across regional pairs if you choose certain options. For example, if you choose the geo-redundant storage option for an Azure Storage account, then your data will be replicated to the paired region.</p>
<p>Virtual machines don’t replicate across regional pairs, but you should still consider storing your VM backups in the paired region. That’s a best practice because Microsoft tries to ensure that at least one region in each pair is available. In the event of a multi-regional outage, Microsoft will prioritize the recovery of one region in each pair, so your safest option for a backup region is the paired region.</p>
<p>All right, now that we’ve covered availability, let’s move on to how you can configure your application to handle spikes in demand. This is referred to as scalability.</p>
<p>The simplest way to scale is to switch an individual VM to a larger size. This is known as vertical scaling. It’s easy to do, but there are limits to that approach. Horizontal scaling, on the other hand, is when you scale by adding more VMs. It’s more complicated to scale horizontally, though.</p>
<p>First, you need to architect your application so it can run across multiple identical machines. Ideally, you should make that tier of your application stateless. That is, the VMs should not store any data locally. Otherwise, the application wouldn’t scale well because client requests would be tied to particular VMs. So the application should save data in a shared external datastore.</p>
<p>Next, you need to create a scale set. This is similar to an availability set because the VMs are distributed across fault domains and update domains, but you can do a lot more with it.</p>
<p>You can configure a scale set to automatically increase or decrease the number of VMs in it according to rules you define. For example, you can create a rule that says if the average CPU usage goes above 80%, then add 3 more VMs. You can also use disk and network metrics in your rules. If you need to scale based on guest operating system metrics, such as available memory or number of processes, then you can enable the diagnostics extension. This will even let you use custom metrics based on something specific in your application logs. </p>
<p>You’ll also usually want to set limits on how far a scale set can scale up or down by configuring a maximum and minimum number of VMs. Considering that a scale set can have up to 1,000 VMs in it, setting a maximum is a good idea. Note that if you’re using custom VM images rather than Azure’s standard images, then the maximum is 600 VMs per scale set.</p>
<p>By default, a scale set is deployed in a single zone. This is called a zonal scale set. But for the ultimate in availability and scalability, you can deploy a scale set across availability zones. This is called a regional scale set. It evenly distributes VMs across the three availability zones in a region. This distribution happens both when you create the scale set and also when it automatically adds or removes VMs during scaling operations. As you can see, combining scale sets with availability zones gives you the best of both worlds.</p>
<p>And that’s it for virtual machine availability and scalability.</p>
<h1 id="Azure-Backup-and-Azure-Site-Recovery"><a href="#Azure-Backup-and-Azure-Site-Recovery" class="headerlink" title="Azure Backup and Azure Site Recovery"></a>Azure Backup and Azure Site Recovery</h1><p>Most Azure customers also have on-premises infrastructure, so Microsoft’s cloud services usually work with local resources as well. This is especially true for business continuity and disaster recovery. For example, Azure Backup doesn’t just back up Azure VMs—it also backs up on-premises VMs and servers. What I find surprising, though, is that in some cases, it even stores the backups on-premises. That’s a pretty unusual feature for a cloud service.</p>
<p>Do you know what else is unusual? If you search for Azure Backup in the Azure portal, it won’t find a service with that name. That’s because Azure Backup is integrated with various other products and services rather than being a separate service of its own.</p>
<p>As you can see, Azure Backup has a rather complicated set of components for different scenarios. I’ll go through the highlights.</p>
<p>Azure Infrastructure-as-a-Service VM Backup is the most straightforward component. As the name implies, it only backs up Azure VMs. Once a day, it backs up each VM’s disks, including application-aware snapshots. It stores the backups in a Recovery Services vault, which is also on Azure. All three of the other components provide some mix of Azure and on-premises options.</p>
<p>The Azure Backup Agent supports both cloud-based and local VMs, as well as physical servers. However, it only supports Windows, and you have to install the agent on every virtual and physical machine you want backed up. It will handle files, folders, and system state, but it’s not application aware. In fact, this is the only component that’s not application aware. It stores its backups in a Recovery Services vault. Confusingly, the Azure Backup Agent is usually referred to as the Microsoft Azure Recovery Services (or MARS) agent.</p>
<p>System Center DPM can basically back up anything except Oracle workloads. For example, it can back up Linux VMs on Hyper-V and VMware. You have three choices for where to store your backups: a Recovery Services vault, locally attached disk, and even tape (which is an on-premises only option).</p>
<p>Azure Backup Server is almost the same except it doesn’t require a System Center license and it doesn’t support tape backup.</p>
<p>Note that both System Center DPM and Azure Backup Server use the Azure Backup Agent to send data to Azure.</p>
<p>To enable backups for an individual Azure VM, you just select Backup from the Operations menu for that VM and click the Enable Backup button. This is really easy, but what if you want to enable backups on all of your VMs? It would be a pain to have to do this manually for each VM and you might forget to enable backups on all of them, especially when you add new VMs.</p>
<p>A much easier way is to create a Recovery Services vault and then set a backup policy there. It will list all of the VMs you have in the same region as the vault, so you can enable backups for all of them at the same time. It only applies to VMs in the same region, though, so if you use multiple regions, you’ll have to create a Recovery Services vault in each one.</p>
<p>Speaking of regions, if you want your Recovery Services vault to survive a regional outage, then it needs to be configured to use geo-redundant storage. Luckily, that’s the default. If you want, you can change it to locally-redundant storage to save money, but if there’s a regional outage where your vault resides, then you won’t be able to recover your data.</p>
<p>When you want to back up on-premises data to Azure, one potential problem is the huge quantity of data that would need to be transferred over your network connection to Azure for the initial backup. One of the best ways to deal with that problem is to use the Azure Import&#x2F;Export service. This allows you to ship physical disks to Microsoft, so they can be uploaded to Azure directly.</p>
<p>Another potential issue is related to installing the Azure Backup Agent. During installation, you need to register the machine. This involves downloading the vault credentials into the agent and also setting an encryption passphrase. It is very important that you save this passphrase somewhere secure. When you’re restoring a backup, you need to provide the vault credentials and the passphrase. If necessary, you can download the vault credentials again, but if you lose the passphrase, then your backup will be unrecoverable.</p>
<p>OK, let’s move on to the Site Recovery service. Its purpose is to get you up and running again as quickly as possible in the event of an outage. It does this by failing over to another location. Once again, this service handles both Azure and on-premises servers. It supports three failover scenarios: Azure to Azure, on-premises to Azure, and on-premises to secondary site.</p>
<p>Replicating between Azure regions is pretty straightforward, but replicating between an on-premises site and either Azure or a secondary site is more complicated, so I’ll give you an overview of those.</p>
<p>These scenarios are further subdivided based on whether you’re replicating physical servers, VMware servers, or Hyper-V servers. To support physical or VMware servers, you need a Configuration server that manages replication, a Process server that sends the replication data to Azure, and a master target server that handles replication data during failback. You also need to install a Mobility service on each server that needs to be replicated.</p>
<p>If you’re replicating to a secondary site, then you need the same components, but the Process server is in the primary site and the Configuration and Master target servers are in the secondary site.</p>
<p>The architecture for Hyper-V replication is simpler. You install the Azure Site Recovery Provider and Recovery Services agent on each Hyper-V host or cluster node. If you’re using the System Center Virtual Machine Manager (or VMM), then that’s where you need to install the Site Recovery Provider. If you’re replicating to a secondary site, then you have to use VMM.</p>
<p>There’s a matrix of supported operating systems for the replicated machines in each of the scenarios. For physical servers, the replicated machines must be running a minimum of Windows Server 2008 R2 with at least SP1. VMware servers must be running at least vSphere 5.5 or vCenter 5.5. Hyper-V servers must be running at least Windows Server 2012 R2, although guest VMs on Hyper-V only need to be running Windows Server 2008 R2 or higher.</p>
<p>In the event of an outage, you have 6 different options for which recovery point to failover to. Latest is the default. This would give you the lowest recovery point objective because it’s the latest recovery point. Considering that, you might be wondering why you wouldn’t always use this option. Well, it has the disadvantage that it delays the failover because it has to process all of the latest data that it received and turn it into a recovery point.</p>
<p>An alternative is to choose Latest processed. This ignores all of the unprocessed data, so the failover happens very quickly. This gives you a much lower recovery time objective, but a higher recovery point objective, because it doesn’t use the latest recovery point.</p>
<p>The next 3 options are all variations of this one since they all ignore unprocessed data. They are Latest application-consistent, Latest multi-VM processed, and Latest multi-VM application-consistent, which is a combination of the previous two. Finally, you can choose a custom recovery point.</p>
<p>And that’s it for this lesson.</p>
<h1 id="Designing-Solutions-for-Serverless-Computing"><a href="#Designing-Solutions-for-Serverless-Computing" class="headerlink" title="Designing Solutions for Serverless Computing"></a>Designing Solutions for Serverless Computing</h1><p>Serverless computing is a hot trend. The idea is that you don’t have to worry about the infrastructure, such as virtual machines, underlying the service because the service takes care of that for you. Although there are a wide variety of Azure services that do this for you, such as the Bot Service and Stream Analytics, the one that people usually mean when they say “serverless” is Azure Functions. That’s because with Azure Functions, you can write almost any kind of code that you want executed and the service will do the rest. It’s more of a general-purpose serverless environment than the others.</p>
<p>Azure Functions is event-driven. In other words, your code will only run when it’s triggered by a certain event. For example, if you need to process images as users upload them to a Blob storage container, then you can use the BlobTrigger to execute your image processing code. There are triggers for events occurring in many other Azure services as well, such as Event Hub, Service Bus, and Cosmos DB. Triggers don’t always come from other services, though. For example, with the HTTPTrigger, you can call your function from an application by sending an HTTP request to it. Yet another possibility is to have your function run on a fixed schedule, such as every day at midnight, by using the TimerTrigger. A function can only have one trigger.</p>
<p>A trigger will include input data, such as the name of the new blob that fired the trigger. You can easily refer to this data in your code because Azure Functions automatically creates what it calls an input binding. This saves you the trouble of having to write code to connect to the input source.</p>
<p>You can also create your own input and output bindings, either in the Azure portal or in the function.json file. Bindings use a declarative syntax, so you don’t have to say how to connect to the data source or sink. You only have to give basic details about its type and where it is.</p>
<p>A typical function gets triggered, performs some simple operations, and then ends, but there are many cases where you would need to do something more complex. For example, suppose you need to run a sequence of functions in a particular order and the output of one function is the input for another function. You could do this by writing code to maintain state and orchestrate the execution of the various functions, but it would be much simpler to use Durable Functions. This is an extension to Azure Functions that lets you create orchestrator functions. This allows you to create workflows and call other functions synchronously and asynchronously.</p>
<p>Most functions don’t run continuously. They’re triggered when an event occurs and they only run briefly. That’s why the most common pricing plan for Azure Functions is the Consumption plan. Under this model, it allocates compute resources when the function is triggered and removes them when the function is finished. It even scales out to handle high loads. You only pay for resources when your function is running.</p>
<p>This works very well most of the time, but there are circumstances when you need to use an App Service plan. Under this model, your functions run on dedicated VMs. Here are some of the reasons why you might want to do this:</p>
<ul>
<li>Your function will run almost continuously. In this case, it would be cheaper to use dedicated VMs than pay-as-you-go.</li>
<li>Your function needs to run for longer than 10 minutes, which is the maximum allowed under the Consumption plan.</li>
<li>Or your function needs to run on Linux. The Consumption plan only supports Windows.</li>
</ul>
<p>Microsoft also provides a simpler service if you don’t want or need to write custom code. It’s called Azure Logic Apps. Like Azure Functions, it’s invoked using triggers. The difference is that the actions executed by Logic Apps are not written in code. For example, an action can send an email or push an item onto a queue.</p>
<p>With Logic Apps, you can create workflows visually in the Azure portal. For example, suppose you want to make a copy of every file that gets uploaded into a Blob storage container. First, you create a Logic App. Then you create a trigger. There are lots available, so it’s usually easiest to search for the one you need. I’ll type “blob”. This trigger gets invoked when a blob is added or modified, which is what we want. Then you have to select the container where the trigger will look for new or modified files.</p>
<p>Next, you add an action. You can either search for an action or narrow down the list by selecting the connector first. Then select the “Copy blob” action. Now paste the URL for your storage account. To get the path of the specific blob from the previous step, you can go over to the dynamic content list and select “Path”.</p>
<p>Then you put in the path of the container where you want the blob to be copied to. This time, we need to select the name from the dynamic content list.</p>
<p>That’s all you have to do. No coding required. Just save it and run it. Now whenever you upload a file to the source blob container, it will get copied to the destination blob container.</p>
<p>Logic Apps is integrated with lots of other Azure services, such as Event Grid and Machine Learning. It also has connectors for products and services from lots of other vendors, including everything from Twitter to Salesforce. It’ll even connect to on-premises servers, such as an Oracle database.</p>
<p>And that’s it for serverless solutions.</p>
<h1 id="Designing-Microservices-Based-Solutions"><a href="#Designing-Microservices-Based-Solutions" class="headerlink" title="Designing Microservices-Based Solutions"></a>Designing Microservices-Based Solutions</h1><p>Another revolution in software development is the move to microservices. Traditionally, applications have been written in monolithic fashion, where all of their various functions are tightly coupled in a single stack. The advantage of this approach is that it’s easy to manage a single, self-contained application. It also tends to have relatively high performance because the components inside the application communicate very quickly with each other.</p>
<p>But there are many disadvantages to this approach. The biggest one is that you can’t easily make changes to a monolithic application. If you need to make a change to a single component, then you have to retest and redeploy the entire application. That’s a big problem, especially if you’re trying to use an agile development methodology.</p>
<p>The microservices approach solves this problem by breaking an application up into numerous independent components. Then if you need to update a single component, you can do it without having to update all of the other components. This is only possible if you have a well-defined interface for calling that microservice. As long as you don’t make a breaking change to a microservice’s interface, then other microservices can continue to call it in the same way, even after an update.</p>
<p>Another advantage of microservices is that you don’t need to use the same programming language or supporting software for all of them. Since microservices communicate with each other through language-independent APIs (usually REST APIs), you’re free to choose whatever technologies you’d like to implement a particular microservice. It’s usually better to choose a few standard technologies, though, so you don’t end up with a patchwork quilt that’s difficult to support.</p>
<p>The biggest downside of the microservices approach is complexity. It’s harder to get a coherent view of an application when it’s so fragmented. These applications may also be slower since the services communicate with each other over longer distances and through more layers. This complexity makes management much more difficult. How do you handle deployment, monitoring, and availability when your application is spread out all over the place?</p>
<p>Luckily, there are some very good solutions. First of all, containers are almost a requirement for implementing microservices. Using VMs alone would be far too expensive and difficult to manage. Containers run on top of VMs and only include the software sitting on top of the operating system, so they’re smaller and can be deployed much more easily.</p>
<p>Azure provides several alternatives for creating and managing containers. The simplest is Azure Container Instances. If you want to deploy a single container quickly, you only need to specify a few details like the number of cores and the amount of memory. Container Instances will take care of the rest and spin up a container for you in seconds. It’s a pretty limited solution, though.</p>
<p>To implement microservices effectively, you need full container orchestration and scaling. Microsoft provides two alternative services for this: Azure Kubernetes Service and Azure Service Fabric.</p>
<p>Azure Kubernetes Service supports the popular open-source Kubernetes container-orchestration system.</p>
<p>Azure Service Fabric is Microsoft’s proprietary container orchestrator. It powers a wide variety of Microsoft services, including everything from Power BI to Cosmos DB.</p>
<p>Azure Service Fabric is quite flexible. Considering that it has Azure in its name, you might think that it only runs on Azure, but surprisingly, you can also run it on-premises on both Windows and Linux, and you can even run it on other cloud platforms like AWS. You can develop microservices that run on Service Fabric using any code you like. And you can develop both stateless and stateful microservices. It also provides application management and lifecycle capabilities. You can use it to deploy, monitor, and upgrade your applications.</p>
<p>When you start building microservices-based applications, you’ll quickly run into the problem of how to make these microservices accessible. Sure, you can create APIs for them, but should you let clients call those APIs directly? If you did, then the client code would have to know the architecture of your application, which would make it complex. Even worse, what if you decide to refactor your application? Would the client code have to change? Also, how would you handle security?</p>
<p>Fortunately, you can solve these problems by using Azure API Management. This service makes it easy to provide APIs that can be used by both internal developers and external partners and customers. It acts as a gateway between clients and your backend microservices. Not only does it provide an easily accessible front-end to your application, but it also handles important management tasks, such as security, monitoring, analytics, and rate limiting.</p>
<p>It’s easy to add an existing API to the API Management service. You only need to supply a few details, such as its name and URL. Then you can secure it and manage it. You can even transform your legacy APIs into modern ones that use REST.</p>
<p>And that’s it for microservices.</p>
<h1 id="Designing-Web-Applications"><a href="#Designing-Web-Applications" class="headerlink" title="Designing Web Applications"></a>Designing Web Applications</h1><p>If you need to deploy a web application that doesn’t have a microservices architecture, then Azure App Service Web Apps is usually the best way to do it. It’s a managed service, so you don’t have to worry about provisioning and maintaining the underlying infrastructure. It’s also very flexible because you can write your application in ASP.NET, ASP.NET Core, Java, Ruby, Node.js, PHP, or Python. Web Apps runs on Windows with IIS, but there’s also a Linux version that I’ll talk about later.</p>
<p>Setting up continuous integration and deployment is easy too because it’s integrated with Azure DevOps, GitHub, BitBucket, Docker Hub, and Azure Container Registry.</p>
<p>Another great feature for software developers and testers is deployment slots. Before you put a new version of an application into production, you’ll want to test it. With App Service, you can create a deployment slot called “testing” or “staging” and another one called “production”. Then you can test the new version of your application in the staging slot, and when you’re satisfied that it works, you can swap it with the production slot, and it will be deployed as the production version. If you discover problems after doing this, you can swap it again and the old version will be back in production. Deployment slots can really reduce the stress of upgrading your apps. This feature is only available in the Standard service tier and above, though. I’ll tell you more about the service tiers in a minute.</p>
<p>Although Web Apps take care of the underlying infrastructure, you do have control over how it scales. There are two ways to do this: scaling up and scaling out. Scaling up means adding more resources, such as disk space. You do that by choosing a higher App Service pricing tier. As you go up in service tiers, you can have more apps, more disk space, and more instances.</p>
<p>The number of instances is how you scale out. For example, in the Premium tier, you can have up to 20. To actually spin up extra instances, you can either do it manually or automatically. To do it automatically, you choose a metric, such as CPU Percentage, and set the App Service to autoscale if that metric reaches a particular threshold, such as 80%. When the average CPU percentage across all of the existing instances reaches that threshold, then App Service will add more instances. How many more is determined by the value you put here. This is a percentage, so if you set it to 25, then it will add 25% more instances when the CPU average hits 80%.</p>
<p>You should also set a rule that tells it to scale <em>in</em> when the CPU average drops below a certain level, so you aren’t wasting resources during quiet times. You can even have different rules for different levels. For example, you could tell it to scale by 25% if the CPU average reaches 60%, and by 40% when the CPU average reaches 80%.</p>
<p>By default, the autoscaling rules you set are always in effect, but you can run them on a schedule if you want. You can also have different rules in effect at different times.</p>
<p>Scaling isn’t the only way to increase a web application’s performance. Another way is to use Azure Redis Cache, which stores recently accessed data in memory. This is especially helpful for caching database records that get accessed multiple times. Another example is caching a user’s session information instead of always having to retrieve it from a cookie in the user’s browser. Getting data from an in-memory cache can significantly speed up web applications.</p>
<p>Another way to speed things up is to use a Content Delivery Network (or CDN). When you put static content from your website into a CDN, users can retrieve it from a nearby edge server rather than from your website. This also reduces the load on your web app. If your entire website is static, then you can serve it from a CDN without even having to deploy any compute resources, such as a web app or VM.</p>
<p>A CDN is especially useful for reducing latency in geographic locations far from where your web app resides. There are lots of other great uses for it too, like streaming videos or distributing firmware updates to IoT devices.</p>
<p>Autoscaling, Azure Redis Cache, and Azure CDN are complementary approaches to increasing performance. You can use all three at the same time to get the best results.</p>
<p>The next thing to look at to make your web app perform reliably is high availability. An Azure App Service Web App is only deployed in one region, so to ensure that it can survive a regional outage, you need to deploy a standby copy of the web app in another region. Ideally, you should deploy it in the region that’s paired with the first region. If there’s a major outage, Microsoft will prioritize bringing up at least one region in every pair.</p>
<p>Under normal circumstances, you’ll want all of your users to go to the web app in the primary region, but when there’s an outage, you’ll want to fail over to the secondary region. Azure Traffic Manager can handle this sort of requirement using priority routing, which used to be called failover routing.</p>
<p>If you have a database behind your web app, which is usually the case, then you’ll have to configure a failover solution for that as well. For example, if you’re using Azure SQL Database, then you’ll need to configure active geo-replication.</p>
<p>Even if you’ve set up a secondary region, you’ll still want to configure backups so you can recover from data corruption problems. You can create backups manually, but of course, it’s much better to automate them. It’s quite easy to do this in the Azure portal. You go into the Backup Configuration page for your app and tell it which storage container to use. To protect against regional failures, you’ll want to use geo-redundant storage. Then you turn on “Scheduled backup”, tell it how often to run the backup, when to start the schedule, and how long to retain the backups. If your app uses a database, you can enter the connection string and it’ll back that up too. The backup and restore feature is only available in the Standard service tier and higher.</p>
<p>Speaking of service tiers, let’s have another look at those. With the Free and Shared plans, your apps share VMs with other customers, so they’re only meant to be used for development and testing. The Basic tier is the first “real” tier, but if you scroll down, you’ll see that it’s missing a lot of really important features, like deployment slots, autoscaling, Traffic Manager, and backups. So you shouldn’t use it for apps that always need to be available.</p>
<p>While we’re here, I should mention what the “Always On” feature does. Normally, when a web app is idle for a period of time, it gets unloaded, which saves resources. If you need an app to stay loaded all the time, then you can enable “Always On”. The main reason to do this is if you have long-running background jobs.</p>
<p>The main advantage of Premium over Standard is that it provides 250 gig of disk space and up to 20 instances. You can go even higher than that with the Isolated tier. This gives you an isolated, dedicated environment. You’d use this if you need more than 20 instances or if you need secure network isolation or if you need instances with a high memory to CPU ratio.</p>
<p>There’s also an option to run App Service on Linux. It’s kind of confusing the way it’s shown in this chart because it looks like it’s separate from the other tiers, but in fact, you can choose from Basic, Standard, Premium, and Isolated for Linux too. You can’t choose Free or Shared, but that isn’t much of a loss. It does have a different feature set, though, which is why it has its own column in the table. In my opinion, the most important missing feature is Traffic Manager. Nonetheless, if you have an application that needs to run on Linux, then App Service for Linux will work very well.</p>
<p>So it’s easy to host web apps using Azure App Service. How about hosting web APIs? App Service makes that easy too. First, you create an API App in Azure App Service. Then you create a REST API using a development tool, such as Visual Studio. Once your code is ready, you push it to the Azure API App. In Visual Studio, you do this by clicking “Publish” and selecting the API App you created earlier. Your API is now hosted in App Service.</p>
<p>By the way, you don’t have to develop your API in .NET. You could develop it using Java, PHP, Node.js, or Python, if you prefer.</p>
<p>There are several ways to secure your API, but they all involve Azure Active Directory (or AAD). </p>
<p>The most basic way is to use AAD alone. To get AAD to handle authentication, you need to register both the API and the client applications using it in your Azure AD tenant. Then you grant permissions in AAD for the client applications to call the API. The applications can then use OAuth2 access tokens to call the API.</p>
<p>A variation of this method is to use the AAD B2C service. It’s designed for customer-facing web and mobile apps, so it has additional capabilities, such as letting users sign up for an application using social media accounts. You still need to register your client application in your Azure AD tenant, just like with the classic AAD method.</p>
<p>You can add yet another layer on top by using the API Management service. As I mentioned earlier, this service is a gateway to your APIs. You can configure it to use either classic AAD authentication or B2C authentication to secure your APIs. This gives you all of the advantages of the API Management service, such as monitoring and rate limiting, while letting you secure your APIs using your preferred method.</p>
<p>And that’s it for web applications.</p>
<h1 id="Creating-Compute-Intensive-Applications"><a href="#Creating-Compute-Intensive-Applications" class="headerlink" title="Creating Compute-Intensive Applications"></a>Creating Compute-Intensive Applications</h1><p>Some industries need massive amounts of compute power for their applications, such as medical research and weather forecasting. Now with the rise of artificial intelligence, the need for high-performance computing is spreading to almost every organization.</p>
<p>Since you can spin up large clusters of VMs on Azure, it’s a great place for running HPC applications. You can build your own solution or you can use one of Microsoft’s offerings to make it easier.</p>
<p>One solution is to use Microsoft HPC Pack, which is a set of tools for building an HPC cluster. HPC Pack has been around since before Azure was even in existence, but running it on Azure VMs is a lot easier than running it on-premises.</p>
<p>Microsoft has another offering that was specifically designed for the cloud, though. It’s called Azure Batch. This service manages the underlying infrastructure and HPC software but still gives you the ability to specify what compute resources you need. The Batch service itself doesn’t even cost anything, but you still have to pay for the compute resources, of course.</p>
<p>Suppose you work for a digital animation company and you need to render the images in a movie. First, you’d upload the data files, which would be animation scene files in this case, to Azure Storage. You’d also upload the application that would process these data files to Azure Storage. Then you’d create a Batch pool of compute nodes. This is when you would tell it what size of VMs you want, how many to put in the pool, what operating system to run, etc. Next, you’d create a job to run on the pool. Then, you’d add tasks to the job. These tasks would be scheduled to automatically run on the pool by the Batch service. The tasks would run the application you uploaded on the data files you uploaded. When the tasks are done, the output files, which would be render files in this case, could be transferred to Azure Storage.</p>
<p>To make all of this work, you need to design the application so that multiple copies of it can run in parallel. Each node in the pool should take one part of the data and process it without having to communicate with any of the other nodes and without storing data locally. This makes it an “embarrassingly parallel” workload that can easily scale.</p>
<p>It’s also possible to run tightly coupled workloads on Azure Batch. These are applications where the nodes <em>do</em> need to communicate with each other. That’s normally done using the Message Passing Interface (or MPI).</p>
<p>When you specify what type of VMs to put in the pool, in many cases you can improve performance by selecting VMs with graphics processing units (or GPUs) on them. Many compute-intensive applications work well with these specialized processors. Alternatively, you can use traditional CPUs, but choose HPC-optimized VMs that have high-performance components. In addition to fast CPUs and storage, some of the HPC VMs also have large memory capacity. For MPI applications, you can also choose VMs with low latency, high bandwidth networking.</p>
<p>These high-performance VMs are pretty expensive, but fortunately, you can take advantage of low-priority VMs to save a huge amount of money. Low-priority VMs typically cost between 65 and 80% less than normal-priority VMs. The difference is that low-priority VMs may not be available when you need them because they run in Azure’s surplus capacity. Even if you’re able to allocate low-priority VMs for a job, they could be preempted and you would lose them. Now you can see why they’re so cheap.</p>
<p>The great thing about Azure Batch is that it’s ideally suited to using low-priority VMs. If you’re running an embarrassingly parallel job and some of the VMs get preempted, it’s not a big deal, because the job will keep running on the remaining VMs, and the interrupted tasks will be automatically requeued. You can even allocate a certain number of dedicated VMs to guarantee that your job will keep running no matter what happens to the low-priority VMs.</p>
<p>Of course, MPI-based applications aren’t well suited to using low-priority VMs because if the application loses a VM, you’d probably have to rerun the entire job. Applications with long-running tasks are also a poor fit because it would be time-consuming to rerun tasks that get interrupted.</p>
<p>Another decision to make is how long to keep your Batch pools running. If you only run jobs periodically, then it would make sense to create a pool when you need to run a job and delete it when the job is finished.</p>
<p>If you need a job to start immediately and you know when you’re going to start it, then you can create a pool ahead of time. If you run jobs almost all of the time, then you should leave your pools <em>running</em> all of the time. If you always have jobs running, but the load varies a lot, then you can scale the pool up and down as needed.</p>
<p>As with most Azure services, you can run Azure Batch from the portal, the CLI, or from your code. All three methods provide rich monitoring capabilities. For example, if you run it from your code, you can request the status of all of the tasks in a job. You can call the Get Task Counts operation to find out how many tasks are active, running, and completed, as well as how many succeeded and failed.</p>
<p>And that’s it for compute-intensive applications.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>I hope you enjoyed learning about Azure’s compute services. Let’s do a quick review of what you learned.</p>
<p>You can put an application’s VMs into availability sets to help it survive both planned and unplanned outages. An availability set lets you configure the number of update domains and fault domains.</p>
<p>Update domains put virtual machines into groups where the VMs will be rebooted at the same time. By default, your VMs will be put into 5 update domains, but you can set it to anything between 2 and 20.</p>
<p>To survive unplanned outages, put VMs into fault domains. The maximum number of fault domains is either 2 or 3, depending on the region. Fault domains are physically isolated from each other, but they’re still within the same datacenter, so they won’t protect you against a data center failure.</p>
<p>Availability zones are an alternative to availability sets. An availability zone is a physically separate zone within an Azure region. Putting VMs in separate availability zones <em>will</em> protect you against a data center failure.</p>
<p>To protect against a <em>regional</em> failure, you need to deploy your VMs in multiple regions, using an active&#x2F;active or active&#x2F;passive model.</p>
<p>To scale an application, you can use vertical scaling, which means to use bigger VMs, or horizontal scaling, which means to use more VMs. With a scale set, you can set metrics to autoscale the number of VMs in the set. You can also configure autoscaling with Azure Cloud Services and Web App for Containers.</p>
<p>You can reduce your VM costs by using either reserved instances, where you prepay for one or three years, or low-priority instances, which can be preempted at any time.</p>
<p>To speed up networking between VMs, you can enable Accelerated Networking on their network interfaces, which allows them to bypass the virtual switch.</p>
<p>Azure DevTest Labs makes it easy to spin up non-production environments using base images, formulas, and artifacts.</p>
<p>Azure IaaS VM Backup only backs up Azure VMs. The Azure Backup Agent supports both cloud-based and local VMs, as well as physical servers. However, it only supports Windows, and you have to install the agent on every virtual and physical machine you want backed up. Both of these products store their backups in a Recovery Services vault.</p>
<p>System Center DPM and Azure Backup Server can back up anything except Oracle. They can store their backups in a Recovery Services vault or locally attached disk. System Center DPM can also store them locally on tape.</p>
<p>To apply a backup policy to a large number of VMs, it’s easiest to do it from a Recovery Services vault.</p>
<p>The Site Recovery service supports three failover scenarios: Azure to Azure, on-premises to Azure, and on-premises to secondary site. To support physical or VMware servers, you need a Configuration server, a Process server, and a master target server. You also need to install a Mobility service on each server that needs to be replicated. To support Hyper-V, you install the Azure Site Recovery Provider and Recovery Services agent on each Hyper-V host or cluster node. In the event of an outage, you have 6 different options for which recovery point to failover to. Latest is the default.</p>
<p>Microsoft’s primary serverless offering is Azure Functions. It’s event-driven and it’s invoked using a trigger that you specify. Inputs and outputs are configured with bindings. Durable Functions is an extension that lets you create orchestrator functions.</p>
<p>Azure Logic Apps is simpler than Azure Functions and it doesn’t require you to write any code. It’s also invoked using triggers.</p>
<p>To implement a microservices architecture, you need to use containers. Azure Container Instances is not really suitable unless you have very simple requirements. Instead, you should use either Azure Container Service or Azure Service Fabric.</p>
<p>Azure API Management acts as a gateway between clients and microservices. It also handles management tasks like security, monitoring, analytics, and rate limiting.</p>
<p>To deploy a web application that doesn’t have a microservices architecture, Azure App Service Web Apps is usually the best choice. One useful feature is deployment slots. You can have multiple versions of your app in different slots and then swap your staging slot with your production slot when you’re ready.</p>
<p>Three typical ways to increase the performance of a web app are scaling, caching, and using an edge network. You can configure App Service to autoscale based on metrics and schedules. For caching, you can use Azure Redis Cache. To serve static content to users in different geographic regions, you can use a content delivery network.</p>
<p>To make a web app highly available, deploy a standby copy in the paired region. Use Azure Traffic Manager to handle routing during a failover.</p>
<p>If your web app needs more than 20 instances or instances with a high memory to CPU ratio or secure network isolation, then you can use the Isolated service tier.</p>
<p>You can host a web API by creating an API App in Azure App Service. To secure the API, use Azure Active Directory. You can use AAD alone or use the AAD B2C service, which is designed for customer-facing web and mobile apps. You can also use the API Management service as a gateway to your API.</p>
<p>Azure Batch is usually the best way to run HPC applications. To use it, you upload the application and data files to Azure Storage, create a pool of compute nodes, create a job, and add tasks to the job. In many cases, you can use low-priority VMs to save money. For machine learning workloads, use Azure Batch AI.</p>
<p>Now you know how to design Azure solutions using virtual machines, serverless computing, and microservices; design web solutions using Azure App Service; and run compute-intensive applications using Azure Batch.</p>
<p>To learn more about Azure’s compute services, you can read Microsoft’s documentation. Also, watch for new Microsoft Azure courses on Cloud Academy because we’re always publishing new courses. Please give this course a rating, and if you have any questions or comments, please let us know. Thanks and keep on learning!</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/18/AZ-104-Back-Up-and-Restore-VMs-with-Azure-Backup-43/" rel="prev" title="AZ-104-Back-Up-and-Restore-VMs-with-Azure-Backup-43">
      <i class="fa fa-chevron-left"></i> AZ-104-Back-Up-and-Restore-VMs-with-Azure-Backup-43
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/18/AZ-104-Knowledge-Check-Design-Azure-Compute-Infrastructure-45/" rel="next" title="AZ-104-Knowledge-Check-Design-Azure-Compute-Infrastructure-45">
      AZ-104-Knowledge-Check-Design-Azure-Compute-Infrastructure-45 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Azure-Virtual-Machine-Availability-and-Scalability-Solutions"><span class="nav-number">2.</span> <span class="nav-text">Azure Virtual Machine Availability and Scalability Solutions</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Azure-Backup-and-Azure-Site-Recovery"><span class="nav-number">3.</span> <span class="nav-text">Azure Backup and Azure Site Recovery</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Designing-Solutions-for-Serverless-Computing"><span class="nav-number">4.</span> <span class="nav-text">Designing Solutions for Serverless Computing</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Designing-Microservices-Based-Solutions"><span class="nav-number">5.</span> <span class="nav-text">Designing Microservices-Based Solutions</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Designing-Web-Applications"><span class="nav-number">6.</span> <span class="nav-text">Designing Web Applications</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Creating-Compute-Intensive-Applications"><span class="nav-number">7.</span> <span class="nav-text">Creating Compute-Intensive Applications</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Conclusion"><span class="nav-number">8.</span> <span class="nav-text">Conclusion</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
