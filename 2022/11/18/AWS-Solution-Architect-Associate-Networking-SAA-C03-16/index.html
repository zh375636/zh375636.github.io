<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Networking (SAA-C03) IntroductionHello, and welcome to this course on networking in AWS, where we’re here to help you on your journey to prepare for the AWS Certified Solutions Architect - Associate c">
<meta property="og:type" content="article">
<meta property="og:title" content="AWS-Solution-Architect-Associate-Networking-SAA-C03-16">
<meta property="og:url" content="https://example.com/2022/11/18/AWS-Solution-Architect-Associate-Networking-SAA-C03-16/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:description" content="Networking (SAA-C03) IntroductionHello, and welcome to this course on networking in AWS, where we’re here to help you on your journey to prepare for the AWS Certified Solutions Architect - Associate c">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-19T02:13:22.000Z">
<meta property="article:modified_time" content="2022-11-27T23:59:40.000Z">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/2022/11/18/AWS-Solution-Architect-Associate-Networking-SAA-C03-16/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>AWS-Solution-Architect-Associate-Networking-SAA-C03-16 | Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Hang's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/18/AWS-Solution-Architect-Associate-Networking-SAA-C03-16/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AWS-Solution-Architect-Associate-Networking-SAA-C03-16
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-18 22:13:22" itemprop="dateCreated datePublished" datetime="2022-11-18T22:13:22-04:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-27 19:59:40" itemprop="dateModified" datetime="2022-11-27T19:59:40-04:00">2022-11-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Solution-Architect-Associate/" itemprop="url" rel="index"><span itemprop="name">AWS-Solution-Architect-Associate</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/18/AWS-Solution-Architect-Associate-Networking-SAA-C03-16/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/18/AWS-Solution-Architect-Associate-Networking-SAA-C03-16/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Networking-SAA-C03-Introduction"><a href="#Networking-SAA-C03-Introduction" class="headerlink" title="Networking (SAA-C03) Introduction"></a>Networking (SAA-C03) Introduction</h1><p>Hello, and welcome to this course on networking in AWS, where we’re here to help you on your journey to prepare for the AWS Certified Solutions Architect - Associate certification. Before we get started, I’d like to introduce myself. My name is Danny Jessee, and I am one of the trainers here at Cloud Academy, specializing in AWS – Amazon Web Services – and AWS certifications.</p>
<p>In this course, the AWS team will be presenting a series of lectures that introduce the various networking services currently available in AWS that may be covered on the exam.</p>
<p>Feel free to contact me with any questions using the details shown on the screen, or you can always get in touch with us here at Cloud Academy by sending an email to <a href="mailto:&#x73;&#117;&#112;&#x70;&#111;&#x72;&#x74;&#x40;&#x63;&#x6c;&#x6f;&#x75;&#100;&#97;&#99;&#97;&#100;&#101;&#109;&#x79;&#x2e;&#x63;&#111;&#109;">&#x73;&#117;&#112;&#x70;&#111;&#x72;&#x74;&#x40;&#x63;&#x6c;&#x6f;&#x75;&#100;&#97;&#99;&#97;&#100;&#101;&#109;&#x79;&#x2e;&#x63;&#111;&#109;</a>, where one of our Cloud experts will reply to your question.</p>
<p>This course has been specifically curated to help you pass the AWS Certified Solutions Architect - Associate exam and is ideal for anyone who is looking to learn more about the various networking services in AWS in preparation for the exam.</p>
<p>The objective of this course is to provide an introduction to networking services in AWS for solution architects, including:</p>
<ul>
<li>Amazon Virtual Private Cloud, or VPC;</li>
<li>Configuring security groups and Network Access Control Lists, or NACLs;</li>
<li>AWS Virtual Private Network, or VPN solutions; and</li>
<li>AWS Direct Connect.</li>
</ul>
<p>You’ll learn about AWS networking components that include:</p>
<ul>
<li>Elastic IP addresses;</li>
<li>Elastic Network Interfaces, or ENIs;</li>
<li>EC2 Enhanced Networking with the Elastic Network Adaptor, or ENA; and</li>
<li>VPC Endpoints.</li>
</ul>
<p>You’ll also learn about global networking services such as Amazon Route 53, Amazon CloudFront, and the AWS Global Accelerator, which leverages the AWS global infrastructure to reduce latency and improve the overall performance of your applications.</p>
<p>Together with the other courses in this learning path, we’ll cover all of the key tools, technologies, and concepts from the AWS Certified Solutions Architect - Associate exam guide and ensure that you are fully prepared to sit this exam.</p>
<p>The AWS Certified Solutions Architect - Associate certification has been designed for anyone who has experience designing cloud solutions that use AWS services to meet current and future business requirements, as well as architectures that are secure, resilient, high-performing, and cost-optimized in accordance with the AWS Well-Architected Framework. All of the AWS Cloud concepts introduced in this course will be explained and reinforced from the ground up.</p>
<p>Here at Cloud Academy, we strive to keep our content current to provide the best training available. If you have any feedback, positive or negative, or if you notice anything that needs to be updated or corrected for the next release cycle, please reach out to us at <a href="mailto:&#115;&#x75;&#112;&#x70;&#x6f;&#114;&#116;&#x40;&#x63;&#108;&#111;&#x75;&#100;&#97;&#99;&#x61;&#x64;&#x65;&#x6d;&#x79;&#46;&#x63;&#111;&#x6d;">&#115;&#x75;&#112;&#x70;&#x6f;&#114;&#116;&#x40;&#x63;&#108;&#111;&#x75;&#100;&#97;&#99;&#x61;&#x64;&#x65;&#x6d;&#x79;&#46;&#x63;&#111;&#x6d;</a>. Thank you!</p>
<h1 id="What-is-a-VPC"><a href="#What-is-a-VPC" class="headerlink" title="What is a VPC?"></a>What is a VPC?</h1><p>Hello and welcome and I’m going to be talking to you about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-introduction/">VPC</a>s. Virtual Private Clouds. Now to understand what a VPC is, let’s just take a look at the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> infrastructure. </p>
<p>So, here is the AWS Cloud. Very simple. And a VPC resides inside of the AWS Cloud and it’s essentially your own isolated segment of the AWS Cloud itself, so here is your VPC sitting inside the AWS Cloud. </p>
<p>Now by default when you create your VPC, the only person that has access to this is your own AWS account, just you. It is totally isolated and no one else can gain access to your VPC other than your own AWS account. Now obviously there are millions upon millions of other VPCs within the AWS network created by other customers all across the world. So, there are millions of customer VPCs. However, they do not have access to your VPC and likewise, you do not have access to their VPC. </p>
<p>Now what do you use a VPC for? Well, essentially it allows you to start deploying resources within your VPC, for example, different compute resources or storage or database and other network infrastructure among others and this allows you to start building and deploying your solutions within the Cloud. </p>
<p>Now by default from a limitation perspective, you are allowed up to five VPCs per region per AWS account and it’s very simple to create a VPC. All you need to do is to give it a name, when you create your VPC and also define an IP address range that the VPC can use and this is done in the form of a CIDR block which stands for Classless Inter-Domain Routing. And I’ll talk more about that when I talk more about subnets in a few minutes. </p>
<p>So, just to recap at a high level, simply put, a VPC is an isolated segment of the AWS public cloud that allows you to provision and deploy resources in a safe and secure manner. I now want to dive deeper into the VPC architecture and start talking about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-subnets/">subnets</a> and how you can segment your VPC out into different areas across multiple availability zones for resiliency and high availability, so let’s take a look.</p>
<h1 id="Subnets"><a href="#Subnets" class="headerlink" title="Subnets"></a>Subnets</h1><p><strong>Resources referenced within this lecture:</strong></p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">VPC TCP&#x2F;IP Addressing</a></p>
<p><strong>Transcript</strong></p>
<p>So <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-what-vpc/">now we know what a VPC is</a>, let’s take a look at subnets. Now, subnets reside inside your VPC, and they allow you to segment your VPC infrastructure into multiple different networks. Now, you might want to do this to create better management for your resources, or to isolate certain resources from others, or even to create high-availability and resiliency within your infrastructure. So let’s take a look at the subnets. </p>
<p>Firstly, then we’ll just draw our VPC quickly. So this is our VPC. And I mentioned when talking about VPCs that when you create your VPC, there’s two pieces of information that you need. You need to give it a name and also a CIDR block address. Now, the CIDR block address is a range of IP addresses and this CIDR block range can have a subnet mask between a range of IP addresses from a &#x2F;16 all the way through to a &#x2F;28. Now, if you’re not familiar with TCP&#x2F;IP addressing, now please take a look at the link on screen and check out the following course and this will dive into the CIDR block and TCP&#x2F;IP addressing in greater detail. </p>
<p>Now, for our example, let’s say we created our VPC with the following CIDR block. 10.0.0.0&#x2F;16. Now, this is important because any subnets that we create within our VPC need to reside within this CIDR block range. So let’s take a look at a couple of subnets. </p>
<p>Now, in this section, I want to talk to you about public subnets and also private subnets. So let’s just create a public subnet there and also a private subnet here. This yellow one can be our public subnet and the green one can be our private subnet. Now, similarly, when we create a VPC, we need to give it a CIDR block range. We need to do the same with our subnets as well. So let’s say for example this is 10.0.1.0&#x2F;24. Now, this range of addresses sits within this bigger CIDR block here, and then this private subnet can be 10.0.2.0&#x2F;24. And again, this CIDR block sits within the bigger VPC CIDR block. </p>
<p>Now, what makes a subnet public and what makes a subnet private? Well, essentially a public subnet is accessible from outside of your VPC. So essentially from the Internet. For any resources created within your public subnet, for example web servers, would be accessible from the Internet. Now, because we want these web service accessible from the Internet, I have two IP addresses. So they have their own internal IP address which will be within the range of the subnet, which, for this subnet, it’s 10.0.1.0&#x2F;24. And then also we’re going to assign them a public IP address as well, because to be accessible from the Internet, the instance itself has to have a public IP address. </p>
<p>Any resources created within your private subnet, for example your backend databases, would be considered private and inaccessible by default from the Internet. So how do you make a subnet public and how do you make one private? When you create a subnet, you create them both exactly the same. It’s what you configure afterwards that will dictate if a subnet is public or private. </p>
<p>There’s two changes you need to make to your infrastructure to make a subnet public. The first is to add an Internet gateway. Now, an Internet gateway is a managed component by AWS that is attached to your VPC and acts as a gateway between your VPC and the outside world. So essentially the Internet. So let’s just add in an Internet gateway here, IGW for Internet gateway. So now we have our Internet gateway attached to our VPC. And this Internet gateway then also connects out to the Internet. So we now have a bridge between our isolated VPC to the Internet by the Internet gateway which is managed by <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a>. </p>
<p>Now, you might think that a public subnet now has access to the Internet because there’s an Internet gateway. However, before the public subnet can access the Internet, we need to add a route to the public subnet’s route table. Now, associated with every subnet when it’s created will also be an associated route table. Now, you can have the same route table associated to multiple subnets. That’s not a problem. However, you can’t associate more than one route table to a single subnet. </p>
<p>Now, by default, when your subnet’s created, it will have a default route in it, and this is a local route. Let’s take a look. Now, your route table will contain a destination field and also a target field. Now, the destination field is the destination address that you’re trying to get to. The target essentially specifies the route to that destination. Now, within every route table that’s created, there will be this local route here. Now, what this enables your subnets to do is simply talk to each other. So any subnet within your VPC is able to communicate with each other without you having to configure any routes. It’s there by default. Every route table has this local route. It can’t be deleted, and it simply allows all subnets within your VPC to communicate with each other. </p>
<p>So what we need to do is we need to add a route to this route table that’s associated to the public subnet. Now, this new route here that’s been added to the route table has a destination of 0.0.0.0&#x2F;0. Now, that essentially means that for any IP address that’s not known within the route table already, send it to this target. Now, this target is the Internet gateway as shown by the IGW. This part here is simply the ID of the Internet gateway. So by adding this route to the route table, this public subnet now knows exactly how to get to the Internet by going by the Internet gateway as shown in the route table. Now, those two components are essentially what makes a subnet public, the fact that we have an Internet gateway attached to the VPC and this subnet has a route pointing to the Internet gateway for any traffic that it doesn’t know how to get to. </p>
<p>Now, if we compare the route table of the private subnet, we can see that it only has this local route, so it has no route to the Internet gateway. It’s not aware that an Internet gateway even exists, so it has no route out to the public Internet. So this is considered a private subnet. Now, if we go back to the public subnet, before we added this route here, so let’s just take that out. This subnet is effectively a private subnet, because it doesn’t have a route to the Internet gateway. So with that in mind, every time you create a subnet, it is a private subnet to begin with and that is until you attach an Internet gateway to your VPC and then add this additional route. </p>
<p>So now we’ve looked at public subnets and also private subnets. Let’s now look at architecting multiple subnets across your VPC for high availability and resilience. So let’s just clear the screen, give us a blank VPC to work with. So let’s consider we have three subnets this time. We’ll have a public subnet, and we’ll have two private subnets. This can be our public subnet, and these two will be our private subnets. This will be our web layer. This will be our application layer, and this will be our database layer. </p>
<p>So in our public subnet, we will have some web servers. In our application layer, we’ll just have some EC2 instances. And in our database layer, we’ll just have some databases. So there we have our three tiers of our deployment. So as we know with any subnet, we have a local route, so each of these will all have a local, as you can’t remove that local route. And this enables all of these subnets to communicate with each other. The public subnet, as we know, will also have a route to the Internet gateway. Now, when you create a subnet, you have to create it in one of the availability zones that are available within that region. Now, if you’re not too familiar with the AWS global infrastructure, then please take a quick read of the blog post below. </p>
<p>Let’s say for example when we created this subnet, we created it in availability zone one, and we’ve done the same for the remainder of our subnets as well, and placed them all in the same availability zone. And that’s all okay, we can deploy infrastructure all within the same availability zone and our solution would be operating fine. However, should AWS have an issue with availability zone within this region, for example they might experience a flood or a fire or a natural disaster, and it took out the services to availability zone one, what would happen to our resources? </p>
<p>Well, effectively, these would also be taken down because they’re all running in availability zone one. So that’s not ideal. It’s not best practice to deploy all of your resources within the same availability zone, within a single region, simply because it doesn’t offer high-availability and resilience. So what should you do in that situation? Well, the best thing to do to ensure high-availability is to add additional subnets to allow for resiliency. So we’ll add an additional web tier and also additional application, and also a database. </p>
<p>So now we have six subnets, and again, we’d replicate our resources, so it’d have our web infrastructure here, we’ll have our application service here and our databases here. Again, then we’ll have the routes and then Internet gateway route as well. This will have a local route, and as we know, this allows communication between all subnets. So now, every subnet can talk to every other subnet with a local route, and also this also has a route to the Internet gateway as well. So now let’s look at the availability zones that we’ll deploy our infrastructure in this time. </p>
<p>Let’s say for example we’ll deploy this in AZ-1, this application subnet in AZ-2, and this database subnet in AZ-3, and similarly, down here, we have this public subnet in AZ-3. This one in one, and this final one in two. So now let’s run through the scenario again. Let’s imagine AZ-1 experienced a failure. So what would happen here? This public subnet would be out of action. This application subnet and that is it. So in this situation, we still have one subnet available in each layer of our infrastructure. So should we experience a failure with availability zone one, our services will remain up and running. </p>
<p>So let’s do the same with availability zone two. What would happen in this situation? Well, both of our public subnets would be okay, because everyone’s in AZ-1 and three. This application subnet would be down, and this database subnet would also be down. So again, at least one subnet in each of our layers is operational and available. So again, our services would still be up and running. </p>
<p>Now, finally, just for clarity, if we take down availability zone three, this web layer would go and also this database layer. So again, we still have at least one subnet in each tier or each layer of our infrastructure operational. So this is a much better design. This allows you to ensure your resources stay up and running should a failure occur in one of the availability zones. Before we move onto some security features, let me just clear the screen because I want to talk to you just quickly about IP addressing, just a couple of points that I want to mention with regards to the subnets. So let’s just clear this quickly. </p>
<p>So I mentioned that when you create your subnet, you have to assign it a CIDR block range that fits within the VPC CIDR block. So say for example we created a subnet here, and we give the subnet the address of 10.0.1.0&#x2F;24. Now, with a slash 24 mask, this gives this subnet a total of 256 IP addresses. You can only actually use 251 IP addresses. And I’ll explain why. So the very first IP address in this subnet is 10.0.1.0 and this is known as the network address. Now, you’re not able to use this as an IP address to assign to your host addresses. This is reserved for networking. Now, the next available IP address after the network address is 10.0.1.1. And this is reserved for AWS routing. So again, not a network address. You can’t use this address as a host network in your subnet. Now, the next available IP address is 10.0.1.2. And again, this one is reserved by AWS, but this time for DNS. So you cannot use this IP address. Now, the fourth IP address that you won’t be able to use in this subnet is 10.0.1.3. And this is actually reserved by AWS for future use. Now, the fifth and final address that you can’t use in an AWS subnet is the last available address in the subnet. So in this case, it’d be 10.0.1.255, and the last address in any subnet is known as the broadcast address, and again, you cannot use this for host resources. </p>
<p>So when working with TCP&#x2F;IP addresses within your subnet, first four addresses in any subnet are reserved and you cannot use for host addresses and also the very last address is reserved. So that’s why use only 251 IP addresses available to you that you can use to assign to your host resources. So now we’ve covered what a VPC is. We’ve looked at subnets, both public and private, and also how it’s best to architect your subnets across multiple availability zones for high-availability. So now let’s look at some security features. I want to start with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-network-access-control-lists-nacls/">network access control lis</a>t. Let’s take a look.</p>
<h1 id="Network-Access-Control-Lists-NACLs"><a href="#Network-Access-Control-Lists-NACLs" class="headerlink" title="Network Access Control Lists (NACLs)"></a>Network Access Control Lists (NACLs)</h1><p>Security is a key part of any deployment within <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a>, and managing security around your <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-introduction/">virtual private cloud</a> is no different. So I want to talk to you about a couple of different components here. </p>
<p>Firstly, I want to talk to you about NACLs which are network access control lists. Now these are essentially virtual network-level firewalls that are associated to each and every <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-subnets/">subnet</a>, and they help to control both ingress and egress traffic moving in and out of your VPC and between your subnets. So let’s just quickly draw out our VPC. Very simple, and let’s just draw in a public subnet for example. So this is going to be public. Up here, we’ll have our internet gateway attached to our VPC, and obviously, we have a route out to the gateway, which then communicates with the internet. </p>
<p>So what we can do here to help maintain security is to configure the network access control list associated to this subnet. Now much like route tables, whenever you create a new subnet, it will also associate a network access control list. Now by default, this NACL will allow all traffic, both inbound and outbound, so it’s not very secure, so it’s a really good practice to configure your NACLs to only allow the traffic that you want to come in and out of your subnet. </p>
<p>Now with this being a public subnet, we’ll probably have some web servers in here talking over HTTP and HTTPS, so let’s look at the inbound network access control list that could be associated to this subnet. Now as you can see, there’s a number of different fields. We have the rule number, the type, the protocol, port range, source, and allow or deny. Now the rule numbers allow you to specify what order the rules will appear inside the NACL, and as soon as traffic hits one of these rule where it matches all of the type, protocol, port range, and source, et cetera, it will carry out the action at the end, whether that is allow or deny. </p>
<p>So let’s look at the requirements required to match this rule here. The type of traffic will need to be HTTP under port 80 using the TCP protocol, and again, the port range is 80 as that’s what used for HTTP. Now the source can be any IP address, so any IP address running HTTP coming into our subnet will be allowed. So as long as they’re running this protocol, then the traffic will be allowed inbound into our public subnet. </p>
<p>Now let’s look at the second rule. Now the second rule uses HTTPS using the TCP protocol using port 443, and again, any source, and the action will be allowed. Now the last rule here, now this is a default rule that’s applied at the end of every network access control list, and that’s why it doesn’t have a rule number, and it states that all traffic using any protocol in any port range from any IP address, then deny that access. So this rule is kind of a cover rule. So basically, what that allows you to do is ensure that any traffic that doesn’t meet the rules that you’ve entered is deleted and denied access to your subnet. </p>
<p>So with this in mind, the only traffic allowed in our public subnet is essentially HTTP and HTTPS, which is exactly what we want for our web servers here, and all other traffic will be denied. So that’s the inbound NACL. Let’s now take a look at the outbound. Now the field types are all exactly the same other than this one here. This has a destination whereas on the inbound, it has the source. So on the outbound, we restrict traffic against its destination. </p>
<p>So the first rule we have here says any traffic using any protocol in any port range going to any destination, then allow that traffic. Anything else should be denied, but in this case, there won’t be anything else because this outbound rule is essentially saying send any traffic you want to using any protocol out from this subnet to any destination. </p>
<p>Now an important point to make about NACLs is that they are stateless, and this means that any response traffic generated from a request will have to be explicitly allowed and configured in either the inbound or the outbound ruleset, depending on where the response is coming from. Now again, much like route tables, you can have the same NACL applied to a number of subnets, but only a single NACL can be associated to one subnet. So network access control lists are a great way to control traffic that comes into and out of a particular subnet. </p>
<p>Let me now talk about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-security-groups/">security groups</a>, and these are another method of controlling traffic, but this time, they work at the instance level rather than the network level like NACLs do.</p>
<h1 id="Security-Groups"><a href="#Security-Groups" class="headerlink" title="Security Groups"></a>Security Groups</h1><p>So, staying with security, I now want to talk to you about security groups. Now these are similar to network access controllers where they filter traffic both inbound and outbound but whereas <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-network-access-control-lists-nacls/">NACLs</a> worked at the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-subnets/">subnet</a> level, security groups work at the instance level and I’ll explain more about this as we go. </p>
<p>So let’s say we have three subnets, okay, so we just draw these out quickly and these would be three private subnets, for example. Each of them will have their IP addresses listed, first one being 10.0.1.0&#x2F;24. .2.0. And the last one, 3.0. Now this first subnet will have EC2 instances in them. The second subnet will have RDS instances running MySQL or Aurora and the last subnet here will also have EC2 instances in them. </p>
<p>Now each of these three subnets are associated to the same network access control list. So, this one is linked with this one and also this one. And this network access control list looks like this. And this is simply saying that any traffic that is running a TCP Protocol across any port range from any source, then allow it and deny all other traffic. So, between these subnets, any TCP Protocol on any port can be used and for simplicity, the same NACL rules are being used for both inbound and outbound. Now that’s not very secure, it’s not very restrictive but from a subnet network level, that is what it’s controlling. Now what we want to do is restrict access to which instances can actually talk to our RDS and Aurora databases here. </p>
<p>Now we only want to allow access from this subnet over here and deny access from this subnet here and we can use security groups to do just that. So, let’s take a look at the security group for this subnet here, from where our databases are. Now security groups have similar fields to NACLs but there’s just a couple less. So, there’s no rule number with the security group which means all the rules within the security group will be assessed before a decision is made on the action and you’ll also notice, there’s no allow or deny either. With security groups, if there’s a rule in there, then it’s considered allowed, if there’s no rule, then all traffic is dropped by default, so with this security group is stating that any MySQL or Aurora traffic using a TCP Protocol on the port 3306 from the source 10.0.1.0 which is this subnet here, then it’s considered allowed as we don’t have another rule in this security group for the source of 10.0.3.0&#x2F;24 which is this subnet here. Then it’s considered denied. It doesn’t exist, so it’s not allowed access, so how do both these NACLs and security groups work together? </p>
<p>Well, the NACL works at the subnet level, so let’s say the NACL is this purple line and as this NACL is associated to this subnet as an example, let’s just put that NACL around the edge of the subnet like so and let’s say this orange is our security group and that security group is associated to our databases inside this subnet. So, let’s assume that our EC2 instances here are looking to communicate with the RDS and Aurora databases over here, so let’s have a look how that traffic would flow through the NACL and also the security group. </p>
<p>So, the request would be sent, it would get to the NACL and the NACL say okay, is this traffic TCP traffic within this port range from any source? And it is. So, the traffic is allowed. So, that traffic is now allowed inside the subnet. It then hits the security group and the security group says is this a MySQL or Aurora traffic running the TCP Protocol using port range 3306 coming from 10.0.1.0? And it is as we’re trying to communicate with the databases, then access is allowed. Now if we look from this subnet here, the 10.0.3.0 and do the same thing where these two EC2 instances are trying to communicate with the RDS and Aurora instances using port 3306, let’s follow the same process. </p>
<p>So, the request is sent, it hits the NACL, the NACL says are you running TCP within this port range from any source? The answer is yes, so access is allowed. It then hits a security group and it says is this traffic MySQL or Aurora using TCP Protocol on port range 3306? At this point, everything is correct, yes. However, the source is different. We don’t have a source address of 10.0.3.0. It doesn’t exist in the security group. So, at this point, the traffic is dropped at the security group and access is not allowed. </p>
<p>So, you can see how NACLs and security groups can be used to filter traffic at different layers. The NACLs are used for the subnet and network layer and the security groups are used at the instance layer. Now one final thing I wanna say about security groups is that unlike NACLs which are stateless by design, security groups are stateful which means you don’t have to configure specific rules to allow return traffic from requests like you have to do with NACLs.</p>
<h1 id="NAT-Gateway"><a href="#NAT-Gateway" class="headerlink" title="NAT Gateway"></a>NAT Gateway</h1><p><strong>Resources referneced within this lecture:</strong></p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/blog/aws-shared-responsibility-model-security/">AWS Shared Responsibility Model</a></p>
<p><strong>Transcript</strong></p>
<p>I now want to talk to you about another VPC component, and that is the NAT gateway. To help explain what this does, let me just draw out our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-introduction/">VPC</a> quickly. So we have a very simple VPC, and we’re gonna have two subnets in this VPC, we’ll have a public subnet and also we’ll have a private subnet as well, and it’s the private subnet that we’re going to be focusing on. </p>
<p>So this will be our public, and the green one will be our private subnet. Now obviously we’ll have an Internet gateway attached to our VPC, which will then connect out to the Internet. Okay, so we have a public subnet, and a private subnet. Now in our private subnet we’ll have a number of EC2 instances running our applications, and in our public subnet we’re likely to have a number of web servers as well. As we know, each of these subnets also have a route table attached. Public route table will have access to the Internet gateway, and also to the other private subnet. </p>
<p>Now we need to start thinking about security again. Now, looking at our EC2 instances in the private subnet, we are responsible, as a part of the AWS Shared Responsibility Model, to update and patch the operating systems running on each of our EC2 instances. Now if you’re not familiar with the AWS Shared Responsibility Model, I suggest you take a look at it. It’s critical to all of your AWS deployments, and it essentially defines the boundaries of security as to what your roles and responsibilities are of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-security-groups/">implementing security within the cloud</a>, and what AWS’s responsibility is of maintaining security of the cloud. For more information, you can take a look at this blog post here. </p>
<p>Okay, so with that in mind, if we have the responsibility of maintaining the operating systems of our EC2 instances, then we need to be able to download updates as and when we need to. However, this subnet is private. Meaning it has no access to the Internet gateway, and therefore the Internet, so how can we download those updates? Well, what we can do, we can add a NAT gateway. </p>
<p>Now, a NAT gateway sits within the public subnet. Because it sits within the public subnet, it has to have a public IP address in the form of an EIP which is an Elastic IP address, and this is assigned to the instance itself. Now because it sits within the public subnet, it has a route out to the Internet gateway, and to the Internet. Now once we have our NAT gateway set up and configured, we need to update the route table of our private subnet. Now, by default our route table in our private subnet will just have the local route that all route tables have. But if we update that to provide a route to the NAT gateway, and we can see that I’ve added this additional route in here. Now this looks very familiar to the route we added to the public subnet to get access to the Internet via the Internet gateway, and it is essentially the same. So we’ll add the 0.0.0.0&#x2F;0 which is essentially a destination to any IP address unknown in the route table already. Then, send it to the target of the NAT gateway. And they can tell it’s a NAT gateway as this first part here, is prefixed with nat. And then this section along here, is essentially the ID of the NAT gateway within your VPC. </p>
<p>So what this route table is telling us, is that if any resource within this subnet needs to gain access to the Internet to perform an update, then it can do so via our NAT over here. This NAT gateway will then take the request, go via the Internet gateway, and download the appropriate software that’s required, and send it back to the EC2 instance requesting it. Now the important thing with a NAT gateway, is that it will not accept any inbound communication initiated from the Internet. It will only accept outbound communications originating from within your VPC. So it will deny all inbound traffic that’s been initiated from the Internet. </p>
<p>Now the NAT gateway itself is managed by <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a>, so you don’t have to provision the instance itself. It’s very easy to do, you simply create the NAT gateway, specify what subnet it should reside in, and associate an Elastic IP address, and AWS will manage all other configuration. Because it’s managed by default, AWS will set up multiple NAT gateways for resiliency, but you’ll only see the one NAT gateway within your account with the associated ID. </p>
<p>Now, earlier I mentioned about configuring your resources across Multi-Availability Zones. So if you have multiple public subnets in different Availability Zones, you will need to set up another NAT gateway within that subnet as well. AWS will not automatically deploy a NAT gateway within each of your public subnets. </p>
<p>So just as a quick summary, a NAT gateway allows instances within a private subnet access to the Internet, but the NAT gateway itself will block all incoming initiations from the Internet. So it protects the private subnet in that way. And this allows you to ensure that you maintain the security of your EC2 instances ensuring that their OS is kept up to date, and any patch management is taken care of as well. Now the next component I want to talk to you about is the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-bastion-hosts/">bastion host</a>. So let’s take a look.</p>
<h1 id="Bastion-Hosts"><a href="#Bastion-Hosts" class="headerlink" title="Bastion Hosts"></a>Bastion Hosts</h1><p><strong>Resources referenced within this lecture:</strong></p>
<p><a target="_blank" rel="noopener" href="https://aws.amazon.com/blogs/security/securely-connect-to-linux-instances-running-in-a-private-amazon-vpc/">SSH Agent Forwarding</a></p>
<p><strong>Transcript</strong></p>
<p>In this section, I want to talk to you about bastion hosts. Now, consider a scenario where you might have EC2 instances sitting in a private subnet, but you want to be able to gain access to those instances from maybe your home office or from somewhere else on the internet. But because they’re sitting in the private subnet, how can you do that? Well, one of the ways you can do this is via a bastion host. </p>
<p>So let’s draw out our VPC configuration to allow me to explain how this works. So here, we have our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-introduction/">VPC</a>. We’re going to have a public subnet and we’ll also have a private subnet as well. So this will be our public and this green one here will be our private. Now, obviously, we have an internet gateway attached as we have a public subnet, our IGW, and this connects out to the internet. We also have routes added to allow the subnets to talk to each other and also the public subnet to route out to the internet gateway as well. </p>
<p>Now, also, in the outside world, we have an engineer. Now, this engineer might be sitting at home in their home office in front of their laptop and what they need to do is to connect to resources sitting within the private subnet over here. Now, in this private subnet, we’re going to have a couple of EC2 instances. Now, we know it’s not possible to initiate an outside request to connect through to the internet down through to the internet gateway of our VPC and then across to our private subnet. It’s not possible. There aren’t routes to enable us to do that. Access isn’t allowed and it is private by design. </p>
<p>However, this engineer here needs to gain access to the EC2 instances to perform some maintenance or updates to those resources. Now, to enable you to do this, you need to use a bastion host. Now, this bastion host sits within the public subnet and this is just another EC2 instance. Now, this instance, to follow best practices, needs to be very secure. It needs to be hardened and very robust, but effectively, it needs to be tightened down to remove any kind of vulnerabilities and loose access controls. </p>
<p>Now, this EC2 instance is a part of a security group and this security group needs to be configured as shown. Now, what this security group shows is the inbound connectivity, and it allows SSH on port 22 from this IP address, which is from the engineer’s IP. So it’s being configured for this engineer over here. So this bastion host will essentially allow an SSH connection coming from our engineer over here. Now, that’s great because this engineer can then gain access to the bastion host here. And then, what that engineer can do is then use this as like a jump server and connect from the bastion host through to our EC2 instances here. </p>
<p>But before any of that can happen, we need to set up another security group for our EC2 instances here. So we’ll have another security group around our EC2 instances and this will be configured as shown. Again, this is the inbound rule set, and we can see that SSH is allowed on port 22 from this source here. Now, this source is actually a security group. It is prefixed with sg, which is security group, and this security group is actually this one here. This is associated with the bastion host. So what this is saying is any instances associated to this security group allow inbound SSH from any resource sitting within this security group, which as we know, is associated to our bastion host. So that will just allow the bastion host SSH access to these instances. </p>
<p>So now, we have our security groups set up and configured. However, let me just talk you through the connection process. So our engineer here will connect to our bastion host. Now, the engineer will be able to access the bastion host using the private key. So let’s just follow this process through. So the engineer will SSH to our bastion host, so it’ll connect via the internet. The connection will then come through the internet gateway. Let’s assume that any net calls that we have allow the access and we come to the security group here. Now, this security group says, allow connection if it’s an SSH connection from this IP address and this is the IP address of our engineer over here. So it allows access through. So now, this engineer has access to our bastion host. But now, our engineer needs to jump across to our private instances. Now, again, we’re going to need a private key to do that. </p>
<p>Now, one method would be to store the private keys on this bastion host and then run the command to SSH and access would be allowed, but that’s not best practice at all. We really don’t want to be installing private keys within the public subnet or on the bastion host because if this bastion host ever got compromised, then the malicious user will be able to use any private keys that are stored on the bastion host and connect to our private instances, which would be very bad. So how does this engineer SSH into our EC2 instances if he doesn’t have the private key? </p>
<p>Now, the best way to do this is to set up something called SSH agent forwarding. Now, what this allows us you to do is to store the private keys for the instances within the private subnet on your local client, so that when you connect through to the bastion host, you can then SSH, but using the private key to the EC2 instances that is stored on your client rather than storing it on the bastion host. Now, with that in mind, once you have connected to your bastion host, using the example that I just showed you, you can then SSH into your private instances, at which point, it will hit the private security group that allows any SSH access on port 22 from the security group associated with the bastion host and then there, you can gain access. </p>
<p>So just to summarize exactly what we’ve done here. We started off by creating an EC2 instance within the public subnet marked as our bastion host. We then hardened that instance to try and protect it against as many security threats as possible and to lock down access to that instance. We then associated a security group that only allowed SSH inbound access from a particular IP address or a particular range of IP addresses. We then added a rule to the security group associated to our private instances that allowed SSH inbound access from the bastion host security group. You then need to ensure that SSH agent forwarding is configured on your client and then this allows you to firstly connect to your bastion host using the private key of the bastion host and then using that as the jump server to jump into your private subnet from your bastion host using the private instances, private key, which is also stored on your client PC. </p>
<p>In the next section, I’m going to be coming away from the security aspects of VPC’s list and I’m going to be focusing more on <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-vpn-direct-connect/">VPC connectivity</a>.</p>
<h1 id="VPN-amp-Direct-Connect"><a href="#VPN-amp-Direct-Connect" class="headerlink" title="VPN &amp; Direct Connect"></a>VPN &amp; Direct Connect</h1><p><strong>Resources referenced within this lecture:</strong></p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-ipsec-vpns-understanding-building-and-configuring/">Amazon VPC IPSec VPNs- Understanding, Building and Configuring</a></p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/">AWS Virtual Private Cloud: Subnets and Routing</a></p>
<p><strong>Transcript</strong></p>
<p>Hello and welcome to this section and I’m going to be talking about VPN connections, Virtual Private Networks. Now a Virtual Private Network is essentially a secure way of connecting two remote networks across the internet. So, let’s have a look how we can use VPNs within our <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-introduction/">VPC</a>. </p>
<p>So, if we just create a VPC over here and we also have our remote data center over here. Just with a little door and this is our data center and this is our VPC. Now within our VPC, we’re going to have a single subnet. Now this is going to be a private subnet, so there’s no internet gateway and there’s no route to the internet gateway as well. It’s totally isolated. So, a bit more information relating to IP addressing, so our VPC will have a CIDR block of 10.0.0.0&#x2F;16 and for our data center, let’s say the IP address sits on a 192.168.0.0 address space. </p>
<p>Okay, so we have our VPC over here sitting in AWS and we have our remote data center over here, maybe sitting in London somewhere. Okay, now we have resources within our data center in London and we also have some resources over in our private subnet, for example, some EC2 instances. Now what we want to do is enable communications between our resources in our private subnet in our VPC in AWS and to resources that are held on premise within our data center. Now we want to do this via a secure connection. </p>
<p>So, one option is to create a VPN connection, a Virtual Private Network. Now let’s look at some of the components involved with that. Firstly, on your VPC side, you need to create something called a virtual gateway and this attaches directly to your VPC. Much in the same way an internet gateway does to enable public subnets access out to the internet and again, this is managed by AWS. So, here we have our virtual gateway. Now over in our data center, we also need another endpoint and this will be our customer gateway. And then this could be a piece of hardware or it can be a software virtual appliance, other way it need to be host within your data center. So, now we have an endpoint at our data center, the customer gateway and we also have an endpoint attached to our VPC, the virtual private gateway. </p>
<p>Now during the creation of our virtual private gateway, we’ll need to supply some additional information that’s going to be used in our customer gateway such as the customer gateway’s IP address and the type of routing to be used whether it’s dynamic or static. Now if you’re not familiar with dynamic or static routing, then please see our existing course shown on the screen and this dives into different types of routing across subnets and across site to site as well. So, that will give you a little bit in-depth information on how the routing would work. </p>
<p>Now once your virtual private gateway is attached to your VPC and configured and also your customer gateway’s installed, then what we can do is initiate a tunnel between the two endpoints. Now, this VPN tunnel can only be initiated from your customer gateway. It can’t be initiated from your virtual gateway. Now if there was some idle activity across this link for a period of 10 seconds or more, then this VPN tunnel connection would drop. So, to prevent that from dropping, you can set up network monitoring to set up continuous network pings from the customer gateway side to the virtual gateway to ensure that connection remains up and running. </p>
<p>So, now we have our VPN tunnel up and running created between our virtual private gateway and our customer gateway, we need to change the route table associated to this private subnet, so our EC2 instances know how to connect to the 192.168 network. So, let’s take a look at that. Now we can see here that we have the local route which we have with every route table as we know but we also have this additional route here. Now the destination is 192.168.0.0&#x2F;16 which points to our data center network and the target is this virtual gateway. Now we know that’s a virtual gateway ‘cause it’s prefixed with vgw and then this is the ID of the virtual gateway itself and this relates to our virtual gateway up here. So the instances within this subnet now have an additional route that points to this virtual gateway to get to the network of the data center. </p>
<p>What you can do is also enable route propagation within your route table as well. Now what this will do is once your VPN tunnel is up and running, then any routes that are represented across your VPN connection will be automatically added to your route table, so you might have other networks within your data center other than the 192.168 that are configured to use that VPN tunnel, so any traffic from another network received by your virtual gateway will allow these routes to be automatically propagated to the route tables that you’ve enabled route propagation on. Now depending on what sort of customer gateway you installed, will depend if it supports the BGP Protocol, which is the Border Gateway Protocol and if it does, then this supports dynamic routing, so this will populate all the routes for the VPN connection for you which means you won’t have to implement any static routing. Now it is recommended that if you can install a customer gateway that does support BGP, then it’s probably best to do so. </p>
<p>Now once our routes were in place, we also need to ensure we have our security groups configured for our instances as well to allow traffic to come from my resources over here and via the customer gateway across the VPN link to our virtual private gateway and then onto our instances but as we know, they are protected by a security group, so we need to ensure that the right protocols et cetera are allowed on the inbound rule set of our security group for our resources that are based over here. So, if we wanted to allow SSH access, for example, or RDP access, then the security group would look as shown. Now we can see that this security group allows both SSH and also RDP and it’s from the source 192.168.0.0 which is of course our network that we’re using on our data center. </p>
<p>So, to quickly recap. We have our virtual private gateway attached to our VPC and we have our customer gateway installed at our remote location. We then configure it with either dynamic or static routing and here we have a static route added for our subnet that points to the virtual private gateway within our VPC to get to our destination network which is of course our destination network of the remote data center. And then we also have our security group protecting our resources within our VPC allowing only specific ports and protocols which are inbound for my remote data center network. So, that’s just a simple example of a site-to-site connection using a VPN which is a secure connection across the internet. </p>
<p>I now want to talk to you about using another site-to-site connection called Direct Connect but this does not use the internet. This is totally isolated infrastructure. So, let me explain how this works. </p>
<p>Okay, so in this section, I’m going to be talking to you about Direct Connect. Now this is another method of connecting your remote location such as your data center or remote office to your AWS environment. Now whereas your VPN connection used the internet to get to your VPC, a Direct Connect connection doesn’t traverse the internet. Instead it uses private infrastructure and connects directly to your VPC. So, there’s no public network that the traffic traverses, so let’s look at the architecture of this to see how it works and how it’s different to a VPN. </p>
<p>Now I’m not going to go into fine configuration details on this, I just want to provide you a high-level overview of how the Direct Connect infrastructure is presented, so let’s take a look. So, let’s start with our on-premise data center that we’ll just over here. This would be our data center. And within our data center, we’ll have a router. Now with a Direct Connection, there’s a middle entity before you get to AWS infrastructure, now this is usually an AWS partner or an AWS customer that holds Direct Connect infrastructure and there’s two parts to this. </p>
<p>The first part is the partner’s infrastructure or the customer’s infrastructure and the other part will be managed by AWS. So, effectively we will have a customer side and also an AWS side as well. Now this is all held within a facility owned and managed by a partner of AWS. This is a separate building entirely to your remote data center. Now again in the customer side, there will also be a router and another router in the AWS side as well. Okay, let’s move on to the final section. So, here we have our AWS region because with AWS Direct Connect, it enables you to create a connection between your data center and an AWS region, not just a VPC, it’s actually connected to a defined region. So, this will be our region here. And within that region we also have our VPC as well. So, this is our VPC and again, within our VPC we’ll have a subnet with perhaps an EC2 instance in it, for example. </p>
<p>Now the reason it’s connected to a region and not a VPC is that a Direct Connect connection allows you to access public as as private resources, so an example of a public source could be Amazon S3 and that’s because Amazon S3 resources can be accessed over the internet via a public connection. Now attached to our VPC, we’ll also have a virtual gateway much like we did when we was talking about our VPN connection. </p>
<p>Okay, let me just recap the three elements that we have here before we go any further. So, we have our customer data center over here with a router. Now here in the middle we have our Direct Connect location, so this is our Direct Connect location. And this sits between our on-premise data center and our AWS infrastructure and this is separated into two cages effectively. We have our customer partner router and we also have the AWS router as well. And then finally we have our AWS infrastructure over here with our region and inside the region, a VPC and we have our public components over here. Let’s just nest that in the AWS cloud. So, that all sits within AWS. </p>
<p>Now I mentioned previously that you can have a private connection and also a public connection and as a part of that configuration, you can configure private virtual interfaces and also public virtual interfaces on your router. So, let’s take a look. So, there’ll be two virtual interfaces. So, one of them will be a private virtual interface and we’ll define this by using this gray line here. So, that connects from your on-premise router to the customer side of the Direct Connect location. Now from here there’ll be a cross connect from the customer router to the AWS router within the same Direct Connect location. And then from here, this virtual private interface will then connect to your virtual gateway. Then this will allow connectivity through to your resources within your VPC. </p>
<p>Now the second interface is a public virtual interface, so let’s use this reddish color for that. So again the connection comes from your on-premise router into the customer side of the Direct Connect location, then there a cross connect across to the AWS router and from here it connects to inside of your AWS region and from here you can access your public AWS resources such as Amazon S3 et cetera. So, now we’ve established a connection from our on-premise data center into a region within AWS where we can access both private resources and also public resources and it’s all done without having to traverse the public internet. Instead there’s dedicated and isolated infrastructure using the Direct Connect locations. Now to be able to use Direct Connect, the only path that you need to establish is from your on-premise data center to a Direct Connect location to enable you to establish a connection to this customer router here. So, as long as you have a dedicated network route to a co-location that provides a Direct Connect connection, then you can establish this dedicated network that we can see here. </p>
<p>Now the great thing when working with Direct Connect is that it’s private connection and also you get speeds from 1 through to 10 gigabits per second. Okay, the final section I want to talk to you about in this course is relating to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-vpc-peering/">VPC peering</a> and also the Transit Gateway, so let’s take a look at this final section.</p>
<h1 id="VPC-Peering"><a href="#VPC-Peering" class="headerlink" title="VPC Peering"></a>VPC Peering</h1><p>In this section, I want to talk to you about VPC peering. Now we’ve looked at <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-vpn-direct-connect/">VPN connectivity</a> which looked at connecting your on-premise data center or remote office to your <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-introduction/">VPC</a> and also Direct Connect which done the same thing but over an isolated network. Now with VPC peering, it’s relating to connectivity again but what it allows you to do is connect two VPCs together. </p>
<p>So, we have one here and another VPC here. Now each of these VPCs will have resources in them. EC2 instances or databases, et cetera and what we want to allow to happen is for these two VPCs to be able to communicate with each other. Now these VPCs might be in the same region to they might be in different regions. Either way we can allow VPC peering to allow them to communicate with each other. Now the peering connection itself here that links the two VPCs is actually run and hosted on the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> infrastructure. So, this is highly resilient, there’s no single point of failure and also there’s no bottlenecked bandwidth either. So, it’s a very good way of linking two VPCs together to allow you to exchange information and for each VPC to communicate with another. </p>
<p>Now you might have multiple VPCs for organization or management and there will be times when you want resources in one VPC to communicate with another. And a quick and simple solution is to implement VPC peering. Now it’s important to mention that this peering connection is a one-to-one connection only. So, if we had a third VPC down here, call this one VPC-3, again this had additional resources in as well and you had a VPC peering connection between two and three, resources in VPC-1 could not go via VPC-1 and then through VPC-2 to get through to VPC-3. That simply is not allowed as it’s a one-to-one connection only. If you wanted VPC-1 to connect to VPC-3, then you’d have to set up a separate VPC peering connection between one and three. So, that’s a very important point when mapping out your peering connections between your VPCs. </p>
<p>Now another important point relates to IP addressing, so for example, if VPC-1 had an address of 10.0.0.0&#x2F;16, VPC-2 was 172.31.0.0&#x2F;16 and then VPC-3 was also 10.0.0.0&#x2F;16, then this connection here would not be possible because when you create VPC peering connections, each VPC cannot have an IP address overlap between them and these two VPCs have the same IP addressing scheme, so this VPC connection would not be possible. So, that’s also something else to bear in mind when creating your VPC peers. So, let’s take that connection away. </p>
<p>Now I also mentioned that you can have VPC peering configured between the same region or between different regions. So, let’s say VPC-1 and VPC-2 was in one region and VPC-3 was in another region. Then this link here would be an inter-region VPC connection. Let me now run through the process of how this peering connection is initiated. </p>
<p>So, let me just get rid of what we have on the screen here and start again. So, we have two VPCs. Our first one and also our second one. VPC-1 and VPC-2. Now VPC-1 is going to be known as the requester and VPC-2 is going to be known as the accepter. Now the owner of VPC-1 needs to send a VPC peering request to the owner of VPC-2. And again, remember, we need to make sure that the CIDR blocks of these VPCs do not overlap, so that request comes across to the VPC accepter and that’s the first stage. If the VPC accepter is happy with that peering connection, then an acknowledgement and acceptance of that request is sent back to the requester and that’s the second stage and this creates the peering connection between the two. At this stage, each VPC needs to update their routing tables to allow the traffic from VPC-1 to get to the destination of VPC-2. </p>
<p>Now to do this, we need to know the CIDR blocks of these VPCs. So, let’s assume VPC-1 is 10.0.0.0&#x2F;16 and VPC-2 is 172.31.0.0&#x2F;16. So that are two CIDR blocks that we have for our VPCs and as we know, they’re not overlapping, so from an IP perspective, there’s no issues there. So, now let’s look at the route table for each of these. So, firstly, VPC-1. As we can see, we always have our local route and then we also have this additional route here. So, the destination 172.31.0.0&#x2F;16 which is VPC-2 to go via the target of this peering connection. And the pcx simply means that this target is a peering connection. And these digits here are the ID of that peering connection. Now this VPC knows how to get to the 172.31 network by going via the peering connection here. </p>
<p>So, let’s now look at the route table for VPC-2. Again, we have our local route which every route table has and then also this additional route that points to VPC-1 again across the same peering connection. So, this VPC can now access the network of VPC-1 again via the same peering connection. </p>
<p>Now the final part of the configuration would be to modify the security groups that are hosting any resources within your VPC. So, you might have a security group here and a security group here each with EC2 instances or databases and we’ll simply need to update the rules to allow the correct resources, ports and protocols to communicate with each other. </p>
<p>So that’s a high-level overview, that is VPC peering. Now what I want to talk to you about is the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-transit-gateway/">AWS Transit Gateway</a> and again, this looks at how to connect more than one VPC together but through a one-to-many connectivity method, so let’s take a look at that.</p>
<h1 id="Transit-Gateway"><a href="#Transit-Gateway" class="headerlink" title="Transit Gateway"></a>Transit Gateway</h1><p>So, the final element I want to talk to you about is the AWS Transit Gateway. And this is essentially a development on from the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-vpc-peering/">VPC peering</a>. In today’s world we’re using more and more <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-introduction/">VPCs</a> to segment and manage different workloads and as our organization gets bigger and bigger, we’re creating more and more VPCs, we have more and more connections from our remote locations such as our data centers and offices, et cetera and creating VPC pairing connections to each one of these bearing in mind it’s a one-on-one connection can be very cumbersome and time consuming and just not very well to manage. </p>
<p>So, let’s say we had four VPCs represented by these circles here. And we also had a couple of remote offices as well. So, one there and one there. Now if we wanted to connect these VPCs into our office locations, now based on what we’ve already spoken about so far, we can use VPC pairing to link our VPCs together. But as we know, this is just a one-one-one connection, so we also need a connection across there and also a connection across there. So, we have one, two, three, four, five, six VPC pairing connections there. Now one of these remote locations might be using a VPN connection to get to that VPC, and also a VPN connection there and maybe even a third VPN connection to this VPC as well and this remote location might be used in Direct Connect to get to a couple of different VPCs in different regions. Now, that is a lot of connections and a lot of gateways to manage. We have customer gateways at the remote ends and also private gateways within our VPCs as well. </p>
<p>What AWS Transit Gateway allows you to do is to connect all of this infrastructure, so all of your VPCs, all of your remote locations, whether it’s over Direct Connect or VPN via a central hub. So, let’s take a look at how that looks. So, again we have our four VPCs and also we have our two data centers here at the bottom, our two remote locations. However, this time, we have the AWS Transit Gateway in the middle. Now, for each VPC or remote location that we want to allow to talk to each other, then all we need to do is to create a single connection to the Transit Gateway, so one from each of the VPCs and also one each from the remote locations as well. Again, these will be a VPN connection and maybe a Direct Connect connection. So, either way, VPN, Direct Connect or VPC, they all connect to this central hub, this AWS Transit Gateway. </p>
<p>As you can see between the two designs, this one over here has a lot more connections than this one over here. So, the AWS Transit Gateway simplifies your whole network connectivity. It allows all of your VPCs to easily communicate with one another and also communicate with your remote locations as well. All the routing is managed centrally within that hub and when any new remote locations or VPCs are created, for example, you might have another two VPCs created, all you’d need to do is to connect it to the AWS Transit Gateway and each of these new VPCs can then communicate with the entire rest of your infrastructure. </p>
<p>Now because the Transit Gateway goes through this central hub, it allows you to centralize all your monitoring as well for your network traffic and connectivity all through the one dashboard which is great. So, that was just a very quick high-level overview of AWS Transit Gateway and how it differs from the VPC pairing.</p>
<h1 id="Elastic-IP-Addresses-EIPs"><a href="#Elastic-IP-Addresses-EIPs" class="headerlink" title="Elastic IP Addresses (EIPs)"></a>Elastic IP Addresses (EIPs)</h1><p>Hello and welcome to this lecture covering an overview of Elastic IP addresses, known as EIPs.</p>
<p>When architecting your infrastructure from a network perspective, you might have both public and private IP addresses. Your public IP addresses will be reachable from the internet from within a public subnet, whereas your private IP addresses will be hidden in a private subnet.</p>
<p>When launching an EC2 instance, you can select the subnet that it will reside in, and if you want EC2 to auto-assign a Public IP address. If you select Enable, then your instance will be launched with one of AWS’ public IP addresses from their pool of available public addresses.</p>
<p>If this auto-assign option is selected, then that public IP address will remain with that instance until it is stopped or terminated, at which point it will be removed from your instance. However, there will be times when you need a persistent IPv4 public IP address that you need to have associated with your instance, which is exactly what an Elastic IP Address provides.</p>
<p>When you create a persistent elastic IP address, the IP address is associated with your account rather than an instance. This means you can attach an EIP address to an instance or an Elastic Network Interface, an ENI, and even if you stop the instance its associated with, the same EIP will remain in place. You can also detach the EIP from an instance and re-attach it to another instance. However, do bear in mind that when you detach an EIP and it’s not associated with a running instance, then you will incur a cost for it. If you no longer need the EIP, you must detach it from the associated instance and release it back to <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a>.</p>
<p>If you associate an EIP to an instance that already has a pooled public IP address, then that pooled public address will be released and put back into the pool, and your instance will take on a new EIP address. It’s also worth mentioning that you can’t convert an existing pooled public IP address to an EIP.</p>
<p>I will now provide a quick demonstration, and I will start by creating a new EIP within my account. I will then associate this EIP to a running instance in my VPC that already has a public IP address. And I will then confirm that the instance has the newly associated public IP address. I will then detached this EIP and release it back to AWS.</p>
<p>Let’s take a look. So I’ve logged into my AWS management console, and I have an instance running here. Now if we look at the settings of this instance, we can see that it has currently a public IP address, 3.9.177.89. So this is sitting in a public subnet at the moment. And this IP address is just allocated out of AWS’ public IP address pool. It’s not an elastic IP address. If it was then you’d see an entry under this section here.</p>
<p>Firstly, what I want to demonstrate is that these public IP addresses that are just allocated from the pool are not persistent. So if I stop this instance and then restart it, we’ll see that it will have a different public IP address. So this currently has 3.9.177.89. So if I go ahead and stop this, that’ll just take a moment to stop. Okay, that’s now stopped, we can see that it’s released the public IP address. And if I start this instance again, and we’ll see what IP address it has this time.</p>
<p>Okay, that’s now back up and running. And we can see that it is a totally different public IP address. So it just goes to show when you stop and start your instances using one of the publicly assigned IP addresses from AWS, that is not an elastic IP address, then that IP address is going to change each time. Now let me go ahead and create an elastic IP address to show you how to do that. Now on the left hand side, under network and security, you will see elastic IPS. So if you select that, at the moment, I don’t have any elastic IP addresses, so all I need to do is select Allocate new address.</p>
<p>Now I can select an elastic IP address that is owned by Amazon or one that’s owned by myself. For this demonstration, I’m going to be using an Amazon-owned address, and select Allocate. Okay and we have our elastic IP address 3.11.45.130. So now we have that here, but at the moment, it’s not actually assigned to any instance. When you have an elastic IP address created and it’s not associated to an instance, it’s going to cost you money. So you want to make sure that you either release any unassociated elastic IP addresses back to AWS, or associate it with an instance. To associate it with an instance, select Actions, and then Associate address.</p>
<p>Now here, you can either associate it to an instance or a network interface. For this demonstration, I’m going to associate it to a running instance. Now the instance that we was looking at just a moment ago, was called public instance. And as we can see that is currently running. Now also have to associate a private IP address to associate to the IP as well, so it can communicate internally with the rest of the subnets on your VPC.</p>
<p>So this is the private IP address that was running on our instance, so we’ll select that. And now I just need to select Associate. So our EIP is now associated to a running instance. So let’s go and take a look. So if we go back to our instances, we can now see that the public IP address is our EIP address, which is 3.11.45.130. And we can also see here that it’s allocated the elastic IP address which is the same.</p>
<p>So to associate an EIP with an already running instance is very easy, it just replaces the existing public IP address that it had previously. Now if I stop this instance and restart it, we’ll see that it maintains this same elastic IP address, 3.11.45.130. So let me just demonstrate that now. So I’m gonna stop this instance.</p>
<p>Okay, that’s now stopped. And we can see here that it’s still maintaining this elastic IP address, whereas previously with the general pooled public IP address, this cleared, this entry cleared when we stopped the instance. So if we start this instance again, and we can see that it’s retained and persisted this public IP address. So it behaves very differently.</p>
<p>Okay, so now what I’m going to do is disassociate this elastic IP from this instance. So if I go back to my elastic IPs, we can see our elastic here and we can see that it’s associated to our instance, if I go to Actions, Disassociate address, and it just gives us information on the instance ID and the network interface that it’s going to disassociate it from.</p>
<p>So if I go ahead and disassociate that, we can now see that it’s not related to any instance at all. And if I go back to my instance, we can see that the elastic IP address is now gone, and instead it had pooled a general AWS public IP address instead. Which as we know, is not persistent when we restart and stop the EC2 instance. However, now I have an elastic IP address that isn’t being used.</p>
<p>So again, this is costing me money. So now I want to release it back to AWS ‘cause I no longer need it. So again, I select the EIP, select Actions, and Release address. Then we just have a confirmation message, and I select Release. And it’s as simple as that.</p>
<h1 id="Elastic-Network-Interfaces-ENIs"><a href="#Elastic-Network-Interfaces-ENIs" class="headerlink" title="Elastic Network Interfaces (ENIs)"></a>Elastic Network Interfaces (ENIs)</h1><p>Hello and welcome to this lecture, which is going to look at elastic network interfaces, which are commonly known as ENIs.</p>
<p>ENIs are logical virtual network cards within your virtual private cloud, your VPC, that you can create, configure, and attach to your EC2 instances. The configuration is bound to the ENI and not the instance that it is attached to. This means that you can also detach your ENI from one instance, and reconnect it to another instance and the configuration of that ENI would move with it. For example, a private IP address or an elastic IP address or it’s MAC address.</p>
<p>You may not have come across ENIs before, because when you create an instance your EC2 instance comes configured with a primary network interface that is already bound to your instance. And this can’t be removed or detached. If you look at your EC2 instances, you’ll see this primary interface labeled Eth0.</p>
<p>However, there will be occasions where you will need your instances to have multiple network interfaces. For example, if you wanted to create a management network, and in this instance, you can create and use an ENI to attach to your instance in addition to its primary interface of Eth0. This second interface can then be configured with a private IP address to handle any management traffic from within a different subnet.</p>
<p>Much like your Eth0 interface, all traffic originating from and being sent to an ENI can be captured using VPC flow logs. More information on VPC flow logs can be found <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/vpc-flow-logs/">here</a>.</p>
<p>When designing your solution and any requirements for multiple interfaces being attached to your instances, you’ll need to bear in mind that the quantity of interfaces is dependent on the EC2 instance type. To check how many interfaces can be attached to your instance, please check the following <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#AvailableIpPerENI">AWS documentation</a>.</p>
<p>Let me now provide a quick demonstration on how to create and attach an ENI to existing EC2 instance.</p>
<p>In this demonstration, I have two private subnets within my VPC. These are labeled as production and management. I have an existing instance called Myinstance, within the production subnet. However, I want to implement a management network that will reside within the management subnet. As a result, I will create a new ENI and configure it for the management subnet, and then attach it to my instance. Let’s take a look. </p>
<p>Okay, so I’m logged into my <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> Management Console, and I’m on my VPC dashboard. I’m just looking at my subnets, and I just want you to see the different subnets I’ve got for this cloud Academy VPC. The two subnets that I’m interested in are the production and the management. So for the production subnet, we have a 10.0.2.0 network. And for the management network, we have a 10.0.3.0 network.</p>
<p>Now I also have an EC2 instance. So if I just go across to EC2, I have an instance called Myinstance. And at the moment, this is residing in the 10.0.2.0 network, which is in the production subnet. Now what I want to do is to add a secondary network interface to this instance, with an IP address that sits on the management network. So at the minute, we can see that it only has this primary Eth0 interface. And we can see that this is the primary network interface, and it has a 10.0.2 address.</p>
<p>So let me go ahead and create a new network interface. So on the left hand side, if you scroll down to Network and Security, and select Network Interfaces, and then Create Network Interface, and add a description here, so I’m going to call it my Management_Interface. And the subnet that I want to associate this with is the management subnet. And I can either auto assign or add a custom IP address. For this demonstration, I’m just going to leave it as auto assigned.</p>
<p>An elastic fabric adapter is a network device that you can attach to your instances to reduce latency and increase throughput for distributed high performance computing and machine learning applications. So we don’t need to do that for this demonstration, but I just wanted to show you what the elastic fabric adapter is. And finally you can select any security groups as well. I’m just gonna select a default security group for this demonstration. Select Create, and we now have our new network interface created.</p>
<p>And we can see here under the Description, that it’s the Management_Interface that I named it. And currently the status is available is naturally in use. So I’ve literally just created a network interface. And if we look at the properties down here, and we can see that it resides on the 10.0.3 network, which is correct. So now what I want to do is attach this to our instance.</p>
<p>So once I’ve selected the interface, if I go to Actions, Attach, select the instance, which is Myinstance, which is running and then select Attach. That interface will then be attached to that EC2 instance. And we can see here that it’s now in use. So if we go back to Myinstance, and select it, so we can take a look at the properties, we can see down here that we now have a secondary network interface. So the Eth0 was the primary that sits on the 10.0.2 network. And that’s the primary network interface. And now if we look at this interface Eth1, this is our new management interface. And we can see that this sits on the 10.0.3 network. So this EC2 instance now has network interfaces connecting to two different subnets and one of those subnets is the management network.</p>
<p>Now to detach the interface is very easy. We can go back to our network interfaces section, select the Interface and select Detach. We get a confirmation message asking if we want to detach it, we say yes for the detachment. Once that interface is detached, we can then delete that interface as well if we no longer need it. And again, just to reiterate, we can see that the network interface itself retains its configuration. So it’s brought the IP address with it. So finally, let me just delete this interface by selecting Delete. Say yes, and that’s it.</p>
<h1 id="EC2-Enhanced-Networking-with-the-Elastic-Network-Adaptor-ENA"><a href="#EC2-Enhanced-Networking-with-the-Elastic-Network-Adaptor-ENA" class="headerlink" title="EC2 Enhanced Networking with the Elastic Network Adaptor (ENA)"></a>EC2 Enhanced Networking with the Elastic Network Adaptor (ENA)</h1><p>Hello and welcome to this lecture which will take a look at how to enable enhanced networking features on your EC2 instances with the Elastic Network Adapter (ENA), which is a custom interface used to optimize network performance.</p>
<p>If you are looking to enable enhanced networking features to reach speeds of up to 100 Gbps for your Linux compute instances, then you can do so using an ENA. However, ENAs are only supported on a limited number of instances as shown below, and by instances running kernel versions 2.6.32 and 3.2 and above.</p>
<p>For an up to date list of supported EC2 compute types please visit the following link to <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html#enabling_enhanced_networking">AWS documentation</a>.</p>
<p>In addition to 100 Gbps speeds, enhanced networking offers higher bandwidth with increased packet per second (PPS) performance, and a big bonus of enhanced networking is that it is offered at no extra cost. In fact, when launching an instance using Amazon Linux 2 or with the latest version of the Amazon Linux AMI, then the instance will have enhanced networking enabled by default, providing its provisioned with one of the supported instance types mentioned earlier.</p>
<p>Enhanced networking is enabled when the ena module is installed on your instance and that the enaSupport attribute is set. If you wanted to confirm that the ena module is installed on your instance then you can run modinfo ena from the terminal prompt. To check that the enaSupport attribute is also set you can use the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> CLI and run the following command, replacing the red text (“instance_id”) with the appropriate instance_id:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ec2 describe-instances --instance-ids instance_id --query &quot;Reservations[].Instances[].EnaSupport&quot;</span><br></pre></td></tr></table></figure>

<h1 id="VPC-Endpoints"><a href="#VPC-Endpoints" class="headerlink" title="VPC Endpoints"></a>VPC Endpoints</h1><p>Hello and welcome to this lecture covering VPC Endpoints.</p>
<p>VPC Endpoints allow you to privately access <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> services using the AWS internal network instead of connecting to such services via the internet using public DNS endpoints. This means that you can connect to the supported services without configuring an Internet Gateway, NAT Gateway, a Virtual Private Network or a Direct Connect connection.</p>
<p>There are 2 types of VPC Endpoints: Interface Endpoints and Gateway Endpoints.</p>
<p>Interface Endpoints are essentially ENIs that are placed within a subnet that act as a target for any traffic that is being sent to a supported services and operates through the use of PrivateLink. PrivateLink allows a private and secure connection between VPCs, AWS services, and on-premises applications, via the AWS internal network.</p>
<p>As an example of supported services, this list only shows a very small subset of what’s available via an Interface Endpoint.</p>
<p>One point to make is that when an interface endpoint is configured within your chosen subnet, the service that it is associated with is NOT able to initiate a connection through to your VPC, communication across this interface HAS to originate from within your VPC first before a response can be made by the service.</p>
<p>You might be wondering how you connect and make use of the endpoints, and the process is seamless to the end user when working with AWS services. When an interface endpoint is created for a service, a specific DNS hostname is created and is associated with a private hosted zone in your VPC. Within this hosted zone a record set for the default DNS name of the service is created resolving to the IP address of your interface endpoint. As a result, any applications using that service already does not need to be reconfigured, requests to that service using the default DNS name will now be resolved to the private IP address of the interface endpoint and will route through the internal AWS network instead of the internet.</p>
<p>A Gateway Endpoint is a target that is used within your route tables to allow you to reach supported services, currently the only supported services using a Gateway Endpoint are Amazon S3 and DynamoDB, but this like is likely to change over time to please ensure you check the latest supported services.</p>
<p>During the creation of your Gateway endpoint you will be asked which route tables within your VPC should be updated to add the new Target of the gateway endpoint. Any route table selected with then have a route automatically added to include the new Gateway Endpoint. The entry of the route will have a prefix list ID of the associated service (Amazon S3 or DynamoDB) and the target entry will be the VPC Endpoint ID, examples of these are shown on screen. You should also be aware that GateWay Endpoint only works with IPv4.</p>
<h1 id="Working-With-Amazon-CloudFront"><a href="#Working-With-Amazon-CloudFront" class="headerlink" title="Working With Amazon CloudFront"></a>Working With Amazon CloudFront</h1><p>In this section, we will review the purpose of Amazon CloudFront and its key features. The main role of CloudFront is caching of content. Caching allows us to store our content closer to the users that need it. If you have a website hosted in the EU-West-2 region, but a lot of your customers are in the US or Australia, they will have higher latency when compared to the users in the UK. But if we cache content closer to them, on 8-west edge locations in the US and Australia, their latency will be reduced. Amazon CloudFront allows customers to distribute content with low latency and high speed. Amazon CloudFront is a pay-as-you-use service. And when using CloudFront, files are delivered to end-users via a global network of edge locations. </p>
<p>CloudFront works with both static and dynamic content. For example, static content stored in Amazon S3 buckets. These static stores hold the definitive version of files. Dynamic content stored on Amazon EC2 or served up using Lambda functions. This content is generated on the compute resource and distributed through Amazon CloudFront. When working with CloudFront, you first create a CloudFront distribution. During this process, you identify one or more origins for the content that this distribution will serve the clients. You also configure options that control protocols that can be used such as HTTP or HTTPS; cache time to lives; custom headers; a price class, where its use all edge locations or a subset of locations; AWS WAF web ACL associations; alternate domain names; custom SSL certificates, and more. When creating a CloudFront distribution, you’re assigned a domain name.</p>
<p> For example, 1234.cloudfront.net. Although you can use this domain name, most customers of Amazon CloudFront will add an alternate domain name to their distribution. A name such as cloudacademy.com is the mat to the CloudFront assigned name using DNS. In the following demonstration, we already have an Internet application load balancer load balancing traffic to our website. We will create a CloudFront distribution to cache our website content globally. We are in the CloudFront distribution center dashboard. To create a distribution, we select Create distribution. We then select our origin domain. The origin can be an AWS origin or we just type in the domain name of the origin that we wish CloudFront into cache. If I click in the ‘Choose origin’ domain box, we can see a list of valid ADS origins, including S3 buckets and our application load balancer. </p>
<p>I’m going to select the application load balancer. With the load balancer selected, you then get to choose protocol information and port information that the distribution will use when connecting to the load balancer. If I scroll down a little bit, we get to choose an origin name. We can accept the default name for the origin or choose a name that’s more meaningful for us. There is a lot of optional information we can select. A lot of these settings are discussed later on in this course. If I scroll down a little bit, we can find settings that allow us to configure cache behavior. If I scroll down a little bit more, we find the pricing class. The pricing class allows us to choose groupings of edge locations that our distribution will use to cache content. We can choose to associate our WAF ACL with our distribution, and we can select an alternate domain name for our distribution. </p>
<p>Most deployments will use an alternate domain name, so that we can use our own nice friendly DNS names instead of having to rely on the CloudFront DNS name. If you choose to use an alternate domain name, you’ll also need to select a digital certificate. The digital certificate can be imported from your own certificate stars, or we can search certificate from Amazon certificate manager. If I scroll down a bit more, we can enable standard logging file distribution, so that we can log viewer requests into an S3 bucket. You can also turn on or off support for IPv6. If you’re happy with our choices, select Create distribution. Once you’ve selected distribution, you should see a message saying that your distribution is being deployed. </p>
<p>Although we often discuss CloudFront as a single cache, actually CloudFront has three cache in layers. Cloudfront distributions, these exist over 300 Amazon edge locations globally. Regional edge caches, and at the time of writing there are 13 regional edge caches. And AWS Origin shield, an additional cache in layer between your regional edge caches and the origins. Origin shield is not enabled by default. You must enable it for each origin in the distributions you create. By having multiple cache layers, you can cache more content for longer. Using regional caches and origin shield, you get better cache hit ratios. Because more of your content is cached, there is a much better chance that the content your customers need will be retrieved from cache. Reduced origin load: With more content being served from cache, less requests are sent to origins. </p>
<p>And when using origin shield, requests for the same object not in cache are consolidated, so only a single request is sent to the origin. Better network performance: Using multiple layers, content can stay on the AWS Lola into network for longer. CloudFront has a long list of security features. These include CloudFront use of SSDs, which are encrypted protecting your data at rest. We can use signed URLs and cookies to restrict access to content that is intended for specific users. We can use AWS WAF to create web ACLs to restrict access to content, and we can use geo restrictions to prevent users in certain regions from accessing content. For more information on AWS WAF, please refer to our existing class content here. Amazon CloudFront itself integrates with identity and access management, which we can use to control administrative access to CloudFront. And CloudFront can be monitored through integration with: Amazon CloudWatch alarms, AWS CloudTrail Logs, and CloudFront real-time IAM standard logs.</p>
<h1 id="Amazon-CloudFront-Patterns"><a href="#Amazon-CloudFront-Patterns" class="headerlink" title="Amazon CloudFront Patterns"></a>Amazon CloudFront Patterns</h1><p>In this section, we will discuss two examples of using CloudFront to cache and secure access to content.</p>
<p>Pattern 1 – Using CloudFront to cache and secure content when an Application Load Balancer is the Origin.</p>
<p>In this pattern we have an Application Load Balancer, load balancing HTTP port 80 and HTTPS port 443 traffic to a set of EC2 instances hosting a website. To integrate with CloudFront we would create a CloudFront distribution with the application load balancer as the origin. It is worth remembering that CloudFront can work with any public endpoint whether AWS or external. This Load Balancer will be an internet-facing load balancer.</p>
<p>For this pattern to work, we will need to do a couple of things.</p>
<ol>
<li>Work with Route 53</li>
<li>Secure connections to the application load balancer</li>
</ol>
<p>Originally the nice friendly name for your website will be mapped to the name of the application load balancer, but now we want the friendly name of your website to route people through CloudFront. For this to work, we need to edit the Alias record in Route53 to map the friendly name to the DNS name that CloudFront has provided you when you created your distribution. Remember we are using an internet-facing load balancer, so if someone knows the DNS name of the load balancer or its IP addresses then they might be able to connect to load balancer directly, bypassing your CloudFront distribution and the performance and security benefits it provides. To secure the connection between our CloudFront distribution and the Application Load Balancer we can do the following:</p>
<p>Firstly, Configure CloudFront to add a custom HTTP header to requests. When creating or editing your CloudFront distribution add a custom header. The custom header will be included in each request sent to the origin. Next. Configure an Application Load Balancer to only forward requests that contain a specific header. To do this we need to select the listeners configured on the load balancer and edit its rules. We then adjust the rules:</p>
<p>Rule 1: if the custom header is included in the request forward traffic to the target group. </p>
<p>Rule last: If the request does not include the custom header then return a 403 error.</p>
<p>With everything saved, if someone tries to access your website using the Application Load Balancers hostname or IP Addresses they should see a 403 error similar to the error below. By using HTTPS for origin requests we are configuring an encrypted connection between our distribution and the Load Balancer. This will help keep your custom header secret. This setting is configured on your CloudFront distribution and requires the appropriate secure listener to be configured on your Application Load Balancer. It is important you rotate the custom header in your distribution and on the load balancer. If you do not rotate the custom header then over time there is a greater chance that the header name and value will be discovered undermining your security.</p>
<p>To do this:</p>
<ol>
<li>Add a second custom header to the CloudFront distribution</li>
<li>Add a new rule to the load balancer listener that uses the new custom header as the condition and forwards traffic to the target group</li>
<li>Remove the old custom header and rule from the cloudfront distribution and the load balancer listener</li>
</ol>
<p>Pattern 2 – Using CloudFront to cache and secure content when an S3 bucket is the origin</p>
<p>Using S3 to deliver content is a common feature of many AWS Architectures, in S3 content is stored in buckets and buckets are in a single region. Because of this your applications can suffer from latency issues if you have customers globally who need to access content from a centralized bucket. CloudFront can help solve this problem by allowing content to be cached closer to the users who need to access it. We can also use S3 to host a website, this has lots of advantages, one of which is we no longer need compute resources such as EC2 to host our static content. When using S3 to host static content we:</p>
<ul>
<li>Create a bucket and enable it for static website hosting</li>
<li>Then Enable public read access on the bucket</li>
</ul>
<p>You will be given a URL that can be used to access your index document, S3 only supports HTTP access when using static website hosting. We have several problems here.</p>
<ol>
<li>What if you wish to use HTTPS instead of HTTP?</li>
<li>What if you don’t or can’t allow public access to content?</li>
<li>What about latency? Our website is still stored in a bucket in a single region</li>
</ol>
<p>CloudFront can solve these issues.</p>
<ul>
<li>CloudFront can distribute your content globally reducing latency for your customers.</li>
<li>When we create a CloudFront distribution we can add an alternate domain name and a certificate allowing us to use or even enforce HTTPS. </li>
<li>We can also remove public access to the S3 bucket and secure access so that only the CloudFront distribution can access content.</li>
</ul>
<p>To enable HTTPS you will need a digital certificate. AWS provides the AWS Certificate Manager service (ACM), through which we can request digital certificates for free. Using ACM we can request internal certificates or trusted public certificates. If you are planning on integrating your CloudFront distribution with AWS Certificate Manager (ACM) please keep in mind that CloudFront works with ACM in the North Virginia region. It is from here that you should create your certificate requests.</p>
<p>To make sure that only your distribution can request content from your S3 bucket and to allow you to remove the public access that static website hosting needs, we use Origin Access Identity (OAI) and S3 Bucket Policies. This process is important, without it users could still use the bucket’s URL to access your content, by passing the security and performance benefits of CloudFront.</p>
<p>Begin by creating an Origin Access Identity (OAI) in cloudfront and then associate it with your CloudFront distribution. Here you can see an OAI that has been created in the CloudFront console, notice the Name and ID. Next, you can see that we have associated the newly created OAI with our distribution</p>
<p>You can then select the option to automatically update the bucket policy of the S3 bucket or you can edit the bucket policy yourself. Here we can see the bucket policy that would be created on the S3 bucket that contains our content. We can see that the principal is the ARN of the OAI and that the effect is set to allow. You can adjust the actions as required, here we are allowing the S3.GetObject action on the bucket. </p>
<p>Finally, notice that public access is blocked. If someone was to obtain the bucket url and tried to access content using the url they would receive an access denied message. But if they use your friendly name mapped to the CloudFront distribution DNS name then access will be allowed. Here is an example of how that record might look in Route 53, we use an alias record mapped to the distribution DNS name.</p>
<h1 id="AWS-Global-Accelerator"><a href="#AWS-Global-Accelerator" class="headerlink" title="AWS Global Accelerator"></a>AWS Global Accelerator</h1><p>Hello and welcome to this lecture covering the AWS Global Accelerator, which is a Global <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> service and therefore not tied to a specific region.</p>
<p>The ultimate aim of the AWS Global Accelerator is to get UDP and TCP traffic from your end user clients to your applications faster and quicker and more reliably, through the use of the AWS global infrastructure and specified endpoints, instead of having to traverse the public internet, which is not as reliable and carries a higher security risk.</p>
<p>Global Accelerator uses two static IP addresses associated with a DNS name which is used as a fixed source to gain access to your application which could be sitting behind a load balancer, such as a network or application load balancer, or directly connected to your EC2 instance or the Elastic IP address. These IP addresses can be mapped to multiple different endpoints, each operating in a different region if a multi-region application is deployed to enhance performance of routing choices.</p>
<p>Because the routing of your request is based across the AWS Global Infrastructure, Global Accelerator intelligently routes customers requests across the most optimized path using its global reach of edge locations, for the lowest latency and avoids any resources that are unhealthy. This helps to improve regional failover and high availability across your deployment.</p>
<p>To set up and configure AWS Global Accelerator there are effectively four steps to follow.</p>
<p>Firstly, you must create your accelerator and give it a name. You must also select if you want to use two IP addresses from AWS’ pool of IP addresses or use your own. For each accelerator created, you must select two IP addresses.</p>
<p>Next, you need to create a listener. The listener is used to receive and process incoming connections based upon both the protocol and ports specified, which can either be UDP or TCP based.</p>
<p>Once your listener is created you must associate it with an endpoint group. Each endpoint group is associated with a different region, and within each group there are multiple endpoints. You can also set a traffic dial for the endpoint group, and this is essentially a percentage of how much traffic you would like to go to that endpoint group. And this helps you with blue and green deployments of your application to control the amount of traffic to specific regions. At the stage of adding your endpoint groups you can also configure health checks to allow the global accelerator to understand what should be deemed as healthy and unhealthy. </p>
<p>Finally, you must associate and register your endpoints for your application. And this can either be an application load balancer, a network load balancer, an EC2 instance or an EIP. For each endpoint, you can also assign a weight to route the percentage of traffic to that endpoint in each of your endpoint groups.</p>
<p>Let me now provide a very quick demonstration to show you how this creation looks within the AWS Console.</p>
<p>Okay so I’m logged in to my AWS Management Console and I need to go to the Global Accelerator which is under the Network and Content Delivery category. So if I select the Global Accelerator, now at the moment I don’t have any Global Accelerators configured. So from here I’ll simply click Create Accelerator.</p>
<p>Now, to start with, I need to select a name for my accelerator. So let me just call this MyAccelerator. Now here we have the IP address type, which is IPv4, and then we have the IP address pool selection. And the default is to use Amazon’s pool of IP addresses but if you want to use your own pool of addresses, then this is where you could change it. And also you can add any tags to this service if you need to.</p>
<p>So onto the next stage, this is where we add our listeners. So we can add in a port, for example, port 80. Either TCP or UDP as the protocol, and then you also have Client affinity here. And we can see that if you have state full applications, Global Accelerator can direct all requests from a user at a specific client IP address to the same endpoint resource to maintain client affinity. The default for this option is None. We don’t need that for this demonstration, so I’m just gonna leave that as None. And if you want to add any more listeners, simply click on Add Listener, and fill in the relevant details.</p>
<p>For this demonstration, I’m just gonna leave it as the one listener. Once your listeners are configured as you need to, click on Next. And here we have our endpoint groups. Here you select your regions that you want your application to reside in. So, for example, I’ll select the London region. And also we have our traffic dial, which as I explained previously, is essentially the percentage of traffic to this region. We can add additional endpoints, so we can have multiple regions if we want to. And you can keep going, add in more more regions. So let’s go and remove those two, just leave it as the one region. If you select on the configure Health checks, then you can set your health check configuration as need be just so the AWS Global Accelerator knows what it deems as healthy.</p>
<p>Once you have set your health checks, then you can select Next. On the final stage we need to add our endpoints. So here we have our endpoint group, and we select add endpoint. Now we can either add an Application Load Balancer, Network Load Balancer, an EC2 instance or an Elastic IP address. For this example, I’m gonna select an EC2 instance. And I won’t need to select the specific instance. I have one here called MyApplication. And again we have weight information, which directs the amount of traffic to each of your endpoint in your groups. I only have the single endpoint in this group, so I’m just gonna change that to 255. It can be from zero all the way to 255.</p>
<p>To add additional endpoints, simply click on Add endpoint. Select the endpoint that you’d like and then the related resource. I’m just gonna have the one endpoint in this endpoint group. And then once you’ve done that, simply click Create accelerator. And this would take a few minutes to configure itself and become active. And as you can see the status is in progress.</p>
<p>Also, as I explained earlier, we can see that this Global Accelerator has been given a DNS name, which results to this two static IP addresses. And these are the two IP addresses from the AWS pool of addresses. So that means you can add or change your endpoint groups and related endpoints in any of the regions without having to change the DNS name or the static IP addresses that it results to. So it’s very easy to change and increase region availability and high availability for your Global Accelerator. And it’s as simple as that.</p>
<h1 id="Using-Amazon-Route-53-Introduction"><a href="#Using-Amazon-Route-53-Introduction" class="headerlink" title="Using Amazon Route 53 - Introduction"></a>Using Amazon Route 53 - Introduction</h1><p>Hello and welcome to this Cloud Academy presentation. This is Jorge Negrón and I’m part of the AWS Content development team here at Cloud Academy. </p>
<p>In this course, you will be introduced to Amazon Route 53 and learn how the service helps you register a domain name and manage it worldwide. Route 53 allows for Domain name registration and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/using-amazon-route-53-route-end-users-internet-applications-1902/amazon-route-53-and-dns-records/">Domain Name System</a> or DNS management. Route 53 also implements traffic management by routing internet traffic to the resources for your domain and even check the availability of your resources using <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/using-amazon-route-53-route-end-users-internet-applications-1902/amazon-route-53-health-checks/">health checks</a> to verify they are working as expected. </p>
<p>Amazon Route 53 uses edge locations in the AWS global infrastructure and it’s a global service. You don’t have to specify a region in configuring Route 53 resources. AWS offers a 100% available SLA for Route 53. This is due to the distributed nature of the DNS system and the high redundancy of the AWS implementation.</p>
<p>Routing policies define how to route internet traffic to the resources in your domain. You can choose from a variety of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/using-amazon-route-53-route-end-users-internet-applications-1902/amazon-route-53-routing-policies/">routing policies</a> including failover routing, and latency routing among others. Route 53’s “<a target="_blank" rel="noopener" href="https://cloudacademy.com/course/using-amazon-route-53-route-end-users-internet-applications-1902/amazon-route-53-traffic-flow/">Traffic flow</a>” feature allows you to create complex routing configurations, combining one or more routing policies for your resources. </p>
<p>Route 53’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/using-amazon-route-53-route-end-users-internet-applications-1902/application-recovery-controller/">application recovery controller</a> feature allows you to manage failovers by using routing integrated with health checks and application component verification. </p>
<p>The <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/using-amazon-route-53-route-end-users-internet-applications-1902/amazon-route-53-resolver/">Amazon Route 53 Resolver service</a> is for VPCs and integrates easily with DNS in your data center. You basically configure endpoints for DNS queries into and out of VPCs. </p>
<p>Finally, Route 53 Resolver DNS Firewall is a managed service for DNS queries that originate in your VPC. You can create rule groups that allow or block specific DNS queries.</p>
<p>In short, with Amazon Route 53 you get a domain name management service with features that go beyond registration and name resolution allowing you to control how traffic is directed globally.</p>
<p>If you have any questions about the material being discussed, please, feel free to contact me <a href="mailto:jorge.negron@cloudacademy.com">jorge.negron@cloudacademy.com</a> with any questions using the details shown on the screen, as an alternative, you can always get in touch with us here at Cloud Academy by sending an email to: <a href="mailto:&#x73;&#x75;&#112;&#x70;&#x6f;&#x72;&#116;&#x40;&#x63;&#108;&#x6f;&#x75;&#x64;&#97;&#99;&#x61;&#x64;&#101;&#x6d;&#121;&#x2e;&#x63;&#111;&#x6d;">&#x73;&#x75;&#112;&#x70;&#x6f;&#x72;&#116;&#x40;&#x63;&#108;&#x6f;&#x75;&#x64;&#97;&#99;&#x61;&#x64;&#101;&#x6d;&#121;&#x2e;&#x63;&#111;&#x6d;</a> where one of our Cloud experts will reply to your question.</p>
<p>This course is intended for architects, developers, system operators, and administrators looking for a way to manage domain name servers using AWS. This course also covers some of the objectives for both the solutions architect associate certification exam and SysOps administrator associate certification exam. </p>
<p>In this course, you will learn what Amazon Route 53 can do in terms of features and capabilities. You will also be able to understand the routing options and health checks performed by the service.</p>
<p>To get the most out of this course you will need to meet the requirements for the AWS cloud practitioner certification. </p>
<p>Feedback on our courses here at Cloud Academy is valuable to us as trainers and any students looking to take the same course in the future. If you have any feedback, positive or negative, it would be greatly appreciated if you could send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>.</p>
<p>Please note that, at the time of writing this content, all course information was accurate. AWS implements hundreds of updates every month as part of its ongoing drive to innovate and enhance its services. As a result, minor discrepancies may appear in the course content over time. Here at Cloud Academy, we strive to keep our content up to date and provide the best training available. </p>
<p>If you notice any information that is outdated, please contact <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. This will allow us to update the course during its next release cycle.</p>
<h1 id="Amazon-Route-53-and-DNS-Records"><a href="#Amazon-Route-53-and-DNS-Records" class="headerlink" title="Amazon Route 53 and DNS Records"></a>Amazon Route 53 and DNS Records</h1><p>Amazon Route 53 is the domain name management service provided by AWS.  The domain name management system or DNS is responsible for translating domain names to IP addresses every time we use the internet, similar to a phone book that translates from a person to an actual number to dial. As such, DNS is part of the essential fabric that holds together the internet. </p>
<p>When you use Amazon Route 53 to register a domain, the service becomes the authoritative DNS server for the domain and creates a public hosted zone. A Public zone defines how traffic is routed on the public internet. A Private zone defines how traffic is routed inside a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-networking/vpc-what-vpc/">virtual private cloud</a> or VPC. VPCs intended to be used with Private Zones need to have DNS Hostname and DNS Support enabled in their configuration. </p>
<p>Private and Public Hosted Zones are made of records. There is a variety of record types. Two of the more important record types are the Name Server or NS record type and the Start of Authority or SOA record type. <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-dns-content-delivery-aws/amazon-route-53/">Amazon Route 53</a> creates a set of 4 unique NS records and 1 SOA record in each hosted zone created. </p>
<p>The Name Server (NS) records are used to identify the DNS servers for a given hosted zone. </p>
<p>The Start of Authority (SOA) record is used to define the authoritative DNS servers for an individual DNS zone. </p>
<p>These two records are essential to integrating your domain to the existing DNS system.</p>
<p>Route 53 supports the common record types of DNS including:</p>
<p>The A record is used to map a hostname to an IP address. An A record is used for IPv4 address.</p>
<p>The AAAA record is also used to map a hostname to an IP address. The AAAA record is used for IPv6 addresses. </p>
<p>A Mail exchange (MX) record is used to identify email servers for a given domain. You can have more than one and set the priority using a number. For example, you may have a primary email server with a priority of 10 and a secondary email server with a priority of 20. The lowest number record is used first. </p>
<p>The text (TXT) record is used to provide information in a text format to systems outside of your domain. It has multiple use cases. </p>
<p>A canonical name or CNAME is used to map a hostname to another hostname. This can be used to map multiple names to the same host. For example, when a server needs to respond as webserver using the hostname WWW and mail server using the hostname MAIL at the same time. </p>
<p>Please note that DNS supports record types above and beyond those mentioned here. </p>
<p>One record type that is outside the scope of DNS is the Alias record type.</p>
<p>The Alias record type is unique to Amazon Route 53 and maps a custom hostname in your domain to an AWS Resource which is usually represented by an internal AWS name. For example, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/cloudfront/overview-2/">CloudFront</a> distributions, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-to-amazon-s3/introduction/">Amazon S3 buckets</a>, and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/using-elastic-load-balancing-ec2-auto-scaling-support-aws-workloads/what-elastic-load-balancer-elb/">Elastic Load Balancers</a> provide you a domain name that is internal to AWS. You can use an alias record to define a custom name to that resource. You can also use Alias records to map to apex records which are the top nodes of a DNS namespace like on example.com or cloudacademy.com</p>
<p>When you create a record using Route 53 you specify the record name, the record type, the actual value, the Time-To-Live in seconds, and the Routing policy for this record. </p>
<p>The Time to Live specifies the amount of time the record is considered valid. The same record result obtained before is used in the future and DNS won’t be queried again until the TTL has expired. </p>
<p>The Routing policy for a record defines how to answer a DNS query. Each type of policy does something different including the possible use of health checks. Let’s talk about those health checks first. </p>
<h1 id="Amazon-Route-53-Health-Checks"><a href="#Amazon-Route-53-Health-Checks" class="headerlink" title="Amazon Route 53 Health Checks"></a>Amazon Route 53 Health Checks</h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-dns-content-delivery-aws/amazon-route-53/">Amazon Route 53</a> health checks are independent resources that can be used by most routing policies when defining a record. When you create a health check, Route 53 sends requests to the endpoint every 30 seconds, and based on the responses, Route 53 decides if the endpoint is Healthy or UnHealthy and uses that information to determine what value to provide as an answer to the query. </p>
<p>You can also configure a health check for other “health checks” allowing you to independently verify different tiers of your application before the actual total application is considered healthy. <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">Amazon</a> Route 53 adds up the number of health checks considered healthy and compares that number to the health threshold value you specify. </p>
<p>With Route 53 health checks you can also monitor the state of a cloud watch alarm. The health check status is healthy when the alarm is in the OK state. The health check status is unhealthy when the alarm status is in the ALARM state. You can also choose what the health check status is when the alarm is in the INSUFFICIENT state. The options are healthy, unhealthy or “last known status”. </p>
<p>When Route 53 receives a query it chooses a record based on the routing policy, it then determines the current health of the selected record by checking the status of the health check for that record and responds to the query with the value of a healthy record. Unhealthy records are not considered. If you do not associate a health check with a record, Route 53 treats those records as always healthy. </p>
<p>The health check is performed by a fleet of health checkers located worldwide. You can use the list of recommended health checkers by region or customize the list to the regions specific to your business. Health checks are performed every 30 seconds unless you specify every 10 seconds. </p>
<p>Endpoint health checks can be specified by IP address or by domain name. The health check protocol can be TCP, HTTP, or HTTPS. For the HTTP-related protocols, you can use an optional string matching where you indicate that Route 53 is to search the response body for the string specified. Route 53 considers the endpoint healthy only if the string specified appears entirely within the first 5120 bytes of the response body.  </p>
<p>Finally, for all health checks, you can choose to get notified when it fails. </p>
<h1 id="Amazon-Route-53-Routing-Policies"><a href="#Amazon-Route-53-Routing-Policies" class="headerlink" title="Amazon Route 53 Routing Policies"></a>Amazon Route 53 Routing Policies</h1><p>The Routing policy for a record defines how to answer a DNS query. Each type of policy does something different. </p>
<p>The Simple routing policy provides the IP address associated with a name. With Simple routing an A record is associated with one or more IP addresses. A random selection will choose which IP to use. It is important to note that Simple Routing policies do not support health checks. All other routing policies do. </p>
<p>The Weighted routing policy is similar to simple routing and you can define a weight per IP address. Basically, you create records that have the same name and type and assign each record a numerical value that favors one IP address over another. A value of 0 suggests a record is never returned. This is useful for simple load distribution or testing new software. Each record is returned based on the weight compared to the total weight of all records. If a chosen record is Unhealthy, the process is repeated until a healthy record is obtained. </p>
<p>The Geolocation routing policy tags records with a location that can be Default, Continent or Country. It allows you to distribute the IP of a resource that can cater to customers in different countries or different languages. It can also help you protect distribution or licensing rights. You can create a default record for IP addresses that do not map to a geographic location. With geolocation routing an IP check verifies the customer’s location and the corresponding record for that location is returned based on the Location Tag for country, continent, or default. </p>
<p>The Geo-proximity routing policy requires that you use Route 53’s traffic Flow feature and create a Traffic Policy. A traffic policy is a resource that combines one or more routing policies.  Geo-proximity records are tagged with an AWS Region or using latitude and longitude coordinates. Geo-proximity routing is based on distance and a defined bias. You can specify a Bias from -99 to 99. This is a value that you can use to route more traffic to an endpoint by using a positive value or Route less traffic to an endpoint by using a negative value. Use the bias of -99 to route the least amount of traffic to an endpoint. You can think of the bias as being able to increase or decrease a region size in terms of coverage. This allows you to shift traffic from one location to another and route traffic based on the location of your resources. </p>
<p>The Failover routing policy is able to route traffic to a primary resource and based on a health check re-direct traffic to a secondary resource. The re-direction happens if the health check fails. Using failover routing you define a record to be primary and a different record to be secondary. You are also required to have a health check pre-defined. The routing of the primary record is active when the health check result is healthy. Otherwise, the secondary record is used. </p>
<p>The Latency routing policy chooses the record with the lowest latency to the customer. You define multiple records with the same name and assign a region to each record. <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> maintains a database of latency between the general location of users and the regions tagged in DNS records. The record used is the one with the lowest recorded latency and is healthy. This may not always be the closest resource, especially if the closest resource is saturated.</p>
<p>The Multi value Answer routing policy returns multiple IP addresses to a query. Up to 8 IP addresses corresponding to healthy records based on a health check are returned. If there are eight or less healthy hosts the response includes all healthy hosts. </p>
<h1 id="Amazon-Route-53-Traffic-Flow"><a href="#Amazon-Route-53-Traffic-Flow" class="headerlink" title="Amazon Route 53 Traffic Flow"></a>Amazon Route 53 Traffic Flow</h1><p>Traffic flow simplifies the process of creating and maintaining records in large and complex configurations. This is useful when you have a group of resources that perform the same operation, such as a fleet of web servers for the same domain. </p>
<p>The traffic flow visual editor lets you create complex sets of records and see the relationships among them. You can combine multiple routing policies and health checks in a single configuration. Each configuration is called a traffic policy and it’s automatically versioned so you don’t have to start all over again when your configuration changes. Old versions of traffic policies continue to be available until you delete them. </p>
<p>A traffic policy can define hundreds of records. Traffic flow creates all those records automatically when you create a policy record. You create policy records to associate traffic policies with a domain or subdomain name records. The traffic policy record appears in the list of records for the hosted zone. You can use the same traffic policy to create records in multiple public-hosted zones. This is useful when you’re using the same hosts for multiple domains. </p>
<p>Please note that the Geo-proximity routing policy is available only if you use traffic flow.</p>
<h1 id="Amazon-Route-53-Resolver"><a href="#Amazon-Route-53-Resolver" class="headerlink" title="Amazon Route 53 Resolver"></a>Amazon Route 53 Resolver</h1><p>The Route 53 resolver is the DNS service for VPCs that integrates with your data center. Connectivity needs to be established between your data center DNS and AWS using a Direct Connect (DX) or a Virtual Private Network (VPN) connection.  You configure endpoints for DNS queries into and out of VPCs. Endpoints are configured through IP address assignment in each subnet needing the Route 53 Resolver. </p>
<p>Inbound queries allow DNS queries that originate in your data center to resolve AWS-hosted domains. </p>
<p>Outbound DNS queries are enabled using conditional forwarding rules. Domains hosted in your data center can be configured as forwarding rules in Route 53 resolver. Rules trigger when a query is made to one of those domains and the request is forwarded to your data center. This recursive DNS for your VPCs controls how DNS queries are handled between your VPCs and your data center. </p>
<p>Finally, the Route 53 Resolver DNS firewall is a managed firewall service for DNS queries that start in your VPCs. You use a firewall rule group to define how Route 53 Resolver DNS firewall inspects and filters traffic coming from your VPC. Each rule consists of a domain list to inspect in DNS queries and an action to take when a query results in a match. You can allow a matching query to go through, allow it to go through with an alert or you can block it and respond with a default or a custom response. To begin the filtering you associate the rule group to the VPCs you want to protect. Route 53 resolver DNS firewall will apply your defined filtering rules to the outgoing VPC traffic.</p>
<h1 id="Application-Recovery-Controller"><a href="#Application-Recovery-Controller" class="headerlink" title="Application Recovery Controller"></a>Application Recovery Controller</h1><p>Route 53 application recovery controller is a set of capabilities that continuously monitors an application’s ability to recover from failures and controls application recovery across multiple availability zones, regions, and possibly your own data center environments. </p>
<p>You can define a readiness check to monitor AWS resource configurations, capacity, and network routing policies. They can check the configuration of Auto Scaling Groups, Amazon EC2 instances, Amazon EBS volumes, Elastic Load Balancers, RDS instances, and DynamoDB tables among others. </p>
<p>These readiness checks ensure that the recovery environment is scaled and configured to take over when needed. You can check AWS service limits to verify that enough capacity can be deployed.  You can also verify that capacity and scaling setups for applications are exactly the same across regions before a failover takes place. </p>
<p>Readiness Checks work with Routing Controls to give you a way to failover an entire application based on custom conditions like application metrics, partial failures, increased error rates, or latency. You can also failover manually.  With Routing Controls you can shift traffic for maintenance purposes or during a real failure scenario. You can also apply safety rules to routing controls as a way to prevent a failover to an unprepared replica. </p>
<p>A control panel is a group of routing controls for an application. As mentioned earlier, A routing control is used to turn traffic flow ON or OFF to individual cells in Regions or Availability Zones. </p>
<p>This will permit you to define custom traffic re-direction for your applications during failover or maintenance cycles. Amazon Route 53 Application recovery controller allows you to configure fine-grain failover and verification steps to implement applications requiring very high availability. </p>
<p>This concludes our introduction to Amazon Route 53. </p>
<h1 id="Using-Amazon-Route-53-Summary"><a href="#Using-Amazon-Route-53-Summary" class="headerlink" title="Using Amazon Route 53 - Summary"></a>Using Amazon Route 53 - Summary</h1><p>In this course, we introduced Amazon Route 53 and how the service helps you register a domain name and manage it worldwide. </p>
<p>For Cloud Academy, this is Jorge Negrón, Thanks for watching!</p>
<h1 id="Networking-Summary"><a href="#Networking-Summary" class="headerlink" title="Networking Summary"></a>Networking Summary</h1><p>So you’ve now finished the theory section of networking for the AWS SAA. And some people find networking confusing and complicated but hopefully, you now have a much better understanding of how AWS networking works. We covered everything that could potentially come up in the exam. But in this course, I want to reiterate some of the main things to remember to ensure that you feel more prepared for any networking questions that could make an appearance. Now, remember I’m here to make sure that you know what you need to know and that you feel confident to pass this certification. So please reach out to me on LinkedIn, Twitter or drop us an email and I’ll happily discuss any questions you have. </p>
<p>Anyway, let’s take a look starting at VPCs. So first and foremost, you have to have solid grasp of VPCs. You’ll definitely come across questions covering VPCs and then networking components and how they all fit together. So let’s break this down in its simplest form. So the VPC is your own networking space of AWS that resides within a single region. And within your VPC you can create both public and private subnets. And each subnet resides in a single availability zone. You can control network traffic between subnets using network access control lists or NACLs and to control access between resources such as EC2 instances we use security groups. And these both work at the port and protocol level. </p>
<p>If we need to connect our VPC to the outside world we must use an internet gateway. And when attached, we can add a route from a subnet to the internet gateway to make that subnet public. If we need private instances to initiate a connection to the internet, then we need to use a NAT gateway and this resides in the public subnet. So if you can grasp those basic principles of network connectivity it will put you in very good stead in breaking down many questions that come up relating to VPCs. Half of the battle is remembering which networking component is used for what purpose. If you get that right you can usually eliminate at least two wrong answers. I find that most people get confused between NACLs and security groups and also when to use internet gateways over NAT gateways.</p>
<p>Okay, so let’s now look at some of the connectivity options when working with VPCs, in particular VPN gateways and Direct Connect. Now, both options provide connectivity from your own corporate network to the AWS Cloud but it’s a difference differences between them that are important as to when you would use one over the other. So you’d use a VPN solution if you are looking for a solution to connect your corporate network to your VPC that was relatively easy to implement where security didn’t really require the use of a private network. And so it could be run across the internet instead. Now with minor configuration of a customer gateway in your network and a virtual private gateway in your VPC it would be set up and running fairly quickly. However, if you require this connection to be fast, stable and private, then a VPN wouldn’t be the right choice. Instead, you’d need to use Direct Connect which would provide a private connection between your data center and an AWS region not just your VPC. Now, this uses dedicated lease lines with an AWS partner and you could connect one interface to a virtual gateway in your VPC and another interface to connect to an AWS region allowing access to public AWS resources such as Amazon S3.</p>
<p>Now, we also covered VPC endpoints in this course. Again, this is connection related but it looks at connectivity between your VPC and other AWS services across a private network without exposing data to the internet using AWS private link. Now, this means that you can connect to the services without configuring an internet gateway or a NAT gateway. For the exam, be aware of interface endpoints and Gateway endpoints. Now interface endpoints are effectively ENIs with a private IP address within your subnet and this acts as an entry point to a supported AWS service. Whereas a Gateway endpoint is added as a target in your route table of your subnets which points to either Amazon S3 or DynamoDB.</p>
<p>So we’ve covered VPC and its components and also network connectivity, but let’s now look at some of a smaller networking components, these being ENIs, EIPs and ENAs. They all sound very similar but all perform very different functions. You don’t need to know the inner workings of each of them but you do need to know when there might be used and what they are. So you might get asked questions about network latency and how to resolve it or questions relating to persistent public IP addresses to help mask instance failures or the requirements to set up a management network between your EC2 instances, for each of these you would use either an ENA an EIP or ENI. So ENAs are used to provide enhanced networking features to high speeds for your Linux compute instances. So if you receive any questions on enhancing network performance for Linux instances and ENA is an option, it’s certainly worth taking note of. </p>
<p>EIPs provide persistent public IP addresses that you can associate with your instance which can be attached to an instance or an elastic network interface, an ENI. And these can be detached from one instance and reattached to another. And this can mask the failure of a publicly accessible instance. And ENIs are used to give your EC2 instances an additional network interface. And this allows the instance to connect to two different subnets at once, each interface configured with an IP address of each subnet. So this is great if you’re creating a management subnet you can then add management network interfaces to each EC2 instance you want to be apart of that management network.</p>
<p>Now we just spoke about networking performance with the ENA but you should also take note of the AWS Global Accelerator too which effectively allows you to get UDP and TCP traffic from your end user clients to your applications faster, quicker and more reliably by using the AWS global infrastructure. And it does this by intelligently routing customer requests across the most optimized path. </p>
<p>So the ENA provides high-speed performance for your instance, whereas the Global Accelerator provides high speed performance from an end client to your application using the AWS network.</p>
<p>The last two services I want to highlight are Route 53 and CloudFront. So the key points at the high level for Route 53 include, it’s a highly available and scalable DNS service that provides secure and reliable routing of requests. Now you have public hosted zones which determine how traffic is routed on the internet and then private hosted zones which determine how traffic is routed within a VPC. Now it uses different routing policies to route traffic and this is important. You need to be aware of those different routing policies. It also supports the most common resource record types as well. </p>
<p>An alias records act like a CNAME record allowing you to route your traffic to other AWS resources such as ELBs, VPC interface endpoints, et cetera. So make sure you’re aware of what an alias record is. So what sort of questions might you see relating to Route 53? Well, I expect your see something relating to routing policies, you will be expected to select the most appropriate routing policy given a particular scenario. So know the difference between the following policies. There’s simple, failover, geo-location, geoproximity, latency, multivalue answer and weighted.</p>
<p>Okay, so moving on to CloudFront. So CloudFront is used to speed up the distribution of your static and dynamic content by storing cache data through its global network of edge locations. Now it’s fault-tolerant and globally scalable by design and it’s AWS’s own content delivery service. </p>
<p>So normally when a user requests content from a web server that you’re hosting without a CDN the request is routed back to the source web server which could actually reside in a different country to the user initiating the request. However, if you use CloudFront, the request is routed to the closest edge location to the user’s location which would likely provide the lowest latency and therefore deliver the best performance using cached data. </p>
<p>So when you’re looking at questions that ask you about distributing traffic or enhancing the performance for your end users, perhaps to your website you need to think about the different network and solutions available to help you to do this. And CloudFront will usually be one or part of the answers. You should be familiar with the configuration of CloudFront distributions and the information they contain such as the origin information, what an Origin Access Identity is, known as OAI, also brush up on your caching behavior options as well which define how you want the data at the edge location to be cached using various methods and policies.</p>
<p>And that now brings me to the end of another section. So you should now have a solid understanding of AWS networking components and concepts. So let’s crack on and tackle the next steps. Again, if you have any questions about any of this please do reach out to me and I’ll be more than happy to explain any topic further with you.</p>
<h1 id="3Subnets"><a href="#3Subnets" class="headerlink" title="3Subnets"></a>3<strong>Subnets</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/vpc-cidr-blocks/">VPC TCP&#x2F;IP Addressing</a></p>
<h1 id="6NAT-Gateway"><a href="#6NAT-Gateway" class="headerlink" title="6NAT Gateway"></a>6<strong>NAT Gateway</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/blog/aws-shared-responsibility-model-security/">AWS Shared Responsibility Model</a></p>
<h1 id="7Bastion-Hosts"><a href="#7Bastion-Hosts" class="headerlink" title="7Bastion Hosts"></a>7<strong>Bastion Hosts</strong></h1><p><a target="_blank" rel="noopener" href="https://aws.amazon.com/blogs/security/securely-connect-to-linux-instances-running-in-a-private-amazon-vpc/">SSH Agent Forwarding</a></p>
<h1 id="8VPN-amp-Direct-Connect"><a href="#8VPN-amp-Direct-Connect" class="headerlink" title="8VPN &amp; Direct Connect"></a>8<strong>VPN &amp; Direct Connect</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/amazon-vpc-ipsec-vpns-understanding-building-and-configuring/">Amazon VPC IPSec VPNs- Understanding, Building and Configuring</a></p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-virtual-private-cloud-subnets-and-routing/">AWS Virtual Private Cloud: Subnets and Routing</a></p>
<h1 id="12Elastic-Network-Interfaces-ENIs"><a href="#12Elastic-Network-Interfaces-ENIs" class="headerlink" title="12Elastic Network Interfaces (ENIs)"></a>12<strong>Elastic Network Interfaces (ENIs)</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/vpc-flow-logs/">VPC Flow Logs</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#AvailableIpPerENI">AWS Docs - Interfaces for One Instance</a></p>
<h1 id="13EC2-Enhanced-Networking-with-the-Elastic-Network-Adaptor-ENA"><a href="#13EC2-Enhanced-Networking-with-the-Elastic-Network-Adaptor-ENA" class="headerlink" title="13EC2 Enhanced Networking with the Elastic Network Adaptor (ENA)"></a>13<strong>EC2 Enhanced Networking with the Elastic Network Adaptor (ENA)</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html#enabling_enhanced_networking">List of Supported EC2 Compute Types</a></p>
<h1 id="15Working-With-Amazon-CloudFront"><a href="#15Working-With-Amazon-CloudFront" class="headerlink" title="15Working With Amazon CloudFront"></a>15<strong>Working With Amazon CloudFront</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/protecting-web-apps-common-exploits-using-aws-waf-1883/">AWS WAF</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/18/AWS-Solution-Architect-Associate-Knowledge-Check-Storage-SAA-C03-2-of-2-15/" rel="prev" title="AWS-Solution-Architect-Associate-Knowledge-Check-Storage-SAA-C03-2-of-2-15">
      <i class="fa fa-chevron-left"></i> AWS-Solution-Architect-Associate-Knowledge-Check-Storage-SAA-C03-2-of-2-15
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/18/AWS-Solution-Architect-Associate-Introduction-to-Virtual-Private-Cloud-VPC-17/" rel="next" title="AWS-Solution-Architect-Associate-Introduction-to-Virtual-Private-Cloud-VPC-17">
      AWS-Solution-Architect-Associate-Introduction-to-Virtual-Private-Cloud-VPC-17 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Networking-SAA-C03-Introduction"><span class="nav-number">1.</span> <span class="nav-text">Networking (SAA-C03) Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#What-is-a-VPC"><span class="nav-number">2.</span> <span class="nav-text">What is a VPC?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Subnets"><span class="nav-number">3.</span> <span class="nav-text">Subnets</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Network-Access-Control-Lists-NACLs"><span class="nav-number">4.</span> <span class="nav-text">Network Access Control Lists (NACLs)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Security-Groups"><span class="nav-number">5.</span> <span class="nav-text">Security Groups</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NAT-Gateway"><span class="nav-number">6.</span> <span class="nav-text">NAT Gateway</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Bastion-Hosts"><span class="nav-number">7.</span> <span class="nav-text">Bastion Hosts</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VPN-amp-Direct-Connect"><span class="nav-number">8.</span> <span class="nav-text">VPN &amp; Direct Connect</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VPC-Peering"><span class="nav-number">9.</span> <span class="nav-text">VPC Peering</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Transit-Gateway"><span class="nav-number">10.</span> <span class="nav-text">Transit Gateway</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Elastic-IP-Addresses-EIPs"><span class="nav-number">11.</span> <span class="nav-text">Elastic IP Addresses (EIPs)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Elastic-Network-Interfaces-ENIs"><span class="nav-number">12.</span> <span class="nav-text">Elastic Network Interfaces (ENIs)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#EC2-Enhanced-Networking-with-the-Elastic-Network-Adaptor-ENA"><span class="nav-number">13.</span> <span class="nav-text">EC2 Enhanced Networking with the Elastic Network Adaptor (ENA)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VPC-Endpoints"><span class="nav-number">14.</span> <span class="nav-text">VPC Endpoints</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Working-With-Amazon-CloudFront"><span class="nav-number">15.</span> <span class="nav-text">Working With Amazon CloudFront</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Amazon-CloudFront-Patterns"><span class="nav-number">16.</span> <span class="nav-text">Amazon CloudFront Patterns</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#AWS-Global-Accelerator"><span class="nav-number">17.</span> <span class="nav-text">AWS Global Accelerator</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Using-Amazon-Route-53-Introduction"><span class="nav-number">18.</span> <span class="nav-text">Using Amazon Route 53 - Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Amazon-Route-53-and-DNS-Records"><span class="nav-number">19.</span> <span class="nav-text">Amazon Route 53 and DNS Records</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Amazon-Route-53-Health-Checks"><span class="nav-number">20.</span> <span class="nav-text">Amazon Route 53 Health Checks</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Amazon-Route-53-Routing-Policies"><span class="nav-number">21.</span> <span class="nav-text">Amazon Route 53 Routing Policies</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Amazon-Route-53-Traffic-Flow"><span class="nav-number">22.</span> <span class="nav-text">Amazon Route 53 Traffic Flow</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Amazon-Route-53-Resolver"><span class="nav-number">23.</span> <span class="nav-text">Amazon Route 53 Resolver</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Application-Recovery-Controller"><span class="nav-number">24.</span> <span class="nav-text">Application Recovery Controller</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Using-Amazon-Route-53-Summary"><span class="nav-number">25.</span> <span class="nav-text">Using Amazon Route 53 - Summary</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Networking-Summary"><span class="nav-number">26.</span> <span class="nav-text">Networking Summary</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3Subnets"><span class="nav-number">27.</span> <span class="nav-text">3Subnets</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6NAT-Gateway"><span class="nav-number">28.</span> <span class="nav-text">6NAT Gateway</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7Bastion-Hosts"><span class="nav-number">29.</span> <span class="nav-text">7Bastion Hosts</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8VPN-amp-Direct-Connect"><span class="nav-number">30.</span> <span class="nav-text">8VPN &amp; Direct Connect</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#12Elastic-Network-Interfaces-ENIs"><span class="nav-number">31.</span> <span class="nav-text">12Elastic Network Interfaces (ENIs)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#13EC2-Enhanced-Networking-with-the-Elastic-Network-Adaptor-ENA"><span class="nav-number">32.</span> <span class="nav-text">13EC2 Enhanced Networking with the Elastic Network Adaptor (ENA)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#15Working-With-Amazon-CloudFront"><span class="nav-number">33.</span> <span class="nav-text">15Working With Amazon CloudFront</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
