<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Course IntroI remember in my early development career, I was working on a basic CMS-backed website. I worked on the backend code and the front-end developer handle, the HTML, CSS, and JavaScript. We">
<meta property="og:type" content="article">
<meta property="og:title" content="Docker-Certified-Associate-Introduction-to-Docker-1">
<meta property="og:url" content="https://example.com/2022/11/19/Docker-Certified-Associate-Introduction-to-Docker-1/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:description" content="Course IntroI remember in my early development career, I was working on a basic CMS-backed website. I worked on the backend code and the front-end developer handle, the HTML, CSS, and JavaScript. We">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-19T04:44:27.000Z">
<meta property="article:modified_time" content="2022-11-21T02:23:20.000Z">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/2022/11/19/Docker-Certified-Associate-Introduction-to-Docker-1/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Docker-Certified-Associate-Introduction-to-Docker-1 | Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Docker-Certified-Associate-Introduction-to-Docker-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Docker-Certified-Associate-Introduction-to-Docker-1
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:44:27" itemprop="dateCreated datePublished" datetime="2022-11-19T00:44:27-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 22:23:20" itemprop="dateModified" datetime="2022-11-20T22:23:20-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Docker-Certified-Associate/" itemprop="url" rel="index"><span itemprop="name">Docker-Certified-Associate</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Docker-Certified-Associate-Introduction-to-Docker-1/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Docker-Certified-Associate-Introduction-to-Docker-1/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <span id="more"></span>

<h1 id="Course-Intro"><a href="#Course-Intro" class="headerlink" title="Course Intro"></a>Course Intro</h1><p>I remember in my early development career, I was working on a basic CMS-backed website. I worked on the backend code and the front-end developer handle, the HTML, CSS, and JavaScript. We were able to get the site up and running rather quickly, well ahead of schedule. Everything worked well on the development laptops.</p>
<p>It all worked well on our development server, and it even worked great on our staging server. You know where it didn’t work well? In production. We handed it over to the client, whose IT staff insisted on getting it up and running in their environment for themselves. They ran into issues getting everything up and running.</p>
<p>Eventually, they had us configure everything, which turned out to be nontrivial, and a time-consuming task, because there were issues with the versions of some of the libraries that the app was using. Now, this was a long time ago in the dark ages before DevOps was a word, before AWS had a service for everything imaginable, and before Docker existed.</p>
<p>Now, sure, there are things that we could have done to make the handoff easier and hindsight is 20&#x2F;20, after all. If we could have bundled all of our code, along with all of the dependencies into one self-contained executable entity, then that really would’ve saved hours of work. Now this scenario is something that Docker can help with, and it’s just one of the reasons why Docker has become so popular.</p>
<p>Welcome to Introduction to Docker, where we’re going to go through some of the concept and features of Docker. A bit about me. I’m a DevOps engineer with a passion for security, for containers and automation, among other tech topics. I’m looking forward to this course because Docker is really more than just a buzzword, it’s also a really useful technology for both developers and operations.</p>
<p>So, who is this course for? If you are a developer, a DevOps engineer, a site reliability engineer, an ops engineer, or some sort of similar role, then this course is going to be valuable for you. As always, I’ve made some assumptions about what you should know before taking this course. First, you’ll want to be familiar with containers as a concept.</p>
<p>Now if you’re not yet, I recommend checking out the course called Introduction to Containers. Second, you’re going to want to be comfortable using the command line. And third, an understanding of Linux is going to be incredibly helpful to contextualize some of the concepts. Finally, if you have some development experience, it’s really going to make it a lot easier to test the stuff out for yourself.</p>
<p>However, if you’re on the operations side of things, you can use the code that I’ve created for these demos. I’ll include a link to the source code in the course description, so you can find it there. When creating this course, I had some learning objectives in mind. Now by the end of the course, you should know what Docker is, you should understand how to create Docker images.</p>
<p>You should understand how to map ports between the Docker, container, and the Docker Host OS. You should understand the basics of Docker networking. You should understand how to use volumes for persistent storage, and you should be able to tag images. So, at a minimum, that’s what I hope you’ll get out of this course.</p>
<p>To meet these learning objectives, here are the lessons. First, we’ll cover what Docker is, followed by an overview of the Docker architecture. Then we’ll walk through installing Docker on a CentOS VM. After that, we’ll create a container. Then, we’re going to walk through the differences between images and containers.</p>
<p>And then we’re going to create images based on Docker files. Then, we’ll create images based on changes made to an existing container. After that, we’ll cover port mapping, then we’re going to talk about networking options. And then we’ll cover volumes followed by tagging, and finally we’ll wrap up with a summary of what we’ve covered.</p>
<p>Okay, before we get started, you’ll want to adjust the speed of the video in the player to find the right setting for you. I like to watch through on two-X, but you may have your own preference. So, feel free to play around with the settings. Also, I have added several links to the course description for reference.</p>
<p>So, when I mention them in the course, you know where to find them. Also, I love hearing from you all. So, if you want to reach out, you can reach me at <a href="mailto:&#115;&#117;&#x70;&#x70;&#x6f;&#114;&#x74;&#64;&#x63;&#108;&#111;&#117;&#x64;&#x61;&#x63;&#97;&#x64;&#101;&#109;&#121;&#46;&#99;&#111;&#x6d;">&#115;&#117;&#x70;&#x70;&#x6f;&#114;&#x74;&#64;&#x63;&#108;&#111;&#117;&#x64;&#x61;&#x63;&#97;&#x64;&#101;&#109;&#121;&#46;&#99;&#111;&#x6d;</a>, or you can find me, I’m @sowhelmed on Twitter. Good or bad, all of the feedback helps me to create better courses for you, so I hope to hear from you.</p>
<p>Alright, if you’re ready to start learning, then I’ll see you in the first lesson.</p>
<h1 id="What-is-Docker"><a href="#What-is-Docker" class="headerlink" title="What is Docker?"></a>What is Docker?</h1><p>Welcome back. Before we dive in to talking about how we use Docker, we need to cover the high-level concepts. So in this lesson I’ll answer the question: What is Docker? So here’s my attempt at a simple explanation. Docker is a container platform that allows you to separate your application from the underlying infrastructure by bundling up your code and all of its dependencies into a self-contained entity that will run the same on any supported system.</p>
<p>Picture an actual physical shipping container. You can use a shipping container to transport anything that will fit inside. Since shipping containers come in standard sizes, they’re easier to manage because they’re consistent. It really doesn’t matter what’s inside the container because the infrastructure used to transport them is the same.</p>
<p>The ships are able to transport them, cranes are able to move them on and off ships, trucks are able to transport them, and none of that infrastructure is concerned with what’s inside the container. When it comes to software development, it’s not the initial development that’s challenging; it’s everything that comes after that.</p>
<p>Deploying code is a challenge. Managing dependencies is a challenge. Handling rollbacks is a challenge. All of these things are made more challenging because the development environments are seldom identical to production, and this is where Docker containers can help. Docker containers are similar to their physical namesake.</p>
<p>They allow you to take whatever software you need to run, bundle it up into a consistent format, and run it on any infrastructure that knows how to handle a container. The end result is kind of like having a single executable for all of your code. It’s similar to an app on your phone. All of the code is bundled up into a single unit, and it’s going to run the same way on my phone and yours.</p>
<p>With Docker, regardless of the programming language you use or the Linux distribution your code runs on, you can wrap it all up into one unit called a container; and the container knows how to run your app. If your app relies on a specific version of ImageMagick, then you can include it in the container.</p>
<p>Then any time you run that container, you know that you have the correct version. If later you need to update the version of ImageMagick, then you create new container with whatever version you need and any time you run that container, it’s going to run correctly because it has everything it needs inside.</p>
<p>Having your code run inside of a container means that it’s isolated from other processes and other containers. So each container can have its own process space, its own network stack, resource allocation, et cetera. Docker containers are often compared to virtual machines because VMs are familiar to most IT people.</p>
<p>However, they are pretty different. When you run a virtual machine, the OS that you’re using in the VM is running on virtualized hardware. That means that you’re using software to emulate hardware and then running a full OS on top. Now virtual machines are great; however, they can be a bit slow to start up, they can consume a lot of resources that you might not need, and they require patching.</p>
<p>Also, they can take up a lot of space on disk, especially considering they contain thousands of files that your app really doesn’t need. Here’s a diagram from Docker’s documentation showing three applications, each running in a VM. So you could imagine that the first one is CentOS, the second is Ubuntu, and the third is Debian.</p>
<p>Each OS is running on the hypervisor and consuming a lot of system resources. Now here’s a look at how Docker is different. Notice the host OS and then the Docker engine here in place of the guest OS. So then you have your binaries and libraries that your application needs followed by your application code.</p>
<p>So what Docker is doing is it’s cutting out the guest OS, allowing you to bundle up the system libraries, any binaries that your app needs, as well as your code, all into one unit that can be executed via the Docker engine. Where VMs run the entire OS, Docker shares the kernel with the host OS. This means that containers can start up about as quickly as any other process since they really don’t contain all of the files required to run the entire OS, and they don’t consume all of the resources that a guest OS does.</p>
<p>So it allows you to run more of them on the same hardware. In Linux, everything is just a file, which means the difference between Ubuntu and CentOS is really just a set of files. By files, I mean things like binaries for package management, configuration files, different services, et cetera. With Docker, you use the kernel of the host OS.</p>
<p>However, because the difference between distributions is really just different files, you can create Docker containers based on the different distributions. So if your application requires some libraries that run on Ubuntu, then you base your container on Ubuntu. This means you can bundle up your code, as well as just the system libraries that you need, into one container.</p>
<p>Once all of your code and dependencies are in a container, they’re going to run the same way anywhere because everything required to have the code run is inside the container. So if you use Docker containers for all of your applications, then that’s going to allow you to standardize on how you deploy all of your applications.</p>
<p>All right, admittedly, this is an intentionally overly simplistic explanation of Docker. However, it should serve as a solid enough intro that we can build on that in the following lessons. So if you’re ready to dive a little bit deeper, let’s cover the architecture of Docker in the next lesson. So if you’re ready, I’ll see you in the next lesson.</p>
<h1 id="The-Docker-Architecture"><a href="#The-Docker-Architecture" class="headerlink" title="The Docker Architecture"></a>The Docker Architecture</h1><p>Welcome back. In this lesson we’re going to take a look at some of the different aspects of the Docker architecture. Now there are a lot of things to explain with Docker and it’s all very interconnected, so don’t feel bad if this doesn’t make sense right away. Stick with it and by the end of this course things should start to make sense.</p>
<p>Okay, at a high level, Docker uses a client-server architecture. The server part is that there’s a Docker daemon, which is responsible for managing Docker objects. By objects I mean things such as images, containers and networks, which we’ll cover later in the course. The daemon exposes a REST API that the client consumes over UNIX sockets or a network interface.</p>
<p>The client is the Docker binary, so whenever you use the docker command, that’s the client. This diagram here gives a glimpse of how the client and daemon interact together. Here you can see that the subcommands issued by the client are sent over to the daemon, for example, the docker pull command here instructs the daemon to get an image from the registry.</p>
<p>The Docker daemon has a lot of different configuration options that you can pass in when you run the daemon. There are different options that let you change how the daemon operates, for example, if you want to use a remote daemon you could adjust the socket option, if you want to have some debugging capabilities you can pass in the -D flag, so if you want to make changes to the runtime, you could do that too.</p>
<p>So the Docker daemon is in charge of managing Docker objects, and the client is the primary way that you’ll interact with the Docker API. Being new to Docker, you don’t need to change anything about the daemon, the defaults will get you by just fine. So while you might not be customizing the daemon settings, knowing about that separation of the client and the daemon will help if you run into an error such as this one when you’re using the Docker binary.</p>
<p>In this example, the Docker binary was used to try and list off the running containers. Since the client relies on that daemon to be running to get that information and the daemon isn’t running, the client is kind of useless and it throws this error, and the solution to this is just to make sure that the daemon is started on the OS that you’re running on.</p>
<p>Containers aren’t a new concept, they’ve existed in some form for years. If you haven’t heard about them before, you probably didn’t have to deal with the types of problems that containers solved. However, the cloud has really shifted things and hyperscale is the new defacto standard. There are a couple of reasons Docker has taken off so well.</p>
<p>First is because Docker took a lot of the current container technologies and combined them into one product. The second reason is that Docker came along at a time when people were looking for better ways to build, deploy and run highly scalable, secure apps. So the combination of market demand and well established technologies made it a prime candidate to become synonymous with the term container.</p>
<p>Docker is actually built on some very well established Linux kernel features, that when combined together, allow processes to be run in isolated environments. Let’s go through the technologies to understand how they combine into one product. The first is called namespaces, which allow you to isolate system resources.</p>
<p>Docker uses a few different namespaces. The namespaces supported by Docker are the pid namespace, the net namespace, the ipc and mnt namespaces, as well as the uts namespace. It uses pid to handle process isolation, this means that each namespace has its own set of process IDs. The net namespace, which is short for networking, is used to isolate network stacks.</p>
<p>Each net namespace has a private set of IP addresses, its own firewall, routing table, et cetera. Linux has several mechanisms for interprocess communication. One of those mechanisms is called System V, using the Roman numeral V for five, or SysV for short. The ipc namespace allows processes to be isolated from SysV-style interprocess communication.</p>
<p>The mnt namespace handles mount points, which allows for isolation of file system mounts. And finally, the uts namespace, which stands for Unix Timesharing System, allows for isolation of the hostname. So namespaces allow for isolated aspects of a system’s resources. Now there are additional Linux kernel namespaces, however the ones that I’ve shown here are the namespaces being used by Docker.</p>
<p>So, when these are all used together they allow for a very high level of process isolation. The next feature that Docker uses is called control groups, or Cgroups for short. Control groups are used to limit resource allocation. Since containers allow processes to be run in isolation, you can’t have any single process consuming all of the system resources.</p>
<p>So as an example, imagine you need to run five containers and one of those consumes all of the system’s CPU. The end result is a sort of denial of service attack, because the other four containers are not able to get the CPU that they need to function. So control groups allow for sort of limits to be set on different subsystems, which ensures that the processes aren’t going to be taking more than they should be allowed.</p>
<p>The next bit of functionality that makes up Docker is the union file system. Now this is an important part of Docker, and it’s functionality that really helps to keep down the overall size of Docker containers as well. A union file system starts with a base image and then can merge in any changes. When you create a Docker container, you have a starting image, which is a set of files that make up the base image for your container.</p>
<p>As you start making customizations by adding or removing packages, files, directories, et cetera, those create different layers. Each layer is a set of file changes that the union file system can merge into the previous layer. Because of this layered design you don’t end up with duplicate files because each layer just needs to know about the changes.</p>
<p>Okay, so none of this was really deep dive, this is after all an intro course, so I want to stop here and let’s summarize what we’ve covered. First, Docker is a client-server application, the client is the Docker binary, the server is the Docker daemon which runs a REST API. Second, Docker is comprised of several well established Linux technologies, including namespaces, control groups and a union file system.</p>
<p>It’s the combination of these technologies that makes Docker so useful. Each of these is great on their own, but together they allow Docker a better way to run your code in isolation. Alright, let’s wrap up here, and in the next lesson we’re going to cover actually installing Docker. So if you’re ready to keep going, then I’ll see you in the next lesson.</p>
<h1 id="Installing-Docker"><a href="#Installing-Docker" class="headerlink" title="Installing Docker"></a>Installing Docker</h1><p>Welcome back! In this lesson we’ll be installing Docker on CentOS Linux. I’ll be using Vagrant to start up a CentOS VM. However, Docker has good documentation covering all of the different installation options available, and there are several operating systems that you can use. So if you wannna run Docker on Windows, macOS or Linux, there are instructions for that, and I’m going to leave the link to that documentation in the description of this course.</p>
<p>Now, I’m currently connected to the CentOS VM via SSH. The Docker documentation recommends that you start with a clean slate and remove any existing version of Docker. Now, this is a new VM. There isn’t anything installed, so this shouldn’t have anything that needs to be removed, but I’m going to run it anyway.</p>
<p>Great. Next up we need to install some prerequisites. The yum-utils package includes the yum-config-manager, which allows us to add and enable yum repositories. The device-mapper and lvm2 packages are used for the devicemapper storage driver. Now, this is only going to take a few moments. And there it is.</p>
<p>So with these installed, now we can use the yum-config-manager that allows us to add the Docker repo. Okay, with the Docker repo added, we can install Docker. And you can see here there is a summary of what’s going to be installed. This is going to install nine dependencies and the total size will be 81 megabytes.</p>
<p>So let’s say yes to this part. And there we go. Now it’s going to ask to verify a couple of GPG keys, and this can be done by typing the letter Y. And once again. Okay, perfect. The next part is going to take a minute or so, so I’m going to speed this up. And we’re back. Okay, everything went well, so the container engine should be all set.</p>
<p>Next let’s start up the Docker daemon. And there it is. And it’s returned with no error message. Now let’s verify that the daemon is running with the status subcommand. So you can see here that the daemon is running. Now, in theory, everything should be working and ready to go. However, let’s verify that, and to do that, we’re going to actually start up a very simplistic hello-world container.</p>
<p>Now, I don’t want you to worry. We haven’t really covered containers yet. If this doesn’t make sense, that’s okay. We’re going to cover that in the next lesson. So let’s test this out by running Docker’s hello-world image. Okay, there’s a lot happening here in this output and we’ll go through that later.</p>
<p>For now, I want you to focus on this “Hello from Docker” message. Now, seeing this means that Docker is working correctly because it was able to grab the image and then run a container based off of that and display the message. Okay, let’s wrap up here. Docker is up and running on CentOS and we’ve verified that it is working.</p>
<p>So if you ran into any issues, what I want you to do is use Docker’s documentation to kind of help work through them. With Docker running, you’ll be ready to start using it for the rest of the course. So if you have it up and running and wanna start actually using it, then I’ll see you in the next lesson.</p>
<h1 id="Creating-and-Executing-Your-First-Container-Using-Docker"><a href="#Creating-and-Executing-Your-First-Container-Using-Docker" class="headerlink" title="Creating and Executing Your First Container Using Docker"></a>Creating and Executing Your First Container Using Docker</h1><p>Welcome back. While we did run the hello-world container in the previous lesson, in this lesson, I’m going to actually explain what’s happening. I want to start by running another container. The command will be similar to the hello-world example, though it’s not exactly the same thing.</p>
<p>I’m going to run this command, and then we’ll break it down so that you can see how it all works in a moment. The command is sudo docker run -it ubuntu &#x2F;bin&#x2F;bash and this is going to take a moment to complete. While this is running, I want to describe what’s happening at a high level. The command that I just ran instructs Docker to run a container based on the official Ubuntu image.</p>
<p>I want you to focus on the Ubuntu part of the command for now. If you recall, the VM that we’re running on here is CentOS. So this is often the point where students ask where is Ubuntu coming from? We’ve run two containers now, we ran hello-world and Ubuntu, and from an outsider’s perspective, it’s not really clear where those names come from and what they actually mean.</p>
<p>When we reviewed the Docker architecture I very casually mentioned that Docker downloads images from a registry. Now that registry’s where hello-world and Ubuntu come from. They’re official images stored on either Docker Hub or the newer Docker Store. Both the Docker Hub and Docker Store serve as centralized locations for Docker images to be downloaded.</p>
<p>Here’s a look at the store. Notice the landing page has a search box, at the top and then there’s this explore link. While this UI is likely to change over time, as of now, the explore page offers a faceted search. And if you notice here, you can select the registry of either Store or Docker Hub. And there are some additional filters on the side here, and I recommend that you check them out for yourself to see what kind of images already exist.</p>
<p>For now, let’s just search for Ubuntu and see what we get. Okay, so we get a few options. Clicking on the one named Ubuntu brings us to a landing page for this particular image. On the right-hand side you can see that there’s a command provided that we can use to download this image from the registry. Running this command as it is will download the latest version of Ubuntu.</p>
<p>The ability to pull the latest version is really useful, especially when developing. However, in production you’ll need to be precise about which versions to use. And that’s where the ability to specify a tag will allow you to download the exact version. That’s something we’ll cover later in the course.</p>
<p>However, I mention it here because depending on when you watch this, the version for latest, may not be the same for you as it is for me. So, let’s go back to the terminal and look at the output. So, notice here at the top, it says unable to find image Ubuntu:latest locally. Docker looks locally on this VM, it can’t find the image, so was it does it goes and downloads it from the Docker Hub.</p>
<p>When it downloads the image, it stores it in a subdirectory that lives inside of the &#x2F;var&#x2F;lib&#x2F;docker directory. The next time it runs, it’s going to see if an image has changed since it was last downloaded. If it hasn’t, then it’s just going to use that local version because it already exists locally.</p>
<p>So, the image is now downloaded locally, and if you notice the prompt has changed. Look up here and notice it says vagrant@localhost. That’s the bash prompt for our CentOS and down here it says root@ followed by the first several characters of the container ID. This is the bash terminal inside of our Ubuntu container.</p>
<p>Let’s look back at the command and see how we got here. Behind the scenes this ran docker pull to pull down the image because it didn’t exist locally. Then the Docker run command allows you to execute a command from inside of the container. The command that we’re running is the bash binary. The way we are able to get an interactive shell is that we’re using the I and T flags.</p>
<p>The I flag makes it interactive by redirecting standard IO. The T flag implements a pseudo TTY, which basically makes the terminal behave like a standard terminal. Because we told Docker to run a bash shell as the container process, if we exit out of this, then the container is going to stop. Okay, let’s wrap up here and let’s summarize what we’ve covered.</p>
<p>First, both the Docker Hub and the new Store serve as a registry of existing images that you can use as is, or to form the base for your own images. Second, when using the Docker run command, behind the scenes it’s going to download the image if it doesn’t exist locally. Then it will run whatever command that you specify.</p>
<p>Using the lowercase I and lowercase T flags will provide an interactive terminal session on the container. And finally, generally speaking, when the process that you run exits the container will too. Alright, in the next lesson we’ll dig into the difference between an image and a container. So if you’re ready to keep learning, then let’s get started in the next lesson.</p>
<h1 id="Images-vs-Containers"><a href="#Images-vs-Containers" class="headerlink" title="Images vs Containers"></a>Images vs Containers</h1><p>Welcome back. Throughout the course I’ve mentioned images and containers. Though, the difference between the two may not be clear. So, that’s what we’ll do in this lesson. We’re going to take a look at the difference between images and containers. At high level, the difference between the two is similar to the difference between an executable and a running application.</p>
<p>Each running application is its own instance and independent of the others. The running application is also independent from the executable in that changes to the app won’t impact the executable. In this analogy, the executable is like an image, and the running app is like a container. An image is a template that defines how the container will look once it creates an instance.</p>
<p>Images are built on the concept of layers. There is always a base layer, and then there is some number of additional layers that represent file changes. Each layer is stacked on top of the others, consisting of the differences between it and the previous layer. The union file system that we talked about in a previous lesson is used to merge the changes.</p>
<p>Because Docker builds images from layers, and the different layers are file diffs. The layers usually don’t take up too much space on disk. Let’s demonstrate the difference between images and containers in a terminal. To start, I’ll switch to the root user that way I don’t have to type sudo so much. Okay so, so far we’ve used two images.</p>
<p>One was the hello-world image, the other was for Ubuntu. We can see those images with the docker images command. Notice here there’s a table that displays the image name, the tag, which are both tagged as latest, and there’s the image ID which is the first few characters of the SHA256 hash for the image.</p>
<p>And take a look at the image sizes. The hello-world image is very small because it contains just a single binary. The Ubuntu image however is a bit larger because it contains all of the software that makes Ubuntu, Ubuntu. That means software such as the apt package manager is included in that. So these are the two images that I have locally.</p>
<p>Using the docker ps command will show all of the running containers. And as you can see there aren’t any here. However, by adding the minus a flag you can see that this lists off all of the previously run containers. Let’s explore the &#x2F;var&#x2F;lib&#x2F;docker directory a bit, because this is where all of the images and containers are actually stored.</p>
<p>Looking at the contents of &#x2F;var&#x2F;lib&#x2F;docker you can see we have a directory here for containers and one for images. Let’s drill into the one for images, and into the image&#x2F;overlay directory. Here you can see some directories for images and layers. From here let’s drill into imagedb&#x2F;content&#x2F;sha256 and notice there are two files here with names consisting of sha256 strings.</p>
<p>If I run the docker images command again, notice that the image ID is a truncated version of these hashes. So this is the file here that is actually the hello-world image, and this one is the Ubuntu image. Now these files are just JSON files. Let’s take a look, let’s show that by printing out the output of the Ubuntu image.</p>
<p>I’m going to pipe it through the Python JSON module, that’s going to make it a bit easier to read. Okay, there’s a lot of info here, and honestly, you don’t need to know any of this to successfully use Docker. The reason I’m showing this is to part one, I wanna demystify Docker just a bit, by pulling back the curtain.</p>
<p>And two, I want to kind of show you how the image is comprised of different layers. By scrolling down to the history array you can see that there are these objects here with the created_by property. These are the commands that need to be executed to turn the default layer named scratch into an Ubuntu container.</p>
<p>Each command produces a new image layer. So behind the scenes the Ubuntu image starts with the default starting image which is called scratch, it’s just a lightweight image. And then it adds all of the files it needs and then executes a series of command on those files, and the final result is an Ubuntu image consisting of several layers.</p>
<p>Now I wanna emphasize again, understanding this directory structure or these file structures is not required for understanding Docker. It’s just going to help you understand just a bit better how things are working behind the scenes. Now, as a Docker user, you won’t be using these files directly, rather, you’re going to use abstractions such as the Dockerfile which will be covered in a later lesson.</p>
<p>And when you want to view information about an image, you don’t even need to browse to the &#x2F;var&#x2F;lib&#x2F;docker directory, you can use things like the Docker inspect command, and it’s going to give you most of the same info. Though inspect isn’t going to show you the command you use for each layer like this.</p>
<p>So, we’ve talked about images a fair amount. They’re the template used for creating containers. Let’s highlight the difference by starting up a container, making some changes to it, and then starting another container to show how they’re separate. Let’s use the Ubuntu image and let’s run the bash process.</p>
<p>So using the I and t flags, it’s going to allow us an interactive terminal session. Okay, so we’re currently at the bash prompt for this container. We’re currently in the root directory. And there’s nothing in the home directory. Okay, I wanna add a new directory for all of my awesome files in the home directory.</p>
<p>Now let’s CD into that. And now let’s create a file by echoing some text. Let’s echo this only exists in this container. And we’ll direct that output to container. txt. Okay, let’s verify that it exists. And there’s our text. Remember when we exit a bash process, the container will stop. That’s because we told Docker to create a container based on Ubuntu, run the bash command.</p>
<p>So once that process terminates, Docker has done everything we’ve asked of it. Now running the Docker ps shows us that there are no running containers. Let’s run another bash process with the Ubuntu image. And there it is. We have our bash prompt. Let’s look in the home directory. And notice that nothing is here.</p>
<p>This is exactly what you’d expect. Because each container is independent of the others. Okay, we can see the two containers that we just created by using the Docker ps command with the minus a flag. And I wanna shrink this text down just a bit so that this table is easier to read. Okay, the container we just ran is the one at the top.</p>
<p>And the one before that is the one with the text file. The important part of this table at the moment is the list of names. Because I didn’t supply any name for these containers, so, Docker provided these names. So you can optionally add your own name, and if not, Docker will name them. I’m going to copy the name of this container here.</p>
<p>This is the one with the text file. The container is currently stopped, so we’re gonna learn a new command. And we’re going to use the Docker start command. Followed by the name of the container. Okay, let’s see if the container is running with the Docker ps command. And it is, so, perfect. You may have noticed that the bash prompt on the screen is not the one for our container.</p>
<p>That’s because we started it and it’s running in the background now. So now in order to interact with it, we need to use the Docker attach command and passing the container name to attach to it. Great. So, here we are at the bash terminal for our container. And this should have our text file. And let’s verify.</p>
<p>And there it is. So, what did all of this prove? We created a container based on the Ubuntu image. And then we added a text file to that container. Then we started up a separate container, also based on Ubuntu, and the text file wasn’t there. It didn’t exist in that container. That’s because each time you create a container, it’s based on how the image looks at the moment the container is created.</p>
<p>Alright, let’s wrap up here and summarize what we’ve covered. Images in Docker are self-contained packages that are used to create containers. Making containers an instance of an image. Alright. In the next lesson, we’re going to look at how to create Docker images using the Dockerfile. So, if you’re ready to keep learning, then I’ll see you in the next lesson.</p>
<h1 id="Images-From-The-Dockerfile"><a href="#Images-From-The-Dockerfile" class="headerlink" title="Images From The Dockerfile"></a>Images From The Dockerfile</h1><p>Welcome back, so far we’ve used existing images that come from Docker registries. In this lesson, we’re going to cover how to create your own image, using a Dockerfile. The Dockerfile is text file with commands that you can use to create your own image. This allows you to specify the starting place for you image, and then you can specify the changes you’d like to have made to that image.</p>
<p>Let’s start off with a very basic example, first, I want to start by removing all of the containers that I’ve created. So I’m going to use the Docker container prune command, now, I feel like there should be some flashing lights and loud sirens going off, because this is going to delete all of the stocked containers.</p>
<p>If you don’t want to remove all of your containers, then don’t use this command. Instead, use the Docker rm command, and specify the containers that you want to remove. Okay, so I’ll say yes to the prompt, great. Next, let’s look at the images, with a command that is probably becoming familiar to you now, which is the Docker images command.</p>
<p>So you can see there are two images, we have Ubuntu and hello world. We’re going to create a new image, here’s what I want for this demo, I want a lightweight container, that runs a binary of my own creation, and by lightweight, what I mean is, I’m looking for a container that only has as much as it needs to run my binary.</p>
<p>I don’t want a bunch of additional, files, such as what you’d see in an Ubuntu image. Here’s the code for the binary, this is a very basic, hello world app, written in Go, and if you want to run this for yourself, the bottom comment here is how you would compile it, so that it will run in the container.</p>
<p>Though, I will mean you’ll need to have Go installed and configured. Now I’ve already compiled the app, and I have the binary ready, so let’s look at how to create an image with Dockerfile that can run this binary. A Dockerfile is actually called Dockerfile, it’s one word, no extension. Here’s the Dockerfile that we’ll use for this demo.</p>
<p>It’s starts out with a from instruction, which is used to specify the starting image. This allows you to set the image that you want to build on top of. This makes Docker rather flexible, because you can use any of the community images, an image from the store, or you own base image, as the start. This demo uses a special image called scratch, the reason it’s special is that it’s not something that you can just run, the same way the we ran the hello world or Ubuntu images.</p>
<p>This is meant to be used a minimalist base. So, from scratch, tells Docker, to start our image using the scratch image. The next instruction is the copy instruction, which allows you to copy files from your host, into a layer of the image. In this example, I’m telling Docker, to copy the file named hello, into the root directory of the image.</p>
<p>After the command is processed, a new layer will be created, containing this binary. Any commands that we run afterward, will be able to interact with that hello binary. The copy instruction can copy files, and directories, and it also supports wild cards. And I’m not going to go into each of the aspects of all of these instructions.</p>
<p>So I’ll leave a link in the course description, for the documentation so you check it out for yourself. Finally, down at the bottom, we have the command instruction, which is the default command to run, when the container starts up, unless one is specified on the command line. So there should be one command instruction per Dockerfile.</p>
<p>If you have multiple, then it’s always going to use the bottom most. This syntax here, has the command to run as an array, where the first element is the binary to execute. And then additional elements in the array, are arguments for the executable. So this is telling Docker to run the hello world binary when the container starts.</p>
<p>Okay, in theory, this Dockerfile should meet the requirements for the demo is set. I said, it should be lightweight, and allow me to run a binary. Because we’re using the default scratch image, it’s going to be lightweight. And using the copy and command instructions, allow us to run the hello binary. Let’s turn this Dockerfile into an image now.</p>
<p>I’m here at the bash prompt, for our CENTOS7 VM, and I’m in a directory containing the Dockerfile, and hello binary. If I run this binary here, it’s going to show us what the results will look like when we run it inside of a Docker container. So there you go. Now I’m currently logged in as root, so I don’t need to type sudo in front of everything, and if I list off the existing images, you can see that they’re currently are the two, that we’ve used throughout the course so far.</p>
<p>And we don’t have any containers at the moment. So, the command to build an image from a Dockerfile, is Docker build, followed by the directory, where the Dockerfile is located. Now you can specify a Dockerfile manually, if you want to have a name other than Dockerfile, we’re not going to covert that, but it’s minus f, for file.</p>
<p>Check that out in the documentation, if that’s something you want to use. In this case, I’m going to use the current directory, because the Dockerfile is located here. And notice it goes through our instructions from the Dockerfile. And it ends with a success message. So, now if we list the images again, it’s going to show our new image.</p>
<p>And there it is. So what I want you notice is that, it doesn’t actually have a repository or a tag, it does have an ID, though, using an ID to reference an image is, one of the most unintuitive ways you can interact with an image. So I built it this way intentionally, to show you what happens when you build this, without providing a repo name.</p>
<p>Let’s remove this image. I want to remove this, and build it again with a repo name. To remove it, we can use the Docker rmi, as in, remove image, and, let’s pass in the ID. Okay, now to verify that it’s gone, there we go. So, let’s do this again, only this time, I’m going to use the minus t flag, to specify the repo and tag.</p>
<p>Let’s call this greeting. And there we have it. Notice here at the bottom, it says, it was successfully tagged with greeting, and a colon, and then the word latest. Listing the images again, notice the repository is named greeting, and then there’s a tag that says latest. Tags in Docker have their own structure, and they allow you to supply a repo name, and a tag, at the same time.</p>
<p>Because I only provided the repository portion of the Docker tag, it’s going to automatically use a tag of latest. In a later lesson, we’re going to get into tagging a bit, so for now, the important part of this, is that we have an image, and it has a name that we can use to reference it. And then, if you notice here, it has a size of around 1.</p>
<p>3 megabytes. Now that we have an image, we can actually create a container based on it. So let’s give that a try. And we’ll do that with the Docker run command, and passing in the repository name of the image. And there it is, there’s the output that we expected from the hello binary. So we can use the Docker ps command, with a minus a flag, to show that the container ran, and then it exited successfully, based on this status code of zero here.</p>
<p>I’m going to remove this with a prune command, just to keep things clean for later lessons, as well as to keep showing the common commands. Okay, let’s dive into things a bit more in depth now. So let’s do a little bit of exploration, again, to help demystify Docker, it’s not essential to mastering Docker, but hopefully this will help to, kind of make sense of things a bit.</p>
<p>Earlier in the course, I showed where the image file was stored, and that it’s just a JSON file. I want to show how the Dockerfile we just used, maps to that image file, that Docker creates behind the scenes. So here’s a listing of the images. If I list the images, you can see the ID for the image we want, the one we just created, it starts with 934.</p>
<p>And it matches up to this image file here. So let’s print the contents, of that, then we’ll pipe it through JSON beautifier, okay. Here in the history section, notice two objects, the first one makes reference to copying a file, and over here in our Dockerfile, this maps to this copy command. Then the second object, which references the command, maps to the cmd instruction in the Dockerfile.</p>
<p>So Docker turns our simple Dockerfile, into a format that it knows how to work with, making it easier for us, as end users, to use relatively simple extractions. Alright, let’s wrap up here. There’s still a lot about the Dockerfile that hasn’t been covered. And later in the course, we’ll cover some more instructions as we go on.</p>
<p>For now, the takeaway is that, you can create your own images using the Dockerfile. It allows you to build your image, based on an existing image, and include any files you may need, and then set the default command to execute, when the container starts up. In the next lesson, we’re going to look at another way to create an image, which is, to use an existing container, as a base, make some changes, and then commit that.</p>
<p>So if you’re ready to learn more, then I’ll see you in the next lesson.</p>
<h1 id="Images-From-Containers"><a href="#Images-From-Containers" class="headerlink" title="Images From Containers"></a>Images From Containers</h1><p>Welcome back. We’ve seen how to create a basic image using a docker file. However, the docker file isn’t the only way to create an image. You can also use the docker commit command to commit changes that you’ve made to an existing container. Now, my recommendation is that you should use the docker file when creating images.</p>
<p>When you use the docker file you get to treat that image as code in a sense. That means you can commit it to source control, you can easily share that docker file with other developers, and you can use it in automated testing to build the image, et cetera. So, while I recommend using the docker file, it’s not the only option.</p>
<p>So I’m going to demonstrate how to use the docker commit command. Using the commit command allows you to save whatever changes you’ve made to a container. So I’m here at the bash prompt for the CentOS host and I’m currently the root user. If you’re trying this along with me you’ll need to be root or you’ll need to use Sudu or maybe you’ll add your user to the docker group, but inevitably you need to have root privileges.</p>
<p>So, there are no running containers as you can see here with the docker ps command and there aren’t any stopped either, which shows because we’re using the -a flag. There are a few images here. We have the greeting image, we have the hello world image, and the Ubuntu image. I’m going to use the Ubuntu as the base for this new image.</p>
<p>I want to create an image that has Python installed. Now, if this wasn’t a demo I’d recommend that you use the official Python image. However, for the sake of this demo I’m going to install it in an Ubuntu container. Let’s fire up the container based on the Ubuntu image and then run the ash binary. Okay great, we’re at the bash prompt for the container and I want to show that Python is not installed.</p>
<p>So, I’m going to use the command which python and it returns nothing. So at a minimum the Python binary can’t be found in any of the directories in the path environment variable. So, before we can install Python I need to update the apt cache and this is going to take a little while. So what I’ll do is speed up the video and I’ll meet ya back.</p>
<p>Okay, welcome back. Now let’s install Python with apt and I will agree to the install. And again, this is gonna take a little while so I’m gonna speed this up too. Alright, with this done let’s verify that it’s installed. It seems that the binary exists and running Python with the version flag. Perfect, it shows that we have Python 2.</p>
<p>\7. 12. Okay, we’re now left with a container that has Python installed. The next step is to turn this into an image. So I’m going to exit out of the bash prompt, which will stop the container. If I list off the images, you can see that we still don’t have our image. We do, however, have a container. The way that you turn a container into an image is with the commit command.</p>
<p>So let’s run docker commit and then paste in the container ID and we’ll pass along the tag for this image, which I’ll call ubuntu_python. Notice how the image is now in the list of images. Here’s the problem with this image. We didn’t specify a new command for this image. So it’s just going to use the default for the Ubuntu image, which in this case happens to be the bash command.</p>
<p>It’s not because we ran the bash command, that’s because whoever created the Ubuntu image used that as a default. So if we run a container based on this new image, since it’s using bash as the default and I’m not using the interactive and a TTY for the pseudoterminal, it’s just going to run the executable and then exit out and so what we’re left with is a stopped container.</p>
<p>So, if the default command that you wanted to use was bash then you’d be all set. However, in this example what I’d rather do is use Python since we took the time to install it. So I’m going to remove this container that I just created. Okay, and I’m going to remove the image that we created so that we can commit a new one with a new command.</p>
<p>Perfect, okay now it’s roughly the same command that we used before only this time we’re going to use the change flag to change the command instruction. You can also change other instructions, however, for this demo. I’m only going to change the command. So the new command is going to instruct the container to use a python binary by default and that’s going to pass in this c flag, which allows some arbitrary Python code to be executed and then the final element in this array here is the Python code that I want to execute.</p>
<p>And what this will do is just print out some text to standard out. Okay, now I need the container ID that this image will be based on and finally a tag for this image. Great, notice the image is in the list. Now if we create a container based on this image the default command should run that python binary, it’s going to pass on the c flag, it’s going to execute the code that I specified, which is import this.</p>
<p>So let’s try that out. Perfect, there’s our output. So everything’s working. If we use the docker ps with the -a flag you can see that here it lists off a truncated version of the command that was executed. So, what have we learned in this lesson? We learned that docker allows you to create an image based on an existing container by using the commit command.</p>
<p>It also allows you to change instructions using the change flag. Alright, let’s wrap up here. In the next lesson we’re going to cover port mapping. So if you’re ready to keep learning then let’s get started in the next lesson.</p>
<h1 id="Port-Mapping"><a href="#Port-Mapping" class="headerlink" title="Port Mapping"></a>Port Mapping</h1><p>Welcome back. So far the code that we’ve run inside of containers has been writing some text to standard output. Now it’s time to run something a bit more complex. So let’s run a basic web application. Here’s the web application we’re going to run. It’s an application written in Go, and it has two URL endpoints.</p>
<p>The first is the root URL, and then there’s this other endpoint at slash host which will display the host name and some environment variables. I’m not going to go through all of this code. The important part to know is that this is a basic web app. It’s going to run on port 8080 and serve up just a bit of markup.</p>
<p>I have the web application compiled into a binary named web app, and it’s in the same directory as the Docker file. If I print off the Docker file to the terminal, you can see that it uses the scratch base image. It copies the web app binary into the container at the root directory, and then it exposes port 8080 from the container.</p>
<p>And we’ll talk about this in a bit. And then it sets the default command to be the web app. So it’s going to actually execute that binary. Okay, let’s build this image, and then we can start up the container based on the image. Great, so the image built successfully. And we can see it here in the list of images.</p>
<p>Let’s run this container with the docker run command. So notice it’s just hanging here. This is expected, because the code is running inside of the container in an infinite loop. It’s just running forever, serving up this website until we stop it. So the web application is running indefinitely and waiting for connections.</p>
<p>And while it’s running, we’re unable to interact with our bash prompt. Now really this is no different than if we ran this outside of Docker. It’s not specific to Docker. However, we can solve this. Docker allows us to run the process in the background with the minus D flag. So for this flag, D stands for detach, as in Docker detaches from standard I&#x2F;O and instead just prints the container ID, and then it’s going to return us to our prompt.</p>
<p>So this allows us to run containers in the background. Let’s try it out. Okay, there, notice the container ID is printed to the screen. And then we have access to our prompt again. So if I list off the containers, you can see based on the status here that that container is up and running. At this point, the container is running.</p>
<p>However, it’s really not clear how we interact with this web app. By default, Docker containers run inside of their own network, called the bridge network. We’re going to dive into that in the coming lesson on networking. So for now, the thing to know is that this web app is running inside of the container, and it’s accessible via the container’s IP address on port 8080.</p>
<p>It’s possible to fetch the IP address using the docker inspect command and then passing in the container ID or name. Notice here, the IP address field, you can see that it’s set with the container’s IP. And if we curl this and we use port 8080, you can see that we get back some HTML. So this is the home page of the app.</p>
<p>Because each container has its own IP address, all of them can run on port 8080 inside of their own container, and then we can interact with them via their IP address. However, there is another way to interact with a web application inside of a container, and that would be to bind the port in the container to a port on the host.</p>
<p>Docker allows you to do this dynamically or explicitly. The Docker file specifies that the container exposes port 8080. By default, the expose instruction really doesn’t do anything to the host. Docker lets you bind the container port to a host port with the publish or publish all flags. Publish all will dynamically map the exposed ports of the container to open ports on the host.</p>
<p>The minus capital P flag is the short form of publish all. So this is going to run the container in detached mode, which means it’s gonna run in the background. It will also dynamically bind the exposed port 8080 to a port on the host. So we can use the docker ps command to see which port. In this case, the port is 32768.</p>
<p>So if we curl localhost on that port, we should get back some HTML. And we do. If I use the terminal-based browser Lynx, you can see that the site is up and running. It’s usable, and everything works. So now if we start up another container, again using the publish all flag to dynamically map the ports, it’s going to choose a different port automatically.</p>
<p>And notice the first container in the list here is 32769, and the second one is 32768. So it’s going to map that for us automatically. Okay, let’s stop these containers. And notice that the stop command allows you to pass in multiple container IDs. So now that they’re stopped, let’s prune them. And that’s going to remove them both.</p>
<p>All right, perfect. So using publish all, you can dynamically map the ports that are exposed from the container to the host. Now, you can also use the publish flag, which will allow you to map specific ports. So in this case, we’re going to use a lowercase P flag, which is the short form of publish, and it allows you to specify the port on the host that you want to use, and then a colon, and then the port on the container.</p>
<p>So what I wanna do is map port 3000 on the host to port 8080 inside of the container. And now if I list off the containers, you can see port 3000 maps to 8080. And if I curl localhost on port 3000, there we go, we get our HTML back. So since I’ve explicitly told Docker to use port 3000 on the host, if I run the same command, it’s going to throw an error.</p>
<p>And there it is. When we did this dynamically, the ports were selected for us to ensure that there wasn’t any conflict. If I run docker ps, you’ll notice only the previous container is running. And if I run it again with the minus A flag, you can see that the other container tried to start and failed, so it’s just left here in a created state.</p>
<p>So as expected, you can’t bind two processes at the same time to the same port. So if you wanted to switch, you would have to stop the first container and then start the other. And there it is. Notice the first container is stopped and no longer using port 3000. And the new container is in a running state, and 3000 is bound to it.</p>
<p>Okay, let’s summarize what we’re covered so far in this lesson. Docker allows you to map ports from containers to the hosts running the containers. The mapping can be done dynamically with the publish all flag or explicitly with the publish flag. And by default, the expose instruction in the Docker file doesn’t actually perform any port mapping.</p>
<p>It’s up to you to determine how you want to publish the ports. All right, in the next lesson, we’re going to be covering the Docker networking just a bit more in depth. So if you’re ready to keep learning, then I’ll see you in the next lesson.</p>
<h1 id="Networking"><a href="#Networking" class="headerlink" title="Networking"></a>Networking</h1><p>Welcome back. In the previous lesson, we touched on networking just a bit when I mentioned bridged networks. Networking with Docker can get as intricate as networking anywhere else. So we’re not going to be covering everything there is to know in this lesson. However, in this lesson we will cover some of the basics that will help get you started.</p>
<p>For this lesson, we’re going to use an image that’s based on Ubuntu 16. 04 and then add some networking tools on top to help kind of show the networking concepts just a bit. Here’s a look at the file. It starts with the From instruction, specifying that the base image is Ubuntu, and then it specifies the tag of 16.</p>
<p>\04. The next instruction is the Run instruction, which is used to install some packages with the Apt package manager. These packages contain some networking binaries, things such as ping, arp-scan, IP, and others. The Copy instruction, we’re using that to copy the same web application binary that we used previously.</p>
<p>And then finally, the Command sets the default command to run bash. So this image will have the tools needed to test out networking with Docker. Okay, so now that you’ve seen the image we’ll be using, I want to introduce a new command. This is the docker network command, and we’re going to us the ls subcommand to show the existing networks.</p>
<p>The three that are listed here are the three that are pre-configured by Docker. The info in this table is pretty basic. There’s an ID, a name, a driver, and a scope. All of these have a local scope, which means they all exist as networks only on this local host. We’re only going to cover these three local options in this course, though future courses will cover additional types.</p>
<p>Let’s go through these three types. The bridge network is the default. Whenever you start up a new container and you don’t specify a network, it’s going to use the default bridge network. Okay, so I’ve created a new directory called networking and I’m currently in that directory. There are no containers running, and there are four images here, though none of these are the image based on that Dockerfile that I showed a minute ago.</p>
<p>So let’s build that image. So here’s a refresher of the contents of that Dockerfile. By listing off the contents here in this directory, you can see that we have the web app binary here alongside the Dockerfile. So using docker build, we can build this, and we can tag it with a repo name of ubuntu_networking.</p>
<p>So this will take a minute. I’m going to speed things along, and I’ll see you in just a second. Okay, with this done, let’s check the images. And there it is, perfect. Now we can start up a container based on this image. And so we’re here at the bash prompt. Let’s list off the interfaces here for this container.</p>
<p>And there we have the loopback interface, and we have the eth0 with an address of 172. 17. 0. 2. This container is using the bridge driver, which is connected to the interfaces on the host. So it has full connectivity. If I ping google.com, there you go. We have some results that come back. Okay, I want to detach from this container without stopping it.</p>
<p>That’s something I haven’t shown previously, but you can do that by pressing CTRL-p and then CTRL-q. And if I run docker ps, notice that the container is still running. From here on the host, you can interact with the container via its IP address. So if I ping it, there’s our response. Let’s start up a few additional containers so that we can see how these containers see each other on the same network.</p>
<p>So this one has an IP address here ending in three. So now we have two containers running inside of the network. Let’s start up one more. Okay, if we try and ping the others, you can see that we get some results back. I want to show all of the containers on this network, so for that I’m going to use the arp-scan tool.</p>
<p>I have the command copied to my clipboard, so I’m just going to paste it in. Okay, take a look at the results. We have the default gateway at the IP address ending in one. Then the other two are the two containers that I started before this one. So all of these containers that I started up are in this bridge network.</p>
<p>They have access to interact with each other as well as being able to reach the outside world. Now there’s not much you can do to customize the default network. However, you can create your own networks if you need some sort of customization. All right, let’s check out the next network on the list, which is our host network.</p>
<p>The host network is an interesting one. Host networks add the container to the host’s networking. This means if you have an application inside of the container running on, say, port 8080, it’s going to be bound to port 8080 on the host. A host network has no isolation between the host and the containers.</p>
<p>Let’s test this out by running the web application, which binds to port 8080. Because this isn’t the default network, we need to specify the host network in the command prompt here using the network flag. So this command will run the container in the background using the host network, and it’s going to run that web application.</p>
<p>Now listing off the containers, you can see that it’s running, and if we inspect the container, you’ll see that it doesn’t get its own IP address. Check out here under the networks section, the IP Address property is empty, and that’s because everything is exposed on this current host. So now if we curl localhost on port 8080, then we get our HTML back.</p>
<p>Now recall that in the Dockerfile, we didn’t actually expose port 8080, and we didn’t publish any of those ports manually. When using host networking, whatever ports you open up in the container are going to be bound to the host. Okay, let’s check out the third networking option, which is the none network.</p>
<p>This, as the name suggests, means there’s no network at all. Let’s start up a container using the none network. Okay, so here we’re at our bash prompt. If I list off the network interfaces, you can see that there’s only the loopback interface. And if I try and ping google.com, it’s going to fail. And there it is.</p>
<p>It’s failed. So the none network is just what it says. There’s no networking interface. It’s completely isolated. All right, let’s wrap up this intro to networking here. Now there’s a lot more that could be covered regarding networking, though it should be covered once you have a more solid grasp of Docker.</p>
<p>So we’re going to save that for a future course. In the next lesson, we’re going to cover persistent storage options when we cover volumes. So if you’re ready to keep learning, then I’m going to see you in the next lesson.</p>
<h1 id="Introduction-to-Persistent-Storage-Options-in-Docker"><a href="#Introduction-to-Persistent-Storage-Options-in-Docker" class="headerlink" title="Introduction to Persistent Storage Options in Docker"></a>Introduction to Persistent Storage Options in Docker</h1><p>Welcome back! Now, if all of your applications were stateless and never needed data storage, life would be much simpler. However, in the real world we need data storage. We’ve talked about the different layers that make up a Docker image. The last layer of the image is a writable layer. Which means applications that need write access will work just fine.</p>
<p>However, as soon as you stop the container, whatever you’ve written there is gone. Which means using the writable layer is not an effective way to handle persistent storage. Luckily, Docker provides three options. Which are bind mounts, volumes and in memory option called tmpfs, as in temporary file system.</p>
<p>Bind mounts have been around for a while. They work by mounting a file or directory that resides on the host, inside the container. This remains an effective mechanism that allows you to access files from the host inside the container. And once the container stops, the data remains because it lives on the host.</p>
<p>The downside here is that bind mounts aren’t as decoupled from the host as you might like. You need to know the exact path on the host that you want to mount in the container. The upside is that this could work well for development, because you don’t need to rebuild the image to access the new source code, so you make changes to your source and it reflects immediately.</p>
<p>Docker still supports bind mounts because they work well. However, the preferred way to handle persistent file storage is with volumes. Volumes are basically just bind mounts, except that Docker manages the storage on the host. So you don’t need to know the fully qualified path to a file or directory. This makes it easier when working cross platform, because Docker handles the volume.</p>
<p>Volumes aren’t limited to the local host file system either, they allow you to use different drivers. The drivers support the use of external storage mechanisms such as Amazon’s S3, Google Cloud Storage, and more. When you stop a container using volumes or bind mounts, the data remains on the host. In contrast, the third storage option, tmpfs, is different.</p>
<p>Temp FS is an in temporary file system is an in memory file system. From inside the container you still interact with the files the same way you would any other file. The difference is that tmpfs is not persistent. Because tmpfs allows file system access for the life of the running container, it’s commonly used to hold sensitive information, that includes things like access tokens.</p>
<p>Let’s try these out. To test out bind mounts and volumes, I’ve created an app in Go that will loop 50 times and it will write the host name and the loop counter to a file. The file is specified as a command line argument so you can pass in any file you want. So this will allow us to write some data to the volumes from multiple containers.</p>
<p>I’ve already compiled this, and the binary is in the same directory as the Dockerfile. The Dockerfile for this demo is very basic. It’s based on the scratch image, it copies the binary to the root directory, and finally it sets the default command to run the binary, and pass in the path to where we want to write the data to be written to.</p>
<p>So that’s our volume. The directory of &#x2F;logs is going to be the mounted directory, and the name myapp is just an arbitrary name I’ve made up, so it has no real meaning. Here in the terminal, you can see there are no containers, and here’s the list of existing images. In this directory you can see the Dockerfile and binary.</p>
<p>Let’s test out bind mounts first, and for that we need a directory to mount. So I’ve created a directory under &#x2F;var&#x2F;demo&#x2F;logs, and you can see here that it’s empty. Okay, let’s build the image that we’ll use for the demo. Let’s call it scratch_volume. Okay, that didn’t take long, and there it is in the list.</p>
<p>So now, I want to paste in a command that I have copied to my clipboard. Most of the parameters used here have been used throughout the course. With the exception of the mount flag. This is the most current way to specify different storage options, since it’s the most flexible. Notice that the type is set to bind.</p>
<p>Then you need to specify the directory source and the destination. The source is the directory on the host you want to mount, and the destination is the path inside the container where it will be mounted. In this example the &#x2F;var&#x2F;demo&#x2F;logs directory will be available inside the container at &#x2F;logs. Recall that this image is going to write some data to the a file inside of the mounted &#x2F;logs directory.</p>
<p>So let’s start up a few containers because I want to show how multiple containers will have access to the same directories and files. Okay, now, that this has been running for a moment, there should be some data that has been written from the container to the bind mount. Here you can see the last 30 lines written to the myapp file that the application created.</p>
<p>If I print out the unique host IDs in the file, here we go, you can see there are four entries. If I compare them against the container IDs you can see that each container was able to write to the same shared file. Remember that when using a bind mount, the directories and files are managed by you and not Docker.</p>
<p>This means that the listing here for volumes will show zero results. However if you list off the files under the &#x2F;var&#x2F;demo&#x2F;logs you’re going to see the myapp file is still available to use on the host. Okay, let’s prune these containers so we can clean things up a bit, and there we go. Now let’s try the volume.</p>
<p>Here’s roughly the same command as before except the type is now set to volume. Also with a bind mount the source is a fully qualified path, and now it’s not. Since Docker manages it, you can just use a name for the volume. Docker allows you to create the volume with the docker volume command. However, if you use the mount flag with a type set to volume, and the volume doesn’t exist, it’s going to automatically be created for you.</p>
<p>Notice how it shows up under the volumes as a local volume and it’s named logs. Docker manages the location of the volume, which you can find by using the docker volume ls command. Notice here that the mount point is under &#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes. Let’s start up a few more containers, okay great! Now we can use tail to show the results streaming in.</p>
<p>Let’s use the tail command and refresh every second. Notice all of the results from the different hosts are being appended. Let’s once again display all of the unique IDs to see if all of the containers successfully were able to write their data. Let’s cat the file, and then let’s cut based on a space, and we’ll grab the second field, and we’ll pipe through sort, and we’ll cap it off piping through the unique binary.</p>
<p>Okay, and you can see we have 4 IDs. Listing off the existing containers you can see it’s the same IDs. With a bit more bash scripting we can sort just the container IDs and there you can see the IDs are in the same order now. Just makes it easier to compare. So what does all of this actually show? Both bind mounts and volumes are roughly the same.</p>
<p>However, volumes are managed by Docker. Both allow multiple containers to access the same mounts. Both keep the data on the host after the containers are stopped or removed. Let’s check out the final storage type, which is the temp filesystem, tmpfs&#x2F; Tmpfs is similar to the others in that you can create it with the mount flag.</p>
<p>However since it’s only creating an in memory construct you don’t need to specify a source directory, because there’s nothing on the host that’s gonna persist that info. For this demo we’ll use the ubuntu image so we can create an interactive bash session. The type here is tmpfs and the destination is set to &#x2F;logs.</p>
<p>So inside the container we’ll have a directory under &#x2F;logs that behaves just like the other storage options; except that it only exists while the container is running. There’s nothing here under the &#x2F;logs. So let’s add a file. We can just echo some text out to standard out, and we’ll call the file demo.</p>
<p>Now, I’m going to exit the container and keep it running with CTRL+p followed by CTRL+q. You can see that based on the listed containers that it’s still running. If I list off the volumes, you can see that it doesn’t show any new volumes. I show this to demonstrate that all three storage types use the same mount flag, however, they’re all implemented in a different way.</p>
<p>If we start a new Ubuntu container with a tmpfs mount we can see that unlike bind mounts and volumes, tmpfs is container specific. Let’s list off the files under &#x2F;logs, and it’s empty. Let’s reattach to this container start with ID starting with 4d. Alright, if we look at the logs directory and print the demo file to screen, you can see that the demo file text is there and the file still exists.</p>
<p>That’s because the container hasn’t been stopped, so while it’s running that information is available. So now if we stop the container by existing out. Okay let’s list off you can see that it’s stopped, and there it is. Now let’s start the container again, okay. And now let’s attach to the container. And here we are, back at the bash prompt.</p>
<p>And if we list off the contents of the logs directory you can see that it’s now empty. Tmpfs is a great option when you need file system access that’s isolated to the container. So this is really great for things like sensitive information, access tokens, or any sort of sensitive information that your app might need while the container’s running is useful for this sort of mount.</p>
<p>Storage is a crucial part of most applications, and that’s why Docker provides you options. Each of these is a viable option, depending on the use case. However, if you’re not sure which type to use, then volumes are probably the safest bet. Alright, let’s wrap up here. In the next lesson, we’re going to learn more about tagging.</p>
<p>So, if you’re ready to keep learning, then I’ll see you in the next lesson!</p>
<h1 id="Tagging"><a href="#Tagging" class="headerlink" title="Tagging"></a>Tagging</h1><p>Welcome back. Throughout the course, we’ve used tags. In the networking lesson, we used the tag 16. 04 to specify the version of Ubuntu. And in other lessons, the tag latest was implied because we didn’t specify a tag for ourselves. In this lesson, we’re going to cover tagging a bit more.</p>
<p>Tags provide you with a way of identifying specific versions of an image. Tags make it easy to deploy a specific version, and then if something goes wrong, you can easily roll back to the previous version. One of the useful features of tags is that an image can have more than one tag. This is useful if you want to have version numbers as well as named versions.</p>
<p>An example of this is the Ubuntu image, which has tags for the version, the OS code name, and optionally a tag to indicate the development image, et cetera. So tags are rather versatile and are an important mechanism for a solid continuous delivery process. However, we’re not going to cover the use cases here.</p>
<p>Rather, since this is an intro course, I want to cover how to actually tag an image. To do that, we have this basic Dockerfile. Starting at the top, you can see the use of the tagged image version. This is going to use the Ubuntu image that’s tagged 16. 04. Then it will create a directory and create a file with the contents of Version 1.</p>
<p>The Docker command will simply print the message to standard out by using the concatenate command. Okay, let’s build this Dockerfile into an image. With the T flag, we’re actually specifying the tag. Thus far, we’ve used the tag as just the local image name. However, the tag structure allows you to define a Docker registry where the image will reside.</p>
<p>If you don’t include a registry name, Docker assumes that you want to use its registry by default. And then you can specify your registry, your username and the image name. And finally you can end it with a tag. Now, this may sound confusing, so let’s use an example. Let’s give this an image name of tag_demo.</p>
<p>And it takes a second to build, and here at the end, notice it says successfully tagged as tag_demo:latest. Up here, we only provided the image name, so Docker provided the tag of latest automatically. If you don’t provide a tag, then Docker automatically uses the special tag called latest. If we list off the images, there it is, and the tag says latest.</p>
<p>Now, imagine you want this image to be Version 1. So, let’s use the command that we haven’t used before called docker tag, and we’ll specify the tag_demo image with a tag of latest. And now we need to set our new tag. It doesn’t require the same name. However, I’m going to keep it the same name for consistency.</p>
<p>So we’ll call it tag_demo:v1. OK, and listing it off, you can see that it’s listed as v1. Notice that both images have the same ID. That’s because it’s the same image with just a different way to reference it. If I was to run a container based on the tag_demo image, without specifying a tag, it’s going to use the image with a tag of latest.</p>
<p>Anytime you reference an image and you don’t provide a specific tag, it’s always going to look for a tag named latest. So, running this returns the message in the file of v1. And if we run another and specify the tag of v1, again we get the same message because these two containers are using the same image, which you can tell from the IDs.</p>
<p>Now, let’s edit the Dockerfile to write out a different message, let’s say, “Version 2,” this time, and let’s save this, great. Now, let’s build this image. This time, I’m going to specify a tag of v2. Okay, check this out. It says it was tagged with v2. Recall that previously when we built the images, we didn’t specify the tag, so it automatically used the tag of latest.</p>
<p>Now, if I list off these images, notice that the v2 image has a different ID than the v1 or latest. Let’s create a container based on the image with a tag of latest. Before we do, what do you expect is gonna be printed to the screen here? Which text will print out for the latest image? Well, if you said, “Version 1,” then you’re correct.</p>
<p>If you said, “Version 2,” maybe running the container tagged v2, it will help clarify things. Notice it prints out, “Version 2”. The reason is that we built the image after changing the message, and we explicitly set the tag to v2, which means that the latest tag is still set to v1. Let’s update the latest tag to point to v2.</p>
<p>So we specify v2, and then we set the latest tag, perfect. Now, listing off the images again, you can see that the IDs match between v2 and latest. If we run a container based on the latest tag, it shows the message, “Version 2”. If we run again without specifying a tag, it automatically tries the one with a tag of latest and again, Version 2.</p>
<p>Let’s make another change to the Dockerfile and we’ll change the message again to Version 3, and let’s save this, perfect. Now, let’s build it again, and tag it with a name but without providing a tag explicitly, so that it’s automatically going to be tagged as latest. Listing off the images, the three named tag_demo each have a different tag.</p>
<p>If we run a container based on the image named tag_demo, it going to print off the message, “Version 3”. So now let’s tag the latest image as v3. And listing off the images, you can see that v3 and latest are both the same image. Running either the image named latest or v3 will produce the same message.</p>
<p>Throughout the course so far, I’ve used some of the public images in the Dockerfile as our base image. Let’s use one of our own images as a base. First, let’s create a new directory and CD into it. And now let’s use nano to create a new Dockerfile. And for this, the only instruction we’re going to use is the FROM instruction, and we’ll specify tag_name and we’ll use v2, and now let’s build this.</p>
<p>And we’ll tag it as different_tag_demo, and we’re not going to provide a tag so that it will automatically be set to latest. And if we run a container based on this new image, it prints off Version 2 because, in the Dockerfile, we explicitly used the v2 tag. Outside of the development environments, it’s considered a best practice to use explicit tags for the image that you want to use in your Dockerfile.</p>
<p>Do you recall earlier in the course I mentioned Docker Hub? Well, before we wrap up this lesson, I want to show how to push an image to Docker Hub. Let’s push the latest version of tag_demo. This is done with a docker push command. If I try this out now, it’s going to throw an error. Okay, notice here it’s throwing an error because I’m not logged in yet.</p>
<p>So, before you can push an image, you need to authenticate with the docker login command. Before that, you need to have an account set up on Docker Hub. Now, that’s a separate thing. You’ll need to go create an account for yourself. Notice it has my username set here as a default, so I can press enter to accept that.</p>
<p>And I’ll paste in my password, and there we go. We’re all logged in. Let’s run the docker push command again and specify the image name, and we get another error message. Don’t worry, this is expected. Notice here in the URL it’s trying to push the image to docker.io&#x2F;library, followed by the name of the image.</p>
<p>The reason that this failed is that you can’t just upload an image of whatever name you want. That would be potentially chaotic. That’s why Docker makes you specify the name of your Docker Hub account in the tag. If you recall, I mentioned that the tag structure is a bit more complex than just an image name.</p>
<p>It also allows you to specify a registry, a username, et cetera. In order to push to my Docker Hub account, I need to tag this with my username. So, if I switch over to the Docker Hub UI, you can see it here. The username is separated with a forward slash, then the image name, and then the specific tag.</p>
<p>Okay, perfect, listing off the images, you can see that it has the same ID has the image named tag_demo. Okay, now we are actually ready to push this image to Docker Hub. This time, we just need to provide the new tag of sowhelmed&#x2F;tag_demo. And if you’re following along, you’ll need to use your own account name.</p>
<p>Now, back in the Docker UI, there we go. There’s our image. It even lists off the command to run so that anybody else can download this image. So, there you have it! Tagging in Docker allows you to give images specific identifiers. An image can have more than one tag. And Docker has a special tag called latest that will be automatically used if you don’t specify a tag.</p>
<p>However, the latest tag only represents the last image that you built that you didn’t provide a tag, unless you tag it as latest for yourself. So, don’t think that by typing latest you’re going to automatically get the newest image. That’s not how it works. And finally, when you upload a image to the Docker Registry, you’ll need to update the tag to include some additional information, such as the account name.</p>
<p>All right, let’s wrap up this lesson here. In the next lesson, we’re going to summarize what we’ve covered throughout the course and wrap things up. So, if you’re ready to wrap up this course, then I’ll see you in the next lesson.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Welcome back. We’ve covered a lot throughout the course, so let’s wrap up the course by summarizing what we’ve learned. In the first two lessons, we talked about Docker at a pretty high level. We covered what it is, and we talked about its architecture. Some topics are a bit of a chicken and egg type of scenario, as in it’s difficult to explain one without first explaining the other, in a circular logic sort of endless loop.</p>
<p>Now that you’ve seen Docker a bit, and you have some familiarity with it, the architecture should make a bit more sense. The gist of that lesson was to explain that Docker isn’t like a virtual machine; rather, it allows you to run processes in an isolated way, using several Linux kernel features. Now, it may be worth going back and re-watching the architecture lesson again so that it kind of ALT clicks now that you have some familiarity with Docker.</p>
<p>After that, we installed Docker on CentOS, and created a container. Creating a container is just a simple command, however, behind the scenes there’s a lot going on. Docker tries to find the image locally. If it can’t, it attempts to download it from a Docker registry, and once the image is on the local host, then it can create containers based off of that image.</p>
<p>And Docker also allows you to use the I and T flags so that you can interact with the processes running inside of the container. After creating the container, we talked about the difference between a container and an image. The difference being that a container is a running instance of an image; similar to how an executable becomes a running process.</p>
<p>Then we went on to cover creating images via the Dockerfile, and via Docker Commit. Creating your own images allows you to bundle up just what you need for your app. Now, there are a lot of best practices for creating images, and we didn’t really get into them. However, practices such as keeping the images as small as possible, using official public images as base images, and ensuring images have one purpose, as well as reducing the number of layers, are just a few best practices.</p>
<p>After creating some basic images that run simple binaries, printing out text to standard output, we tested a web application. With the webapp we get to see how ports work, and how to dynamically and explicitly set them. And we tested out three different networking options. Tested out bridge networks, which are the default if you don’t specify one.</p>
<p>Bridge networks allow containers to start in their own network that’s connected to the interfaces of the host OS. The default bridge network isn’t very customizable, however, you can create your own if you need to make some changes. We covered volumes after that. Docker provides three different storage options.</p>
<p>Volumes are the newest and most versatile because they also can allow you to specify your own driver to use. The drivers allow you to have different storage options, such as S3, Google Cloud Storage, or others, in place of local disc storage. We also covered the original option called, bind mounts, The difference between bind mounts and volumes is that volumes are managed by the Docker engine.</p>
<p>Bind mounts aren’t, and that requires you to know where on disc that mount is located. The final option was the temporary file system, named TempFS, which is an in memory option that lasts while the container is running. The final lesson covered tagging a bit more in depth. Tagging is important, and in production it matters how you tag things.</p>
<p>Following a strict procedure for tagging ensures that you’re going to be able to deploy the correct version, and then roll back if needed. And while it’s important, there’s no single strategy that’s going to work for everyone. So it’s important to find a strategy that works for your team. At the start of the course, I listed off some learning objectives.</p>
<p>I said, by the end of the course, you should understand what Docker is. You should understand how to create Docker images. You should understand how to map ports between the Docker host, and the Docker container. You should understand the networking basics. And you should understand how to use volumes for persistent storage.</p>
<p>And finally I said that you should be able to tag images. Now having made it this far, you should feel comfortable with each of these objectives by now. So, what’s next? What comes after all of this? Next, I recommend that you try this stuff out for yourself. Hands on experience is the best teacher. So, I recommend that you try out our Docker Labs, and that you try installing this locally, and follow some of the examples.</p>
<p>When you’ve gone through the examples, try and create some of your own. If you have some source code that you want to try and bundle up, I think that’s the best way to learn, is seeing how things that you already are familiar with will work inside of a container. Docker is a technology that continues to evolve, so depending on when you see this course, things may have changed.</p>
<p>If part of the changes introduce errors, then I want you to try and work through them. These are the sorts of errors that you’re going to run into in the real world. So, take the opportunity to understand why the error is happening, and it’s going to give you a better depth of knowledge into Docker. All right, let’s wrap up the course here.</p>
<p>As I mentioned at the start, I enjoy hearing from you guys. If you don’t provide me with the feedback about what you dislike, and what you like, I can’t improve upon the content. So, feel free to reach out to me via <a href="mailto:&#115;&#x75;&#112;&#x70;&#111;&#114;&#x74;&#x40;&#x63;&#x6c;&#111;&#x75;&#100;&#97;&#99;&#97;&#100;&#101;&#x6d;&#121;&#x2e;&#x63;&#111;&#109;">&#115;&#x75;&#112;&#x70;&#111;&#114;&#x74;&#x40;&#x63;&#x6c;&#111;&#x75;&#100;&#97;&#99;&#97;&#100;&#101;&#x6d;&#121;&#x2e;&#x63;&#111;&#109;</a>, or on Twitter, I’m @sowhelmed. That’s gonna do it for this course.</p>
<p>Thank you so much for watching. I hope that this has been useful to you. I had a lot of fun making it, and I hope that you’ve enjoyed it. I’m Ben Lambert. From Cloud Academy and myself, thanks for watching.</p>
<h1 id="7Images-From-The-Dockerfile"><a href="#7Images-From-The-Dockerfile" class="headerlink" title="7Images From The Dockerfile"></a>7<strong>Images From The Dockerfile</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.docker.com/engine/reference/builder/">Docker Documentation</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/19/CKA-Cert-Prep-Certified-Kubernetes-Administrator-CKA-Exam-16/" rel="prev" title="CKA-Cert-Prep-Certified-Kubernetes-Administrator-CKA-Exam-16">
      <i class="fa fa-chevron-left"></i> CKA-Cert-Prep-Certified-Kubernetes-Administrator-CKA-Exam-16
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/19/Docker-Certified-Associate-Docker-Playground-2/" rel="next" title="Docker-Certified-Associate-Docker-Playground-2">
      Docker-Certified-Associate-Docker-Playground-2 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Course-Intro"><span class="nav-number">1.</span> <span class="nav-text">Course Intro</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#What-is-Docker"><span class="nav-number">2.</span> <span class="nav-text">What is Docker?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-Docker-Architecture"><span class="nav-number">3.</span> <span class="nav-text">The Docker Architecture</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Installing-Docker"><span class="nav-number">4.</span> <span class="nav-text">Installing Docker</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Creating-and-Executing-Your-First-Container-Using-Docker"><span class="nav-number">5.</span> <span class="nav-text">Creating and Executing Your First Container Using Docker</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Images-vs-Containers"><span class="nav-number">6.</span> <span class="nav-text">Images vs Containers</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Images-From-The-Dockerfile"><span class="nav-number">7.</span> <span class="nav-text">Images From The Dockerfile</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Images-From-Containers"><span class="nav-number">8.</span> <span class="nav-text">Images From Containers</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Port-Mapping"><span class="nav-number">9.</span> <span class="nav-text">Port Mapping</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Networking"><span class="nav-number">10.</span> <span class="nav-text">Networking</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction-to-Persistent-Storage-Options-in-Docker"><span class="nav-number">11.</span> <span class="nav-text">Introduction to Persistent Storage Options in Docker</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Tagging"><span class="nav-number">12.</span> <span class="nav-text">Tagging</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Summary"><span class="nav-number">13.</span> <span class="nav-text">Summary</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7Images-From-The-Dockerfile"><span class="nav-number">14.</span> <span class="nav-text">7Images From The Dockerfile</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
