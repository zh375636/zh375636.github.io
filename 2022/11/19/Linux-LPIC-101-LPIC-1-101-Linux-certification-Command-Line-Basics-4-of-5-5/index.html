<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Course introductionWelcome to the fourth course in our series preparing you for the LPIC1, Linux Server Professional certification exam. In this course, we’ll learn about the Linux command line. And">
<meta property="og:type" content="article">
<meta property="og:title" content="Linux-LPIC-101-LPIC-1-101-Linux-certification---Command-Line-Basics-4-of-5-5">
<meta property="og:url" content="https://example.com/2022/11/19/Linux-LPIC-101-LPIC-1-101-Linux-certification-Command-Line-Basics-4-of-5-5/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:description" content="Course introductionWelcome to the fourth course in our series preparing you for the LPIC1, Linux Server Professional certification exam. In this course, we’ll learn about the Linux command line. And">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-19T05:08:49.000Z">
<meta property="article:modified_time" content="2022-11-21T00:24:28.000Z">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/2022/11/19/Linux-LPIC-101-LPIC-1-101-Linux-certification-Command-Line-Basics-4-of-5-5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Linux-LPIC-101-LPIC-1-101-Linux-certification---Command-Line-Basics-4-of-5-5 | Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Linux-LPIC-101-LPIC-1-101-Linux-certification-Command-Line-Basics-4-of-5-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Linux-LPIC-101-LPIC-1-101-Linux-certification---Command-Line-Basics-4-of-5-5
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 01:08:49" itemprop="dateCreated datePublished" datetime="2022-11-19T01:08:49-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-20 20:24:28" itemprop="dateModified" datetime="2022-11-20T20:24:28-04:00">2022-11-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LPIC-1-101/" itemprop="url" rel="index"><span itemprop="name">LPIC-1-101</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Linux-LPIC-101-LPIC-1-101-Linux-certification-Command-Line-Basics-4-of-5-5/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Linux-LPIC-101-LPIC-1-101-Linux-certification-Command-Line-Basics-4-of-5-5/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <span id="more"></span>

<h1 id="Course-introduction"><a href="#Course-introduction" class="headerlink" title="Course introduction"></a>Course introduction</h1><p>Welcome to the fourth course in our series preparing you for the LPIC1, Linux Server Professional certification exam. In this course, we’ll learn about the Linux command line. And especially how, by using text based tools you can closely and efficiently control just about everything that’s happening on your system. We’ll explore terminal shells and environment variables.</p>
<p>Manipulating and redirecting text streams. File management, and archive backup tools. How to control systems and processes.</p>
<p>How to launch sophisticated conditional tech searches in the world of the terminal text editor, in particular VI. We’ll also learn how to use Linux’s “man” system of in line help documentation.</p>
<p>I must warn you, that some of the videos in this course are going to be packed end to end with commands and more commands.</p>
<p>Unfortunately, there really is no way around it. The power of the Linux command line lies partly in having access to the full tool kit. And there are a lot of tools in this kit. But successfully absorbing and mastering the material, will simply be impossible without trying everything out yourself. Even better, you should try to work on actual projects using these tools.</p>
<p>Finally, while we will normally connect Linux topics to their cloud computing counterparts and show how system administration is done on AWS, since the material on this course lies so close to the very core of systems administration, there really is nothing here that would be done any differently in the cloud. But I have little doubt that over the course of a career administrating AWS infrastructure, that you will happily make good use of many of these tools.</p>
<h1 id="Working-on-the-command-line"><a href="#Working-on-the-command-line" class="headerlink" title="Working on the command line"></a>Working on the command line</h1><h3 id="Understanding-Linux-shells"><a href="#Understanding-Linux-shells" class="headerlink" title="Understanding Linux shells"></a>Understanding Linux shells</h3><p>A Linux administrator’s primary working environment is the command line which is, to be more precise, a command language interpreter. That is to say in much the same way as a computer language like C or Java, the interpreter will translate your commands into terms your operating system can understand, allowing them to be executed. Technically speaking every command line is a shell. A relatively independent compute environment bound by it’s own set of rules and restrictions. Of course, a shell exists within the computer and network that spawned it, but can also be given unique characteristics. Bash which stands for Bourne Shell, perhaps the best known Linux command language interpreter, is the one we’ll use for this course. Of course, there’s nothing stopping you from switching between different interpreters. Typing “sh” by the way will open a new shell using the sh environment. As you can see, the sh shell isn’t currently set to provide as descriptive a command prompt as bash.</p>
<p>Typing “Exit” will drop us back into our original bash shell. Typing “Exit” once again would close the window altogether.</p>
<p>While the terminal command line is the most visible place we use these tools, and the place where we’ll do most of our learning in these courses. In administration terms, they’re usually most productively utilized as parts of scripts.</p>
<p>Bash scripts are effectively executable text files containing commands that automate processes harnessing some extremely sophisticated resource manipulation tools. We’ll talk more about scripting later in this series. For now, it’s enough to know that everything we’ll discuss here, as useful as it is, will prove even more useful later.</p>
<p>Let’s talk about some of the more basic command line tools. Typing “Echo,” followed by some text will cause that text to be output on the next line. Nothing too exciting.</p>
<p>Let’s try “echo $USER,” and see what’s printed to the screen. So user it would seem is a pre-existing system variable that contains the name of the current user. And the dollar sign tells bash that the following text string is a name of a variable, rather than just text to be printed.</p>
<p>Typing “echo $user” in lower case by the way won’t work. Bash is generally very case sensitive. We could however add a new variable using “user&#x3D;myname” and then run echo again, “echo $USER.” This time the new value of user is printed. Where do these system variables come from? The “set” command when run without argument will output a list of all current shell variables and functions. Note how user is the last, meaning most recent, value in the list. Interestingly some of these variables will actually change dynamically. So for instance, the pwd, which stands for present work directory, right now is &#x2F;home&#x2F;ubuntu. But if I change directories to say, &#x2F;etc and run set again, you’ll see the value of pwd has followed us. Typing pwd in lowercase in the command line will by the way display our current work directory. Another system variable that’s often really useful is uname. Although you could probably have figured out that we’re using Linux on your own. Adding a “-a” to that however will output the Linux kernel version our system architecture and the current date and time.</p>
<p>Let’s review. Your command line exists within a shell of which bash and sh are two examples. Commands can be executed from the command line or through scripts. Echo will print a string or the value of a variable to the screen. You can create new variables using name&#x3D;value.</p>
<h3 id="Working-with-Linux-environment-variables"><a href="#Working-with-Linux-environment-variables" class="headerlink" title="Working with Linux environment variables"></a>Working with Linux environment variables</h3><p>Set has many command line arguments but I believe that simply being aware of its role as a reporter of shell variables is enough for the LPI exam. Unset will, when followed by the name of a variable, remove that value. Let’s run “unset user” using lowercase. And then run set again. Our original value of user has been removed, although we can still see a trace of it’s existence in this _&#x3D;user. If we were to exit this shell and start a new one even that trace would no longer be there.</p>
<p>Like set, running env without arguments will display environment variables. However, unlike set env will not display functions. Also unlike set env will not include a variable until it’s been exported to the environment. From that point however the variable would be available to child processes. Let’s illustrate that. We’ll create a variable called “stuff” and give it the value of hello. Running set will display our new value. Running env on the other hand comes up with nothing. Even when we grep for stuff specifically. Now if we type bash we’ll find ourselves in a new shell session. One level below our original shell. And at this level our stuff variable fails to show up even for set.</p>
<p>Let’s exit this shell and now back in our home shell we’ll run set again. Stuff is right there where it’s always been. Now let’s export the stuff variable using export followed by the variable name.</p>
<p>Now running env again and grepping for stuff shows us that stuff is part of the environment. We’ll open a new lower level bash shell and run “echo $stuff.” And what do you know, the value of stuff has followed us down to this new child shell.</p>
<p>To review, “set” contains functions and variables even before they’ve been exported. Running env will only display exported variables. Exporting a value with the export command will make the variable available to child shell sessions.</p>
<h3 id="Using-man-the-Linux-help-documentation-resource"><a href="#Using-man-the-Linux-help-documentation-resource" class="headerlink" title="Using man, the Linux help documentation resource"></a>Using man, the Linux help documentation resource</h3><p>One of the most basic needs you’ll probably encounter in your shell work is access to useful and contextual help. Did that command require a -a or –append? Was the a supposed to be upper or lower case? How is that command actually spelled? Linux comes with a very complete help system called man. Typing man, followed by the name of the command you’re working with will usually return a manual page describing the use and function of the particular command. This simple man page nicely shows us how man pages break down including sections for name, synopsis, description, author, bug information, copyright and related sources.</p>
<p>Note the number one at the top of the page indicating the page type. There are nine page types in the man system, as illustrated here. The LPI exam will actually expect you to be familiar with these types and their corresponding numbers. Man bash is a huge man file that has a lot to teach you about how shells work. If there doesn’t seem to be a man page for a very basic command like unset you’ll probably find it within man bash, which can be searched by hitting the forward slash and entering a string.</p>
<p>If you can’t remember the precise name of a command, which can make finding the right man page a bit of a challenge you can use apropos.</p>
<p>Finally, past commands that you’ve executed remain accessible to you through history. Typing history alone will display previous commands in reversed order. You can search the record by running history with grep. Or read the hidden .bash_history file itself, which can be edited. I can’t tell you how many times history has made my job and my life so much easier.</p>
<h1 id="Process-text-streams-using-filters"><a href="#Process-text-streams-using-filters" class="headerlink" title="Process text streams using filters"></a>Process text streams using filters</h1><p>When people talk about Linux you’ll often hear the expression nearly everything in Linux is a text file.</p>
<p>Whether it’s the configuration files kept in &#x2F;etc, executable scripts or logs so much of what goes on in Linux is really nothing more than the system reading plain text or lightly formatted files. With all that can be controlled using text, it’s stands to reason that there’s a great deal that can be accomplished by filtering and editing that text. And especially by filtering and editing it on the fly as processes are actually an execution.</p>
<p>We’re going to illustrate the text filtering and manipulation tools any Linux sysadmin will need by performing rather insignificant actions but the skills themselves are directly transferable to the most sophisticated and even elegant tasks. But this is one of those times I referred to earlier when you’re unfortunately going to be deluged with commands and their arguments. Take it slowly don’t be afraid to listen to something over again and don’t forget that I will insert periodic review to help all these digest properly. And most of all, work through all these commands on your own.</p>
<h3 id="Working-with-Linux-text-manipulation-tools"><a href="#Working-with-Linux-text-manipulation-tools" class="headerlink" title="Working with Linux text manipulation tools"></a>Working with Linux text manipulation tools</h3><p>You should note that each of these tools has many possible arguments and use cases that we’re not going to go into right now. You’ll generally need to have a decent overview level knowledge of text processing commands for the LPI exam and won’t be expected to dig deeply into complex options.</p>
<p>As we’ve seen already many times in this series, cat will print a file to the screen. We didn’t yet mention that cat is actually short for “concatenate” which means to join things together. Adding the “-n” argument will print the text with numbered lines. And using uppercase A will print all characters. If you need a more simplified version of that file, we can use cut to strip away everything we don’t need. Here the “-d” followed by the colon sets the field delimiter to colon meaning that every instance of a colon marks the beginning of a new field. “-f1” means that we only want to print the first field.</p>
<p>This doesn’t actually change the contents of the file nor could we in the case of the password file without becoming the administrator but we could easily save our newly edited text by piping the string to a file. Let’s see what it looks like.</p>
<p>“Expand” will convert tabs in a text string to spaces. We’ll work with the file called file that contains two lines one whose words are separated by tabs and the other separated by spaces. Running “expand -t” followed by the number 15 and the name of our file will replace every tab in the file with 15 spaces. Running “unexpand” with the number one and the name of our file will replace every set of one spaces with a tab. Running it again with the value two will replace every set of two spaces with a tab.</p>
<p>“Fmt” formats large bodies of text. “Fmt -w” will force a file to break to a new line every X number of characters. “Fmt -t” will indent all paragraph lines after the first line, “Pr” will also add formatting to the text.</p>
<p>“Pr -d” will print double spaced “-l” will set a limit to the total number of screen lines. Head will print only the indicated number of lines from the top, the head of the file.</p>
<p>“Od” which stands for octal dump will print the characters of a file in different formats. “Od -a” for instance will display our text with “ht” representing each tab and “sp” for each space. “Od -c” will print tabs as “&#x2F;t” and new lines as “&#x2F;m.” And here’s OD’s default output.</p>
<p>Let’s review. Cat prints to the screen, cut will isolate a single column and print only that. Expand converts tabs to spaces while unexpand converts spaces to tabs. “Fmt -w” formats the width of the text that’s displayed to the screen, “pr -d” and “-l” control line spacing and screen length. Head prints only the first defined number of lines of a file and “od” will print files in different formats.</p>
<p>Less is an old friend we’ve used previously to view text. Less will display large bodies of text one screen at a time allowing you to use regular controls like the arrow keys or page up and page down to move through a document.</p>
<p>Join is a tool for merging columns of data for multiple files assuming that they share a common field. I’ve created two very simple files part one and part two containing simple numbered columns. By running join and specifying our two files, the data from both will be usefully displayed. Paste besides printing a single file will also by default print the data from two files side by side, adding “-s” will print the two file sequentially rather than side by side. Although I admit that this particular example doesn’t look that useful.</p>
<p>“Nl” like “cat -n” will print the lines of a file with numbers. Sort will reorder the contents of a file either by number or alphabetic sequence. Running sort with “-n” telling Linux that we want this sorted by number will display the lines in ascending order. “Sort -nr” will do the same but in reverse or descending order. Sort without the “-n” switch will list the files in alphabetic order. This is a version of the file without numbers again adding “-r” will reverse the output.</p>
<p>Split is one of those rare text tools that actually does something permanent by default. Running split will take a file or text stream and create smaller files from it according to your specified size. So to create files each no greater than say two lines long use “split -2” and the file name. In this case, listing the files in this directory reveals six files named xaa to xaf each no longer than two lines. If you don’t specify a file length, split will default to 1,000 lines.</p>
<p>Tail will print only the last lines of a file. The number of lines it does print depends on your specification. Therefore, “tail -n 3” will print the last three lines of the etc&#x2F;group file. When you add the “-f” switch, tail will continue printing any new lines that are subsequently added to the file. This can be really useful when you’re trying to monitor a system event. Running tail against a log file like syslog will allow you to see system events as they happen. “Tr” will translate text from one format to another.</p>
<p>Let’s take off the new split files that we created and read it using cat but rather than display it to the screen as is we’ll pipe it (using the shift and backslash keys) to tr, in this case converting all lowercase characters to uppercase. Here’s a file I created with a couple of such duplicates.</p>
<p>“Uniq -u” will print only unique lines. Quickly printing document’s statistics is the job of “wc.” “Wc” will tell you the total number of lines, words and bytes of a file.</p>
<h3 id="Introduction-to-sed-on-Linux"><a href="#Introduction-to-sed-on-Linux" class="headerlink" title="Introduction to sed on Linux"></a>Introduction to sed on Linux</h3><p>Finally, we come to “sed” which stands for stream editor. In truth, sed could easily fill a course all its own and is treated with some awe by those admins familiar with its magic. It’s almost embarrassing to reduce sed to just a couple of simple examples but this should actually cover you for the LPI exam and I’ll let you get away with it as long as you make a solemn promise to dig deeper on your own later.</p>
<p>Let’s take another look at our part one file and note its contents. Suppose you’ve grown tired of dogs and would prefer a horse. You can cat the file again and pipe it to sed using “s” and forward slash tells sed to substitute horse for dog, which is exactly what it does. Running sed again with a “d” following dog will delete the dog line entirely. My apologies to dog lovers.</p>
<p>Let’s review. Less displays text files one screen at a time. By the way, there’s another similar tool called “More.” Join merges columns from multiple files that share a common field. Paste prints multiple files together. “Nl” prints a file with its line numbers. Sort controls the order by which you can print a files contents. Split creates smaller files out of a single large file. Tail prints or monitors the end of a file. “Tr” translates text from one format to another. Unique will isolate duplicated lines. “Wc” displays documents statistics. And sed does just about everything else.</p>
<h1 id="Perform-basic-file-management"><a href="#Perform-basic-file-management" class="headerlink" title="Perform basic file management"></a>Perform basic file management</h1><p>When most people think about managing files on a computer, it’s a GUI interface like Gnome Nautilus that usually comes to mind first. However, while navigating through your files visually does certainly have some benefits, once you get used to the speed and power of command-line file management you may never want to go back. But in any case you’ll have no choice but to use these skills when you’re logged into a headless server, remote machine, or LXC vm. So consider these commands to fall pretty much in the “basic survival skills” category.</p>
<h3 id="Basic-Linux-file-and-directory-management"><a href="#Basic-Linux-file-and-directory-management" class="headerlink" title="Basic Linux file and directory management"></a>Basic Linux file and directory management</h3><p>Let’s start at the beginning with some commands that we’ve come across already in these courses. We’ll begin by listing the files and directories in our current location using “ls.” You can create a new empty file using touch followed by the file name. If a file with that name already exists, then touch will simply update its last updated information. You can create a new directory using mkdir. If you want to create a directory somewhere on your file system besides the current location, simply include the absolute address in your command, and if you’ll need admin rights, sudo. You’ll sometimes need to create an entire directory tree. This is common when you’re installing a package that expects a data file to exist in a certain location whose parent directories don’t yet exist on your system. This requires just one simple command using mkdir with the “-p” switch. See how long it would take you to do that in the GUI file manager.</p>
<p>Let’s return to our home directory. You can copy files or directory trees between locations using “cp.” “Cp file1 newplace&#x2F;“ will make a copy of file1 in the new place directory. If you want to copy a directory and its file and subdirectories all at once, we would add “-r” to the “cp” command to make the operation recursive. Let’s go take a look to make sure both the directory and the copy of the file called “file1” have been copied faithfully. Remind me to clean up that poor &#x2F;etc&#x2F;perl directory once we’re done with all this.</p>
<p>You can move a file or directory tree from one place to another or just rename them using “mv.” Where “file1” is the original name of the file we’d like to change and “file2” is the new name we’d like it to have. Since we’ve been using “ls” to list the contents of our files a bit, now’s probably a good time to show how using “ls -l” you can list files and directories with longer descriptions. And running “file” against a file directory will display useful file information.</p>
<p>“Rm” will delete or remove a file. “Rm -r” followed by the name of the directory will remove the directory and all the files and directories that it contains. Be aware, be very aware, that “rm” by default will not ask you if you’re sure you want to remove these files and it won’t place the files in a trash can that can be recovered later. Once you run “rm,” your files are for all intents and purposes gone. Having said that if you run “rm” with the “-i” switch, you’ll be asked if you’re sure before anything happens.</p>
<p>One of the things that really makes the command line stand far apart from GUI file managers is globbing. Even if the word itself sounds like it might be referring to some mildly toxic liquid that oozes from between the keys of your keyboard, it’s actually about adding global identifiers to your commands.</p>
<p>To illustrate let’s create a few new files to replace the ones we’ve just removed. Now let’s use “ls” and “grep” to list all the files in this directory whose names begin with the letters “F” and “I.” If we now run “rm file” with a question mark, it will delete file 1 and file 2 but not file 22. Why not? Because the question mark will include exactly one instance of any character. If you would have wanted to remove file22, which has two characters after the word file as well we would have used an asterisk instead.</p>
<p>This kind of pinpoint accuracy in identifying files is obviously going to be useful far beyond simple file deletion but can also play a huge role in sophisticated scripting.</p>
<p>Let’s take a moment and review what we’ve seen. Touch will create or update a new file. Mkdir will create a new directory. “Mkdir -p” will add any parent directories that may be necessary. “Cp” creates copies of a file and “cp -r” copies directories and their contents. “Mv” moves or renames files or directories. And “rm,” “rm -r,” and “rm -dir” remove files and directories. The question mark when used for file globbing will include any single character while an asterisk will include any number of characters.</p>
<h3 id="Archives-and-file-compression-using-tar"><a href="#Archives-and-file-compression-using-tar" class="headerlink" title="Archives and file compression using tar"></a>Archives and file compression using tar</h3><p>Your lives as Linux system administrators will never be complete unless you can create archives and backups of large groups of files and directories. Now that we’re able to use tools like globbing to identify specific subsets of file systems, we should also be able to pipe the lists of files to generate entirely new backup archives. Tar, which stands for Tape Archive, although it obviously works just as well without backup tapes, uses existing archiving and compression software to create, amend and restore file archives. “Tar-cvf” where c stands for create, “V” for verbose and “F” for the name of a file will create a new archive called newarch on the USB device indicated. The asterisk tells tar to create that archive from all the files but not directories in the current directory.</p>
<p>An archive is simply a structured collection of files that are bundled into a single file. Adding the letter z will tell tar to compress the archive as well.</p>
<p>An uppercase A will append rather than create an archive. By the way, tar always expects the name of the new archive file you want to create to immediately follow the “f” switch. And the files or directories to be included to follow after that. This can be a bit confusing but you absolutely must remember this detail for the LPI exam. “-x” used this way will extract the files of an archive into the current directory. As you can see, tar archives take a -tar file extension, and archives that were compressed using gzip will end with tar.gz.</p>
<p>Besides working through tar, you can also directly compress or decompress archives using the gzip, gunzip, bzip2 or xz programs. You’ll probably run into archives in these formats during your career and once again the LPI exam expects you to be familiar with them.</p>
<h3 id="Archives-and-file-compression-using-cpio"><a href="#Archives-and-file-compression-using-cpio" class="headerlink" title="Archives and file compression using cpio"></a>Archives and file compression using cpio</h3><p>The cpio utility does a lot of what tar can do although it usually works with pipe data rather than as a standalone. Let me show you what I mean. Let’s list all the files in this directory. There’s currently only one actual file besides the directories. Now let’s list the files and pipe the list to cpio. “-o” will create the archive called “lsarch.cpio.” Adding gzip to the command will compress the archive. Now let’s move to the root directory and use the find tool to search to a maximum depth of four directories for any file with a file extension of .txt. There are a couple of such files. Now let’s use cpio to create a new archive of just those files. We’ll just jump back into our home directory to make sure the archive has in fact been created.</p>
<p>Finally, we must discuss “dd,” which some believe stands for “disc destroyer,” since it’s so easy to misuse it to wipe out vast volumes of valuable data. Still dd’s great risk is more than balanced by its still-greater value. Dd always takes an “if-of” structure. That is, “if” equals the files I’d like to copy and “of” equals the place to which I’d like them copied. The beauty of dd is that it will copy a file system or an entire partition in its exact original format. It can use this to copy an entire hard drive and move it over to a new computer. And you’ll be able to boot from it as though it was the original. Here’s a simple example where the goal is to copy the sdb1 partition referenced by the link the &#x2F;dev directory to the location of your backup media. This will copy a whole drive sdb to the backup drive you’ve mounted in mnt&#x2F;drive. We’re not going to talk about it in this video but adding tools like SCP and Rsync to the mix will allow you to perform all of these functions not just locally but between remote computers often all using a single command.</p>
<p>So let’s review all of this. Tar with the “-c” switch will create a new archive. Adding a z will compress it too. And uppercase A will append new files to an existing archive. Tar-x will extract the contents of an existing archive. cpio when you pipe data streams to it, will create archives and when gzip is added these archives will be compressed. You can use the powerful find tool to carefully select which files to pipe to cpio or to any one of dozens of other Linux command-line tools for that matter. And dd will copy an exact image of a partition, drive, or selection of files.</p>
<h1 id="Use-streams-pipes-and-redirects"><a href="#Use-streams-pipes-and-redirects" class="headerlink" title="Use streams, pipes and redirects"></a>Use streams, pipes and redirects</h1><p>In the previous video, we discussed file management how you can control and manage your files directly but also indirectly through piping file names and attributes between commands. But if pipes increase the versatility of file manipulation just imagine what it can do to data streams.</p>
<p>Now don’t get all worried. Data streams don’t have to be all that complicated. It can be something as simple as using “cat” to display the contents of a file to your screen. That streamed file one to the screen as we’ve seen before. They can also use cat to redirect the contents of the file to another file like this. As we’ve seen many times already, you can also pipe data from one program to another where the pipe symbol is produced by hitting the shift and back slash keys together. Let’s use the cat program to stream the contents of the syslog file to the grep program to print to the screen only those lines containing the words eth0, which is of course, the name of my first network interface.</p>
<h3 id="Working-with-Linux-data-streaming"><a href="#Working-with-Linux-data-streaming" class="headerlink" title="Working with Linux data streaming"></a>Working with Linux data streaming</h3><p>Linux categorizes all data flows as one of three file descriptors stdin, standard input, which is designated by the number zero, even if isn’t technically a number. Stdout, standard output identified by one and stderr, standard error, identified as two.</p>
<p>Standard input obviously is the data that is input into a program while standard output is the data that’s output from a program. Let’s illustrate this.</p>
<p>Let’s run the program “tail” which if you’ll remember outputs a file’s last lines against syslog and redirects the contents using one and forward arrow to a new file called say, “log data.” The number one tells Linux to redirect the standard output meaning whatever lines of the syslog file tail delivers to become the contents of the file log data. You don’t actually need to include the one in this case, since one happens to be the default via the redirect sign anyway. If you wanted to simply append the contents of syslog to the end of the current contents of the file without overriding whatever’s there already you would use two forward arrows like this. That’s how standard output works.</p>
<p>Let’s see what standard error will produce for us. We’ll cat our file one file redirecting the standard error output to a file called errors. Viewing errors shows us that the file is still empty. That makes sense because if the previous cat command worked it wouldn’t have produced an error. Now let’s try to cat a file that doesn’t actually exist and view the errors file once again. This time there’s something there.</p>
<p>Linux doesn’t restrict a stream to a single output target: Tee allows you to send data off in two separate directions at the same time. This command will list using the long form the contents of the current directory on the screen but also add them to the file list.text.</p>
<p>Finally, you can redirect data streams as input to the xargs program. xargs will execute commands like rm in cases where you need more complicated filters than the command itself would normally allow. From our root directory and using sudo let’s use find to search for all files with a .c extension but pipe that list to grep that will filter only those files that contain a text string, “stdlib.h.”</p>
<p>Let’s review. You can redirect a stream to overwrite the contents of a file using the forward arrow. Two forward arrows will append the new text to the file’s existing contents. The pipe symbol will stream data to the program to the right of the pipe. There are three file descriptors: standard input, standard output, and standard error. One and forward arrow will direct standard output, while two and forward arrow will direct standard error. Tee directs data to multiple streams and XRX controls command execution on pipe data.</p>
<h1 id="Create-monitor-and-kill-processes"><a href="#Create-monitor-and-kill-processes" class="headerlink" title="Create, monitor and kill processes"></a>Create, monitor and kill processes</h1><p>While working with multiple processes from a command line interface might not be quite as intuitive as it is with graphic desktops which give you all kinds of visual indicators telling you what’s happening and where moving between programs is as simple as clicking on a window. Linux provides server admins with a very rich set of tools nonetheless. In this video, we’re going to explore how you can manage and keep track of the processes running on your machine.</p>
<h3 id="Killing-off-misbehaving-Linux-system-processes"><a href="#Killing-off-misbehaving-Linux-system-processes" class="headerlink" title="Killing off misbehaving Linux system processes"></a>Killing off misbehaving Linux system processes</h3><p>First of all you will sometimes need to know exactly what is currently active. The quickest way to do that is by using ps. Ps displays useful information about a different live process on each line, indicating the user who started the process, who is often root, the process ID or PID, the percentage of CPU resources and memory this process is currently using and skipping over to the final column at the right, the command use to launch the process. On most systems and especially systems running graphic desktops, the number processes returned by ps will run in the hundreds. You will therefore often want to narrow down your search using grep. You can also get PIDs for individual processes using pgrep. This example will search for a process called SSHD that was launched by the user root.</p>
<p>Free will show you how much system memory you’re currently using and how much is still free. Free-h will display that in more human readable terms. And uptime will tell you how long it’s been since the last time you booted the system. One company I worked for took great pride in having uptime on some servers return well over a year.</p>
<p>If you’re experiencing system slowdowns or other trouble, you can easily check which processes are selfishly grabbing most of the resources by running top. Top until you exit by pressing the Q key will display a regularly updated list of the processes using the most resources. The percentage of CPU and memory columns are the ones that the most interesting for us. Once you spot the culprit and decide you’re going to have teach it a lesson it soon won’t forget, you should note its PID or command name because that’s what you’ll use to shut it down. This is something that unfortunately I have to deal with almost daily. While Linux software is generally highly reliable there’s one video production package in particular that while offering fantastic features and quality will often freeze on me. Shutting it down using the close button or other normal approaches just won’t work so I have no choice but to kill its process from the command line. When a process, well let’s call it my app, does freeze I have two choices, killall followed by the name of the process which is usually the same as the command you see listed in top or ps would do the job nicely, while just kill and the PID that was displayed in top will also work.</p>
<p>The kill command, by the way, can also be accompanied by a signal code. Here are the most common signal codes. Number one, or SIGHUP which stands for Signal Hangup signals to a process that its parent shell is closing. Number two, or SIGINT interrupt is the equivalent of a Ctrl-c that interrupts a process. Ckill -9 will force the process to shut down while SIGTERM15 will immediately terminate a process. Running kill with no signal code will default to 15. Pkill works much the same as killall with the important difference that it will guess what you meant with misspelled processes thus if rather than pkill SSHD we were to run SSH, pkill would kill SSHD and in the process of course shutdown our SSH session so be extra careful with pkill.</p>
<p>There is chance by the way that you will kill the process but its GUI window will still appear on your desktop. This is called a zombie process. Unlike real life zombies, these won’t do you any harm and will disappear when you reboot.</p>
<p>To review ps will list all live processes. Pgrep allows you to narrow the listing down by user and process name. Free shows how much memory you’re using. Top displays those processes using the most resources. Killall or pkill will shut down a process by name and kill will shut it down based on PID.</p>
<h3 id="Using-screen-for-multi-screen-terminal-sessions"><a href="#Using-screen-for-multi-screen-terminal-sessions" class="headerlink" title="Using screen for multi-screen terminal sessions"></a>Using screen for multi-screen terminal sessions</h3><p>Believe it or not you can actually have multiple working windows each with its own running processes within a single terminal. Screen is a rather complicated program that creates an entirely keyboard based environment for managing these multiple windows or more accurately screens. The LPIC exam expects you to be at least familiar with the basics of Screen so I’ll give you a short walkthrough. First of all if it isn’t already, you need to install Screen using App Get. To launch a new screen, type screen. After the initial information pages your terminal will look the way it normal does. Ctrl-a w will display a window bar at the bottom with your current shell. You should be aware that for some reason Screen documentation uses uppercase C-a rather than Ctrl-a to describe their escape key combination.</p>
<p>You can detach from your current session using Ctrl-a and d. This will dump you back in your normal Linux parent shell. Part of the challenge of using Screen is keeping track of where you are and indeed, whether you’re inside or outside Screen. To list the currently running screen sessions from outside Screen type screen-ls. To get back into your screen type screen-x. Once inside you can create a new window using Ctrl-a c and split your screen horizontally using Ctrl a S. You can jump between screens using Ctrl-a tab. Ctrl-a&#x2F; will exit a screen and its programs.</p>
<p>That should be enough to get you started with Screen. Let’s quickly review Screen commands. Screen run from a regular shell will open a new screen. Screen-ls will list all current screens and screen-x will attach you to a live screen. From inside a Screen shell Ctrl-a c will create a new screen. Ctrl-a S will split your screen horizontally. Ctrl-a d will detach you from a screen. Ctrl-a tab will move between screens and Ctrl-a&#x2F; will exit a screen and all its programs.</p>
<h3 id="Controlling-running-Linux-processes"><a href="#Controlling-running-Linux-processes" class="headerlink" title="Controlling running Linux processes"></a>Controlling running Linux processes</h3><p>Until now besides our detour into Screen we’ve discussed identifying and if necessary killing processes. Now we’ll talk about directly managing ongoing processes that we don’t want to kill. By default, every job you start will take complete control of the shell from which it was launched. As we’ll see in a minute, it can be useful to see both its job number and its PID at startup. To do that add the &amp; character to the command. I’ve created a very large file called Big File that I’ll now copy the big file to, something that will take some time. Therefore we’ll run it with the &amp;. This will run the copy operation in the background. But besides learning the PID issued by the Linux kernel, we’re also told that this is job ID one within this shell. Since everything is happening in the background, we’ve got control of our command line prompt. Should we want to bring the job back to the foreground, we would use fg, standing for foreground, and the job ID. Should we now want to send the job back to the background, we hit Ctrl-z and then bg and then the job ID. Let’s delete the file we just created. A good Linux admin always cleans up his messes, right?</p>
<p>Now let’s run this again in the background. To see what’s going on we can use the jobs command to display all background processes and their status. We can also use ps by itself to display all processes running in this particular shell. Unlike psaux which displays all processes running on the whole system.</p>
<p>Finally we can run a command with nohup that’s no hang up in front of it to ensure that even if I should close this particular shell the process will survive until it’s complete. Just to review these last points adding an &amp; character after a command will force the process to run in the background. Fg and the job ID will bring it back to the foreground. Ctrl-z and then bg along with the job ID will send it back to the background again. Jobs and ps will both display current shell processes. And adding nohup to a command will ensure that it completes regardless of what might happen to the shell itself.</p>
<h1 id="Modify-process-execution-priorities"><a href="#Modify-process-execution-priorities" class="headerlink" title="Modify process execution priorities"></a>Modify process execution priorities</h1><p>Anytime you’ve got more than one process running on a system there’s a risk that competition for finite resources might cause trouble. Because default priorities don’t always work for every configuration, an operating system needs a tool that allows administrators to edit the priority scheduler.</p>
<h3 id="Using-nice-to-manage-multiple-processes"><a href="#Using-nice-to-manage-multiple-processes" class="headerlink" title="Using nice to manage multiple processes"></a>Using nice to manage multiple processes</h3><p>In Linux, that tool is called “nice.” To make it a bit easier to see this actually working, using screen, I’ve opened two terminals. Running “top” in the upper terminal you can see that every process has a priority number under the PR column and under the NI column a nice value. By default, every process has a nice value of 0 and a PR value of 20. You can change a processes nice value to make it as high as 19, which would raise the PR to 39 or as low as minus 20, 19 or really, really nice would lower the priority of a process to the point that the needs of all other processes would take precedence. In other words, our process is being nice to everyone else.</p>
<p>Lowering its nice value to minus 20, will give a process a very high priority in the competition for system resources or in other words it’s not being very nice to other processes at all. If you’re launching a process, you can manually set the value through nice.</p>
<p>Let’s say that you want to download a package using apt-get but you don’t want it to take too many CPU cycles away from other programs that you’ve got going. You might launch the process through “nice” like this. You can see that the process being run by root has a nice value of 10. Note by the way that the minus 10 I used here is not negative 10 but -10. If you wanted to lower the nice value to say minus 10 I would do it with two dashes the first being a dash and the second the minus sign.</p>
<p>For processes that are already running, you can edit the nice value using “re-nice.” Looking at “top” we can see the SSHD process is currently running with a nice value of 0. If I’d like to change that to minus 10 or to make it less nice I would note the process ID and in any other terminal run “re-nice minus 10-p” for process and the process ID. See how within a second or two the SSHD’s nice value changes. Re-nice doesn’t take a dash as part of the syntax so a single dash would in fact mean the minus sign. Don’t blame me for all of this. I didn’t come up with these rules. I just have to learn to live with them just like you.</p>
<p>Besides “top” you can also use “ps” to view all processes nice values using the “-elf” switch. You can also of course “grep” for a particular program or PID. Not only will nice and re-nice control the priority given to an individual process but they can also be used to control all processes launched by particular users or groups. To raise the nice level of the user Ubuntu to 10 use re-nice followed by “-u” and the user name. To lower the nice value of a group use “-g” and then the name of the group. Let’s review. A really nice process can have a value as high as 19. While a nasty, un-nice process can be selfish and go as low as minus 20. Launching a new process to control its nice value can be done using the nice program. Adjusting the nice value of a running process is done using “re-nice.” You can edit nice values for users and groups and view nice values using either “top” or “ps.”</p>
<h1 id="Search-text-files-using-regular-expressions"><a href="#Search-text-files-using-regular-expressions" class="headerlink" title="Search text files using regular expressions"></a>Search text files using regular expressions</h1><p>Regular expressions often described as Regex. regex are text strings that contain some mixture of regular letters that are meant to be understood literally as simple characters and meta-characters that have meaning at the system or processing level. Thus, characters like the dot, brackets, the caret, dollar sign, backslash and asterisk can all be used for instructions for tools like grep.</p>
<p>In this video, we’ll learn how to properly notate and use these instructions both in their regular and extended levels. We’re also going to learn how to use the grep tool much more effectively. By the way, as I don’t believe I’ve mentioned this before grep stands for Global Regular Expression Print.</p>
<h3 id="How-to-run-sophisticated-text-searches-using-regex-and-other-text-streaming-tools"><a href="#How-to-run-sophisticated-text-searches-using-regex-and-other-text-streaming-tools" class="headerlink" title="How to run sophisticated text searches using regex and other text streaming tools"></a>How to run sophisticated text searches using regex and other text streaming tools</h3><p>Here’s a silly but widely-used example. Looking at the fruits.txt file I created, we see that it contains the word “banana. “Rather than just searching for the whole word, something even a Windows user could do, we’ll do it like trained Linux admins and use grep to search for “banana,” specifically taking advantage of the repeated incidence of the letters A-N. Naturally, this won’t be so efficient in our case but you can no doubt imagine how it can be applied to more complicated cases. This will search for any letter B followed by any number of A-Ns and then an A.</p>
<p>The problem is that telling GREP to look for A-N and just A-N requires the use of parentheses and parentheses are reserved special characters. To tell grep to treat the parentheses the way we’d like we need to prefix each one with a backslash can quickly become tiresome. Using egrep or extended grep, on the other hand, tells Linux to treat the parentheses exactly the way we want them in this case. This produces the exact same results with a simpler command.</p>
<p>If you need to search through a file or directories of files for a complicated string, you can use either fgrep or grep -f. Fgrep, which stands for fast grep, works by ignoring any meta meanings that a special character like a dollar sign or an asterisk might sometimes have and searches for their literal presence. Let’s say that you’ve got a file that contains a high-level password that you’d like to find since the password contains say a dollar sign which is normally a special character you can use fgrep on the text.txt file to get it. You could also use grep with the “-f “switch to read the password from a file I’ve created, which contains nothing but the password like this. This can be very useful if you often search for the same complicated string and don’t want the hassle of retyping it over and over again. By the way, from a security perspective it’s very bad practice to store passwords in unencrypted files.</p>
<p>Processing text while taking into account special characters can add a dimension of complexity to just about any streaming operation. You can always simply remove special characters either in a live stream or by saving to a new file.</p>
<p>Let’s use the substitution tool “sed” to illustrate. We’ve created an html file called text.html that predictably contains html-formatting tags. Suppose you’d like to use the files text but without the tags. You can pipe the text to sed and have sed strip all the formatting. Here we’re simply removing each pair of left and right arrows and the characters between them. The “&#x2F;g,” by the way, tells sed to apply the changes globally or on every instance it encounters, rather than only on the first one. We’ve already seen how to pipe text to grep which then filters for specific strings. In fact however, grep can also be used on its own in a significant range of functions. Let’s try to find the word “sdb1, “ the designation for one of my disk partitions in the dmesg log file. We’re used to running it after cat like this. We can do the exact same thing without cat this way.</p>
<p>If you’d like to find the string “sdb1” wherever it’s found in any of the log files in the &#x2F;var&#x2F;log directory or in sub-directories below it add the “-r” recursive switch. You can use grep with “-v” to display only those lines without a particular string. Looking at the dmesg file we can see that the number three does show up a whole lot of times. We can exclude all lines containing the number three this way.</p>
<p>Let’s do that again adding the “-n” switch to print line numbers along with our output. This can be really useful if you would now want to find or edit specific lines within the file itself.</p>
<p>Let’s review. Regex meta-characters include the dot, or period, brackets, the caret, dollar sign, backslash and asterisk. To apply Regex functionality to grep filters you’ll often need the backslash character. Egrep will produce the same effect without the need for escape characters. Fgrep will search for literal strings, while grep-f will read a search string from any file. You can strip special formatting characters from a file using sed. “Grep -r” will search all files within a direct retrieve for a string. “-v” will display all the lines that don’t contain a specified string. And “-n” will number the lines displayed.</p>
<h1 id="Perform-basic-file-editing-operations-using-vi"><a href="#Perform-basic-file-editing-operations-using-vi" class="headerlink" title="Perform basic file editing operations using vi"></a>Perform basic file editing operations using vi</h1><p>Since text files are the core of everything that happens in Linux, and since Linux administrators and developers spend so much of their time working with text, you can easily see how choosing a text editing tool is a big decision. This is something with which you’ll probably end up spending more time than with your closest family members, for better or for worse. Linux has a great range of editors freely available to suit every need. Of course, since you’ll need to produce clean plain text, you’re not likely to settle for a full-featured office suite like LibreOffice.</p>
<p>Once that’s off the table, you could always go with a GUI package like Gedit, which includes a great library of built-in formatting tools for bash or all major programming languages. However, since so much of Linux administration takes place in the terminal, most admins prefer a terminal-based text editor. As you might already have noticed, my favorite is nano because of its balance of standard navigation tools and quick keystroke shortcuts like CTRL+X to save and exit, and CTRL+K to delete an entire line.</p>
<p>But admins and developers with very deep experience will often look sadly at people like me who insist on using nano or Gedit, as though we’re part of some unfortunate lower level of humanity. These are VI or VIM users, and having tasted a bit of the power of their chosen text editors, I can certainly appreciate why they think this way. The LPIC exam does too, as they’ve made it an important part of their exam requirements. But first, a little bit of server history. Once upon a time, hardware was much simpler, and system memory was much less available. It wasn’t uncommon for the keyboards attached to servers to have pretty much nothing more than the alphabet and numbers. There were no arrow or page up and page down keys, and certainly no function keys. And even if there were, not a lot of operating systems would have known what to do with them. Since there was so little to work with, software interfaces had to be creative and resourceful. Thus, was VI born.</p>
<h3 id="Understanding-VI-modes-and-keystroke-commands"><a href="#Understanding-VI-modes-and-keystroke-commands" class="headerlink" title="Understanding VI modes and keystroke commands"></a>Understanding VI modes and keystroke commands</h3><p>It’s a text editor that never asks your fingers to leave the main keys. And don’t even think about using a mouse. There are, therefore, keystroke sequences for doing absolutely everything. By the way, these days, you’re much more likely to encounter VIM, which stands for VI Improved, which incorporates the functionality of the original VI, along with some generous nods to modern computing habits. In any case, this style of commands and operations that came to exist from necessity had the fortunate benefit of also being incredibly efficient and fast. Someone who’s invested the time and energy to familiarize themself with the workings of VI will almost certainly be able to outperform people on similar tasks using other tools.</p>
<p>But here is the problem, if VI operations require the use of regular alphanumeric keys, then how are you supposed to use those keys to actually enter regular text? To make this possible, VI works in multiple modes.</p>
<p>Normal or command mode, is the mode that by default you will see when you start up VIM. Normal mode doesn’t allow you to actually edit text, but it does let you quickly perform just about any other task.</p>
<p>From normal mode, hitting the uppercase I or insert key will take you to insert mode, where you’ll do most of your typing. You can add, change and delete text, and even navigate through the page using arrow keys. But you can’t launch commands. Command line mode, which is where you perform file management tasks and when necessary, exit VI, is accessed by typing a colon followed by your command.</p>
<p>Let’s try it out. From the command line we’ll open VI, using either vi, or vim on my Ubuntu system, and the name of a file. Since we are by default in command mode, we can’t actually edit the text. I’ll hit the insert key and enter insert mode and add a few words. Notice how I can move around the text using the arrow keys. If I hit the ESC key, I’ll move back to command mode. Even if I can’t edit the text directly in command mode, the position of the cursor is important, as we’ll soon see.</p>
<p>You can now move around using the keys between h, and l. H will move one position to the left, j will go down one line, k goes up a line, and l moves one position to the right. The o key will move your cursor back to the start of the line you’re on. Now, based on the current cursor position, here’s how you use the command line to edit. dw will delete the word to the right of the cursor. U will undo your last operation. D$ will delete everything from the cursor to the end of the line. Dd will delete the entire line.</p>
<p>P for paste, will take the text that was most recently deleted and paste it at the current cursor position. P will also paste text copied using yy, which copies the entire current line. &#x2F; will take the next text you write and search a document for it, while N will repeat the previous search. Uppercase ZZ will save the current file and exit VI. Using command line mode, as you’ll remember always prefaced by a colon, w and enter will save your file, w a space and a new name followed by enter will save the file with it’s new name. W! overwrites the current file. Exit, or wq will exit VI, but only if the file hasn’t been changed, and wq! will exit without saving the file.</p>
<p>Let’s review. There are three modes to VI. Command mode, the default, allows you to edit your text, but not directly. Insert mode, reached through the uppercase I or insert keys, allows you to navigate and edit text directly. Command line mode permits file management operations. Command line operations include :w to save a file, exit or wq to exit VI, and q closes VI without saving. In command mode, dw deletes the word to the right of the cursor, d$ deletes to the end of the line, and dd deletes the entire line. P inserts recently deleted text to the current position, while u undoes the last action. Yy copies the current line, and uppercase ZZ saves and edits. Finally, h moves one position to the left, l one position right, j moves down, and k moves up.</p>
<p>To be honest, you can review these commands all you like and that will get you through the exam. But to really begin to master VI or VIM probably requires at least a week of actually working with it on a real project. While I can’t say that I’ve made it to that level, I’m still a solid nano kind of guy, I strongly suspect that you’ll never regret the investment.</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/19/Linux-LPIC-101-Create-Your-First-Amazon-EC2-Instance-Linux-4/" rel="prev" title="Linux-LPIC-101-Create-Your-First-Amazon-EC2-Instance-Linux-4">
      <i class="fa fa-chevron-left"></i> Linux-LPIC-101-Create-Your-First-Amazon-EC2-Instance-Linux-4
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/19/Linux-LPIC-101-Linux-Command-Line-Fundamentals-6/" rel="next" title="Linux-LPIC-101-Linux-Command-Line-Fundamentals-6">
      Linux-LPIC-101-Linux-Command-Line-Fundamentals-6 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Course-introduction"><span class="nav-number">1.</span> <span class="nav-text">Course introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Working-on-the-command-line"><span class="nav-number">2.</span> <span class="nav-text">Working on the command line</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Understanding-Linux-shells"><span class="nav-number">2.0.1.</span> <span class="nav-text">Understanding Linux shells</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Working-with-Linux-environment-variables"><span class="nav-number">2.0.2.</span> <span class="nav-text">Working with Linux environment variables</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-man-the-Linux-help-documentation-resource"><span class="nav-number">2.0.3.</span> <span class="nav-text">Using man, the Linux help documentation resource</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Process-text-streams-using-filters"><span class="nav-number">3.</span> <span class="nav-text">Process text streams using filters</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Working-with-Linux-text-manipulation-tools"><span class="nav-number">3.0.1.</span> <span class="nav-text">Working with Linux text manipulation tools</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Introduction-to-sed-on-Linux"><span class="nav-number">3.0.2.</span> <span class="nav-text">Introduction to sed on Linux</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Perform-basic-file-management"><span class="nav-number">4.</span> <span class="nav-text">Perform basic file management</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Basic-Linux-file-and-directory-management"><span class="nav-number">4.0.1.</span> <span class="nav-text">Basic Linux file and directory management</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Archives-and-file-compression-using-tar"><span class="nav-number">4.0.2.</span> <span class="nav-text">Archives and file compression using tar</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Archives-and-file-compression-using-cpio"><span class="nav-number">4.0.3.</span> <span class="nav-text">Archives and file compression using cpio</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Use-streams-pipes-and-redirects"><span class="nav-number">5.</span> <span class="nav-text">Use streams, pipes and redirects</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Working-with-Linux-data-streaming"><span class="nav-number">5.0.1.</span> <span class="nav-text">Working with Linux data streaming</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Create-monitor-and-kill-processes"><span class="nav-number">6.</span> <span class="nav-text">Create, monitor and kill processes</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Killing-off-misbehaving-Linux-system-processes"><span class="nav-number">6.0.1.</span> <span class="nav-text">Killing off misbehaving Linux system processes</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-screen-for-multi-screen-terminal-sessions"><span class="nav-number">6.0.2.</span> <span class="nav-text">Using screen for multi-screen terminal sessions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Controlling-running-Linux-processes"><span class="nav-number">6.0.3.</span> <span class="nav-text">Controlling running Linux processes</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Modify-process-execution-priorities"><span class="nav-number">7.</span> <span class="nav-text">Modify process execution priorities</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-nice-to-manage-multiple-processes"><span class="nav-number">7.0.1.</span> <span class="nav-text">Using nice to manage multiple processes</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Search-text-files-using-regular-expressions"><span class="nav-number">8.</span> <span class="nav-text">Search text files using regular expressions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-run-sophisticated-text-searches-using-regex-and-other-text-streaming-tools"><span class="nav-number">8.0.1.</span> <span class="nav-text">How to run sophisticated text searches using regex and other text streaming tools</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Perform-basic-file-editing-operations-using-vi"><span class="nav-number">9.</span> <span class="nav-text">Perform basic file editing operations using vi</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Understanding-VI-modes-and-keystroke-commands"><span class="nav-number">9.0.1.</span> <span class="nav-text">Understanding VI modes and keystroke commands</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
