<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Course IntroHello and welcome to “Deploying Networking and Compute Resources on Google Cloud Platform”. My name is Thomas Mitchell and I’ll be taking you through this course.  I’m a Content Author at">
<meta property="og:type" content="article">
<meta property="og:title" content="GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8">
<meta property="og:url" content="https://example.com/2022/11/19/GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:description" content="Course IntroHello and welcome to “Deploying Networking and Compute Resources on Google Cloud Platform”. My name is Thomas Mitchell and I’ll be taking you through this course.  I’m a Content Author at">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-19T04:02:45.000Z">
<meta property="article:modified_time" content="2022-11-23T00:51:08.000Z">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8 | Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Hang's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:02:45" itemprop="dateCreated datePublished" datetime="2022-11-19T00:02:45-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-22 20:51:08" itemprop="dateModified" datetime="2022-11-22T20:51:08-04:00">2022-11-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GCP-Cloud-Engineer/" itemprop="url" rel="index"><span itemprop="name">GCP-Cloud-Engineer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/GCP-Cloud-Engineer-Deploying-Networking-and-Compute-Resources-on-Google-Cloud-Platform-8/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Course-Intro"><a href="#Course-Intro" class="headerlink" title="Course Intro"></a>Course Intro</h1><p>Hello and welcome to “Deploying Networking and Compute Resources on Google Cloud Platform”. My name is Thomas Mitchell and I’ll be taking you through this course. </p>
<p>I’m a Content Author at Cloud Academy and I have over 25 years of IT experience, several of those with cloud technologies. If you have any questions, feel free to connect with me on LinkedIn, or send an email to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>.</p>
<p>This course is intended for Google Cloud Engineers who deploy applications, monitor operations and manage enterprise solutions. It’s also intended for those interested in obtaining the Associate Cloud Engineer certification.</p>
<p>To get the most from this course, you should have a basic understanding of the Google Cloud Platform, its Compute Instance offerings, and its Network offerings.</p>
<p>We’ll kick off this course by diving into the deployment and implementation of networking resources such as VPCs and subnets. You’ll learn how to create a VPC and how to define subnets contained within the VPC. You’ll also learn how to create ingress and egress firewall rules for a VPC.</p>
<p>Later on, you’ll learn how to create a VPN connection between a Google VPC and an external network. You’ll also learn how to distribute network traffic to an application by using a load balancer.</p>
<p>As we work through the course, you’ll then learn how to deploy and implement Compute Engine resources via the Cloud Console and via gcloud. After deploying a compute instance, you’ll learn how to create and assign disks to an existing compute instance and how to assign an availability policy to a compute instance.</p>
<p>As we enter the home stretch of this course, you’ll learn how to create an autoscaled managed instance group, using an instance template, and how to generate and upload custom SSH keys for compute instances.</p>
<p>Rounding out the course, you’ll learn how to configure a VM for Cloud Operations, and how to install the Ops Agent. You’ll also learn how to assess compute quotas and how to request quota increases.</p>
<p>By the time you complete this course, you’ll have a full understanding of how to Deploy Networking and Compute Resources on Google Cloud Platform.</p>
<p>We’d love to get your feedback on this course, so please give it a rating when you’re finished. So, if you’re ready to learn how to Deploy Networking and Compute Resources on Google Cloud Platform, let’s get started.</p>
<h1 id="VPCs-and-Subnets"><a href="#VPCs-and-Subnets" class="headerlink" title="VPCs and Subnets"></a>VPCs and Subnets</h1><p>A VPC network is a virtual network that’s deployed in the Virtual Private Cloud, hence the term VPC Network. Just like any other physical network, a VPC network provides connectivity for VMs, Kubernetes clusters, and many other resources that need to communicate. </p>
<p>In this lesson, we’re going to talk a little bit about VPC networks, their properties, and the different types of VPC networks that are available to you. Once we’ve covered the basics of VPC networks, we’ll work through a demo so you can see how a VPC network is deployed. </p>
<p>Now, before we get into the two types of VPC networks that are available, what I want to do is briefly touch on subnets and the role that they play. Any VPC network that’s created will need to have at least one subnet defined before the network can be used. This is because VPC networks, themselves, do not have any IP address ranges associated with them. Instead, IP ranges are defined for the subnets which are defined within the network itself. </p>
<p>The type of VPC network that you deploy will determine how the initial subnet for the network is deployed. GCP offers two types of VPC networks, determined by their subnet creation mode. </p>
<p>Creating an auto mode network results in one subnet from each region to automatically be created within the network. The subnets that are automatically created use a set of predefined IP ranges from the 10.128.0.0&#x2F;9 CIDR block. </p>
<p>Now, while an auto mode VPC network automatically creates subnets, this does not preclude you from adding additional subnets manually, as needed. However, any manually added subnets that you create need to use IP ranges outside of 10.128.0.0&#x2F;9 range. </p>
<p>Alternatively, you can also create what’s called a custom mode network. When a custom mode network is created, it’s created with no subnets at all. In practice, you would typically deploy custom mode networks when you need more control over the subnets and IP ranges that are provisioned within them. </p>
<p>In the upcoming demonstration, I’m going to show you how to deploy a custom mode network. After <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploying the network</a>, I’ll show you how to create a single subnet within the network.</p>
<h1 id="DEMO-Creating-a-VPC-with-Subnets"><a href="#DEMO-Creating-a-VPC-with-Subnets" class="headerlink" title="DEMO: Creating a VPC with Subnets"></a>DEMO: Creating a VPC with Subnets</h1><p>So, what we’re going do here is create a custom mode <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">network</a>. To create our custom mode network, what I’m going to do here is browse to the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/vpcs-and-subnets/">VPC</a> networks page. </p>
<p>From here, all I need to do is click the CREATE VPC NETWORK link here, and this begins the process. I’m just going to provide a name here for my network, and then what I’ll do is I’ll tell GCP that I want to create a custom network by choosing Custom for the Subnet creation mode. </p>
<p>Now, what I need to do here in the New subnet section is specify my subnet configuration. So, what I’m going to do here is provide a name for the subnet, and then select a Region, and what I’ll do is, I’ll just set this Region to us-central. </p>
<p>I’m going to provide a primary IP address range for my subnet, and what I’m going to use here is 192.168.0.0&#x2F;16. Now, I don’t need a secondary IP address range for this exercise, so I’ll leave this alone. </p>
<p>Now, if I enable Private Google access for the subnet, any GCP, VM instances that I deploy, will only be able to use internal IP addresses only. They won’t be able to have external IP addresses. So, for this exercise, I’m going to leave Private Google access disabled. </p>
<p>I’m also going to leave the Flow logs disabled as well. </p>
<p>Now, I’ll go ahead and click Done here, and what I’ll do is I’ll leave the Dynamic routing mode set to Regional dynamic routing, which is the default setting. In this mode, routes to on prime resources that are learned by a given Cloud Router in the VPC network, only apply to the subnets in the same region as the Cloud Router. Setting a DNS server policy provides me with access to name resolution servers that are provided by GCP in a VPC network with inbound forwarding. </p>
<p>Now, this DNS server policy is an optional setting that I don’t need to configure for this exercise, so I’ll leave it set to No policy. At this point, I can click Create to deploy my custom VPC network. Now, once my VPC network is created, I can view it’s properties. We’ll go ahead and select it here, and from here I can see the details of my new custom network. </p>
<p>So, with that said, you now know how to deploy a custom mode VPC network on Google Cloud Platform.</p>
<h1 id="Ingress-and-Egress-Firewall-Rules-for-a-VPC"><a href="#Ingress-and-Egress-Firewall-Rules-for-a-VPC" class="headerlink" title="Ingress and Egress Firewall Rules for a VPC"></a>Ingress and Egress Firewall Rules for a VPC</h1><p>GCP firewall rules are used to allow or deny traffic to and from VM instances, based on your security needs. Once configured and enabled, GCP firewall rules are always enforced, which means deployed instances are protected, regardless of their OS, configuration, or even startup status. </p>
<p>It’s worth noting that every <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/vpcs-and-subnets/">VPC</a> <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">network</a> actually functions as a distributed firewall. That said, although firewall rules are defined at the network level, connections to instances are actually allowed and denied on a per-instance basis. As such, GCP firewall rules essentially exist between instances and networks, as well as between individual instances within the same network. </p>
<p>Whenever you create GCP firewall rules, you need to specify a VPC network, along with settings that define what the rule is supposed to do. The settings that you configure will allow you to target specific types of traffic, based on protocols, sources, destinations, and ports. </p>
<p>There are three ways to create and modify GCP firewall rules. You can perform these functions through the Google Cloud Platform Console, the gcloud command line tool, and via REST API. </p>
<p>Anytime you create or modify a firewall rule, you can also specify the distinct instances to which the rule should apply. You can do this by using the target component of the rule that you’re defining. </p>
<p>In the next lesson, I’m going to show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/ingress-and-egress-firewall-rules-for-a-vpc/">create an ingress firewall</a> for a VPC network.</p>
<h1 id="DEMO-Creating-an-Ingress-Firewall-Rule-for-a-VPC"><a href="#DEMO-Creating-an-Ingress-Firewall-Rule-for-a-VPC" class="headerlink" title="DEMO: Creating an Ingress Firewall Rule for a VPC"></a>DEMO: Creating an Ingress Firewall Rule for a VPC</h1><p>Welcome back. In this demonstration, we’re going to walk through the process of creating an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/ingress-and-egress-firewall-rules-for-a-vpc/">Ingress Firewall Rule for the VPC network</a> that we created earlier. </p>
<p>So, let’s get started by going to the Firewall rules page in our Google Cloud Platform console. Now, to get there, what I need to do is, browse to VPC network, under the Networking section, and then from here, click on Firewall rules. </p>
<p>Now, from here, what I need to do is, click on Create Firewall Rule, and this begins the process. Now, let’s give our firewall rule a Name, and then specify the network where the firewall rule is going to be implemented. I’ll call my firewall rule, rdp-in, and what I’m going to do is apply it to my testnetwork. </p>
<p>What we need to do here is specify the priority of the rule that we’re deploying. The lower the number, the higher the priority, the higher the number, the lower the priority. For this exercise, I’m going to leave it at the default setting of 1000. </p>
<p>Now for this rule, I’m going to choose Ingress as the direction of traffic, because I want to allow rdp from my workstation IP. </p>
<p>Obviously, we want to choose Allow as the action on match, and then we need to specify the Targets of our rule. </p>
<p>Now what I’m going to do here, is select All instances in the network. Now what this does, is ensure that this rule applies to all instances that are eventually connected to this network. We’ll <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploy</a> a VM later to this network, so I want this Ingress rule to apply to it when it’s deployed. Now, with that said, what I could do here, if I wanted to, is instead, set the rule to apply to specific instances by target tag. This would allow me to specify which instances the rule would apply to. </p>
<p>For this exercise, we’re applying the rule to all instances, so there’s no need to do this. What we need to do next here, is specify the Source filter. In the Source filter dropdown, I can specify an IP address range, source tags, or even in some cases, a service account. I’m going to leave this set to IP ranges, since I’m going to specifically allow traffic from the IP of my workstation that I’m working from. For this exercise, I’m going to browse to whatsmyip.org to check the public IP of my workstation. </p>
<p>What we’ll do here is, get my public IP address, and bounce back over to our portal here. We’ll put my public IP in the Source IP ranges field. Now, when I do this, I need to use the CIDR notation. So what I had to do is append the &#x2F;32 to my IP address. At this point, I need to define the protocols and ports to which my new rule is going to apply. In this case, I’m going to specify a destination port of TCP 3389, so I can allow rdp to any VM instances I deploy later. So we’ll select tcp, and then we’ll specify 3389. Now with that set, I can leave the rest of the options at their defaults, and then click Create to deploy my Ingress rule. </p>
<p>So now that I have my Ingress rule deployed, when I spin up my VM later on and connect it to my subnet, the VM will be protected by my new rule.</p>
<h1 id="Creating-a-VPN-Connection"><a href="#Creating-a-VPN-Connection" class="headerlink" title="Creating a VPN Connection"></a>Creating a VPN Connection</h1><p>In Google Cloud Platform, Cloud VPN supports several types of networks. These <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">supported networks</a> include <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/vpcs-and-subnets/">VPC</a> custom networks, auto-mode networks, and legacy networks. </p>
<p>When creating a VPN in GCP, you should be sure to adhere to Google’s best practices. These best practices include using VPC networks instead of legacy networks and using custom mode VPC networks instead of auto-mode networks. </p>
<p>Because legacy networks do not support subnets, when you provision a legacy network, the entire network will use a single range of IP addresses. Legacy networks also cannot be converted into VPC networks if needed. </p>
<p>When it comes to custom mode VPC networks, these networks provide you with full control over the range of IP addresses that are used by their subnets. It’s also important to note that when you connect two VPC networks using Cloud VPN, at least one of the networks needs to be a custom mode network. This is because auto-mode networks use the same range of internal IP addresses for their subnets. This would cause an overlap problem if you didn’t use at least one custom mode network when creating the VPN. </p>
<p>When configuring a VPN, you’ll have a few different routing options. While classic VPN supports dynamic and static routing options from VPN tunnels, HA VPN requires dynamic routing. </p>
<p>Dynamic routing, by the way, uses the Border Gateway routing Protocol, otherwise known as BGP, and it uses a Cloud Router to automatically manage the exchange of routes using the BGP protocol. </p>
<p>The dynamic routing mode of a VPC network controls the behavior of all its Cloud Routers and it determines whether or not the routes learned from peer networks are only applied to GCP resources in the same region as the VPN tunnel or if they’re applied in all regions. </p>
<p>Static routing comes in two flavors: policy-based and route-based. If you can’t use BGP or dynamic routing or HA VPN, you should consider the static routing option. When using policy-based routing, the local IP ranges and remote IP ranges are both defined as part of the tunnel creation process. However, when you create a route-based VPN, you only need to specify the list of remote IP ranges. </p>
<p>In the next lesson, I’ll show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-how-to-create-a-vpn/">create a VPN</a> between a Google VPC and an external network, using Cloud VPN.</p>
<h1 id="DEMO-How-to-Create-a-VPN"><a href="#DEMO-How-to-Create-a-VPN" class="headerlink" title="DEMO: How to Create a VPN"></a>DEMO: How to Create a VPN</h1><p>Welcome back. In this lesson, we’re going to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/creating-a-vpn-connection/">create a classic VPN gateway</a> and a tunnel using static routing. For this exercise, we’ll <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploy</a> a policy-based VPN. </p>
<p>So to configure our VPN, what I need to do is browse to the VPN page from my Google Cloud Platform console. I can actually find this page under Hybrid Connectivity. </p>
<p>Once I’m here, I can begin the deployment process by clicking create. </p>
<p>Now, from this Create a VPN page, I can create either a HA VPN or a classic VPN. For this particular exercise, I’m going to create a classic VPN. </p>
<p>From here, I need to configure my VPN gateway. A VPN gateway serves as an endpoint for a VPN tunnel. I need to give it a name, a description, and I need to specify which GCP network to deploy the gateway and tunnel to. And since cloud VPN gateways and tunnels are regional objects, I also need to tell GCP which region the gateway needs to be deployed to. </p>
<p>I should also point out that for best performance the gateway and tunnel should be located in the same region as the GCP resources that will be accessed over the tunnel. </p>
<p>What I also need to do here is create a new external IP address for my gateway. I could also select an existing external IP address if I already had one created. </p>
<p>So let’s get started. What I’m going to do here is call my gateway, myvpngateway. </p>
<p>I’m going to leave the description blank for this exercise. And what I’m going to do is deploy my gateway to the default region here. I’m going to deploy my gateway to my test network, so I need to select it from the Network dropdown. </p>
<p>Since I don’t have an existing external IP address to associate with my gateway, let’s go through the process here to create one. </p>
<p>With this information supplied, I can now create my tunnel. </p>
<p>To create the tunnel, I need to provide more information. I need to give my tunnel a name and a description. I also need to tell my tunnel what the public IP is for the remote side of my VPN. For IKE version, I need to choose a version that’s supported by both the GCP side of the tunnel and the remote side. IKEv2 is the preferred option as long as the remote side supports it. </p>
<p>The pre-shared key is a text value that’s used for authentication. Whatever I provide here for the pre-shared key needs to also be provided on the other side of the VPN connection. </p>
<p>So what I’ll do here is I’ll call my tunnel, myvpntunnel. As I did with the gateway, I’ll leave the description blank. The remote peer IP address is 40.86.78.94. This was taken from the VPN device on the foreign side of my VPN tunnel. </p>
<p>Since my Azure VPN, which is what I’m using on the foreign side, supports IKEv2, I’ll choose IKEv2 here. And then I need to provide a pre-shared key. What I’d need to do with this pre-shared key is provide it to the admin on the foreign side of the VPN tunnel, so the admin on the foreign side could configure the VPN on that side as well. </p>
<p>Without matching keys, the VPN wouldn’t come up. Now, since I’m creating a policy-based tunnel, I need to select policy-based here. This is my routing option. If we hover over Routing options here, we can see that BGP provides the easiest to configure as well as the most resilient IPsec VPN configuration. However, this won’t work if the foreign device doesn’t support it. We also have route-based options and policy-based. For this demonstration, we’re using policy-based. </p>
<p>The remote network ranges that I add here are those networks on the remote side of the VPN that I want to access over the VPN. For local IP ranges, I need to select the local subnetworks that I want to grant access to over the VPN. I can either specify local IP ranges or select local subnets. So I’ll go ahead and select my default subnet here for my test network. Now, after click done here and with my gateway and tunnel information complete, I just have to create to deploy the VPN. Now, it’s important to note here that the process I just followed on the GCP side of the VPN also needs to be followed in some fashion on the remote side as well. That’s because both sides of the VPN will have different configuration processes. For example, if the remote side is an Azure VPN gateway, you’d have to follow the Azure VPN setup process to configure that side of the VPN. </p>
<p>If the remote side is a Cisco ASA, you’d have to follow the Cisco documentation to configure the Cisco ASA device. Since this is a GCP course, I’m not going to get into the configuration of the remote side of the VPN. I just wanted to make sure that you knew how to configure the GCP side, since that’s what’s covered on the exam.</p>
<h1 id="Launching-a-Compute-Instance-Using-Cloud-Console"><a href="#Launching-a-Compute-Instance-Using-Cloud-Console" class="headerlink" title="Launching a Compute Instance Using Cloud Console"></a>Launching a Compute Instance Using Cloud Console</h1><p>When you create a VM instance from a boot disk image, you can use either a regular image or a Shielded VM image. </p>
<p>Shielded VM images provide advanced security features like UEFI-compliant firmware, Secure Boot, and vTPM-protected Measured Boot. </p>
<p>There are several ways to create a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">compute instance</a> from an image. You can create an instance from a public image, a custom image, or even from an image that’s been shared with you. You can also create an instance from a snapshot or from a container image. Let’s talk a little bit about each option. </p>
<p>As I mentioned, instances can be provisioned from public images. These public images are provided by Google, different open-source communities, and even some third-party vendors. By default, all GCP projects have access to these public images. As such, they can be used to create compute instances. </p>
<p>While public images are available to all projects, a custom image belongs only to a specific project. To use a custom image to create an instance, you first must create the custom image. </p>
<p>In cases where another user has shared an image with you, you can use the shared image to create a new compute instance. Another way to provision a compute instance is to use a snapshot. For example, if you backed up a boot persistent disk with a snapshot, you could then use the snapshot to create a new compute instance. </p>
<p>Yet another way to provision a compute instance is to use a container image. To deploy and launch a container on a Compute Engine instance, you’d need to specify a container image name along with any optional configuration parameters. The Compute Engine then creates the compute instance using the latest version of the Container-Optimized OS public image, which has Docker installed. The container is then launched by the Compute Engine when the VM starts. </p>
<p>In the next lesson, we’re going to walk through a demonstration that shows you <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-how-to-launch-a-compute-instance-in-cloud-console/">how to launch a compute instance in Cloud Console</a>.</p>
<h1 id="DEMO-How-to-Launch-a-Compute-Instance-in-Cloud-Console"><a href="#DEMO-How-to-Launch-a-Compute-Instance-in-Cloud-Console" class="headerlink" title="DEMO: How to Launch a Compute Instance in Cloud Console"></a>DEMO: How to Launch a Compute Instance in Cloud Console</h1><p>Welcome back. In this lesson, what we’re going to do is <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/launching-a-compute-instance-using-cloud-console/">launch a compute engine instance</a> using a custom network configuration. We’re going to connect this compute engine instance to the virtual network that we deployed earlier. To begin the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deployment</a>, what we need to do is browse to the VM instances page under compute engine over here on the left. </p>
<p>Now, from here, what we want to do is click the Create button. I’ll call my instance vm1. And you’ll notice, if I try to use capital letters here, it’s going to tell me that the name must be lowercase, numbers, and hyphens. Now over here on the right side, I can see the monthly estimate for my VM instance as configured, and then in these two dropdowns, I can specify the region, which is the geographical location where the VM is going to run, and the zone, which is an isolated location within that region. Now, what the zone does, as you can see here, is determine what computing resources are available and where data is stored and used. Now, in the machine type box, here, I can customize my VM. I can select the CPUs and memory that my VM should use. </p>
<p>What I’m going to do here is select two CPUs and 7.5 gig of memory. What this is, is the N1-standard-2 size. And when I make that change, I can see my monthly estimate changes as well. Now, if I hover over the icon next to container, I can see that I can deploy a container to this VM instance by using a container-optimized OS image. I’m not going to do that for this lesson here. What I am going to do, is under boot disk, here, I’m going to change this boot disk. We can see right now that the current boot disk is a 10 gig standard persistent disk running the Debian&#x2F;GNU Linux 9 image. What I’m going to do here, is change this. And for this exercise, we’re going to deploy a Windows Server 2016 Datacenter image. So, we’ll go ahead and scroll down here, and we can see Windows Server 2016 Datacenter. So, we’ll go ahead and select it here. And then down here, we can select the boot disk type and the size. If we select the dropdown here, we can select a standard persistent disk or an SSD. I’ll leave this standard persistent here and 50 gig will suffice for this exercise. So, we’ll click Select. </p>
<p>Now, as we scroll down the page here, we have an option here for identity and API access. If we hover over the icon next to identity and API, we can see that any applications that run on the VM, they use the service account to call Google Cloud APIs. Now, from here, we can select the service account that we want to use, along with the level of API access that we want to allow. For this demonstration, we’re going to leave this at its default setting. We don’t need to do anything special here. In the firewall section, what we can do is add tags and rules to allow specific network traffic to and from the internet. What I’m going to do is allow HTTP traffic in case I want to do some kind of demonstration later on, using this VM. Now, to customize the configuration of the VM, regarding the network we’re going to connect to, any additional NICs, any additional disks, et cetera, what we can do here is select the management, security, disks, network, and sole tenancy dropdown here. </p>
<p>Now, from here, under Management, we can provide a description for our VM, any labels for our VM, and if we hover over the icon for labels, we can see that you use them to organize projects and to kind of group resources together. We’re not going to do any labeling or description here and then we can also specify deletion protection. What deletion protection does is ensure that a VM can’t be deleted. You can see here if we check the box, nothing really changes. This is just something that happens on the underside or under the covers, so to speak. So, we’ll uncheck this box here. We can also specify metadata for our VM and then under availability policy, we can specify premptability, on-host maintenance, and automatic restart. Now, that being said, a pre-emptible VM, although it’s going to be cheaper, will only last for 24 hours. And, essentially, it can be terminated if system demands need that. This option might be good for development environments or quick testing. And then of course, the on-host maintenance and automatic restart options relate to infrastructure maintenance that’s performed within the Google platform. I’m going to leave these options at their defaults. But, if we select the dropdown, you can see we can either migrate VM instances or terminate them in the event that they need to go down for any kind of infrastructure maintenance. The automatic restart is either on or off. Essentially, automatic restart tells the compute engine to automatically restart any VM instances if they’re terminated for non-user initiated reasons. Typically, this means maintenance events or hardware failures. We’ll leave these options at their defaults and then switch over to security, here. </p>
<p>We can see, here, we have options for shielded VM. Now, you can see here that they’re turned off here. They’re not even enabled. Now, if we hover over shielded VM here, we can see that these features include trusted UEFI firmware, and also options for secure boot, TPM and integrity monitoring. We can also specify SSH keys, which we’re not going to do here. We’ll do this at a later time in another lesson. And then, under disks, we can specify deletion rules for the boot disk. Essentially, we can tell Google Cloud Platform to delete the boot disk when the instance is deleted. This is on by default, which makes sense. </p>
<p>Typically, you don’t want the boot disk to sit around if you’ve killed off the instance. And then we can also specify encryption options. We can allow Google to manage our keys. We can select customer-managed keys, or we can select customer-supplied keys. We can also configure additional disks here. If we have an existing disk we want to attach, we can attach it here, or we can add a new disk. So, what I’ll do here is add a new disk here, and I’ll just leave the naming set to its default disk1. And then, under the type, here, we have a couple different options. We can use a local SSD scratch disk, a persistent SSD disk, or a standard persistent disk. </p>
<p>If we hover over type, here, we can see that what this tells us is that storage space is obviously less expensive for a standard persistent disk. SSD persistent disks are better for random IOPs or for streaming throughput, with lower latencies. What we’ll do is, we’ll leave this set to standard persistent disk, and then, obviously, for source type, we can use either an image or we can use a blank disk. We’re going to use a blank disk here, and for mode, we’ll leave the option at read&#x2F;write. We’re not going to make a read-only disk. Now, the deletion rule, here, is a little different than the boot disk. By default, the deletion rule, here, says to keep the disk when you delete the instance. What I want to do here is delete my disk if we delete the instance from my lab environment. </p>
<p>Now a good reason to leave this default of keep disk is that for example, if you have a file server you’ve deployed, what you want to do is make sure than when you delete the instance, that you don’t delete any data that may be critical. So, if you have a separate disk that you’ve provisioned to store shares and whatnot, if you delete the instance, you may want to keep that data. So, if you leave this when deleting instance deletion rule set to keep disk, you don’t have to worry about losing that data if you delete the instance as part of a migration or whatever kind of maintenance you’re going to do. Of course, here, for size, we can specify the size of the disk. </p>
<p>I’m going to change this to 10 gigabytes. And when I do that, it tells me that this may result in reduced performance because I’ve entered a volume of less than 200 gig. This is a lab environment, and a demonstration, so I’m not really worried about performance here. And then as you can see here, we also have the encryption options that we were offered for our boot disk. We’ll leave this at the default Google Managed Key. </p>
<p>And then what we can do is click Done to provision the disk here. Now, under networking, we can assign network tags, or we can set a custom host name for this instance. We’ll leave the default here, but more importantly, this is where we can either add new network interfaces or edit the existing ones. So, for example, the default network interface is called default-default with an address of 10.128.0.0. </p>
<p>What I’m going to do is connect this to my test network, which is a 192 network. So, I select the dropdown here, and then select the test network. And then we can see it’s automatically assigned to the default <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/vpcs-and-subnets/">subnet</a> of that network, and then from here, I have an option to specify a primary internal IP address. An ephemeral IP address won’t change when you restart the instance. However, deleting and recreating an instance will change its internal IP. </p>
<p>Now, if we select the dropdown, here, we have a couple different options. We have an ephemeral automatic, an ephemeral custom, or we can reserve static internal addresses. If we hover over the icon, here, we can see that if we select the ephemeral automatic, what Google is going to do is assign an address from the subnetwork range, or, if we select ephemeral custom, we can manually enter an address. Now, if we select the third option, which is a static internal IP address, what this will do is allow our instance to keep its IP even when it’s deleted and recreated. So, we’ll go ahead and we’ll reserve a static internal IP address. And then, what we have to do, when we do this, is give the IP address a name. </p>
<p>So, what I’m going to do is call this privateIPVM1. So, that tells me that it’s a private IP for my VM1 virtual machine. We can see it’s already associated with the default subnet and then we can either assign it automatically or let me choose. So, let’s let me choose, here, and what I’ll do is, I’ll give it an address of 192.168.1.25. That falls within the range of my subnet. So, we’ll go ahead, and we’ll reserve that IP. </p>
<p>Now, for the external IP, what we can do is create an external IP address that’s associated with my instance. What we can do is either use an ephemeral address, or we can select none. We can also select an unused static address. Now, if we select none, we’re not going to have external internet access. So, what I can do here, is I’ll just choose ephemeral. </p>
<p>Now, the network service tier gives us a couple different options. We can choose premium or standard. What this tier does is allow you to optimize network quality and performance. I don’t need premium performance here for my lab environment, so I’ll select standard. We don’t need to do any IP forwarding, nor do we need to create a public DNS pointer record, so we’ll just click Done, here. </p>
<p>If I wanted to create a new network interface, I could click add, here, and create a second NIC for my VM. I don’t need that for this lab environment, so I’ll cancel here. Now, if we select sole tenancy, we can see, here, we can specify tenancy affinity labels. We don’t need to do that here. So, what we can do now, with our VM configured, we can look at the monthly estimate here, and suddenly the cost of my VM has gotten a little more expensive than what it was when we started. But, to provision our VM, we now scroll down and click create. What this is going to do is create a VM called VM1 on my test network, with the options that I’ve chosen throughout this configuration process. </p>
<p>So, with that said, you can see that lots of configuration can be done right from within the VM deployment wizard. You can pretty much deploy your VM with any combination of configuration options that you need.</p>
<h1 id="DEMO-Launching-a-Compute-Instance-Using-Cloud-SDK"><a href="#DEMO-Launching-a-Compute-Instance-Using-Cloud-SDK" class="headerlink" title="DEMO: Launching a Compute Instance Using Cloud SDK"></a>DEMO: Launching a Compute Instance Using Cloud SDK</h1><p>While it’s very easy to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/launching-a-compute-instance-using-cloud-console/">launch a compute instance using the Cloud Console</a>, it’s also quite easy to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">launch a compute instance</a> using the Cloud SDK or G Cloud. In this demonstration, I’m going to show you how to launch a compute instance in GCP using the Cloud SDK. </p>
<p>What we’re going to do here is launch a basic VM with a default configuration. In doing so, you’ll get to see which switches and commands are absolutely necessary to deploying a compute instance using G Cloud. </p>
<p>As you can see on your screen here, I’m logged into my Google platform. To bring up the Cloud SDK, I simply click the Activate Cloud Shell icon along here at the top right corner. What I’ll do here is expand this. </p>
<p>From here, in order to launch a default compute instance, I’m going to use the G Cloud Compute Instances Create command. </p>
<p>By running the G Cloud Compute Instances Create command and specifying “my new VM 3,” we’re going to deploy an instance called My New VM 3. By specifying the zone switch, we’re telling GCP to deploy the instance in the US Central 1-A Zone. </p>
<p>Once I hit Enter, the deployment begins. Since I haven’t specified any network information, disc information, or OS information, GCP is going to provision a VM with default settings. In this case, my VM is going to be created as an M1 Standard-1 Machine type with a single nick. The image for my VM is going to be debian by default. If I switch over to my portal here and take a look, I can see My New VM 3 being deployed. Now, if I wanted to deploy an instance with a bit more customization, I could run the same command, but with additional switches to find. However, before doing that, I need to run the G Cloud Compute Images List command to see what public images are available. </p>
<p>As you can see on your screen, we have quite a few images available to us here. I can also see the different projects and families for each image as well. With this information, I can specify the Image Switch and the Image Project Switch with the G Cloud Computer Instances Create command to specify which OS I want my VM to run. What I’ll do here: I’ll open a separate window to make things a little easier to see. Now, as you can see here, the command that I’m going to run creates a new VM called My New VM 4 and uses the Windows Server 2016 DC image under the Image Project Windows Cloud. What we’re going to do is deploy the VM into the US Central 1-A Zone. </p>
<p>So we’ll go ahead and hit Enter here. And if we go up into our Instances pane here and refresh, we can see My New VM 4 shows up, and starts to deploy. For a complete list of all switches that you can use when deploying a compute instance with G Cloud, visit the URL that you see on your screen. </p>
<p>So, while we’re going to call it a wrap for this demo, I encourage you to experiment with many different switches in your own lab environment. You never know which switch may make an appearance on an exam.</p>
<h1 id="Assign-Disks-to-a-Compute-Instance"><a href="#Assign-Disks-to-a-Compute-Instance" class="headerlink" title="Assign Disks to a Compute Instance"></a>Assign Disks to a Compute Instance</h1><p>When <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">adding</a> storage to a compute instance, you have a choice of a few different disk types. You can add zonal persistent disks, regional persistent disks or you can add local SSDs. </p>
<p>Zonal persistent disks are available as either standard hard disk drives or solid state drives. The compute engine actually manages the hardware underneath the zonal persistent disks so they can be added and resized without the need to deal with striping or redundancy. I should also note that unless you’re creating a new zonal persistent disk from an image, the disk will start with no data or file system. That being said, you’ll have to format any new disk after you attach it to an instance. </p>
<p>Regional persistent disks are like zonal persistent disks but different in a few ways. For example, regional persistent disks cannot be used as boot disks. In addition, regional persistent disks support force attachment to another VM instance in the event of a zonal failure. It’s also important to note that you can create a regional persistent disk from snapshots but not from images. Local SSD disks, unlike persistent disks, are physically attached to the server that hosts the virtual machine instance. This configuration offers superior performance to persistent disks, higher IOPS than persistent disks, and very low latency when compared to persistent disks. </p>
<p>Earlier on, you learned how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-how-to-launch-a-compute-instance-in-cloud-console/">deploy a compute instance</a>. During the demonstration, I showed you how to add a second disk to the VM. The process for adding a disk to an insisting VM is essentially the same as it is when provisioning a new instance. So I’m not going to drag you through another demo just to show you how to add a disk to an existing instance. Just refer to the VM deployment demo to see how to add a disk to a VM instance.</p>
<h1 id="Assign-an-Availability-Policy-to-a-Compute-Instance"><a href="#Assign-an-Availability-Policy-to-a-Compute-Instance" class="headerlink" title="Assign an Availability Policy to a Compute Instance"></a>Assign an Availability Policy to a Compute Instance</h1><p>Just like any other cloud platform, Google Compute Engine performs regular maintenance on its underlying infrastructure. To ensure that your GCP-based solutions remain up during these maintenance events, you can <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">configure</a> instance availability options that control the behavior of VM instances when these types of maintenance events occur. </p>
<p>Certain maintenance events that occur will sometimes require Google to move a VM off the host that’s undergoing maintenance. When this is necessary, Compute Engine will automatically handle the scheduling behavior of these instances. If an instance’s availability policy is configured to use live migration, Compute Engine will live migrate the VM instance during maintenance in order to prevent any applications that are running on that instance from experiencing a disruption during the maintenance event. Now that said, you can also opt to terminate your instances during these types of maintenance events instead of live migrating them. If you opt to do this, any apps that are running on those instances will obviously experience an outage. </p>
<p>The availability policy assigned to a compute instance will determine how the instance behaves when a maintenance event requires Google to move the instance to another underlying host. To configure an instance’s availability policy, you need to configure two settings. You need to set the instance’s maintenance behavior and you need to configure the instance’s restart behavior. An instance’s maintenance behavior controls whether or not the instance is live migrated or terminated whenever there’s a maintenance event. </p>
<p>The restart behavior controls whether or not the instance automatically restarts if it crashes or gets terminated. By default, maintenance behavior is set to live migrate. However, if you prefer to terminate instances during maintenance events, you can change the behavior to terminate the instance during maintenance events instead. If you choose to terminate an instance during maintenance, you can either opt to leave the instance terminated or you can set it to restart automatically after termination. If you choose to do this, what Google Compute Engine will do is tell the instance to shut down. It will then wait a short period of time to ensure that the instance shuts down cleanly. Google Compute Engine will then terminate the instance and then restart it on hardware that’s not part of the maintenance event. </p>
<p>In the next lesson, I’ll show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-working-with-availability-policies/">set the availability policy of an existing VM instance</a>.</p>
<h1 id="DEMO-Working-with-Availability-Policies"><a href="#DEMO-Working-with-Availability-Policies" class="headerlink" title="DEMO: Working with Availability Policies"></a>DEMO: Working with Availability Policies</h1><p>In this demonstration, I’m going to show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/assign-an-availability-policy-to-a-compute-instance/">change the availability policy</a> for an existing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">compute instance</a>. Although this can be done via the console or G-Cloud or via A-P-I, I’m going to do it via the console in this demonstration. So to change the availability policy for my existing instance, I need to browse to the V-M instances page in the console. </p>
<p>From here I just need to click on the instance that I want to edit, and then from the instance details page that I am taken to, I need to click the edit button at the top of the page. Scrolling down, under availability policies, I can update the policy for the instance as needed. For this example, I’ll set my policy to terminate the V-M on host maintenance, but I’ll leave the automatic restart option set to on. To save my new availability policy settings, I just have to click save. </p>
<p>Now with these settings, what will happen is, my instance will terminate and restart on new hardware automatically whenever a maintenance event occurs on the underlying hardware.</p>
<h1 id="Autoscaled-Managed-Instance-Groups"><a href="#Autoscaled-Managed-Instance-Groups" class="headerlink" title="Autoscaled Managed Instance Groups"></a>Autoscaled Managed Instance Groups</h1><p>Whenever you’re <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploying an application</a> that may or may not experience usage spikes, it’s a good idea to leverage a managed instance group. What a managed instance group does is allow you to operate an application across multiple identical VMs. To achieve robust scalability and availability, you can leverage managed instance group features that include things like autoscaling, autohealing, regional deployment, and even auto-updating. When you take advantage of an autoscaled managed instance group, you have the ability to automatically add or delete instances as the load on the application increases or decreases. </p>
<p>Hosting an application on an autoscaled managed instance group allows that application to gracefully handle traffic increases. It also helps reduce costs because the number of instances is reduced when the load is no longer there. In the next lesson, we’ll walk through the process of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-creating-an-autoscaled-managed-instance-group-using-an-instance-template/">creating an autoscaled managed instance group</a> from an instance template.</p>
<h1 id="DEMO-Creating-an-Autoscaled-Managed-Instance-Group-Using-an-Instance-Template"><a href="#DEMO-Creating-an-Autoscaled-Managed-Instance-Group-Using-an-Instance-Template" class="headerlink" title="DEMO: Creating an Autoscaled Managed Instance Group Using an Instance Template"></a>DEMO: Creating an Autoscaled Managed Instance Group Using an Instance Template</h1><p>In this demonstration, I’m going to show you how to create an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/autoscaled-managed-instance-groups/">autoscaled managed instance group</a> from an instance template. However, before I create the autoscaled managed instance group, I need to first create an instance template. </p>
<p>To create an instance template, what I need to do is browse my GCP Console and then go to the Instance Templates page. This is found under the Compute Engine page. From here, I simply click Create Instance Template. For this exercise, I’m going accept the default settings. My machine type will be n1-standard-1, my image will be a latest Debian image, actually, it’ll be the latest Debian image. My boot disk is going be named after my instance name. </p>
<p>Because this is a default image, the template is going to use the default VPC <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">network</a> and an ephemeral external IP address will be assigned. With my template configuration set, what I can do is scroll down and click Create at the bottom to create the template that I’m going to use for my autoscaled managed instance group. </p>
<p>Now, with my instance template created, I can now create my autoscaled managed instance group. To do this, what I need to do is browse to the Instance Groups page in the GCP Console, and then form here I can click create an instance group. I’ll call my managed instance group here mymig for managed instance group and then I need to tell GCP which zone to locate the group in. So I’m going to select the default here which is us-central1 and us-central1a. </p>
<p>Now we can see here on the left-hand side I’m actually creating a managed instance group versus an unmanaged instance group. Now, under the Instance Template dropdown, I can select my instance-template-1 that I just created earlier. Since we’re creating an autoscaled instance group, we’re going to leave autoscaling turned on. And under Autoscaling Policy, we’ll base our autoscaling on CPU usage and then what we’ll do is leave the defaults here for the target CPU usage. If we hover over the icon here, what this is going to do is tell me that autoscaling will add or remove instances in the group to maintain this particular level of CPU usage on each instance. </p>
<p>Under minimum and maximum number of instances, this is, as it states, the minimum number of instances in my managed instance group and the maximum number of instances in my group. Now, if I hover over the icon here for maximum, we’ll see that this is indeed the largest number of VM instances that’s allowed, even if the target is exceeded. On the flip side, if we hover over minimum number of instances, we can see that this number here is the least number of VM instances that the group will contain even if the target is not met. So we’re always going to have one instance and we’re never going to have more than 10 instances. </p>
<p>Now, if we hover over the cool down period here, we can see that what this is, this is the number of seconds to wait before collecting information from a new instance. Now, essentially what this should be is at least the amount of time it takes to initialize the new instance when it spins up. We’ll leave this at the default here. We’re not going to do any auto healing here. We’ll leave this turned off by default and now to create my new autoscaled managed instance, I can simply click Create. </p>
<p>After a few minutes, I’ll see my new autoscaled managed instance group up and running in my coil here. And you can see we get the green check box telling me that my instance group is ready to go. So let’s call it a wrap here and I’ll see you over in the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-load-balancing-http-traffic-with-a-load-balancer/">next lesson</a>.</p>
<h1 id="DEMO-Load-Balancing-HTTP-Traffic-with-a-Load-Balancer"><a href="#DEMO-Load-Balancing-HTTP-Traffic-with-a-Load-Balancer" class="headerlink" title="DEMO: Load Balancing HTTP Traffic with a Load Balancer"></a>DEMO: Load Balancing HTTP Traffic with a Load Balancer</h1><p>Welcome back. Another skill that Google tests for on their exams is the ability to effectively load balance applications, using various types of load balancers available on GCP. What we’re going to do here is configure some basic load balancing for IIS across two different VM instances. </p>
<p>In this demonstration, we’ll configure TCP load balancing to publicly load balance port 80 across two IIS webservers, called WEB1 and WEB2. Now, what I’ve done ahead of time to prepare for this demo is spin up the two IIS servers. Each IIS instance displays the name of the web server when you browse to the instance. I’ve also ensured that the existing firewall in GCP allows port 80 to reach my VMs. </p>
<p>To get started with our load balancer configuration, let’s browse to my instances. If I browse to the IP for each, I can see that Web1 displays WEB1 on the IIS page, and I can see Web2 displays WEB2 on the page. This tells me that IIS is working as it should on each specific instance. </p>
<p>So, now that we know IIS is good on each instance, let’s get started on the load balancer <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deployment</a>. To begin the deployment process, what I need to do is browse to the Load Balancing page, now this located here under Network Services. From here, I can begin the setup by clicking create load balancer. Now, when we do that, we’re presented with three options. We can deploy a layer-7 HTTPS load balancer, a layer-4 TCP load balancer, or a layer-4 UDP load balancer. </p>
<p>For this exercise, we’re going to deploy the one in the middle, which is a TCP load balancer, so let’s click Start configuration to get rolling here. As we get started here, we can see that we have a couple different options for this load balancer. We can make the load balancer internet facing, or we can load balance only between VMs in my network. What we’re going to do in this exercise is create an internet-facing load balancer. Another choice that I need to make here is whether or not I make my load balancer span multiple regions or if I just want to place the backend in a single region only. Since both of my VMs are in the same region, we’ll choose the single region option and then click continue. </p>
<p>At this point, I need to give my load balancer a name, so I’ll call it myloadbalancer. In addition, what I need to do is configure the backend for the load balancer and the front end for the load balancer. The backend configuration specifies what the load balancer will be load balancing, and what load balancing rules it needs to follow. </p>
<p>The front-end configuration is where I define the public IP for the load balancer, and which ports to load balance. So, let’s click Backend configuration. If you look at the name field here, the load balancer name that I already provided shows up and can’t be modified. For my region, I’m going to deploy my load balancer to us-central1. Since I’m load balancing specific instances, rather than <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/autoscaled-managed-instance-groups/">instance groups</a>, I can specify those instances by choosing the select existing instances option, and then selecting my two web servers. We’re not going to use a backup pool here and our failover ratio isn’t really critical, so we’ll leave these at their defaults. </p>
<p>Under Health check, what I need to do is Create a new health check. This health check is used to determine which instances are alive on the backend. It’s what prevents the load balancer from sending traffic to a downed instance. So I’ll create a new health check here and I’ll call it port80alive. I can leave the rest of the settings at their defaults. And then to finish the set up of my backend, I need to click the Save and Continue button. The blue circle with a check mark here tells me that my backend configuration was completed successfully. Now, what I have to do is configure my front end. To start off, I need to give my front-end rule a name, so I’ll call this myfrontend. Now, I’m going to change the network service tier here to standard, since I don’t need premium features for this exercise. And when I do that, it tells me that the standard tier uses the same region as my backend’s which is fine. For the IP here, I want to reserve a static IP address. </p>
<p>I could use an ephemeral address, but that’s likely to cause problems if the address changes later. So, static it is. We’ll call it mylbIP and then we’ll reserve it. Since we’re load balancing port 80 for this exercise, we’ll specify port 80 here in the port box. And then we can click Done. After I’ve done so, I see the blue circle with the check mark that indicates the front-end config is successful as well. From here, I can click the review and finalize option here to ensure my settings are what I need them to be, and then I can click create to deploy the configured load balancer. We’ll give this a few minutes to deploy and get up to speed and then we’ll test it. On the load balancer screen, under the Backend column for the load balancer, we can see a green check mark that indicates the new load balancer is healthy. </p>
<p>So, now that the load balancer is configured, let’s open a browser window and browse to the public IP of our load balancer. We can see that it returns the name of the web server that I was directed to. If I go in and shut down my web1 server here and then try again, we’ll see that this time we’re sent to the other web server. And we can see web2 is now listed. This tells me that load balancing is working as expected. Although I’ve shown you how to provision a TCP load balancer here, there are other options, as I mentioned earlier. </p>
<p>So, be sure to get in and play around with the different load balancer options to get a feel for how they work.</p>
<h1 id="DEMO-Generating-and-Uploading-a-Custom-SSH-Key-for-Instances"><a href="#DEMO-Generating-and-Uploading-a-Custom-SSH-Key-for-Instances" class="headerlink" title="DEMO: Generating and Uploading a Custom SSH Key for Instances"></a>DEMO: Generating and Uploading a Custom SSH Key for Instances</h1><p>When connecting to a Linux VM instance, you’ll sometimes need or want to connect, using a custom SSH key. To connect to a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">GCP compute instance</a> using a custom SSH key, you first need to generate the keypair. This keypair includes the public key that gets added to the compute instance as well as the private key that you use to connect with. What we’re going to do here in this lesson is walk through the process of creating a custom SSH key that we’re going to use to connect to an existing Linux VM that I’ve deployed. </p>
<p>Now, since windows doesn’t offer a built-in tool for generating SSH keys, I’m going to use the PuTTYgen tool to create my keypair. On the screen, here, you can see that we’re going to be working with VM2, which is actually a Linux VM. To create a custom SSH key for this VM, let’s drag my PuttyGen console over from the other screen. </p>
<p>To create a keypair, I just need to click generate here and then follow the instructions for moving my mouse around. Now, I do have to make sure that the key I’m generating is at least 2,048 bits. When I’m done here, my pubic key is shown at the top here. </p>
<p>Now, at this point, I can save my private key and my public key. Now, in the key comment section, what I need to do is replace this existing text with the username for whom the key is going to apply. So I’ll call this vmadmin. I can also provide a passphrase to protect my key if I wanted to. But I’m going to skip that for this exercise. So let me save my private key. And then I’ll save my public key. </p>
<p>Now after I’ve saved my keys, what I want to do is copy the public key from the top of the PuttyGen window, because I’m going to add this to my VM instance. With my pubic and private keys saved, and my pubic key value copied to my clipboard, I can switch back over to my VM here and I can click Edit. If I scroll down to SSH Keys, I can see that I have no SSH keys assigned yet. I’m going to change this by clicking Show and Edit. At this point, I need to paste my public key value into the box here, and then click Save down at the bottom. What this does is store the public key with the VM instance. Before I navigate away from my VM instance, I need to copy the external IP of it, so I can try to connect to it. </p>
<p>With the public key stored and the external IP copied, let’s drag my Putty utility over and try to connect. To connect, what I need to do is copy the external IP address of my instance into the hostname field here. I also need to ensure that SSH is selected here. Now, before I connect, what I need to do is expand SSH down here on the left side and select the Auth option. From here, I can browse to my private key that I’m going to use to authenticate. </p>
<p>At the prompt here, I need to provide the username that I entered in the key comment section when I created the key. If everything works like it’s supposed to, I’m granted access to the VM, like you see here. So that is how you create a key or really a keypair, how you upload the public key to your instance and how you use the private key to connect to that instance using a third-party utility.</p>
<h1 id="Monitoring-and-Logging-with-Cloud-Operations"><a href="#Monitoring-and-Logging-with-Cloud-Operations" class="headerlink" title="Monitoring and Logging with Cloud Operations"></a>Monitoring and Logging with Cloud Operations</h1><p>To monitor VMs, you can use the Ops Agent which collects system and application metrics from virtual machine instances. It then sends these metrics to Cloud Operations monitoring. The agent, by default, collects metrics information on disk, CPU, network, processes, and more.</p>
<p>Now, with all that said, using the Ops agent, although recommended, is only optional. However, without the agent, only some instance metrics can be captured. For example, if all you are interested in is CPU utilization, basic disk traffic information, uptime info, and network traffic, you can get away without using the agent. However, Cloud Operations uses the agent to access additional system resources and application services in VM instances. If you need (or want) this additional information, you need to install the Ops agent. </p>
<p>When using the Ops agent with a Google Compute Engine instance, the agent sends monitoring information to each instance’s associated project. However, it should be noted that for instances without external IP addresses, you need to enable Private Google Access in order to allow the Ops agent to send metrics.</p>
<h1 id="Configuring-a-VM-for-Cloud-Operations"><a href="#Configuring-a-VM-for-Cloud-Operations" class="headerlink" title="Configuring a VM for Cloud Operations"></a>Configuring a VM for Cloud Operations</h1><p>Before installing the Ops agent, you need to be sure that you are running a supported VM instance in a Google Cloud project, and a supported operating system. Visit the URL on your screen for a complete list of supported instances and operating systems:</p>
<p><a target="_blank" rel="noopener" href="https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent">https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent</a></p>
<p>You’ll also need credentials on the VM instance that authorize communication with Cloud Logging and Cloud Monitoring. Since Google’s Compute Engine VM instances typically already have the correct credentials by default, this should rarely be an issue.</p>
<p>In addition to the proper credentials, you’ll also have to enable the services for both the Cloud Logging API and Cloud Monitoring API, and you’ll have to ensure that neither the legacy Cloud Logging agent, nor the Cloud Monitoring agent are installed on the VM. </p>
<p>I do want to mention that there are a few different ways to install the Ops Agent, depending on your environment. For example, you can use gcloud and Agent policies to install agents on a fleet of VMs. More specifically, you use the Google Cloud CLI to create an Agent Policy, which, in turn, installs and manages the agents on all of your VMs.</p>
<p>You can also install and manage agents on your fleet of VMs using automation tools like Ansible, Chef, Puppet, and Terraform.</p>
<p>And then, of course, you can install the Ops Agent on individual VMs, using the Google Cloud CLI or Google Cloud console.</p>
<p>So, depending on your needs, you can use one method, or you can mix and match as necessary.</p>
<p>Before you install the Ops agent, you need to be sure that the VM instance has the credentials that the agent needs, because the agent needs to be able to send monitoring information to Cloud Operations. Generally speaking, this permission is granted via service account credentials that are stored on the VM instance. For an installation on a Compute Engine VM instance on GCP, the default service account on the instance should, by default, have the necessary credentials.</p>
<p>So, with that said, I’m going to show you, in the next lesson, how to install the Ops agent on a GCP compute instance.</p>
<h1 id="DEMO-Installing-the-Ops-Agent-for-Monitoring-and-Logging"><a href="#DEMO-Installing-the-Ops-Agent-for-Monitoring-and-Logging" class="headerlink" title="DEMO: Installing the Ops Agent for Monitoring and Logging"></a>DEMO: Installing the Ops Agent for Monitoring and Logging</h1><p>Welcome back. So, what I’m going to do in this quick demonstration is just walk you through the process of installing the Ops Agent on an existing VM in Google Cloud Platform. Now, on the screen I’m logged into my platform, and I have my project open here. And what we’re going to do here is browse into the monitoring section, and then we’ll actually open up a VM, and we’ll install the agent. </p>
<p>So, to do this, we’re going to select the hamburger here for the navigation menu, and then what happens here is we scroll down, and it’s near the bottom here. Under Operations, we have Monitoring. What we’re going to do here is open our dashboards here, under Monitoring. And then from here, since we’re going to install this Ops Agent on a VM instance, we’re going to select VM instances in the dashboards options here.</p>
<p>Then you’ll see here, I have server01. Server01 is going to be the server we install on. You’ll notice we have no agent detected currently, so to do this, we simply select the checkbox next to server01 and then we click on ‘Install Agents’. Now, what we could do here is just copy the code that it gives us here. If we were going to run this in Cloud Shell manually, but what you can do here is simply click ‘Run in Cloud Shell, and when I do this, it’s going to open these commands right in Cloud Shell. So, we’ll go ahead and click ‘Run in Cloud Shell’. And let me see if I can drag this up a little bit, there we go. I’m going to just scroll this back down. </p>
<p>So, you’ll notice here it opened up these commands already, and it’s actually running this using a file called agentstoinstall.csv. This has already created that CSV for me, I didn’t create any files, this actually does it for me based on the servers that I selected. So, what I’m going to do here is just hit ‘Enter’ on my keyboard. And what it does here is it asks me to authorize Cloud Shell, so we’ll go ahead and authorize it. You see the progress bar here, and we’ll give this a few minutes to complete. You’ll see we got one of one succeeded, zero of one failed, and one of one completed. </p>
<p>What I’ll do here is I’ll close Cloud Shell up, and you see here that the agent now shows pending. So, we’ll give this a few minutes and then what we’ll do is refresh and we’ll see what this shows when everything is said and done. Let’s go ahead and refresh the screen. Now, notice here, and this is something to keep an eye on. Right now, it’s telling me the Legacy Agent is installed. Now, we didn’t cover Legacy Agent here because it’s being phased out, but if we give this another minute or two, this actually does go through the process and it does in fact install the Ops Agent. </p>
<p>So, we’ll go ahead and just refresh here and see if it shows up right away. All right, let’s give it another minute or two, and we’ll do a refresh and you’ll see how this agent summary will eventually show one VM with Ops Agent. Let’s go ahead and refresh one more time here. It usually takes a few minutes, and there we go. So, now we have one VM with the Ops Agent and none with the legacy and none with no agents. You’ll see down here server01 shows the Ops Agent is installed and active. So, that’s how you can use the Google Cloud Platform console to install the Ops Agent on a Virtual Machine in Google Cloud.</p>
<h1 id="Assessing-Compute-Quotas"><a href="#Assessing-Compute-Quotas" class="headerlink" title="Assessing Compute Quotas"></a>Assessing Compute Quotas</h1><p>When <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">deploying resources on GCP</a>, it’s important to consider what your quotas may be. This is because Compute Engine enforces resource quotas for several reasons, most notably, to protect the overall GCP community from unexpected usage spikes. This is especially true for free trial accounts.</p>
<p>While GCP may offer expanded quotas for paying customers, the free trial quotas that are in place provide limited access for organizations that are just kicking the tires of the Google Cloud Platform on a free trial basis. Now, with that said, even for paying customers, quotas may differ. For example, an organization that is growing rapidly, and deploying compute resources at a fast clip, may see its quotas expanded more quickly than a smaller organization that deploys one or two compute instances a year. However, organizations expecting an upcoming usage increase can proactively request quota adjustments, using the Quotas page in the GCP Console. It’s important to note, though, that if a project’s billing service is disrupted, the quotas for that project will reset to default values. So, it’s important that you keep billing in check and invoices paid on time!</p>
<p>Checking the available quota for resources in a given project is easy. All you have to do is browse to the Quotas page in the Google Cloud Platform Console and see what’s available. Although, you can also use the gcloud command-line tool, to check quotas by running the command that you see on your screen. This command checks project-wide quotas. Simply replace yourproject with your own project ID. Now, since this command doesn’t list per-region quotas, you can, instead, run this next command that you see on your screen to list quotas in a region Just replace REGION with the region for which you want to list quota information. </p>
<p>In the next lesson, I’ll show you how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/demo-requesting-an-increase-in-quota/">request a quota increase</a>.</p>
<h1 id="DEMO-Requesting-an-Increase-in-Quota"><a href="#DEMO-Requesting-an-Increase-in-Quota" class="headerlink" title="DEMO: Requesting an Increase in Quota"></a>DEMO: Requesting an Increase in Quota</h1><p>Welcome back. In this quick demonstration, what we’re going to do is request a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/assessing-compute-quotas/">quota</a> increase from the Quotas page in the GCP console. </p>
<p>Now although we’re going to request an increase in quota, we aren’t going to incur any new charges because there’s no charge for requesting a quota increase. The only time our charges will increase is when we actually use the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/deploying-networking-and-compute-resources-on-google-cloud-platform/course-intro/">new resources</a> that become available as a result of the quota increase. </p>
<p>Now before requesting our quota change we have to be sure that the account we’re using to make the request has the service usage quotas update permission. Since this permission is included by default for owner, editor and quota administrator roles, we’re good to go here since I’m logged in as the owner. </p>
<p>To make my quota change request, what I need to do is go to the Quotas page. The Quotas page is found under IAM &amp; admin and then under Quotas. From this Quotas page, what I need to do is select the quota that I want to change and then click Edit Quotas at the top of the page. What I’m going to do here is check the box of the service that I want to edit. And then I’ll go ahead and click Edit Quotas. </p>
<p>What I’ll do here is request an increase to 300 and in the Request description, I’ll just leave a description here, to let Google know why I’m requesting this. And then I’ll click Done. Once I’ve done this, I can submit my request. </p>
<p>Now, had I request a quota decrease, my request would be rejected by default. If I really, really wanted to reduce my quota, what I would need to do is reply to the eventual rejection email with an explanation of my requirements. What would then happen is that GCP support reps would respond to my request. Generally speaking, the Compute Engine team responds to requests within 48 hours. </p>
<p>So because of that slight delay what you’ll want to do in a production environment is request any necessary quota increases at least a few days ahead of time so there’s enough time for support to fulfill the request before the added resources are actually needed.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>I hope you’ve enjoyed learning how to Deploy Networking and Compute Resources on Google Cloud Platform. Let’s review what you’ve learned.</p>
<p>We kicked off the course by covering the deployment and implementation of networking resources such as VPCs and subnets. You learned how to create a VPC and how to define subnets contained within the VPC. You also learned how to create ingress and egress firewall rules for a VPC.</p>
<p>Later on, in the course, you learned how to create a VPN connection between a Google VPC and an external network. You also learned how to distribute network traffic to an application by using a load balancer.</p>
<p>As we moved through the course, you learned how to deploy and implement Compute Engine resources via the Cloud Console and via gcloud. After deploying a compute instance, you learned how to create and assign disks to an existing compute instance and how to assign an availability policy to a compute instance.</p>
<p>Down the home stretch of this course, you learned how to create and autoscaled managed instance group, using an instance template, and how to generate and upload custom SSH keys for compute instances.</p>
<p>Rounding out the course, you learned how to configure a VM for Cloud Operations, and how to install the Ops Agent. You also learned how to assess compute quotas and how to request quota increases.</p>
<p>At this point, you should now have a full understanding of how to Deploy Networking and Compute Resources on Google Cloud Platform.</p>
<p>To learn more about Deploying Networking and Compute Resources on Google Cloud Platform, you can, and should, read Google’s documentation. Be sure to also watch for new courses on Cloud Academy, because we’re always publishing new ones. Be sure to give this course a rating, and if you have any questions or comments, please let us know. As always, thanks for watching and happy learning!</p>
<h1 id="19Configuring-a-VM-for-Cloud-Operations"><a href="#19Configuring-a-VM-for-Cloud-Operations" class="headerlink" title="19Configuring a VM for Cloud Operations"></a>19<strong>Configuring a VM for Cloud Operations</strong></h1><p><a target="_blank" rel="noopener" href="https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent">Ops Agent Supported Systems</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/19/GCP-Cloud-Engineer-Designing-a-Google-Cloud-Infrastructure-7/" rel="prev" title="GCP-Cloud-Engineer-Designing-a-Google-Cloud-Infrastructure-7">
      <i class="fa fa-chevron-left"></i> GCP-Cloud-Engineer-Designing-a-Google-Cloud-Infrastructure-7
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/19/GCP-Cloud-Engineer-Starting-a-Linux-Virtual-Machine-on-Google-Compute-Engine-9/" rel="next" title="GCP-Cloud-Engineer-Starting-a-Linux-Virtual-Machine-on-Google-Compute-Engine-9">
      GCP-Cloud-Engineer-Starting-a-Linux-Virtual-Machine-on-Google-Compute-Engine-9 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Course-Intro"><span class="nav-number">1.</span> <span class="nav-text">Course Intro</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VPCs-and-Subnets"><span class="nav-number">2.</span> <span class="nav-text">VPCs and Subnets</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-Creating-a-VPC-with-Subnets"><span class="nav-number">3.</span> <span class="nav-text">DEMO: Creating a VPC with Subnets</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Ingress-and-Egress-Firewall-Rules-for-a-VPC"><span class="nav-number">4.</span> <span class="nav-text">Ingress and Egress Firewall Rules for a VPC</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-Creating-an-Ingress-Firewall-Rule-for-a-VPC"><span class="nav-number">5.</span> <span class="nav-text">DEMO: Creating an Ingress Firewall Rule for a VPC</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Creating-a-VPN-Connection"><span class="nav-number">6.</span> <span class="nav-text">Creating a VPN Connection</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-How-to-Create-a-VPN"><span class="nav-number">7.</span> <span class="nav-text">DEMO: How to Create a VPN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Launching-a-Compute-Instance-Using-Cloud-Console"><span class="nav-number">8.</span> <span class="nav-text">Launching a Compute Instance Using Cloud Console</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-How-to-Launch-a-Compute-Instance-in-Cloud-Console"><span class="nav-number">9.</span> <span class="nav-text">DEMO: How to Launch a Compute Instance in Cloud Console</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-Launching-a-Compute-Instance-Using-Cloud-SDK"><span class="nav-number">10.</span> <span class="nav-text">DEMO: Launching a Compute Instance Using Cloud SDK</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Assign-Disks-to-a-Compute-Instance"><span class="nav-number">11.</span> <span class="nav-text">Assign Disks to a Compute Instance</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Assign-an-Availability-Policy-to-a-Compute-Instance"><span class="nav-number">12.</span> <span class="nav-text">Assign an Availability Policy to a Compute Instance</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-Working-with-Availability-Policies"><span class="nav-number">13.</span> <span class="nav-text">DEMO: Working with Availability Policies</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Autoscaled-Managed-Instance-Groups"><span class="nav-number">14.</span> <span class="nav-text">Autoscaled Managed Instance Groups</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-Creating-an-Autoscaled-Managed-Instance-Group-Using-an-Instance-Template"><span class="nav-number">15.</span> <span class="nav-text">DEMO: Creating an Autoscaled Managed Instance Group Using an Instance Template</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-Load-Balancing-HTTP-Traffic-with-a-Load-Balancer"><span class="nav-number">16.</span> <span class="nav-text">DEMO: Load Balancing HTTP Traffic with a Load Balancer</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-Generating-and-Uploading-a-Custom-SSH-Key-for-Instances"><span class="nav-number">17.</span> <span class="nav-text">DEMO: Generating and Uploading a Custom SSH Key for Instances</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Monitoring-and-Logging-with-Cloud-Operations"><span class="nav-number">18.</span> <span class="nav-text">Monitoring and Logging with Cloud Operations</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Configuring-a-VM-for-Cloud-Operations"><span class="nav-number">19.</span> <span class="nav-text">Configuring a VM for Cloud Operations</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-Installing-the-Ops-Agent-for-Monitoring-and-Logging"><span class="nav-number">20.</span> <span class="nav-text">DEMO: Installing the Ops Agent for Monitoring and Logging</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Assessing-Compute-Quotas"><span class="nav-number">21.</span> <span class="nav-text">Assessing Compute Quotas</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DEMO-Requesting-an-Increase-in-Quota"><span class="nav-number">22.</span> <span class="nav-text">DEMO: Requesting an Increase in Quota</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Conclusion"><span class="nav-number">23.</span> <span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#19Configuring-a-VM-for-Cloud-Operations"><span class="nav-number">24.</span> <span class="nav-text">19Configuring a VM for Cloud Operations</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
