<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Course IntroductionWelcome to Container Orchestration with Docker Swarm Mode. About MeI’m Logan Rakai and I’ll be your instructor for this Course. I’m a content researcher and developer here at Clou">
<meta property="og:type" content="article">
<meta property="og:title" content="Docker-Certified-Associate-Container-Orchestration-With-Docker-Swarm-Mode-5">
<meta property="og:url" content="https://example.com/2022/11/19/Docker-Certified-Associate-Container-Orchestration-With-Docker-Swarm-Mode-5/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:description" content="Course IntroductionWelcome to Container Orchestration with Docker Swarm Mode. About MeI’m Logan Rakai and I’ll be your instructor for this Course. I’m a content researcher and developer here at Clou">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-19T04:44:33.000Z">
<meta property="article:modified_time" content="2022-11-21T07:02:06.000Z">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/2022/11/19/Docker-Certified-Associate-Container-Orchestration-With-Docker-Swarm-Mode-5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Docker-Certified-Associate-Container-Orchestration-With-Docker-Swarm-Mode-5 | Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/19/Docker-Certified-Associate-Container-Orchestration-With-Docker-Swarm-Mode-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Docker-Certified-Associate-Container-Orchestration-With-Docker-Swarm-Mode-5
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-19 00:44:33" itemprop="dateCreated datePublished" datetime="2022-11-19T00:44:33-04:00">2022-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-21 03:02:06" itemprop="dateModified" datetime="2022-11-21T03:02:06-04:00">2022-11-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Docker-Certified-Associate/" itemprop="url" rel="index"><span itemprop="name">Docker-Certified-Associate</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/19/Docker-Certified-Associate-Container-Orchestration-With-Docker-Swarm-Mode-5/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/19/Docker-Certified-Associate-Container-Orchestration-With-Docker-Swarm-Mode-5/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <span id="more"></span>

<h1 id="Course-Introduction"><a href="#Course-Introduction" class="headerlink" title="Course Introduction"></a>Course Introduction</h1><p>Welcome to Container Orchestration with Docker Swarm Mode.</p>
<p>About Me<br>I’m Logan Rakai and I’ll be your instructor for this Course. I’m a content researcher and developer here at Cloud Academy. I’ve been thinking a lot about how to maximize the return on your time invested in this course. I’m confident that you’ll be confident in your ability to orchestrate containers with Docker Swarm mode after completing the course. I have over ten years of experience in software research and development including five years in the cloud. I’m an AWS Certified DevOps Engineer Professional and a Microsoft Certified Solutions Expert: Cloud Platform and Infrastructure. You can connect with me on LinkedIn or on Twitter.</p>
<p>Who this course is for<br>This course is for anyone that is interested in orchestrating distributed systems at any scale.<br>DevOps Engineers<br>Site Reliability Engineers<br>Cloud Engineers<br>Software Engineers</p>
<p>Prerequisites<br>In order to get the most out of this course, you should have experience with Docker. You should have a solid understanding of images, networks, volumes, and have experience using Docker compose for managing multi-container applications. If you need to brush up on any of those topics, Cloud Academy has some great courses for that. “Introduction to Docker” by Ben Lambert covers fundamental Docker concepts and “Managing Applications with Docker Compose” by yours truly for working with multi-container applications using Docker Compose.</p>
<p>You can follow along with the course examples, and I’d encourage you to. You will need Docker version 1.13 or greater installed. I’ll be using a Mac with Docker for Mac version 17.12 installed but you can also follow along in Linux. You should have VirtualBox installed as well. Swarm mode in Windows has some additional limitations mainly around network encryption. I’ll mention the limitations when we cover the relevant topic. Almost everything we discuss will apply to Windows environments but I’ll be using Linux containers in the demos.<br>I’ve put resources that I use for the demos on GitHub. A clickable link is available at the bottom of the transcript for this lesson. Most of the work will happen at the command-line although we will work with some files near the end of the course. I’ll be using Visual Studio Code for working with the files but you could use whatever you are comfortable with.</p>
<p>Learning Objectives<br>After completing this course, you will be able to:<br>“ Describe what Docker swarm mode can accomplish<br>“ Explain the architecture of a swarm mode cluster<br>“ Use the Docker CLI to manage nodes in a swarm mode cluster<br>“ Use the Docker CLI to manage services in a swarm mode cluster<br>“ Deploy multi-service applications to a swarm using stacks</p>
<p>Feedback<br>I’m happy to hear from you. I make content for you and I want it to be as good as it can be. If you have any feedback, please get in touch with me by leaving a comment on the Comments tab below the video, by emailing <a href="mailto:&#115;&#117;&#112;&#112;&#x6f;&#x72;&#116;&#64;&#x63;&#108;&#x6f;&#117;&#100;&#97;&#99;&#x61;&#x64;&#x65;&#x6d;&#121;&#x2e;&#x63;&#x6f;&#x6d;">&#115;&#117;&#112;&#112;&#x6f;&#x72;&#116;&#64;&#x63;&#108;&#x6f;&#117;&#100;&#97;&#99;&#x61;&#x64;&#x65;&#x6d;&#121;&#x2e;&#x63;&#x6f;&#x6d;</a>, or by connecting with me on Twitter where my handle is @LoganRakai.</p>
<p><a target="_blank" rel="noopener" href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/cloudacademy/docker-swarm-mode-training">Course resources on GitHub</a></p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>Welcome to this overview lesson on Docker swarm mode. We’ll get a conceptual understanding of swarm mode in this lesson before understanding its architecture and diving into the details and demos in following lessons.</p>
<p>Agenda<br>We’ll start the lesson by getting an understanding of why we need swarm mode. After that, we’ll highlight some features of Docker swarm mode to understand what swarm mode can do for you. Next, we’ll learn about the main concepts of Docker swarm mode. Lastly, I’ll touch on the universal control plane which is Docker’s enterprise product built on top of swarm mode.</p>
<p>Why Swarm?<br>Docker has made great strides in advancing development and operational agility, portability, and cost savings by leveraging containers. You can see a lot of benefits even when you use a single Docker host. But when container applications reach a certain level of complexity or scale you need to make use of several machines. Container orchestration products and tools allow you to manage multiple container hosts in concert. Docker swarm mode is one such tool.</p>
<p>Swarm Mode<br>Swarm mode is a feature built into the Docker Engine providing native container orchestration in Docker. Swarm mode is something you need to enable and when you do, the Docker Engine is said to be running in swarm mode. With swarm mode you can control a cluster of machines in a way that is similar to running and about as easy as running a single Docker Engine. Of course there are some differences and we’ll see them in this course.</p>
<p>Calling swarm mode a container orchestration feature doesn’t quite do it justice. It encompasses cluster management, container orchestration, and more. Some of the main features of swarm mode include:<br>“ Integrated cluster management within the Docker Engine without any additional software<br>“ A declarative service model that allows you to declare what you want and Docker can create it for you. There is no need for you to specify the sequence of commands to realize what you want.<br>“ Swarm mode is able to monitor the cluster state and reconcile any differences between the desired state and the actual state. (Desired state reconciliation)<br>“ Swarm mode uses certificates and cryptographic tokens to secure the cluster<br>“ As well as features you’d expect in a container orchestration offering such as service scaling, multi-host networking, resource-aware scheduling, load balancing, rolling updates, restart policies, and more.</p>
<p>Name disambiguation<br>Docker actually has two cluster management solutions. Both are open source and live on GitHub. Surprisingly, they are both called swarm. Docker Swarm, with a capital S, was the first container orchestration project by Docker. It uses the Docker API to turn a pool of Docker hosts into a single, virtual Docker host using a proxy system. To reduce confusion, Docker Swarm is now referred to as Docker Swarm standalone in documentation.</p>
<p>Although Docker Swarm standalone project is still maintained, the newer container orchestration tool is called Swarmkit. It is what is built into the Docker Engine since Docker version 1.12. You might see swarmkit mentioned from time to time, but this is the most commonly referred to as swarm mode. Docker recommends Swarm mode unless you have a specific reason to use Swarm standalone.</p>
<p>So now you know that there are two swarms, Swarm standalone and swarm mode. It’s useful to be aware of the distinction. You might search for Docker swarm online and stumble upon something related to Swarm standalone when you wanted swarm mode. To avoid any confusion, this course deals exclusively with swarm mode. In the remainder of the course, if I refer to swarm, I’m referring to Docker running in swarm mode. In practice, it’s pretty common to drop mode from the name although it can potentially lead to misunderstandings. In the remainder of the lesson, we’ll cover the architecture of swarm mode.</p>
<p>Swarm Mode Concepts<br>Before going too far, we’ll cover some of the main concepts and swarm mode terminology.</p>
<p>A swarm consists of one or more Docker Engines running in swarm mode. Each instance of the Docker Engine in the swarm is referred to as a node. It is possible to run multiple nodes on a single machine. For example, by using virtual machines. In production environments, you should use multiple machines to ensure availability of the swarm if a machine goes down.</p>
<p>Nodes can participate in a swarm by taking on specific roles: managers and workers. Every swarm requires at least one manager. Managers have several responsibilities, but we’ll start simple and consider one main responsibility. Managers accept specifications from users and drive the actual state of the swarm to the specified desired state. They do so by delegating units of work to workers in the swarm. Workers are primarily responsible for running the delegated units of work. Workers also run an agent which reports back to managers on the status of their work. A node can be either a manager, or a worker.</p>
<p>The specifications that users submit to managers are called services. This is the same concept as a service in Docker Compose. The service configuration declares its desired state, which includes the networks and volumes it uses, the number of replicas, resource constraints, and other details. A manager will ensure the actual state of the swarm matches the service configuration. if it is possible to realize in the swarm. There may not be enough available resources in the swarm which would prevent the desired state from being achieved. Docker will also make the changes necessary to reconcile the actual state with the desired state if you update a service.</p>
<p>There are two kinds of services: replicated and global. You specify the number of replicas for a replicated service based on the scale you desire. A global service allocates one unit of work for each node in the swarm. Global services can be useful for monitoring services, for example.</p>
<p>The units of work delegated by managers to realize a service configuration are referred to as tasks. The tasks correspond to running containers that are replicas of the service. Managers schedule the tasks across nodes in the swarm. If a node leaves the swarm, the tasks that the node was running will be scheduled onto the remaining nodes in the swarm.</p>
<p>By default, manager nodes also run tasks like workers. You can configure managers to participate exclusively in managing the cluster and that is probably a good idea in production. Allowing managers to run tasks by default enables easy to setup and functional single node swarms.</p>
<p>Universal Control Plane<br>The last topic I want to cover in giving an overview of swarm mode is the Universal Control Plane (UCP). UCP is only relevant for the enterprise edition of Docker so I will only briefly touch on it.</p>
<p>Working with swarm mode is similar to working with Docker. You interact with it through the Docker CLI. That is great, but sometimes it can be nice to have a web interface to manage and visualize the cluster and containers. UCP is Docker’s enterprise offering that is built on top of swarm mode to provide a web interface for cluster management and role-based access control. Because UCP is built on swarm, what you learn in this course applies to UCP as well.</p>
<p>Closing<br>All right, now we have a basic understanding of swarm mode. We will take closer look at how swarm mode works by understanding main components of its architecture in the next group of lessons.</p>
<h1 id="Networking"><a href="#Networking" class="headerlink" title="Networking"></a>Networking</h1><p>Thanks for joining me for this lesson on Docker swarm mode architecture. You heard about the great benefits swarm mode provides in the previous lesson. In these architecture lessons, we’ll understand more about the parts of swarm mode that enable it to accomplish all those great benefits, starting with networking. This lesson and the following architecture lessons build the foundations for using swarm mode. I promise we’ll be seeing swarm mode in action in the demos of the next lesson group in the course.</p>
<p>Agenda<br>This lesson will cover everything that is unique to swarm mode and networking:<br>“ (Overlay networks) Starting with a Docker network type exclusive to swarm mode, the overlay network.<br>“ (Service discovery) After that, we’ll discuss how services in a swarm can be discovered across multiple host swarm networks.<br>“ (Load balancing) On a related note, we’ll see how load is balanced across all the replicas of a service.<br>“ (External access) Then the mechanisms for accessing the swarm services from outside the swarm will be explored.</p>
<p>Networking<br>The networking requirements in a swarm are much more complex than using a single Docker host. Services need to communicate with one another and the replicas of the service can be spread across multiple nodes. Fortunately, Docker includes a network driver that makes multi-host networking reliable, secure, and a breeze to set up.</p>
<p>Overlay Networks<br>The driver I’m referring to is the overlay network driver. With the overlay driver a multi-host networking in a swarm is natively supported. There is no need to perform any external configuration. You can attach a service to one or more overlay networks, in the same way you would attach a container to one or more user-defined networks when not running in swarm mode.<br>Overlay networks only apply to swarm services and can’t be connected to by containers that aren’t part of a swarm service. Managers automatically extend overlay networks to nodes that run tasks requiring access to a given overlay network.</p>
<p>Network isolation and firewalls<br>It’s a good time to review Docker network isolation and firewall rules. These rules apply to overlay networks just as they do for bridge networks.<br>Containers within a Docker network are permitted access on all ports of containers in the same network.<br>Access is denied between containers that don’t share a common network.<br>Traffic originating inside of a Docker network and not destined for a Docker host is permitted. For example, access to the internet. However, any network infrastructure outside of Docker may still deny the traffic.<br>Ingress traffic, or traffic coming into a Docker network, is denied by default. Ports must be published in order to grant access form outside of Docker.</p>
<p>Service Discovery<br>With services distributed across multiple nodes, a service discovery mechanism is required in order to connect to the nodes running tasks for a service. Swarm mode has an integrated service discovery. It is based upon the domain name system (DNS). The DNS is internal to Docker and implemented in the Docker Engine. It is used for resolving names to IP addresses.</p>
<p>Actually, the same service discovery system is used when not running in swarm mode. Service discovery in Docker is scoped to a network. When you are in swarm mode, the network can be an overlay spanning multiple hosts. But the same internal DNS system is used. All nodes in a network store corresponding DNS records for the network. Only service replicas in the network can resolve other services and replicas in the network by name.</p>
<p>Internal Load balancing<br>There are some unique service discovery considerations for Swarm mode. Each individual task is discoverable with a name to IP mapping in the internal DNS. But because services can be replicated across multiple nodes, which IP address should a service name request resolve to? Docker assigns a service a single virtual IP (VIP) address, by default. Requests for the virtual IP address are automatically load balanced across all healthy tasks spread across the overlay network. By using a virtual IP, Docker can manage the load balancing allowing clients to interact with a single IP address without considering load balancing. It also makes the service more resilient since the service can scale and tasks can change the nodes that they are scheduled on but clients are sheltered from the changes.</p>
<p>Internal load balancing example<br>To illustrate how service discover and load balancing work in swarm mode, consider two services deployed in a swarm service A and service B. Service A has a single replica while service B has two replicas. When service A makes a request for service B by name, the virtual IP of service B is resolved by the DNS server. Service A uses the virtual IP to make a request for service B. Using support for ip virtual servers (IPVS) the request for the virtual IP address is routed to one of the two nodes running service B tasks.</p>
<p>DNS Round Robin<br>Besides the default virtual IP, you can configure load balancing using DNS round robin (DNS RR). You can configure the load balancing on a per service basis. When DNS round robin is used, the Docker Engine’s DNS server resolves a service name to individual task IP addresses by cycling through the list of IP addresses of node’s running a task in the service. If you need more control over load balancing than a virtual IP can give you, DNS round robin should be used for integrating your own external load balancer.</p>
<p>External Access<br>We’ve covered access to services within a Docker network, but what about accessing a service from the outside? With a single Docker host, you would publish a container port on the host to permit access to a container. Similar functionality is still available in swarm. But there are actually two modes for publishing ports in swarm.</p>
<p>Host mode<br>The first is the same as you would expect when publishing a port when not running in swarm mode. The container port is published on the host that is running the task for a service. This mode is referred to as host mode service publishing. You need to be careful with specifying a host port in host mode. If you have more tasks than available hosts, tasks will fail to run because the host port can only be bound to one task. You can omit a host port to allow Docker to assign an available port number in the default port range of 30000-32767. However, this can make it more difficult to work. Also, there isn’t load balancing unless you configure it externally. Obviously, that is useful when you don’t want load balancing, but what about when you do?</p>
<p>Ingress mode<br>Because services can be replicated and tasks can be rescheduled onto different nodes as the state of the swarm changes, it is useful to have the option to load balance a published port across all tasks of a service. This is referred to as ingress mode service publishing. For convenience, all nodes in the swarm publish the port. This is different from host mode where a port is only published if the node is running a task for the service. In ingress mode, requests are round robin load balanced across the healthy instances of the service’s tasks regardless of the node that receives the request.</p>
<p>Ingress mode is the default service publishing mode. It’s ideal when you have multiple replicas of a service and need to load balance between them. Host mode publishing is useful when you have an external service discovery service and potentially for global services where one task for a service runs on each node. For example, a global service that monitors each node’s health shouldn’t be load balanced since you want to get the status of a specific node.</p>
<p>Routing Mesh<br>At this point, you might be wondering how ingress mode publishing work. The magic happens in what is called the routing mesh. The routing mesh combines two of the swarm components that we discussed earlier: an overlay network, and a service virtual IP.</p>
<p>When you initialize a swarm, the manager creates an overlay network named ingress. Every node that joins the swarm is in the ingress network. The sole purpose of the ingress network is to transport traffic from external clients that is destined to published service ports to the service inside the swarm.</p>
<p>When a node receives an external request on the ingress network the node resolves the service name to a virtual IP address. This process is carried out using the same internal DNS server as we discussed in the internal load balancing. The IP virtual server then load balances the request to a service replica over the ingress network.</p>
<p>Because every node is in the ingress network, every node can resolve the external requests can handle the external requests. The nodes need to have a couple of ports open for all of this magic to work:<br>o Port 7946 for both TCP and UDP protocols to enable container network discovery.<br>o Port 4789 for the UDP protocol to enable the container ingress network.</p>
<p>It’s worth mentioning that you could add an external load balancer on top of the load balancing provided by the routing mesh. For example, if you have nodes running in the cloud, you can have the nodes in a private subnet so they aren’t directly accessible from the internet. You could provision a cloud load balancer to handle requests from the internet and load balance them across nodes in the swarm. The swarm nodes then load balance again across the nodes running tasks for the service.</p>
<p>As a final note on the routing mesh, if you are planning to use the routing mesh on Windows, you need to be running version 17.09 or greater.</p>
<p>docker_gwbridge<br>Besides the ingress network, Docker also creates a second network when running in swarm mode called docker_gwbridge. The docker_gwbridge is a virtual bridge that connects the overlay networks (including the ingress network) to an individual Docker daemon’s physical network. This interface provides default gateway functionality for all containers attached to the network. Docker creates it automatically when you initialize a swarm or join a Docker host to a swarm, but it is not a Docker device. It exists in the kernel of the Docker host. You can see it if you list the network interfaces on your host.</p>
<p>Recap<br>There was quite a few topics related to networking in swarm mode. Let’s recap the main points:<br>“ Swarm mode includes a new type of Docker network, the overlay network. Overlay networks make it easy to use multi-host networking in a swarm.<br>“ The same internal DNS service discovery mechanism used when not running in swarm mode is used in swarm mode. The internal DNS naturally extends to multi-host networks.<br>“ The services in a swarm can be load balanced by using a virtual IP address or by DNS round robin.<br>“ External access to the swarm is made possible by publishing ports. There are two modes for publishing in swarm mode: host and ingress.<br>o In host mode each service replica publishes it’s container port on the host. No load balancing is used.<br>o In ingress mode, every node in the swarm publishes the port and requests are load balanced across all the replicas of a service. Any node can handle requests for the service even if the node doesn’t have a replica of the service itself.<br>“ Ingress mode is made possible by the swarm routing mesh which uses two default swarm networks: the ingress overlay network and docker_gwbridge network</p>
<p>Closing<br>In the next lesson, we’ll look into swarm mode container orchestration features including rolling updates and scheduling constraints. When you’re ready continue on to the next lesson to see how swarm can orchestrate containers.</p>
<h1 id="Orchestration"><a href="#Orchestration" class="headerlink" title="Orchestration"></a>Orchestration</h1><p>Swarm mode is made to be familiar to single host Docker users. When you deploy a service, it is similar to running a container. You can specify an image, volumes, networks, published ports, After all, service tasks ultimately run containers. But there are container orchestration features of swarm mode that are unique to running services in a swarm.</p>
<p>Agenda<br>We’ll look at the following orchestration features of swarm mode:<br>“ (Service placement) Which nodes service tasks are placed on<br>“ (Update behavior) how service updates are rolled out, and<br>“ (Rollback behavior) how services can be rolled back to a previous version.</p>
<p>Service placement<br>As we’ve discussed, services can declare a set number of replicas as a replicated service or can be started on every worker node in a cluster as a global service. For replicated services, decisions need to be made by swarm managers for where service tasks will be scheduled, or where the service will be placed. A replicated service’s tasks will be spread across nodes by default. That is to promote high availability in case a node fails. But there are three ways that you can influence where a service is placed:<br>\1. CPU and Memory reservations<br>\2. Placement constraints<br>\3. Placement preferences<br>You can specify each at service creation time. Global services can also be restricted to a subset of nodes with these conditions. Although a node will never have more than one task for a global service. Let’s take a closer look at each.</p>
<p>CPU and Memory reservations<br>Similar to running individual containers, you can declare CPU and memory reservations for services. Each service task can only be scheduled on a node that has enough available CPU and memory to meet the given reservations. Any tasks that remain stay in a pending state until a node with sufficient resources becomes available. Global services will only run on nodes that meet a given resource reservation.</p>
<p>Setting sufficient memory reservations for services is important when there isn’t an abundance of CPU and memory available for the applications you are running. If services attempt to use more memory than is available, the container or Docker daemon could get killed by the out of memory or OOM killer.</p>
<p>Placement constraints<br>Placement constraints allow you to restrict the placement of tasks by providing equality and inequality conditions. The conditions compare node attributes to a string value. There are a few built-in attributes for each node<br>\1. node.id matches the ID of a node<br>\2. node.hostname matches a node’s hostname<br>\3. node.role matches a node’s role, either manager or worker</p>
<p>You can also define your own labels. You can configure labels on a Docker engine or on a node. Engine labels are usually used to indicate things like operating system, system architecture, available drivers. An example is engine.labels.operatingsystem and values could be Ubuntu 14.04 or Windows Server 2016. Node labels are added by Swarm administrators for operational purposes. Node labels can indicate they type of application a node is intended to run, the datacenter location a node is in, the server rack a node is in, et cetera. An example is node.labels.datacenter and values could be north, south, east, or west.</p>
<p>When you provide multiple placement constraints for a service, all constraints must be satisfied by a node in order to be scheduled a service task. If resource reservations are also provided, all constraints and resource reservations must be met. This is true for replicated and global services.</p>
<p>Placement Preference<br>Placement preference is not required as was the case for resource reservations and placement constraints. Instead, placement preferences influence how tasks are distributed across appropriate nodes. Currently the only distribution option is spread which will evenly spread tasks.<br>Labels are again used as the attribute for spreading tasks. For example, assume every node in a swarm has a datacenter label with either east or west as the value. Using the datacenter label and the spread placement preference, half of the tasks will be scheduled on east datacenter nodes and the other half on west datacenter nodes.</p>
<p>Multiple placement preferences can be specified. In this case a hierarchy of preferences is created. For example, if the first preference is datacenter and the second Is server-rack, tasks will be evenly spread across nodes in each datacenter, and within each datacenter tasks are spread evenly across racks.</p>
<p>Nodes that are missing a placement preference label are included in the spread and receive tasks in proportion equal to all other label values. They are treated as the group having the null value for the label. Placement preferences are ignored by global services.</p>
<p>That’s all that there is to influencing service placement in swarm.</p>
<p>Update Behavior<br>You can also configure the way that swarm applies updates to services. Swarm supports rolling updates where a fixed number of replicas are updated at a time until all service replicas have been updated.</p>
<p>You can configure several update parameters:<br>\1. Update parallelism, which sets the number of tasks the scheduler updates at a time<br>\2. Update delay, which sets the amount of time between updating sets of tasks, and<br>\3. Update failure action, which can be set to pause, continue or automatically rollback if an update fails. The default is to pause.<br>These are the three main settings. There are also settings to configure what qualifies as failure. You can set a ratio for the number of failed task updates to tolerate before failing a service update, and set the frequency for monitoring for a failure.</p>
<p>These parameters give you some flexibility in how aggressively or conservatively you roll out an update to the swarm.</p>
<p>Rolling Back Updates<br>Docker swarm keeps track of the previous configuration for services. This allows you to rollback manually at any time or automatically when an update fails, as we discussed.</p>
<p>The same options available for configuring update behavior are available separately for configuring rollbacks. For example, rollback parallelism sets how many nodes to roll back at a time.</p>
<p>Recap<br>In this lesson, we saw how you can influence the nodes that swarm schedules services on by using resource reservations, placement constraints, and placement preferences. Resource reservations and placement constraints must be satisfied, while placement preferences won’t prevent a task from being scheduled. We also discussed how rolling updates and rollbacks can be configured in Swarm. Updates and rollbacks share the same available configuration options.</p>
<p>Closing<br>In the next lesson, we’ll see how swarm mode keeps a consistent view of the swarm. An important topic for any distributed system. When you are ready, continue on to the next lesson to learn about swarm mode consistency.</p>
<h1 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h1><p>Consistency is an important consideration for any distributed system. In this lesson, we’ll look at the consistency model of swarm mode and how it can impact how you operate a swarm.</p>
<p>Agenda<br>To kick things off we’ll discuss:<br>“ (Consistency) the consistency problem and<br>“ (Raft) how swarm mode goes about solving it, in particular the Raft Consensus algorithm.<br>“ (Tradeoffs) We’ll cover just what you need to know of Raft to understand key tradeoffs that you should consider when deciding on the composition of your swarm.<br>“ (Raft Logs) Lastly, we’ll talk about the raft logs where the cluster state is stored.</p>
<p>Consistency<br>We have seen that swarm mode can include several manager and worker nodes in a swarm. This provides fault tolerance if a node were to go down and ensures services are highly available. But with multiple managers, how does swarm make decisions regarding the state of the cluster? Do nodes in the swarm share a consistent view of the cluster or could one node have a different view than the other? And if so, for how long? These questions all touch on the issue of consistency.</p>
<p>In swarm mode, managers all share a consistent internal state of the entire swarm. This avoids any potential issues that could arise if managers were allowed to eventually converge to a shared state. Workers, on the other hand, do not share a view of the entire swarm. That is exclusively a manager responsibility.</p>
<p>The managers maintain a consistent view of the state of the cluster by using a consensus algorithm. There are several consensus algorithms to choose from and the implementation details are outside the scope of this course. But the consensus algorithm has an impact on how the swarm operates. We’ll look at the basics of swarm modes consensus algorithm so we can understand the implications in operating a swarm.</p>
<p>Raft Consensus<br>The consensus algorithm used by managers to maintain a consistent view of the state of the cluster is called Raft. Raft achieves consensus by electing one manager as the leader. The elected leader makes all of the decisions for changing the state of the cluster to bring it to the desired state. For example, the leader accepts new service requests and service updates and also decides how to schedule tasks.</p>
<p>In order to maintain a consistent view across the managers, the decisions aren’t acted upon until a majority of managers agree on the proposed changes to the cluster. A manager “agrees” simply by receiving a proposed change and acknowledging they received it. When the leader is certain a majority of managers have received the proposed change, the change can be implemented. In this context, the majority of managers are referred to as a quorum.</p>
<p>The reason why a quorum is enough to proceed is because Raft limits how many managers failures it can tolerate. If you have N managers in a swarm, Raft allows for (N-1)&#x2F;2 failures. In the case of a three manager swarm, that means 3 minus 1 divided by two is one, so one manager can fail and the swarm can continue to operate as usual. If two managers were to fail, the cluster state would freeze until a quorum of managers again became available. In the absence of a quorum, currently running services will continue to run but no new scheduling decisions take place.</p>
<p>Regarding leader elections, when a swarm is initialized the first manager is automatically the leader. If the currently elected leader fails or voluntarily steps down, say to perform system updates, an election between remaining manager nodes takes place. Until a newly elected leader is chosen, the cluster state is frozen.</p>
<p>Manager Tradeoffs<br>After that overview of Raft consensus, you might be tempted to add a lot of managers to your swarm. The more managers, the more failures your swarm can tolerate and remain fully operational. Although, that is true, the more managers that are in the swarm also increases the amount of managerial traffic required for maintaining a consistent view of the cluster and the amount of time it takes to achieve reach consensus with every state change. Although increasing managers does increase fault-tolerance it generally decreases performance and scalability.</p>
<p>There are some general rules for setting the number of managers:<br>You should usually have an odd number of managers. Having an even number of managers doesn’t improve the fault tolerance compared to having one less manager and increases communication overhead.<br>A single manager swarm is acceptable for development and test swarms. Because a single manager swarm can’t tolerate any failures, it is not something you should use in production.<br>A three manager swarm can tolerate one failure, while a five manager swarm can tolerate two.<br>Docker recommends a maximum of seven managers which can tolerate three manager failures. Above seven has too much of an impact on performance to be beneficial.</p>
<p>However many managers you settle on, you will want to distribute them across availability zones to maintain a fully operational swarm in the event of a datacenter outage. Docker recommends distributing across at least three availability zones in production.</p>
<p>Working Manager<br>There is another tradeoff when considering managers in a swarm. Have you heard the bad joke that goes “Don’t stand around doing nothing. People will think you’re the boss.” In swarm mode, you need to consider whether or not you let the boss, or the managers, do work. By default managers perform worker responsibilities, namely running tasks. But that has more to do with enabling single node swarms than anything.</p>
<p>Because managers participate in the Raft consensus process, it can be detrimental to the performance of the swarm if managers are overly utilized. You can use conservative resource reservations to make sure that managers won’t become starved for resources. To be on the safe side, you can also prevent any work from being scheduled on manager nodes by draining them. Draining essentially removes any tasks currently on a node and preventing new tasks from being scheduled to it.</p>
<p>Worker Node Tradeoffs?<br>You might be wondering if there are any tradeoffs to consider when adding worker nodes to a swarm. There really isn’t much to worry about in the case of adding more worker nodes. More workers give you more capacity for running services and improves service fault tolerance. More workers don’t affect the manager’s raft consensus process so the swarm performance isn’t harmed.</p>
<p>Workers actually do participate in a consensus process. To exchange overlay network information nodes participate in a weakly-consistent, highly scalable gossip protocol called SWIM. The details are outside the scope of this course and the performance implications are negligible. The protocol is an example of an eventually consistent model where the network state is allowed to differ between nodes but eventually they converge on a consistent view.</p>
<p>Raft logs<br>The last topic we’ll discuss in this lesson is Raft logs. If you arrived at this lesson from a search for log rafts, I’m afraid you’ll need to continue your search. The logs we’re talking about are where the leader manager records the Raft consensus state changes, such as creating a new service or adding a new worker. These logs are what get shared with other managers to establish a quorum.</p>
<p>The Raft logs are persisted to disk. The logs are stored in the raft subdirectory of your Docker swarm data directory. This is &#x2F;var&#x2F;lib&#x2F;docker&#x2F;swarm on Linux by default. As part of a disaster recovery strategy, you can back up a swarm cluster by backing up the entire swarm directory which includes certificates and other files in addition to the raft change logs in the raft subdirectory. You can restore a new swarm from a backup by replacing the directory swarm directory with the backed-up copy.</p>
<p>Recap<br>That’s everything for this lesson. We started by understanding how swarm mode solves consistency challenges by electing a leader manager and ensuring a majority of managers acknowledge swarm changes. This strategy comes from the Raft consensus algorithm. We understood the tradeoffs between fault tolerance and performance when choosing the number of managers in a swarm, as well as whether or not managers should do work. We finished by discussing the raft logs which are persisted on disk and record all the changes the leader makes to a swarm.</p>
<p>Closing<br>In the next lesson, we will cover the security measures included in swarm mode. Continue on to the next lesson when you are ready to learn about security in Docker swarm mode.</p>
<h1 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h1><p>Docker takes security seriously. All the security features that you can use when not running in swarm mode can be used in swarm mode. This includes using trusted images, encrypted communication with docker engines, and kernel security features leveraged by Docker. This lesson covers the security provisions in Docker swarm mode.</p>
<p>Agenda<br>We’ll begin by covering the<br>“ (Cluster Management) cluster management aspects of swarm security<br>“ (Data Plane) Next, we will discuss security of data communicated between services<br>“ (Secrets) After that, we’ll see how swarm secrets are kept secure.<br>“ (Locking a Swarm) Lastly, the locking functionality of a swarm will be described.</p>
<p>Cluster Management<br>Docker swarm mode uses public key infrastructure (PKI) to secure swarm communication and state. Swarm nodes encrypt all control plane communication using mutual transport level security (TLS). When you initialize a swarm, Docker assigns the node that executed the command as a manager. The manager automatically creates several resources for security:<br>“ A root Certificate Authority (CA): This plays the standard role of a CA in PKI by being a trusted entity that issues certificates verifying the identity of certificate holders.<br>“ A key pair: This is the public and private key used for secure communication between nodes in the swarm.<br>“ A worker token: This token is used to by nodes to join the swarm as a worker node. The token is a digest of the root CA and a secret.<br>“ A manager token: This is similar to the worker token but used to join nodes as managers in the swarm.<br>Whenever a new node joins the swarm, the manager issues a new certificate identifying the node. The node uses the certificate for communicating in the swarm. New manager nodes also get a copy of the root CA certificate so that they can take over leadership in the event of an election.</p>
<p>You can use an alternate CA instead of allowing Docker to automatically handle their creation for you. The CA can also be rotated out whenever your security policies require it. Rotating the CA will automatically rotate the TLS certificates of all swarm nodes in the cluster.</p>
<p>Data Plane<br>As for the data plane, you can enable encryption of overlay networks at the time of creation. Any time traffic leaves a host an IPSec encrypted channel is used to communicate with a destination host where the traffic is decrypted. The swarm leader periodically regenerates and distributes the key used for encrypting IPSec data plane traffic. Overlay network encryption is not supported for Windows as of Docker version 17.12.</p>
<p>Raft Logs&#x2F;Secrets<br>The Raft logs are encrypted at rest on the manger nodes. This protects against intruders that gain access to the raft logs on disk. The encryption is particularly important because swarm secrets are stored in the raft logs. Secrets are a feature of swarm that allows you to securely store secrets that can be used by services. This could include passwords, API keys, or any other information you wouldn’t want to be exposed over the network or in a Dockerfile. In Windows, secrets are supported in version 17.06 an above.</p>
<p>Locking a Swarm<br>A challenge with encrypting the raft logs is that the keys used to encrypt the logs needs to be stored somewhere a manager has access to. By default, the keys are stored on disk along with the raft logs. If an attacker gains access to the raft logs, there is a good chance they could gain access to the keys used to encrypt them. They could then decrypt the logs and expose any secrets therein.</p>
<p>For an extra layer of security, a swarm allows you to take control of the key used for encrypting the logs. This allows you to implement strategies where the key is never persisted to disk. This works with a swarm feature called autolock. When a swarm is autolocked, you must provide the key when starting a docker daemon. For greatly improved security, you have to pay that price of requiring manual intervention when a manager is restarted. You can rotate the key at any point or disable autolock so managers can be restarted without intervention.</p>
<p>Recap<br>In this lesson, we saw the security measures that are in place in out of the box when using swarm mode. This included several security layers with regards to managing a cluster. We also saw how overlay network communication can optionally be encrypted to secure communication between services. Swarm supports sharing secrets and uses encryption to protect the secrets on disk in the manager Raft logs. The keys for decrypting the logs are stored on disk by default, but you can use autolocking to take control of the keys and improve the defense of your swarm.</p>
<p>Closing<br>We have now covered all of the architecture topics related to swarm mode. In the following lesson group, we will get hands-on with a swarm and see how to operate and use a swarm from the command line and by describing applications in stack files.</p>
<h1 id="Setting-Up-a-Swarm"><a href="#Setting-Up-a-Swarm" class="headerlink" title="Setting Up a Swarm"></a>Setting Up a Swarm</h1><p>All right, this lesson and remaining lessons focus more on getting hands-on with Docker swarm mode. You will see a lot of the concept knowledge that you’ve built up in the previous lessons in action. These lessons will focus more on the commands you need to use to accomplish tasks related to swarm mode, starting with setting up a swarm.</p>
<p>We will begin by laying out the options available to you for setting up a swarm mode cluster. After that we’ll show two ways to set up a swarm locally on your machine: as a single node swarm and as a multi-node swarm using virtual machines.</p>
<p>There are several options for creating a swarm mode cluster. You should consider factors such as the workloads you want to deploy on the swarm, the management complexity, and cost when determining which option to choose.</p>
<p>The simplest option is creating a single-node swarm. Recall that swarm mode managers can also perform work by default meaning that you can run swarm workloads with a single node. We will see later in this lesson how easy it is to set up. This may be appropriate in development and test scenarios. With no fault tolerance, it is not something to do in production.</p>
<p>The other options are for multi-node clusters. There are unmanaged options that you put you in charge of maintaining the infrastructure and applying patches, and there are more managed options where you can use the swarm as a service without worrying about hardware or software patches.</p>
<p>For the unmanaged option, you would likely have your own compute cluster or private cloud. You would need to ensure Docker is installed on the bare metal servers or on virtual machines running on top. The network firewall would need to allow traffic on the ports swarm mode requires (TCP port 7946 and UDP ports 7946 and 4789). The Universal Control Plane that is available through Docker Enterprise edition can set up an on-prem swarm using a graphical interface.</p>
<p>Here is a screenshot of the UCP web interface in action showing a three node swarm.</p>
<p>We will setup a multi-node cluster using VMs on a single physical host later in this lesson. You could run VMs in a public cloud and make a swarm out of the VMs. However, there may be a better option if you are going to leverage the public cloud.</p>
<p>For the more managed options, you could use cloud provider templates that allow you to set a few parameters and have swarm created for you. This is true for Microsoft Azure, Amazon Web Services, and IBM Cloud. You can also leverage Docker’s Docker Cloud offering to create swarms on Azure and AWS through the Docker Cloud graphical interface. Each option is explained in Docker’s own documentation.</p>
<p>Now, it’s time to demo setting up some swarms. I’ll first setup a single node swarm and then a multi-node swarm using virtual machines and the help of the docker-machine command.</p>
<p>I’m here at my terminal on my mac. I have Docker for Mac installed<br>$ docker version<br>To see the current status of the Docker daemon’s swarm mode, you can use the docker info command and look for the Swarm key:</p>
<p>$ docker info | grep Swarm<br>The inactive value means the daemon is not running in swarm mode.</p>
<p>Now we’ll see how easy it is to start running in swarm mode. The commands relevant to managing a swarm are under the swarm subcommand of the Docker CLI.</p>
<p>$ docker swarm –help<br>In the commands list you see everything from rotating the root certificate authority for a swarm to unlocking a locked swarm. The only command needed to start a new swarm is </p>
<p>$ docker swarm init<br>And that’s all that it takes to start running a single-host swarm. The output tells you that the current node is running as a swarm manager and provides a command for joining workers to the swarm. The value of the token argument is the worker join token. A similar looking token is used for joining manager’s to a swarm as seen from the join-token manager output</p>
<p>$ docker swarm join-token manager</p>
<p>Let’s probe around to see some of the changes that occur when you start running in swarm mode. First, let’s revisit the docker info output<br>$ docker info<br>The state has changed to active to indicate that the daemon is indeed running in swarm mode. There is also a bunch of useful tidbits related to the swarm’s configuration: Number of managers, number of nodes, right down to internals of the Raft consensus algorithm. You can even eek out additional information including TLS certificate info by using the format flag and specifying the Swarm field</p>
<p>$ docker info –format ‘‘<br>I’ll clear that because it is quite unsightly and there is no pretty print option.</p>
<p>We can also verify that the networks we learned in the swarm architecture lessons have been created<br>$ docker network ls<br>Here we see the docker_gwbridge local bridge network for connecting overlay networks to the hosts network and the ingress network used for handling external ingress traffic to the swarm.</p>
<p>That’s all there is to the single-node swarm. You could start using it for development and test scenarios as is. For demonstration purposes, I want to use a multi-node cluster so I will tear down our current swarm. To do that, you force leave the swarm<br>docker swarm leave –force<br>The force flag is required because when the last manager in a swarm leaves all the swarm state goes with it. This is what we want to happen in this case.</p>
<p>I’ll set up a multi-node swarm with two workers and one manager for demonstrating various swarm concepts. Remember that one manager is not a good idea in production, but it is going to be enough to illustrate working with a swarm mode cluster. To quickly create Docker-enabled VMs, I’m going to use docker-machine.<br>$docker-machine<br>docker-machine comes installed with Docker for Mac and Docker for Windows. Only a few docker-machine commands are needed so I’ll explain them as they are required. But know that there is a lot more to docker-machine than what I’ll explain in this lesson.</p>
<p>The first command is create, which does exactly what you’d expect. </p>
<p>$ docker-machine create vm1<br>By default it will create a VM in VirtualBox using an image with docker installed. Virtualbox was installed previously on my mac so everything went off without a hitch. I’m using the names vm1, vm2, and vm3 instead of more descriptive names like manger1 because it’s possible for nodes to change their role in a swarm. However, vm1 will be used as the manager in this lesson. I’ll speed this up until it finishes…<br>Now I’ll create vm2 in the same way</p>
<p>$ docker-machine create vm2<br>And finally vm3</p>
<p>$ docker-machine create vm3<br>Now I’ll use the ls command to list the vms and their IP addresses</p>
<p>$ docker-machine ls<br>The machines are at 192.168.99.100, 101, and 102. The VMs are running the 18.01 edge release which doesn’t have any significant changes in swarm mode compared to the 17.12 stable release I have running on my Mac. I’ll connect to vm1 using docker-machine’s ssh command</p>
<p>$ docker-machine ssh vm1<br>And I’ll show docker info to confirm that docker is installed but swarm mode is inactive</p>
<p>$ docker info<br>To initialize a swarm, I’ll use the same init command as with a single-node setup but with an advertise address:</p>
<p>$ docker swarm init –help<br>The advertise address is the IP address other nodes will use to join the swarm.</p>
<p>$ docker swarm init –advertise-addr 192.168.99.100<br>I’ll give the IP address but you could alternatively provide the network interface name. I’ll copy the prepared join command for joining workers. You can always retrieve the join token later using the join-token swarm subcommand.<br>I’ll drop out of vm1 and ssh into vm2 to join the swarm</p>
<p>$ exit</p>
<p>$ docker-machine ssh vm2</p>
<p>$ docker swarm join …<br>The output acknowledges that the node joined the swarm as a worker node. Now I’ll repeat the process for vm3.<br>To confirm the swarm has one manager and 3 nodes in total, I need to run the docker info command on the manager node, which is vm1. </p>
<p>$ docker info<br>There we have it, a 3-node swarm with one manager setup with the help of docker-machine.</p>
<p>In this lesson, we learned some of the options available for setting up a swarm mode cluster. These included some high touch options putting you in charge of the hardware and software patching to fully automated solutions like the one provided by Docker Cloud allowing you to spin up a swarm on Amazon Web Services or Azure from the comfort of a graphical interface.<br>We then saw how to set up a single node swarm using the swarm init command<br>After we set up a multi-node swarm with the help of docker-machine and Virtualbox. The same init command was used with an advertise address for other nodes to use to join the swarm using the join command.</p>
<p>This is a depiction of the swarm that we currently have set up. vm1, vm2, and vm3 are all in the swarm, while my mac is not participating in the swarm. vm1 is the swarm manager, as indicated by the orange tie. We’ll use this multi-node swarm for the remainder of the lessons.</p>
<h1 id="Managing-Nodes"><a href="#Managing-Nodes" class="headerlink" title="Managing Nodes"></a>Managing Nodes</h1><p>We now have a 3-node swarm with one manager. This lesson will demonstrate how to perform swarm node management tasks. For example, promoting a worker to a manager, organizing nodes with labels, and preventing manager’s from doing work.</p>
<p>Agenda<br>I’ll give a brief overview of the swarm node management tasks we’ll be going through. We’ll spend most of the time at the command-line where we’ll execute the tasks on the swarm we stood up.</p>
<p>Node Management<br>Promoting<br>The first task that we’ll go through is promoting a worker node to a manager. You may want to do this to increase your fault-tolerance or in order to take an existing manager out of service without impacting the number of managers available. Remember that if you are going for an increase in fault-tolerance that you should increase the manager count up to the next odd number. For example, going from one manager to three.</p>
<p>Demoting<br>Demoting is the opposite of promoting. It takes a node that is currently in a manager role and demotes the node to a worker role.</p>
<p>Availability<br>The availability of a node refers to the ability to schedule tasks to the node. It isn’t whether a node is up or down which one might logically guess. The availability of a node is configured by managers. The allowed availability states are: active, pause, and drain. Active means that work can be scheduled on a node, pause means no new work can be scheduled but existing work scheduled on the node won’t be canceled, and drain means nothing can be scheduled and any running work is terminated. Setting availability to drain is useful for gracefully taking a node offline to perform maintenance. Draining managers is also useful to prevent them from having work scheduled to them, which is the default behavior.</p>
<p>Labeling<br>The final node management task that we’ll demonstrate is labeling. Recall that labels are useful for influencing where services are placed in a swarm. For example, labels can be used to ensure that tasks are scheduled in different availability zones to provide service availability SLAs.</p>
<p>Demo<br>Now I’ll hop over to the command-line and start with the demo</p>
<p>I’m connected into the vm1 swarm node which is currently the manager of the swarm. In docker, node management tasks are accomplished by using the docker node management command.</p>
<p>$ docker node –help<br>There are some standard commands that are available for most docker management commands: namely ls for listing nodes, ps for listing tasks scheduled to nodes, and rm for removing nodes from a swarm. Inspect is also a familiar docker command that lists detailed information about a node. To get a view of the swarm, I’ll run the ls command</p>
<p>$ docker node ls<br>And we see the three nodes, that all three are available, and that only vm1 is a manager, and is therefore the leader.</p>
<p>To promote vm2 to the manager role in the swarm, I’ll use the promote command:<br>$ docker node promote vm2<br>And easy as that vm2 is now a manager in the cluster</p>
<p>$ docker node ls<br>The manager status of reachable means the node is a manager and is participating in the Raft consensus quorum. The other possible manager status is unavailable, which indicates the manager has a problem communicating with the other managers.</p>
<p>To change vm2 back to the worker role, I’ll use the demote command:<br>$ docker node demote vm2</p>
<p>$ docker node ls</p>
<p>Next up is modifying the availability of a node. You can use the update command for that<br>$ docker node update –help<br>The availability option does what we want. You can also see the label-add and label-rm options which add and remove labels from nodes. There’s also the role option which promote and demote are a short form of updating a node to the role of either worker or manager. Let’s say we don’t want the manager to have any tasks scheduled to it, so I’ll set the availability of vm1 to drain</p>
<p>$ docker node update –availability drain vm1</p>
<p>$ docker node ls<br>and the availability in the ls table reflects the change.</p>
<p>I actually want the manager to be able run tasks so I’ll undo that by setting availability to active<br>$ docker node update –availability active vm1</p>
<p>To finish up I’ll add a fictitious availability zone labels to each node using the label-add update option. I’ll say vm1 is in zone 1, vm2 is in zone 2, and vm3 is in zone 3:<br>$ docker node update –label-add zone&#x3D;1 vm1</p>
<p>$ docker node update –label-add zone&#x3D;2 vm2</p>
<p>$ docker node update –label-add zone&#x3D;3 vm3<br>To see node labels, you need to use the inspect command</p>
<p>$ docker node inspect vm3<br>Here is the labels property in the Spec. You can also filter out everything but the labels by using the format option with a Go template</p>
<p>$ docker node inspect -f ‘&amp;#123;&amp;#123;.Spec.Labels&amp;#125;&amp;#125;’ vm3<br>Here again is the zone label key-value pair in the Labels map.</p>
<p>Recap<br>In this lesson we learned about the node management tasks that are part of managing a swarm. We understood the concepts and demonstrated how to promote and demote a node, set a node’s availability, and label swarm nodes.</p>
<p>This slide shows the current state of our swarm. Each node is now labeled with a zone compared to where we began the lesson.</p>
<p>Closing<br>In the next lesson, we’ll see how to schedule tasks onto the swarm by using services. If you are ready to see swarm mode in action, continue on to the next Lesson.</p>
<h1 id="Managing-Services"><a href="#Managing-Services" class="headerlink" title="Managing Services"></a>Managing Services</h1><p>Services are what make up distributed applications running on a swarm. In this lesson, we’ll get experience running and managing services in our swarm.</p>
<p>Agenda<br>To begin, I’ll give a quick rundown of what services we’ll be running, and then we’ll get into the demo.</p>
<p>The Plan<br>I’ll use two images for demonstrating how to work with services.<br>The first is a swarm visualizer provided by Docker. It allows you to visualize the state of nodes in a swarm and see where service tasks have been scheduled. It requires information that only manager nodes have access to. We’ll constrain the placement of the service to make sure it gets what it needs.<br>The second is a web service that serves a simple web page that displays the name of the node running the task. This will give us a way to verify that requests are load balanced across multiple nodes when using the ingress network in swarm.</p>
<p>Demo<br>Ok, now let’s get to the demo.</p>
<p>When working with services, all of the commands are conveniently located under the docker service management command<br>$ docker service –help<br>There are some familiar commands: inspect, logs, ls, ps, and rm. They do what you would expect given your knowledge of the Docker CLI. We’ll use them as we work through this demo. We’ll give the rest more attention, starting with create.</p>
<p>$ docker service create –help | more<br>This is the equivalent of docker run for swarm services. There are too many options to go through. Several match docker run options and several others are unique to services. We’ll go through some of the unique ones in this lesson and save some for the next.</p>
<p>Let’s start by creating the swarm visualizer. The visualizer must run on managers, so we can use a constraint on the node role to handle that. For demonstration purposes, I’ll make the service global so that every manager will run one task for the service. The service could be load-balanced since the swarm state that the service visualizes is the same regardless of which manager you use. But I will publish the port using host mode so we can compare that to ingress mode. Ingress mode is the default, so the mode&#x3D;host part of the string must be provided. The mount option is required so that the service containers can access the manager node’s docker daemon socket. That is where it pulls the swarm state information from. Finally, we’ll give the service the name viz and specify the latest version of the dockersamples&#x2F;visualizer image.</p>
<p>$ docker service create <br>–constraint&#x3D;node.role&#x3D;&#x3D;manager <br>–mode global <br>–publish mode&#x3D;host,target&#x3D;8080,published&#x3D;8080 <br>–mount&#x3D;type&#x3D;bind,src&#x3D;&#x2F;var&#x2F;run&#x2F;docker.sock,dst&#x3D;&#x2F;var&#x2F;run&#x2F;docker.sock <br>–name&#x3D;viz <br>dockersamples&#x2F;visualizer</p>
<p>The commands can get pretty long and we’ll see how to bettern manage them in the next lesson. I’ll speed things up until it is finished. The service converged message lets us know that the actual state has converged to the desired state in the service spec. We can see the service spec using inspect<br>$ docker service inspect viz –pretty | more<br>This output shows some of the default values that were used, such as the update and rollback config. It also shows that the service mode is global and that the port has been published in host mode. We can use the ps command to confirm the actual state matches the desired state</p>
<p>$ docker service ps viz</p>
<p>Now let’s switch over to a web browser to see the swarm visualizer. The manager is running on vm1 which has an IP address of 192.168.99.100. The visualizer displays a column for each node. The node’s name, role, memory, operating system, and the hard to read text is the node labels we applied earlier. Tasks are shown with squares under each node’s heading. Currently there is only the one visualizer task. If we didn’t have any role constraint there would be one on every node, but because the service was constrained to managers, there is only one. Task borders are color-coded according to their service. Because the service published its port in host mode, I have to use the manager’s IP. If I try vm2’s IP, it won’t be able to reach the service. So I’ll go back to vm1’s IP address.</p>
<p>I’ll promote vm2 to be a manager and that will cause a viz replica to be started on vm2 because the viz service is global. I’ll use the ls command to see the change. Notice the replicas has jumped up to 2. After awhile there will be 2 of 2 tasks running and I can try again to access the visualizer on vm2 in the browser. There it is. Both vm1 and vm2 are manager’s and there are two replicas of the viz service shown. I’ll go back to vm1’s visualizer and demote vm2 back to a worker. Now we’re back to just one viz replica.</p>
<p>Let’s focus in on the 2nd service now. I’ll switch over to VS Code and quickly go through the source. This file, index.php, is doing going to echo back the node name which it gets from an environment variable. That’s all there is to it. Taking a look at the Dockerfile, the base image is an php image with the apache web server installed. The index.php source file is copied into the image and the web server serves it on port 80. There is also a healthcheck embedded in the image. You can of course override the image healthcheck or create a healthcheck if the image doesn’t have one when you create the service. This is the same behavior as with docker run.</p>
<p>Back to the command line. We’ll create the service with a constraint to not schedule any tasks in zone 1. The exclamation mark followed by equals means not equal to. We’ll declare 2 replicas. This implies the service mode is replicated and not global. replicated is also the default. The manager will try to spread the tasks over available nodes by default, but we will specify a placement preference to take control of how it spreads. Next, I’ll add an environment variable for the NODE_NAME and use a Go template to get the hostname of the node. Port 80 will be published in ingress mode by default making the service reachable from any node’s IP address regardless of if a task is running on the node. I’ll give the service the name nodenamer and specify version 1.0.0.</p>
<p>$ docker service create <br>–constraint node.labels.zone!&#x3D;1 <br>–replicas 2 <br>–placement-pref ‘spread&#x3D;node.labels.zone’ <br>-e NODE_NAME&#x3D;’&amp;#123;&amp;#123;.Node.Hostname&amp;#125;&amp;#125;’ <br>–publish 80:80 <br>–name nodenamer <br>lrakai&#x2F;nodenamer:1.0.0</p>
<p>Now the two tasks move through the preparing, and starting states to reach the running state before the service converges to the desired state. We can check on the swarm state in the visualizer. There are two tasks for the nodenamer service and they have a dark grey border. They are deployed evenly across all the zones except zone 1 as we constrained the placement. We can also test the ingress routing capabilities. I’ll send a request to port 80 on vm1 which isn’t running a task for the service. But the page loads thanks to the ingress routing mesh. if I reload a few times, you can see the node name changing. This illustrates the virtual IP load balancing of the service. If I send my requests to vm2, the behavior is the same.</p>
<p>Back at the command-line I can also access the service at localhost on vm1 through the ingress network.<br>$ curl localhost<br>The output doesn’t have new line so the command prompt gets tacked onto the end. Version 1.0.1 of nodenamer fixes this issue. We’ll do a rolling update to version 1.0.1. Before we do, we can inspect the service</p>
<p>$ docker service inspect nodenamer<br>and observe the setting for updates. Parallelism is one by default so only one task will be upgraded at a time. We won’t look at failed updates, so the only other relevant setting is update order which is only available in Docker 17.05 and above. It defaults to stopping existing tasks and then starting a new task. The other value is start first, which starts a new task first and then stop the old one when the new task is running. There’s also update delay which sets the delay between rolling updates. It defaults to zero which is not a problem in this case, we’ll still be able to see the update roll through because it takes some time for new tasks to get to running. Let’s do the update to version 1.0.1</p>
<p>$ docker service update –image lrakai&#x2F;nodenamer:1.0.1 nodenamer<br>And switch over the the visualizer to watch the update roll through. The old task on vm2 is taken down first, then a new task using the 1.0.1 image comes in. As soon as it reaches the running state, the task on vm3 is stopped and a new 1.0.1 image task starts.<br>Now if I curl localhost from vm1, the new line is added to the output.</p>
<p>We can scale up the service to, say 6 replicas using the scale command<br>$ docker service scale replicas&#x3D;6<br>and we will see them come up equally spread across the eligible nodes. Even though there are more than one task on each node there are no port conflicts. This wouldn’t be the case if host mode was used for publishing the service port.</p>
<p>Let’s set the parallelism for rollbacks to 2 so we can rollback faster than we update.<br>$ docker service update –rollback-parallelism 2<br>Then we intentionally update the service back to version 1.0.0 so we can finish the lesson with a rollback to version 1.0.1.</p>
<p>$ docker service update –image lrakai&#x2F;nodenamer:1.0.0 nodenamer<br>And we can see it roll through 1 task at a time.<br>Now we can rollback</p>
<p>$ docker service rollback nodenamer<br>and we should see two tasks at a time being rolled back. There we see it rolling back two at a time.</p>
<p>That’s it for this lesson. You now know how to put the theory we studied earlier into practice by using the docker service management command for managing services.</p>
<p>Closing<br>In the next lesson, we’ll cut down on the lengthy commands and improve the repeatability and maintainability of swarm service deployments by using stacks. Whenever you are ready, continue on to the next lesson.</p>
<h1 id="Working-with-Stacks"><a href="#Working-with-Stacks" class="headerlink" title="Working with Stacks"></a>Working with Stacks</h1><p>Stacks help you manage applications distributed across a swarm. In this lesson, we’ll get some practice working with stacks. I think you’ll find that it’s easy to get the hang of and better than writing sprawling, multi-line docker service create commands.</p>
<p>Agenda<br>We’ll start the lesson by introducing stacks and stack files. It won’t take very long because your prior experience with Docker Compose will serve you well here. Then we’ll get started with a demo. Our last demo of the course.</p>
<p>Stacks<br>In swarm mode, stacks are a group of related services that can be orchestrated and scaled together. It carries the same meaning as a software stack or technology stack in application development.</p>
<p>Stacks are declared using a Compose file. That makes it very easy to start using stacks given your Docker Compose experience. You can use stacks to manage services, networks, and volumes as you would with Docker Compose. For a compose file to work as a stack, you have to be using Compose file version 3 or greater. Although they are the same type of file, when you deploy an application declared in a compose file to a swarm, it’s referred to as a stack. By convention, the file name that is used to indicate a stack is docker-stack.yml.</p>
<p>A lot of the Docker Compose features you know and love work with stacks. These include the declarative configuration, an active community on Github, and the benefits of source-controlled configuration. Similar to Compose, when you deploy a stack a network is created by default to isolate the stack from other services.</p>
<p>However, there are some differences between using Docker Compose and stacks that you should be aware of. Currently, there are several configuration options that are ignored with stacks that you could use in Compose. Some of the most notable ones are build and depends_on. The Compose file reference documentation should be consulted as support is added&#x2F;removed for options over time. A link to the documentation is at the bottom of the transcript for this video.</p>
<p>On the flip side, what’s stacks can use that Compose can’t are mostly gathered under the deploy key. That is where you can specify options for node labels, replication mode, resource reservations, update configuration, and others. Currently, there isn’t support for configuration rollbacks in a stack file, and placement preferences and endpoint_mode for setting virtual IP or DNS round robin service discovery are only available in version 3.3 Compose files or above. Stack files also support swarm secrets by a top-level secrets key. We won’t get into the details but know that they are supported.</p>
<p>With previous experience in Compose, that’s all that we need to go over to start using stacks in swarm mode. We can get started with the demo which will reproduce what we did in the last lesson’s demo except using stacks.</p>
<p>Demo<br>I’ll start by removing the currently running services we deployed with docker service create, since we’re going to recreate them using a stack.<br>$ docker service rm viz nodenamer</p>
<p>Now let’s take a look at the stack file. I won’t dwell on it since it is a one-to-one mapping of the commands we entered to create the services before except with more structure and slightly different option names. The stack specific options are under the deploy keys. Because we have a placement preference, we need to use version 3.3 or higher. It is more pleasant to work with stacks compared to entering all the options at the command-line. We’ll also see next that commands for stacks can limit output to services declared in a stack without having to do any filtering.</p>
<p>The commands for working with stacks are organized under the docker stack management command<br>$ docker stack –help<br>ls lists the current stacks, services lists the services in a stack and ps lists all the service tasks for a given stacks. The deploy and rm commands are similar to docker-compose up and down. In fact, up and down are aliases for deploy and rm so you could use up and down with stacks if you prefer.</p>
<p>Let’s look at the deploy options<br>$ docker stack deploy –help<br>You have options for removing services that are no longer in a stack, controlling when images are resolved, and for passing along credentials if you are using images in a private Docker registry. The one required option is -c to specify a Compose file for the stack.</p>
<p>$ docker stack deploy -c docker-stack.yml demo<br>I’ll call the stack demo. We can see the stack has a network created automatically for the services in the stack. Of course, you can, and often should, exercise more control over the networks you want, just as you would in Docker Compose. The stack has finished deploying so we should see the visualizer on port 8080 of vm1, and there it is.</p>
<p>To do an update you use the same deploy command you used with the original stack deploy. Let’s make an update to the stack so there are 6 replicas, and let’s also put a resource reservation of half a cpu for each nodenamer replica. Each vm only has one cpu so there won’t enough cpu available for all 6 replicas. We’ll use this to verify that swarm respects the resource constraints. Re-run the deploy command<br>$ docker stack deploy -c docker-stack.yml demo<br>The configuration changes will be detected, and the swarm leader will bring the swarm to the new desired state. Let’s watch the visualizer to see what happens. We can see 2 new tasks starting on vm2 and then another on vm3. After all the tasks on vm2 are running one is stopped to respect the resource reservations. We can also see from listing the services in the stack that only 4 of 6 tasks for nodenamer are running while two are left pending.</p>
<p>That’s all for this demo and this lesson. We saw that working with stacks is a natural extension of Compose files and docker commands.</p>
<p>Closing<br>We’ve almost reached the finish line now! Join me for the final lesson when you’re ready to wrap up the course.</p>
<p><a target="_blank" rel="noopener" href="https://docs.docker.com/compose/compose-file">Compose File Reference</a></p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Here we are the of this course about container orchestration with Docker swarm mode. I hope you it has been as fun for you as it was for me. We covered a lot of ground in this course. Let’s take a look back at what we learned.</p>
<p>Course Review<br>We started with a high-level overview of swarm mode and then dove into various components of the swarm mode architecture. The first was networking.<br>We learned about the overlay network type that makes networking swarm services distributed across multiple hosts extremely easy.<br>We saw how swarm accomplishes load balancing by virtual IP or by DNS round robin.<br>Finally, we saw swarm services can be accessed via any node when using ingress port publishing. That is possible thanks to the swarm mode routing mesh.</p>
<p>After that, we looked at the headline architecture component: container orchestration. In that lesson we saw how to influence the placement of services on the swarm,<br>and we also considered rolling updates and rollbacks.</p>
<p>The next architecture component was consistency. Swarm mode uses the raft consensus algorithm for guaranteeing a consistent state of the swarm. Managers participate in elections and elect a single leader responsible for making changes to bring the actual swarm state to the desired state.<br>We examined the fault-tolerance and performance tradeoff related to the number of managers in a swarm. You should consider using 3, 5, or 7 for production workloads.<br>Lastly, we discussed the raft logs where cluster state is persisted.</p>
<p>Security was the last architecture component we looked at.<br>Swarm mode has many security features enabled by default including public key infrastructure and token semantics for joining members to a swarm.<br>Data plane communication on overlay networks is optionally encrypted using IPSec.<br>We also learned how you can improve swarm security by taking control of keys used for decrypting raft logs through a feature called autolocking.</p>
<p>Then we started getting hands-on and learned about options for setting up swarms from single-node, to mutli-node, and from on-prem to in the cloud. We then created a single-node swarm and a multi-node swarm with the help of docker machine.</p>
<p>Following that, we discussed node management in swarm. We demonstrated routine tasks such as promoting, demoting, labeling, and setting a node’s availability to schedule jobs.</p>
<p>The next demo focused lesson was about service management. We saw how to create and update services using various configurations such as host and ingress routing, global and replicated services, resource and placement constraints, and updates and rollbacks.</p>
<p>In the last demo lesson, we explored using stacks for managing distributed applications in Docker swarm mode. Stacks are represented using Compose files and have swarm specific configuration under the deploy key.</p>
<p>Learning Outcomes<br>By taking this course, you have achieved the following learning outcomes. You are able to:<br>“ Describe what Docker swarm mode can accomplish<br>“ Explain the architecture of a swarm mode cluster<br>“ Use the Docker CLI to manage nodes in a swarm mode cluster<br>“ Use the Docker CLI to manage services in a swarm mode cluster<br>“ Deploy multi-service applications to a swarm using stacks</p>
<p>Learning More<br>There are a few places I can recommend for learning more. Try out some of the labs, quizzes or other courses on Cloud Academy. There is more content on swarm as well as other container orchestration tools in case you want to understand the entire ecosystem.<br><a target="_blank" rel="noopener" href="https://cloudacademy.com/">https://cloudacademy.com</a></p>
<p>The Docker Swarm Mode docs are a great place to learn all the intricacies of swarm mode and to stay on top of release changes.<br><a target="_blank" rel="noopener" href="https://cloudacademy.com/admin/clouda/videos/video/2103/change/https:/docs.docker.com/compose/">https://docs.docker.com/compose/</a></p>
<p>The Docker swarmkit GitHub repository is the ultimate place to learn about swarm mode from its source. See what features are coming next for swarm mode and learn from discussions around reported issues. Maybe even report your own or contribute to the code base.<br><a target="_blank" rel="noopener" href="https://github.com/docker/swarmkit">https://github.com/docker/swarmkit</a></p>
<p>Feedback<br>I’m happy to hear from you. I make content for you. If you have any feedback, please get in touch with me by leaving a comment on the Comments tab below the video, by emailing <a href="mailto:&#x73;&#x75;&#112;&#x70;&#x6f;&#114;&#116;&#64;&#x63;&#x6c;&#111;&#x75;&#100;&#97;&#x63;&#97;&#x64;&#101;&#109;&#x79;&#46;&#x63;&#x6f;&#109;">&#x73;&#x75;&#112;&#x70;&#x6f;&#114;&#116;&#64;&#x63;&#x6c;&#111;&#x75;&#100;&#97;&#x63;&#97;&#x64;&#101;&#109;&#x79;&#46;&#x63;&#x6f;&#109;</a>, or by connecting with me on Twitter where my handle is @LoganRakai.</p>
<p>Thank you<br>That does it for another course here on Cloud Academy. You have developed some serious Docker swarm mode skills and should be proud of your accomplishment. Now go and do me the ultimate service by putting what you’ve learned here into practice. Until next time, I’m Logan Rakai with Cloud Academy.</p>
<p>What’s that? All right, swarm twister, take us away!</p>
<h1 id="1Course-Introduction"><a href="#1Course-Introduction" class="headerlink" title="1Course Introduction"></a>1<strong>Course Introduction</strong></h1><p><a target="_blank" rel="noopener" href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/cloudacademy/docker-swarm-mode-training">Course resources on GitHub</a></p>
<h1 id="7Setting-Up-a-Swarm"><a href="#7Setting-Up-a-Swarm" class="headerlink" title="7Setting Up a Swarm"></a>7<strong>Setting Up a Swarm</strong></h1><p><a target="_blank" rel="noopener" href="https://gitlab.com/gitlab-org/ci-cd/docker-machine">Gitlab Fork</a></p>
<h1 id="10Working-with-Stacks"><a href="#10Working-with-Stacks" class="headerlink" title="10Working with Stacks"></a>10<strong>Working with Stacks</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.docker.com/compose/compose-file">Compose File Reference</a></p>
<h1 id="11Summary"><a href="#11Summary" class="headerlink" title="11Summary"></a>11<strong>Summary</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.docker.com/compose/">Docker Swarm Mode docs</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/docker/swarmkit">Docker Swarmkit GitHub repository</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/19/Docker-Certified-Associate-Docker-Basics-Challenge-4/" rel="prev" title="Docker-Certified-Associate-Docker-Basics-Challenge-4">
      <i class="fa fa-chevron-left"></i> Docker-Certified-Associate-Docker-Basics-Challenge-4
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/19/Docker-Certified-Associate-Manage-Your-Cluster-Using-Docker-Swarm-Mode-6/" rel="next" title="Docker-Certified-Associate-Manage-Your-Cluster-Using-Docker-Swarm-Mode-6">
      Docker-Certified-Associate-Manage-Your-Cluster-Using-Docker-Swarm-Mode-6 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Course-Introduction"><span class="nav-number">1.</span> <span class="nav-text">Course Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Overview"><span class="nav-number">2.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Networking"><span class="nav-number">3.</span> <span class="nav-text">Networking</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Orchestration"><span class="nav-number">4.</span> <span class="nav-text">Orchestration</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Consistency"><span class="nav-number">5.</span> <span class="nav-text">Consistency</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Security"><span class="nav-number">6.</span> <span class="nav-text">Security</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Setting-Up-a-Swarm"><span class="nav-number">7.</span> <span class="nav-text">Setting Up a Swarm</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Managing-Nodes"><span class="nav-number">8.</span> <span class="nav-text">Managing Nodes</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Managing-Services"><span class="nav-number">9.</span> <span class="nav-text">Managing Services</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Working-with-Stacks"><span class="nav-number">10.</span> <span class="nav-text">Working with Stacks</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Summary"><span class="nav-number">11.</span> <span class="nav-text">Summary</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1Course-Introduction"><span class="nav-number">12.</span> <span class="nav-text">1Course Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7Setting-Up-a-Swarm"><span class="nav-number">13.</span> <span class="nav-text">7Setting Up a Swarm</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#10Working-with-Stacks"><span class="nav-number">14.</span> <span class="nav-text">10Working with Stacks</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#11Summary"><span class="nav-number">15.</span> <span class="nav-text">11Summary</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
