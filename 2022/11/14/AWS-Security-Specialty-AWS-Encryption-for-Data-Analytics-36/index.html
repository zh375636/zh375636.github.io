<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="IntroductionHello, and welcome to this course. I shall be looking at the different encryption mechanisms that can be utilized across a range of AWS services, that are commonly used for big data solu">
<meta property="og:type" content="article">
<meta property="og:title" content="AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36">
<meta property="og:url" content="https://example.com/2022/11/14/AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:description" content="IntroductionHello, and welcome to this course. I shall be looking at the different encryption mechanisms that can be utilized across a range of AWS services, that are commonly used for big data solu">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-14T17:52:42.000Z">
<meta property="article:modified_time" content="2022-11-20T02:55:16.000Z">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/2022/11/14/AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36 | Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:42" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:42-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 22:55:16" itemprop="dateModified" datetime="2022-11-19T22:55:16-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-AWS-Encryption-for-Data-Analytics-36/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hello, and welcome to this course. I shall be looking at the different encryption mechanisms that can be utilized across a range of AWS services, that are commonly used for big data solutions, thereby enhancing security around the protection of your data. Before we start, I would like to introduce myself.</p>
<p>My name is Stuart Scott. I’m one of the trainers here at Cloud Academy, and I specialize in AWS, <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">Amazon Web Services</a>. Feel free to connect with me with any questions using the detail shared on the screen. Alternatively, you can always get in touch with us here at Cloud Academy using the community forum where one of our Cloud experts will reply to your question.</p>
<p>This course has been designed for those who are responsible for implementing and managing security, architecting big data solutions, and anyone wanting to learn more about the encryption options available across different AWS services. This course will cover the following topics regarding services that can be used for big data encryption.</p>
<p>Starting with an overview of encryption, this lecture explains what encryption is, the difference between symmetric and asymmetric encryption options, and why you may want to implement encryption in the first place.</p>
<p>Then, I will talk about some of the encryption options for big data storage services, including S3 and Amazon Athena, and how it works with S3 encryption.</p>
<p>Then Elastic MapReduce, followed by RDS. Following these lectures, I will then look at encryption for the Amazon Kinesis platform, which will include Kinesis Firehose, and Kinesis Streams. Finally, I will then look at encryption mechanisms for big data warehousing, where I shall be focusing on Amazon Redshift.</p>
<p>At the very end of the course, there will be a summary lecture highlighting the main points taken from each of the previous lectures within the course. Almost like a cram session.</p>
<p>This course will provide you with an overview of what encryption is, and the differences between symmetric and asymmetric cryptography.<br>You will also gain the knowledge and understanding of available encryption mechanisms that can be used with big data solutions running on the following AWS services; S3, Athena, EMR, RDS, Kinesis Firehose, Kinesis Streams, and Redshift. As I have already mentioned, this course will be based on a number of different AWS services, and so it would be beneficial to have a basic understanding and awareness of each.</p>
<p>It is also recommended that you have an understanding of the Key Management Service, KMS, as this will be referenced throughout the course. If you are unfamiliar with KMS, then we do have an existing course that focuses on the service, which can be found here. Feedback on our courses here at Cloud Academy are valuable to both us as trainers, and any students looking to take the same course in the future.</p>
<p>If you have any feedback, positive or negative, it would be greatly appreciated if you could use the comment section found at the landing page of this course. That now brings us to the end of this lecture. Coming up next, we’re going to start off by looking at an <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/overview-of-encryption-1/">overview of encryption</a>.</p>
<h1 id="Overview-of-Encryption"><a href="#Overview-of-Encryption" class="headerlink" title="Overview of Encryption"></a>Overview of Encryption</h1><p>Hello, and welcome to this lecture where I will be explaining what encryption is at a high level, and when and why you may want or need to use it.</p>
<p>Unencrypted data can read and seen by anyone who has access to it, whether this data is stored at rest or set between two locations in transit, it’s known as plaintext or clear text data.</p>
<p>The data is plain to see and can be seen and understood by any recipient. There is no problem with this, as long as the data is not sensitive in any way and doesn’t need to be restricted. However, on the other hand, if you do have data that is sensitive, and you need to ensure the contents of this data is only viewable by a particular recipient or recipients, then you need to add a level of encryption to that data.</p>
<p>But what is encryption? Data encryption is the mechanism in which information is altered, rendering the plaintext data unreadable through the use of mathematical algorithms and encryption keys. When encrypted, the original plaintext data is now known as ciphertext, which is unreadable. To decrypt the data, an encryption key is required to revert the ciphertext back into a readable format or plaintext.</p>
<p>A key is simply a string of characters used in conjunction with the encryption algorithm, and the longer the key, the most robust the encryption. This encryption involving keys can be categorized by either being symmetric cryptography or asymmetric cryptography. Let’s talk a look at both methods. I’ll start with symmetric cryptography first.</p>
<p>With symmetric encryption, a single key is used to both encrypt and also decrypt the data. So for example, if someone was using the symmetric encryption method, they would encrypt their data with a key, and then when that same person needed to access that data, they would use the same key that was used to encrypt the data to decrypt the data.</p>
<p>However, if the encrypted data was being read by a different person, that person would need to be issued the same key. Remember, the same key is needed to decrypt the data that was used to encrypt it. As a result, this key must be sent securely between two parties, and here exposes a weakness in this method.</p>
<p>If the key is intercepted by anyone during that transmission, then the third party could easily decrypt any data associated with that key.</p>
<p>Some common symmetric cryptography algorithms that are used are AES, advanced encryption standard, DES, digital encryption standard, Triple-DES, and Blowfish. Now let’s compare this to asymmetric encryption, which involves two separate keys.</p>
<p>One is used to encrypt the data, and another separate key is used to decrypt the data. These keys are both created at the same time and are linked through a mathematical algorithm. One key is considered the private key and should be kept by a single party, and should never be shared with anyone else. The other key is considered the public key, and this key can be given and shared with anyone.</p>
<p>Unlike with symmetric encryption, the public key does not have to be sent over secure transmission. It doesn’t matter who has access to this public key, as without the private key, any data encrypted with it cannot be accessed. Both the private and public key is required to decrypt the data when asymmetric encryption has been used.</p>
<p>So how does it work? If another party wanted to send you an encrypted message or data, they would encrypt the message using their own public key, which could be made freely available to them or anyone. It’s public for a reason. This message is then sent to you where you will use your own private key which has that mathematical relationship with your public key to decrypt the data.</p>
<p>This allows you to send encrypted data to anyone without the risk of exposing your private key, resolving the issue highlighted with symmetric encryption. The advantage that symmetric has over asymmetric is the speed of encryption and decryption. Symmetric is a lot faster from a performance perspective.</p>
<p>However, it does carry an additional risk, as highlighted. Some common examples of asymmetric cryptography algorithms are RSA, Diffie-Hellman, and Digital Signature Algorithm. So now we know what encryption is and are familiar with the differences between symmetric and asymmetric algorithms, when and why you may want to use encryption.</p>
<p>It may seem obvious. You want to protect your data, and that’s true. But do you want to protect it at rest or when it’s in transit, or both? And not forgetting other legal requirements, too. Any sensitive data that is stored at rest should be encrypted to protect both you and your customers. Should an untrusted entity gain access to the data, you can be assured that the information held within it cannot easily be accessed, safeguarding your business and your customer’s data from the intrusion.</p>
<p>In today’s world of virtualization and cloud technology, the physical location of stored data is often unknown. When you then couple this with replication, high availability, resiliency, or DR, where your data could be moved and replicated across a series of different AZs and regions automatically by design of some of the AWS services.</p>
<p>By encrypting your data, you be safe in the knowledge that any unexpected distribution of data by AWS would not be accessible by anyone unexpected. Be mindful that when your sensitive data is being moved and distributed, it should be done so via a secure mechanism, providing encryption in transit where possible.</p>
<p>Much of this can be done over HTTPS or SSL within AWS. If encryption in transit is not possible, then at the very least, the data should be encrypted prior to transmission. You may also have to apply encryption mechanisms against your data to adhere to specific compliance and legal controls that may be required to meet internal customer or external governing standards, such as PCI DSS or HIPAA.</p>
<p>By applying encryption to data bound by these standards and governance, it will help you achieve the required controls and compliance requirements. Big data solutions often hold very sensitive information, and so understanding how to apply and adopt encryption methods for different services that can be used for big data is crucial.</p>
<p>That now brings us to the end of this lecture. Coming up next, I’m going to start looking at encryption methods used for Amazon’s Simple Storage Service, known as S3.</p>
<h1 id="Amazon-S3-and-Amazon-Athena-Encryption"><a href="#Amazon-S3-and-Amazon-Athena-Encryption" class="headerlink" title="Amazon S3 and Amazon Athena Encryption"></a>Amazon S3 and Amazon Athena Encryption</h1><p>Hello and welcome to this lecture where I’m going to cover the different <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">encryption</a> mechanisms available for data being stored on S3 and when queried using Amazon Athena. S3 can be used to analyze large-scale data sets of information with the help of Amazon Athena which is an interactive query service that uses standard SQL.</p>
<p>Let me start by discussing the different encryption options available with S3. So, Amazon S3 offers both server-side encryption, SSE, and client-side encryption, CSE. I want to begin by looking at the different options available when using server-side encryption. Server-side encryption known as SSE is used for securing data at rest.</p>
<p>When SSE is applied, the data is encrypted at an object level before it is written to the physical disk that construct S3. If an object is encrypted with SSE, how you access the object remains the same as long as you have the relevant permissions to access the object. There are three different forms of SSE with S3, each providing a different method of encryption key management.</p>
<p>Firstly, SSE with Amazon S3-Managed Keys known as SSE-S3. Secondly, SSE with AWS KMS-Managed Keys known as SSE-KMS, and thirdly, SSE with Customer-Provided Keys known as SSE-C. Let’s take a look of each of these in more detail starting with SSE-S3. With SSE-S3 encryption, Amazon S3 uses a unique key to encrypt each data object and then this key itself is encrypted with a master key, providing a multifactor encryption mechanism.</p>
<p>The complete encryption and decryption cycle of the object is all managed by <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> and can be set by selecting the Amazon S3 master key encryption option when uploading an object in the management console or by using the AWS CLI. The objects are encrypted using one of the strongest algorithms, AES-256. As we know from the previous lecture, AES is a symmetric encryption algorithm.</p>
<p>In this case, symmetric cryptography works well as AWS will manage the encryption and decryption of the object when it is access by a user or service, therefore the key does not need to be sent to anyone else which may risk key exposure. To help enforce an encryption requirement on S3, SSE can work in conjunction with S3 bucket policies.</p>
<p>So, you could enforce conditions within a bucket policy to deny any object that is not uploaded with server-side encryption within the header during a PutObject request. For example, if you are an administrator of an S3 bucket which was being used as your storage layer, you could add the following bucket policy to ensure that only objects that had the SSE-S3 encryption specified were allowed to be uploaded.</p>
<p>This would deny any object that did not have the SSE-S3 server-side encryption enabled. If you are not using the management console to instigate the SSE encryption and instead you were using the AWS CLI, the user would have to add the server-side encryption AES256 parameter to enforce the encryption.</p>
<p>Let me now move on to SSE-KMS to show you how this method of encryption works. As you may have guessed, SSE-KMS uses the key management service to help with key management during encryption. If you are unfamiliar with KMS, then I recommend that you take our existing KMS course to help you understand how the service works and the different components within the service which can be found here.</p>
<p>If you select to use SSE-KMS for your object encryption, you have the opportunity to either select the default AWS S3 customer master key, CMK, which is managed by AWS or to set one of your existing customer-managed CMKs. This key will be used to encrypt the data keys generated by KMS which are then used to encrypt your object data on S3.</p>
<p>So, to be clear, the KMS CMK is used to encrypt the data keys not the actual object itself. With SSE-S3, a multifactor encryption process was used by first encrypting the object data with a data key and then this data key was encrypted with a master key. In the case of SSE-KMS, the master key puts on the same role as the KMS-CMK selected.</p>
<p>When you upload an object to S3 using SSE-KMS, a request is made by S3 to KMS which returns two versions of a randomly generated data encryption key. One version of this data key is plain text which S3 stores in memory and uses to perform the encryption of the object at which point it is removed from memory.</p>
<p>The second version is an encrypted version of the data key and is uploaded with the object. When S3 needs to decrypt the data, S3 sends AWS-KMS the encrypted data key associated with the object and KMS uses the CMK associated to decrypt the data key and responds with a plain text version of the key allowing you to decrypt the object.</p>
<p>Again, this key is stored in memory and will be deleted as soon as decryption has happened. If you don’t have a CMK configured, but you still want to use SSE-KMS, then S3 will automatically create the default AWS S3 CMK for you the first time you upload an object with this encryption type. It will then use the same CMK for all other uploads unless a customer-managed CMK is specified within that same region.</p>
<p>However, this AWS-managed CMK does not provide the same level of management that the customer-managed CMK does. By using your own customer-managed CMK, it gives you far greater flexibility of how your key is managed. For example, you are able to disable, rotate, and apply access controls to the CMK and audit it against their usage using AWS CloudTrail.</p>
<p>Similarly with SSE-S3, SSE-KMS also supports bucket policies. However, a different value needs to be configured for the server-side encryption parameter to indicate SSE-KMS encryption, So, the last option of SSE encryption is SSE-C, so let me now take a look at this option. So, SSE-C is server-side encryption for customer-provided keys.</p>
<p>So, here the encryption is provided to AWS S3 without using KMS and the S3 service itself performs the encryption. All we need to do is to supply the key. When you upload your data object, you must send your customer-provided key with the request. On this point, it’s worth mentioning that SSE-C only works with requests using HTTPS.</p>
<p>S3 will reject any request sent using HTTP. This helps to secure the data in transit, specifically for a customer-provided key. Once the encryption has taken place which will use AES-256, AWS deletes the key from memory, but instead stores a randomly salted hash message authentication code, a HMAC value, which is used for data integrity and authentication of the key to validate future requests.</p>
<p>When requesting to access the object from S3, you must again supply the same customer-provided key to decrypt the object. Remember, AES is symmetric, meaning you need the same key to decrypt as you use to encrypt. There are a number of request headers that you must use when using SSE-C as shown in the table below.</p>
<p>Now, I have covered server-side encryption, let me now talk to you about client-side encryption options within S3. This differs from server-side encryption in the fact that data is encrypted before it is sent to S3 for storage. S3 does not form any encryption itself when client-side encryption is used as the encryption mechanism.</p>
<p>There are two options that you can use, client-side encryption with KMS, CSE-KMS, and client-side encryption using a custom client-side master key, CSE-C. When using CSE-KMS with a CMK, you only need to supply the CMK-ID to the Amazon S3 encryption client. For example, the Amazon S3 encryption client in the AWS SDK for Java and the encryption is managed for you by AWS.</p>
<p>When you upload an object to S3 using this method, supplying the CMK-ID, a request is made by the client to KMS which returns two versions of a randomly generated data encryption key. One version of this data key is plain text which the client uses to perform the encryption of the object before it’s uploaded.</p>
<p>The second version is cipher blob of the data key and is uploaded with the object by the client as object metadata. When you retrieve the object on S3, the object is downloaded in an encrypted form along with the cipher blob data encryption key. Once downloaded, the client sends the ciphered blob to KMS to retrieve the matching plain text version of the data key to enable the decryption of the object.</p>
<p>It’s worth mentioning that for each object that is uploaded a different data encryption key is used. When using CSE-C using the client-side master key, your key is never sent to AWS like it is with CSE-KMS, so if you lose your client side master key, then you will lose access to your data. When performing an upload of an object, again, you need to provide the key to the client, for example, the Amazon S3 encryption client when using the AWS SDK for Java, but this time it will be your client-side master key. As this is the master key, it is only used to encrypt a randomly generated symmetric data encryption key generated by the client. This data key is then used to encrypt the object data.</p>
<p>Once the object is encrypted, the client-side master key is used to encrypt the data key. The encrypted data key is then made a part of the metadata of the object before both the encrypted object and the data key are uploaded to S3. When the encrypted object is retrieved, it is downloaded in an encrypted format along with its metadata including the encrypted data key.</p>
<p>The correct client-side master key is then identified to decrypt the data key which then in turn decrypts the object. So, we’ve now looked at the different encryption objects available when storing and sending data to S3. Let me now talk a little about how Amazon Athena handles encryption and encrypted S3 objects when performing queries against the data.</p>
<p>Amazon Athena is a serverless interactive query service which uses standard SQL and automatically execute queries in parallel, making it extremely fast. Amazon Athena supports the ability to query S3 data that is already encrypted and if configured to do so, Athena can also encrypt the results of the query which can then be stored in S3.</p>
<p>This encryption of results is independent of the underlying queried S3 data, meaning that even if the S3 data is not encrypted, the queried results can be encrypted. A couple of points to be aware of is that Amazon Athena only supports data that has been encrypted with the following S3 encryption methods, SSE-S3, SSE-KMS, and CSE-KMS.</p>
<p>SSE-C and CSE-E are not supported. In addition to this, it’s important to understand that Amazon Athena will only run queries against encrypted objects that are in the same region as the query itself. If you need to query S3 data that’s been encrypted using KMS, then specific permissions are required by the Athena user to enable them to perform the query.</p>
<p>You could simply add the users to the key policy of the CMK to provide the relevant access. However, if you wanted to just restrict the specific actions required for Athena to work, then you could simply grant access to the following actions, kms:Decrypt which is required for working with encrypted data sets and queries, and kms:GenerateDataKey which is required for working with encrypted queries only.</p>
<p>That now brings us to the end of this lecture of S3 and Athena encryption. Coming up next, I will be discussing encryption when using <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/elastic-mapreduce-emr-encryption-3/">Elastic MapReduce</a>, EMR.</p>
<h1 id="Elastic-MapReduce-EMR-Encryption"><a href="#Elastic-MapReduce-EMR-Encryption" class="headerlink" title="Elastic MapReduce (EMR) Encryption"></a>Elastic MapReduce (EMR) Encryption</h1><p>Hello and welcome to this lecture where I’ll discuss different <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">encryption</a> options available for the Amazon Elastic MapReduce Service, EMR. EMR is a managed service by <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> and is comprised of a cluster of EC2 instances that’s highly scalable to process and run big data frameworks such Apache Hadoop and Spark.</p>
<p>From EMR version 4.8.0 and onwards, we have the ability to create a security configuration specifying different settings on how to manage encryption for your data within your clusters. You can either encrypt your data at rest, data in transit, or if required, both together. The great thing about these security configurations is they’re not actually a part of your EC2 clusters.</p>
<p>They exist as a separate entity within EMR and therefore you can reuse the same security configuration for both existing and future clusters created. One key point of EMR is that by default, the instances within a cluster do not encrypt data at rest. The instances used within EMR are created from pre-configured AMIs, Amazon Machine Images that have been published and released by AWS.</p>
<p>However, if you need to ensure that the EBS root device volume is encrypted for your EC2 instances within a cluster, then you must use Amazon EMR version 5.7.0 or later and specify a custom AMI which will allow you to encrypt this volume. You may need this additional level of encryption at root volume level for specific compliance reasons.</p>
<p>Although EMR does not encrypt data at rest by default, there are a number of mechanisms you can use to enforce encryption. If you decide to use Elastic Block Store, EBS as persistence storage rather than <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-s3-and-amazon-athena-encryption-2/">S3</a> or DynamoDB, then there a number of options that can work together if you enable local disk encryption at rest in your EMR security configuration.</p>
<p>However, these are not possible for EBS root device volumes. Once enabled, the following features are available. Linux Unified Key Setup. EBS cluster volumes can be encrypted using this method whereby you can specify AWS KMS to be used as your key management provider, or use a custom key provider.</p>
<p>Open-Source HDFS encryption. This provides two Hadoop encryption options. Secure Hadoop RPC which would be set to privacy which uses simple authentication security layer, and data encryption of HDFS Block transfer which would be set to true to use the AES-256 algorithm.</p>
<p>If S3 was used, you could use S3’s own encryption tools discussed in a previous lecture. As a result, EMR supports the use of SSE-S3 or SSE-KMS to form the encryption service side at rest. Alternatively, you could encrypt your data using your client before storing on S3 using CSE-KMS or CSE-C where it would remain stored in an encrypted form.</p>
<p>From an encryption in transit perspective, you could enable open source transport layer security encryption features and select a certificate provider type which can be either PEM where you will need to manually create PEM certificates, bundle them up with a zip file and then reference the zip file in S3 or custom where you would add a custom certificate provider as a Java class that provides encryption artifacts.</p>
<p>Once the TLS certificate provider has been configured in the security configuration file, the following encryption applications specific encryption features can be enabled which will vary depending on your EMR version. Hadoop. Hadoop might reduce encrypted shuffle which uses TLS. Both secure Hadoop RPC which uses Simple Authentication Security Layer, and data encryption of HDFS Block Transfer which uses AES-256, are both activated when at rest encryption is enabled in the security configuration.</p>
<p>Presto. When using EMR version 5.6.0 and later, any internal communication between Presto nodes will use SSL and TLS. Tez. Tez Shuffle Handler uses TLS. And Spark. The Akka protocol uses TLS. Block Transfer Service uses Simple Authentication Security Layer and 3DES. External shuffle service uses the Simple Authentication Security Layer.</p>
<p>When using encryption at rest using KMS Customer Master Keys, you need to ensure that the role assigned to your EC2 instances within your cluster has the relevant permissions to enable access to the Customer Master Key. This is done by adding the relevant role to the Key users for the CMK. Finally, EMR has the option of implementing Transparent Encryption in HDFS.</p>
<p>This offers end to end encryption, applying both encryption at rest and in transit. When implemented, data is encrypted and decrypted transparently without requiring any change to application code. This is made possible by using HDFS encryption zones, each having its own KMS key. By default, EMR uses the Hadoop KMS, but you can select an alternative if required.</p>
<p>Each file within the encryption zone is encrypted by a different data key which are then encrypted by the HDFS encryption zone keys. With this in mind, it is not possible to move files between encryption zones as the data key and encryption zone key will not match. For details on how to configure this method of encryption, see the AWS documentation <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-encryption-tdehdfs.html#emr-configure-HDFS-transparent-encryption">link</a> here.</p>
<p>This lecture has covered the encryption mechanisms that you can choose to apply encryption across EMR, which remember is not provided by default. For more information on how to set up these different methods of encryption in detail, I recommend you visit the relevant AWS documentation pages on EMR. Coming up on the next lecture, I will look at encryption options when using the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/relational-database-service-rds-encryption-3/">relational database service RDS</a>.</p>
<h1 id="Relational-Database-Service-RDS-Encryption"><a href="#Relational-Database-Service-RDS-Encryption" class="headerlink" title="Relational Database Service (RDS) Encryption"></a>Relational Database Service (RDS) Encryption</h1><p>Hello and welcome to this short lecture covering RDS encryption options. RDS allows you to set up a relational database using a number of different engines such as MySQL, Oracle, SQL Server, etc. During the creation of your RDS database instance, you have the opportunity to Enable Encryption at the Configure Advanced Settings screen under Database Options and Enable Encryption.</p>
<p>By enabling your encryption here, you are enabling encryption at rest for your storage, snapshots, read replicas and your back-ups. Keys to manage this encryption can be issued by using KMS. It’s not possible to add this level of encryption after your database has been created. It has to be done during its creation.</p>
<p>However, there is a workaround allowing you to encrypt an unencrypted database as follows. You can create a snapshot of your unencrypted database, create an encrypted copy of that snapshot, use that encrypted snapshot to create a new database, and then, finally, your database would then be encrypted.</p>
<p>If the KMS key that was used for the encryption is disabled, then you’ll not be able to read or write to your database and RDS will move your database instances into a terminal state where it can no longer be accessed.</p>
<p>At this stage, the only option in retrieving your data is to reinstate the KMS key and then recover your database from a previous back-up. The previous RDS instance in a terminal state will still not be accessible. Read replicas follow the same encryption pattern as defined by the database source. So, for example, if your database had encrypted at rest enabled, then the read replica will also be encrypted. It would not be possible to have an encrypted read replica if the database itself was not encrypted.</p>
<p>In addition to encryption offered by RDS itself at the application level, there are additional platform level encryption mechanisms that could be used for protecting data at rest including Oracle and SQL Server Transparent Data Encryption, known as TDE, and this could be used in conjunction with the method order discussed but it would impact the performance of the database MySQL cryptographic functions and Microsoft Transact-SQL cryptographic functions.</p>
<p>If you want to use the TDE method, then you must first ensure that the database is associated to an option group. Option groups provide default settings for your database and help with management which includes some security features. However, option groups only exist for the following database engines and versions.</p>
<p>Once the database is associated with an option group, you must ensure that the Oracle Transparent Data Encryption option is added to that group. Once this TDE option has been added to the option group, it cannot be removed. TDE can use two different encryption modes, firstly, TDE tablespace encryption which encrypts entire tables and, secondly, TDE column encryption which just encrypts individual elements of the database.</p>
<p>RDS offers the ability to encrypt instances in all regions other than the China Beijing region and across the following Instance Types only. In comparison to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/elastic-mapreduce-emr-encryption-3/">EMR</a>, applying encryption at rest for RDS is simplified thanks to the built in application encryption option which EMR does not have.</p>
<p>When looking at Encryption in Transit for communication between your application and RDS, then you can secure this communication using SSL&#x2F;TLS which is Secure Sockets Layer Transport Layer Security which are both cryptographic protocols.</p>
<p>This is always recommended if you have to abide by specific compliance and governance controls or when the data being sent to RDS is highly sensitive such as containing customer details. The method in which this process is carried out varies dependent on which database type you have. For more information on the implementation of this encryption for the following database engines, take a look at the <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html">link</a> shown on the screen.</p>
<p>If you are using Oracle with RDS, then instead of using SSL encryption between a client and the database you could use Oracle’s Native Network Encryption, NNE, which will encrypt all connections to and from the database. It is, however, not possible to use both SSL and NNE together for encryption. You must use one or the other if required.</p>
<p>To enable NNE, you must add the NATIVE_NETWORK_ENCRYPTION to the database options group. More information on Oracle NNE can be found here.</p>
<p>That brings us to the end of this lecture. Coming up next I shall be looking at the encryption across big data frameworks starting with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-kinesis-encryption-1/">Amazon Kinesis Firehose</a>.</p>
<h1 id="Amazon-Kinesis-Encryption"><a href="#Amazon-Kinesis-Encryption" class="headerlink" title="Amazon Kinesis Encryption"></a>Amazon Kinesis Encryption</h1><p>Hello, and welcome to this lecture where I’m going to be looking at how Amazon Kinesis utilizes <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">encryption</a> mechanisms. I will be looking at both Kinesis Firehose and Kinesis Streams.</p>
<p>If you are new to Amazon Kinesis, you may find it useful to take our existing course covering AWS Kinesis found <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/intro-amazon-kinesis/introduction-to-amazon-kinesis/">here</a>.</p>
<p>Let me start by providing a high level overview of the differences between each of these services. Amazon Firehose. This service is used to deliver real-time streaming data to different services and destinations within <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a>, many of which can be used for big data such as S3 Redshift and Amazon Elasticsearch.</p>
<p>The service is fully managed by AWS, taking a lot of the administration of maintenance out of your hands. Firehose is used to receive data from your data producers where it then automatically delivers the data to your chosen destination. Amazon Streams. This service essentially collects and processes huge amounts of data in real time and makes it available for consumption.</p>
<p>This data can come from a variety of different sources. For example, log data from the infrastructure, social media, web clicks during feeds, market data, etc. So now we have a high-level overview of each of these. We need to understand how they implement encryption of any data process in stored should it be required.</p>
<p>When clients are sending data to Kinesis in transit, the data can be sent over HTTPS, which is HTTP with SSL encryption. However, once it enters the Kinesis service, it is then unencrypted by default. Using both Kinesis Streams and Firehose encryption, you can assure your streams remain encrypted up until the data is sent to its final destination.</p>
<p>As we know, Amazon Firehose is used to send data to a final destination. If Amazon S3 is used as a destination, Firehose can implement encryption using SSE-KMS on S3. Access to this key in the desired S3 bucket can be given to Firehose via an IAM role to enable this data encryption to take place. Once this role has been created, the relevant permissions must be assigned, which must include the following KMS actions against the CMK used, kms:Decrypt and kms:GenerateDataKey.</p>
<p>You can apply the following policy as a trusted entity on the role itself, ensuring you replace the account ID with your own, which would give Kinesis Firehose the relevant access. If you have configured Kinesis Firehose to use Redshift as a destination, then Firehose still copies the data to S3 first as an intermediary location.</p>
<p>In this instance, the same KMS permissions mentioned previously should be implemented to enforce encryption of the data at rest and before it is sent to your Redshift cluster from S3, plus the relevant permissions required for Redshift. Similarly, with Elasticsearch as a destination, S3 can also be used to backup all of the data it sends to Elasticsearch.</p>
<p>And so again, it would need the same KMS permissions plus the relevant permissions for Elasticsearch. Let’s now take a look at the encryption for Amazon Kinesis Streams.</p>
<p>Since July 2017, Amazon Streams now has the ability to implement SSE encryption using KMS to encrypt data as it enters the stream directly from the producers.</p>
<p>As a part of this process, it’s important to ensure that both producer and consumer applications have permissions to use the KMS key. Otherwise encryption and decryption will not be possible, and you will receive an unauthorized KMS master key permission error.</p>
<p>Put simply, a producer is something that adds data to a Kinesis stream, such as a web service sending log data, encryption happens at the producer level.</p>
<p>The Consumer is usually a Kinesis application that processes data from within the Kinesis stream. Decryption happens at the consumer level.</p>
<p>Your producers must have the following permissions against the CMK used, kms:GenerateDataKey, and the following against the Kinesis stream, kinesis:PutRecord and kinesis:PutRecords.</p>
<p>Your consumers on the other hand will require the following against the CMK, kms:Decrypt, and the following against the Kinesis stream, kinesis:GetRecords and kinesis:DescribeStream. Utilizing SSE with KMS for Kinesis Streams essentially encrypts a data entering a stream before it is saved to the Kinesis Streams storage layer and then decrypted after it’s accessed from the storage layer, giving full at-rest encryption within the stream.</p>
<p>Kinesis SSE encryption will typically call upon KMS to generate a new data key every five minutes. So, if you had your stream running for a month or more, thousands of data keys would be generated within this time frame. You may be wondering if by applying this encryption using the producers and then decrypting the data using the consumers, if any latency is added to the performance. And the simple answer is yes. It does add a small overhead, which impacts the performance of PutRecord and PutRecords and GetRecords by less than a hundred microseconds.</p>
<p>Before we finish this lecture, I just want to mention that AWS has released a blog post that shows how to implement encryption from client to destination by building a real-time streaming application using Kinesis, in which your records are encrypted while at rest and in transit, which you may want to take a look at here.</p>
<p>That now brings us to the end of this lecture. Coming up next, I shall be looking at encryption when using the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-redshift-3/">Amazon Redshift</a> service.</p>
<h1 id="Amazon-Redshift"><a href="#Amazon-Redshift" class="headerlink" title="Amazon Redshift"></a>Amazon Redshift</h1><p>Hello and welcome to this lecture. I want to talk to you about available <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">encryption</a> options when using Redshift. Redshift is a fully managed service that can scale up to over a petabyte in size, which is used as a data warehouse for big data solutions. Using Redshift clusters, you are able to run analytics against your datasets using fast, SQL-based query tools and business intelligence applications to gather greater understanding of vision for your business.</p>
<p>So how does Redshift handle encryption of huge amounts of data?</p>
<p>Redshift offers encryption at rest using a four-tired hierarchy of encryption keys using either KMS or CloudHSM to manage the top tier of keys. When encryption is enabled for your cluster, it can’t be disable and vice versa. When you have an unencrypted cluster, it can’t be encrypted.</p>
<p>Encryption for your cluster can only happen during its creation, and once encrypted, the data, metadata, and any snapshots are also encrypted. The tiering level of encryption keys are as follows, tier one is the master key, tier two is the cluster encryption key, the CEK, tier three, the database encryption key, the DEK, and finally tier four, the data encryption keys themselves.</p>
<p>As mentioned previously, the master keys can either be managed by KMS or CloudHSM. Amazon Redshift integrates well with KMS but not CloudHSM, and so integration with a HSM device requires additional configuration or steps to implement such as adding certificates to establish a trusted connection between both resources, your HSM device and your Redshift cluster.</p>
<p>The encryption method differs slightly between the two options of KMS and CloudHSM. So let me break each of these down individually starting with KMS. During the creation of your cluster, you can either select the default KMS key for Redshift or select your own CMK, which gives you more flexibility over the control of the key, specifically from an auditable perspective.</p>
<p>The default KMS key for Redshift is automatically created by Redshift the first time the key option is selected and used, and it is fully managed by AWS. The CMK is known as the master key, tier one, and once selected, Redshift can enforce the encryption process as follows. So Redshift will send a request to KMS for a new KMS key.</p>
<p>This KMS key is then encrypted with the CMK master key, tier one. This encrypted KMS data key is then used as the cluster encryption key, the CEK, tier two. This CEK is then sent by KMS to Redshift where it is stored separately from the cluster. Redshift then sends this encrypted CEK to the cluster over a secure channel where it is stored in memory.</p>
<p>Redshift then requests KMS to decrypt the CEK, tier two. This decrypted CEK is then also stored in memory. Redshift then creates a random database encryption key, the DEK, tier three, and loads that into the memory of the cluster. The decrypted CEK in memory then encrypts the DEK, which is also stored in memory.</p>
<p>This encrypted DEK is then sent over a secure channel and stored in Redshift separately from the cluster. Both the CEK and the DEK are now stored in memory of the cluster both in an encrypted and decrypted form. The decrypted DEK is then used to encrypt data keys, tier four, that are randomly generated by Redshift for each data block in the database.</p>
<p>When performing encryption using CloudHSM, the process is different. If you are new to CloudHSM, then you may want to look at our existing course covering the service found here. When working with CloudHSM to perform your encryption, firstly you must set up a trusted connection between your HSM client and Redshift while using client and server certificates.</p>
<p>This connection is required to provide secure communications, allowing encryption keys to be sent between your HSM client and your Redshift clusters. Using a randomly generated private and public key pair, Redshift creates a public client certificate, which is encrypted and stored by Redshift. This must be downloaded and registered to your HSM client, and assigned to the correct HSM partition.</p>
<p>You must then configure Redshift with the following details of your HSM client: the HSM IP address, the HSM partition name, the HSM partition password, and the public HSM server certificate, which is encrypted by CloudHSM using an internal master key. Once this information has been provided, Redshift will confirm and verify that it can connect and access development partition.</p>
<p>For detailed instructions on how to configure Redshift encryption using CloudHSM, please see the following AWS documentation that will provided step-by-step details.</p>
<p>If your internal security policies or governance controls dictate that you must apply key rotation, then this is possible with Redshift enabling you to rotate encryption keys for encrypted clusters, however, you do need to be aware that during the key rotation process, it will make a cluster unavailable for a very short period of time, and so it’s best to only rotate keys as and when you need to, or if you feel they may have been compromised.</p>
<p>During the rotation, Redshift will rotate the CEK for your cluster and for any backups of that cluster. It will rotate a DEK for the cluster but it’s not possible to rotate a DEK for the snapshots stored in <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-s3-and-amazon-athena-encryption-2/">S3</a> that have been encrypted using the DEK. It will put the cluster into a state of ‘rotating keys’ until the process is completed when the status will return to ‘available’.</p>
<p>To perform a key rotation of your cluster, it’s very simple using the AWS Management Console. Select Amazon Redshift from within the management console, navigate to clusters, select the cluster you wish to rotate keys for, select the database, rotate encryption keys, and select yes, rotate keys, then your cluster will temporarily be unavailable whilst the key rotation process completes.</p>
<p>This now brings us to the end of this lecture on Amazon Redshift encryption. Coming up next, I shall be providing a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/summary-3/">summary</a> of the key points throughout the previous lectures.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Hello, and welcome to this final lecture, where I shall be highlighting some key points from each lecture that you have covered throughout the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/introduction-43/">course</a>.</p>
<p>I started off by providing an overview of encryption in general, where we learned unencrypted data is known as cleartext or plaintext. Data encryption is the mechanism in which information is altered, rendering the plaintext data unreadable through the use of mathematical algorithms and keys.</p>
<p>A key is simply a string of characters used with the the encryption algorithm, and the longer the key, the more robust the encryption. Key cryptography is either symmetric or asymmetric. Symmetric cryptography uses a single key to perform the encryption and decryption. And common symmetric algorithms are AES, DES, Triple-DES, and Blowfish.</p>
<p>Asymmetric cryptography uses different keys, one to perform encryption and one to perform decryption. In this process, one key is public, and one key is private. Common asymmetric algorithms are RSA, Diffie-Hellman, and Digital Signature Algorithm.</p>
<p>I then started to explain about the different encryption mechanisms that are used across a range of services, specifically ones that can be used for big data, starting with S3.</p>
<p>We learned that S3 offers server-side encryption, SSE, and client-side encryption, CSE. SSE offers three different options. SSE with Amazon S3-Managed Keys, which is SSE-S3, SSE with AWS KMS-Managed Keys, which SSE-KMS, and SSE with Customer-provided Keys, SSE-C. Client-side encryption offers two different options, client-side encryption with KMS, CSE-KMS, and client-side encryption using a custom client-side master key, CSE-C.</p>
<p>SSE-S3 is managed by AWS and uses AES-256 symmetric encryption, which supports bucket policies.</p>
<p>SSE-KMS uses the key management service to help with key management, and it allows you to use your own keys, the CMK, through KMS, giving more control and flexibility. The CMK encrypts the data key, not the data itself, and this also supports bucket policies.</p>
<p>SSE-C uses customer-provided keys using AES-256. During an upload of an object, you must also send the key with it. And it only works with HTTPS to secure data in transit, specifically the key.</p>
<p>Client-side encryption using KMS uses an S3 encryption client, such as the Amazon S3 Encryption Client in the AWS SDK for Java and you must supply the CMK ID from KMS. And the encryption happens prior to upload and after download of an object. CSE-C uses a custom master key, which is never sent to <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a>. It also uses an S3 client, like CSE-KMS, and again, encryption happens prior to upload and after download of an object. We then looked at Athena.</p>
<p>And Athena supports the ability to query encrypted data on S3. It can also encrypt queried results, even if the data queried was not encrypted. SSE-C and CSE-C are not currently supported by Athena. But Athena does support SSE-KMS, SSE-S3, and CSE-KMS. Athena will only query objects in the same region as where Athena is running.</p>
<p>And KMS Decrypt and KMS Generate Key permissions are required to allow Athena to query encrypted data on S3 using KMS. Following this lecture, I then looked at Elastic MapReduce Encryption. And the key points from this lecture were that by default EMR does not implement encryption at rest.</p>
<p>From EMR version 4.8.0 and onwards, you are able to configure a security configuration specifying different settings on how to manage encryption for your data. The security configuration allows you to configure encryption at rest, in transit, or both together. The security configuration exists separately from your EC2 clusters.</p>
<p>And using EMR version 5.7.0, you can specify your own custom AMI, allowing you to encrypt the EBS route device volume of your instances.</p>
<p>Using EBS as your persistent storage layer, you can implement Linux Unified Key Setup with KMS and open-source HDFS encryption. This provides two Hadoop encryption options, Secure Hadoop RPC and data encryption of HDFS block transfer.</p>
<p>When using S3, EMR supports the use of SSE-S3 or SSE-KMS to perform server-side encryption. You could also encrypt your data using your client before storing on S3 using CSE-KMS or CSE-C.</p>
<p>EMR in transit encryption, you can enable open-source TLS encryption features. When a TLS certificate provider has been configured, the following application-specific encryption features can be enabled: Hadoop, with Hadoop MapReduce Encrypted Shuffle, Secure Hadoop RPC, and data encryption of HDFS block transfer.</p>
<p>With Presto, when using EMR version 5.6.0 and later, any internal communication between Presto nodes will use SSL TLS. With Tez, Tez Shuffle Handler uses TLS. And Spark, the Akka protocol uses TLS, block transfer service uses SASL and Triple-DES, external shuffle service uses SASL.</p>
<p>Transparent encryption can also be used by implementing transparent encryption in HDFS.</p>
<p>Following EMR, I looked at encryption for the RDS service, and here we learned that you can configure encryption at rest during its configuration by selecting the checkbox for “enable encryption”. This encryption can only be implemented during the database creation. And read replicas will have the same level of encryption as the master database.</p>
<p>You can also implement application-level encryption using Oracle and SQL Server Transparent Data Encryption, TDE, MySQL cryptographic functions, and Microsoft Transact-SQL cryptographic functions. To use TDE encryption, the database must be a part of an option group with the TDE option added to the group.</p>
<p>TDE can use two different encryption modes, TDE table namespace encryption and TDE column encryption. RDS in-transit encryption can be enabled by using SSL between your application and the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/relational-database-service-rds-encryption-3/">RDS database</a>. To use Oracle’s native network encryption, NNE, you must add native network encryption to the database options group.</p>
<p>Moving on from databases, the next topic was encryption mechanisms when using the Amazon Kinesis platform for both Kinesis Firehose and Kinesis Streams. Within this lecture, we learned that data being sent to Kinesis can be sent using SSL for in-transit encryption. By default, once the data enters Kinesis, it is decrypted.</p>
<p>Kinesis Firehose can use SSE-KMS when sending data to S3. Kinesis Firehose must have the KMS decrypt and the KMS generate data key permission of the CMK when using this method. If data is being sent to Amazon Redshift by Kinesis Firehose, S3 will still be used as an intermediary storage location, and so the same encryption can be applied.</p>
<p>Since July 2017, Kinesis Streams can now apply SSE encryption to incoming data to the stream using KMS. Producers and consumers need to have the relevant permissions to the KMS CMK. Kinesis Streams will request a new data encryption key approximately every five minutes. And a performance hit of approximately 100 microseconds is added for the encryption and decryption to take place by the producers and consumers.</p>
<p>We then finished up by looking at encryption options within Amazon Redshift. Amazon Redshift uses a four-tiered structure of encryption keys. Tier one is the master key, tier two, the cluster encryption key, CEK, tier three, the database encryption key, DEK, and then tier four, the data encryption keys.</p>
<p>The master key can be generated by either KMS or CloudHSM. Integration exists between KMS and Amazon Redshift, but not between CloudHSM and Redshift. When using CloudHSM, a trust must be established between your HSM and Amazon Redshift to send secure encryption keys between the two resources. For this to take place, you must download a certificate from Redshift to your HSM device, and then configure Redshift with the following details of your HSM: the HSM IP address, HSM partition name, the HSM partition password, and the public HSM service certificate.</p>
<p>You can perform a key rotation using the AWS Management Console for both your CEK and DEK.</p>
<p>That has now brought me to the end of this lecture and to the end of this course. I hope it has given you a good understanding of encryption itself, including symmetric and asymmetric cryptography, and opened you to some encryption mechanisms that are offered by services which are commonly used for big data solutions, using Amazon S3, <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/aws-big-data-security-encryption/amazon-s3-and-amazon-athena-encryption-2/">Athena</a>, Elastic MapReduce, the RDS service, Kinesis Firehose, Kinesis Streams, and Redshift.</p>
<p>You should now be able to enforce additional security controls, including encryption, into your existing infrastructure to help secure your data.</p>
<p>If you have any feedback on the course, positive or negative, please do leave a comment on the course landing page. We do look at the comments, and your feedback is greatly appreciated.</p>
<p>Thank you for your time, and good luck with your continued learning of cloud computing.</p>
<p>Thank you.</p>
<h1 id="4Elastic-MapReduce-EMR-Encryption"><a href="#4Elastic-MapReduce-EMR-Encryption" class="headerlink" title="4Elastic MapReduce (EMR) Encryption"></a>4<strong>Elastic MapReduce (EMR) Encryption</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-encryption-tdehdfs.html#emr-configure-HDFS-transparent-encryption">Encryption Method Configuration</a></p>
<h1 id="5Relational-Database-Service-RDS-Encryption"><a href="#5Relational-Database-Service-RDS-Encryption" class="headerlink" title="5Relational Database Service (RDS) Encryption"></a>5<strong>Relational Database Service (RDS) Encryption</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html">Encryption Implementation</a></p>
<h1 id="6Amazon-Kinesis-Encryption"><a href="#6Amazon-Kinesis-Encryption" class="headerlink" title="6Amazon Kinesis Encryption"></a>6<strong>Amazon Kinesis Encryption</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/intro-amazon-kinesis/introduction-to-amazon-kinesis/">Course: Introduction to Amazon Kinesis</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/14/AWS-Security-Specialty-Manage-Your-Own-Encryption-Keys-Using-AWS-CloudHSM-35/" rel="prev" title="AWS-Security-Specialty-Manage-Your-Own-Encryption-Keys-Using-AWS-CloudHSM-35">
      <i class="fa fa-chevron-left"></i> AWS-Security-Specialty-Manage-Your-Own-Encryption-Keys-Using-AWS-CloudHSM-35
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/14/AWS-Security-Specialty-Protecting-Web-Apps-with-AWS-WAF-Shield-Firewall-Manager-37/" rel="next" title="AWS-Security-Specialty-Protecting-Web-Apps-with-AWS-WAF-Shield-Firewall-Manager-37">
      AWS-Security-Specialty-Protecting-Web-Apps-with-AWS-WAF-Shield-Firewall-Manager-37 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Overview-of-Encryption"><span class="nav-number">2.</span> <span class="nav-text">Overview of Encryption</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Amazon-S3-and-Amazon-Athena-Encryption"><span class="nav-number">3.</span> <span class="nav-text">Amazon S3 and Amazon Athena Encryption</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Elastic-MapReduce-EMR-Encryption"><span class="nav-number">4.</span> <span class="nav-text">Elastic MapReduce (EMR) Encryption</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Relational-Database-Service-RDS-Encryption"><span class="nav-number">5.</span> <span class="nav-text">Relational Database Service (RDS) Encryption</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Amazon-Kinesis-Encryption"><span class="nav-number">6.</span> <span class="nav-text">Amazon Kinesis Encryption</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Amazon-Redshift"><span class="nav-number">7.</span> <span class="nav-text">Amazon Redshift</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Summary"><span class="nav-number">8.</span> <span class="nav-text">Summary</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4Elastic-MapReduce-EMR-Encryption"><span class="nav-number">9.</span> <span class="nav-text">4Elastic MapReduce (EMR) Encryption</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5Relational-Database-Service-RDS-Encryption"><span class="nav-number">10.</span> <span class="nav-text">5Relational Database Service (RDS) Encryption</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6Amazon-Kinesis-Encryption"><span class="nav-number">11.</span> <span class="nav-text">6Amazon Kinesis Encryption</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2653</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
