<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="IntroductionGreetings. Welcome to Cloud Academy’s course on Microsoft Cosmos DB. I’m delighted to have you join me on what is bound to be an educational and delightful adventure into the world of data">
<meta property="og:type" content="article">
<meta property="og:title" content="AZ-204-Introduction-to-Azure-Cosmos-DB-23">
<meta property="og:url" content="https://example.com/2022/11/14/AZ-204-Introduction-to-Azure-Cosmos-DB-23/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:description" content="IntroductionGreetings. Welcome to Cloud Academy’s course on Microsoft Cosmos DB. I’m delighted to have you join me on what is bound to be an educational and delightful adventure into the world of data">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-14T15:18:10.000Z">
<meta property="article:modified_time" content="2022-11-15T04:42:40.000Z">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/2022/11/14/AZ-204-Introduction-to-Azure-Cosmos-DB-23/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>AZ-204-Introduction-to-Azure-Cosmos-DB-23 | Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AZ-204-Introduction-to-Azure-Cosmos-DB-23/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AZ-204-Introduction-to-Azure-Cosmos-DB-23
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 11:18:10" itemprop="dateCreated datePublished" datetime="2022-11-14T11:18:10-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-15 00:42:40" itemprop="dateModified" datetime="2022-11-15T00:42:40-04:00">2022-11-15</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AZ-204-Introduction-to-Azure-Cosmos-DB-23/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AZ-204-Introduction-to-Azure-Cosmos-DB-23/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Greetings. Welcome to Cloud Academy’s course on Microsoft Cosmos DB. I’m delighted to have you join me on what is bound to be an educational and delightful adventure into the world of database technology. First, I’ll let you know a little bit about myself before I get into the course outline. My name is Jonathan. I’m one of the course developers with Cloud Academy. I work professionally as a technical consultant specializing in DevOps, data engineering, and security. Long ago in another life, I was a public school teacher, so I love educating people and I’m thrilled to be doing it again, only now, with technology. </p>
<p>This course is designed to be very practical. It’s meant for technology professionals, DevOps engineers, data architects, CTOs, etc, with the goal of helping them get a solid understanding of Cosmos DB in a short time. So, what exactly are the prerequisites then for a course like that? Well, we’re going to be doing a pretty deep dive on the Cosmos DB architecture and its varying data models. For that reason, we recommend that people have some basic knowledge of database technologies. You should also have at least a passing familiarity with <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft Azure</a> and cloud hosting generally. So, when I talk about how an Azure service can talk to Cosmos DB, I’m going to assume that the students know what that means at a high level. In short, if you have any technical experience working with cloud providers and databases, you’ll probably be fine. If this is your first time learning about databases, then maybe you’ll struggle a bit.</p>
<p>So, what are the exact learning objectives for a course like this? Well, I’ve narrowed it down to three big ones that will guide each section. Objective one, is to ensure that the student gains a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/intro-azure-cosmos-db/">basic understanding of the Cosmos DB</a> technology, including its feature set and design philosophy and a little bit of history too. Objective two, is to teach students how to use Cosmos DB, via its APIs, Microsoft CLI tools, and the Azure web console. Finally, objective three, is to give students a practical understanding of how to integrate Cosmos DB with other Azure services with the goal of creating a working app. So in short, what is Cosmos DB, how do we use it, and then concrete example. So, lastly, I would like to encourage everyone to leave feedback. Email <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a> if you have any questions, comments, suggestions, or concerns. We always appreciate people taking the time to provide feedback. So now without further ado, let’s get started.</p>
<h1 id="Introduction-to-Cosmos-DB"><a href="#Introduction-to-Cosmos-DB" class="headerlink" title="Introduction to Cosmos DB"></a>Introduction to Cosmos DB</h1><p>The fact that you’re here with me taking this course implies that you know, or at least care a little bit about data based technology. If that’s the case, then you know there are a lot of different products out there. There are relational databases like PostgreSQL and MySQL as well. You have no sequel systems like MongoDB or key value stores, collum databases, things like Cassandra, numerous enterprise offerings from big companies. Things like Amazon’s DynamoDB. So with such a crowded ecosystem, the first question anyone would rightly ask about Cosmos DB is what makes it so special? Before we try to tackle that question, let’s talk a little history.</p>
<p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/introduction/">Cosmos DB</a> is actually an extension of Microsoft’s DocumentDB which was released back in 2014. Microsoft had been developing Cosmos DB since 2010 and in 2017, it officially migrated all DocumentDB users to Cosmos DB. Cosmos DB supports the same SQL-like API as DocumentDB as well as several other APIs and features. Now according to <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft Azure</a>‘s own documentation, Cosmos DB is best described as a globally distributed multi-model database. Now the two descriptive terms there are key. </p>
<p>Globally distributed and multi-model, that should already give you an idea of the problems Cosmos DB is meant to solve. For those of you familiar with CAP theory, C-A-P CAP theory, you could infer that availability is one of the chief guarantees. This is critical because achieving reliable database performance across multiple geographic regions is very difficult, especially for relational databases. So what do we mean when we say that Cosmos DB is a multi-model database? When we use the term model when talking about databases, we’re referring to how the data is actually stored and what sort of APIs are used for clients to read and write data. So for example, Cassandra has a certain API and storage paradigm that makes it more suitable for some use cases than others. MongoDB and PostgreSQL have their own models. So what does it mean to say that Cosmos DB is multi-model? Well, as you might guess, this simply means that with Cosmos DB, you have the flexibility to use a variety of different APIs for different use cases. In fact, the available models for Cosmos DB come from well known database technologies. Cosmos DB supports Table API, Cassandra, SQL, MongoDB, and Gremlin. </p>
<p>There are STKs available in multiple languages for clients. Cosmos DB is sort of like DynamoDB in that it is a database as a service. That is, you don’t install it on your own server and configure it like you would with Cassandra or Postgres. Rather, what you do is you sign up for access through Azure, and behind the scenes Microsoft handles the scaling. Microsoft Azure offers 99.999% uptime SLA to ease concerns about entrusting your precious data to them. Still, it is important to keep in mind the relative lack of control you have if you rely on Cosmos DB. It isn’t like a typical database system where you can SSH to the server and tune things the way you want. This is understandably a deal breaker for some people. On the flip side, as a former DynamoDB user, I can say that it can be a really big boon for a small startup to have the reliability and performance guarantees of a large company like Microsoft backing your app. </p>
<p>It lets you focus on your business logic and scale very quickly. So, that’s it in a nutshell. Cosmos DB is a powerful database as a service system designed to support a variety of data models and work across multiple geographic regions. In the next lesson, we’ll dive into the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/cosmos-db-features-and-capabilities/">feature set</a> and talk about how companies actually might use Cosmos DB. See you there.</p>
<h1 id="Cosmos-DB-Features-and-Capabilities"><a href="#Cosmos-DB-Features-and-Capabilities" class="headerlink" title="Cosmos DB Features and Capabilities"></a>Cosmos DB Features and Capabilities</h1><p>For this section we’re gonna focus on Cosmos DB’s unique capabilities. We are not going to cover literally every single thing <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/introduction/">Cosmos DB</a> can do. There is a lot of overlap with other database technologies and quite frankly if you just want a feature list you’re better off reading their documentation, linked below. Instead, in this lesson, we’re going to focus on the six most important and compelling capabilities unique to Cosmos DB. Those six features are, in order, global distribution of data, serverless architecture, multi-model support, throughput consistency guarantees, partitioning, and security. Let’s start by talking about Cosmos DB multi-region support. This is one of the main reasons enterprises choose to use Cosmos DB. The fact that it is designed from the ground up to support access patterns from all over the planet. With over 50 geographic locations for its data centers, Cosmos DB users can ensure minimal latency for their users. What’s more, new locations are regularly added each year. Multi-region logic is deeply integrated into the Cosmos DB service. As the user, you can associate as many geographic regions with your data as you want.</p>
<p>You can tune consistency levels for read and write operations, to improve availability or data precision. You can set entire regions as read only, write only, or read-write. Furthermore, you get built-in failover that lets your set priority lets you set priorities for each region, so you can decide what happens if one of your US data centers goes down, for example. You can plan for exactly which regions take precedence and how you will recover. In section two, we’ll go into how all of these geolocation features are used via their Cosmos DB rest API and web console. The next key thing to introduce is Cosmos DB’s serverless architecture. As described previously, Cosmos DB is an example of a database as a service. You do not set up database servers and manage them, instead you just get an endpoint for your app to utilize. The currency for making use of the Cosmos DB endpoint is known as request units. This will determine how much you pay and what sort of performance guarantees you can get. The larger your data, the more frequent your queries, the more indexing you do, the more consistency you demand, the larger the number of request units you will need. The nice thing about this system is it greatly simplified your data layer. You don’t need to think about memories, CPU, hardware provisioning, OS optimization, updates and patches, SSL certs, et cetera, et cetera. All of this operational overhead of managing a database is gone. The time saved alone could translate into more than enough cost savings to offset the cost of needed request units. Cosmos DB’s serverless architecture also ensures strong SLAs. You get a guarantee of 99.999% uptime, far better than what a typical tech company achieves on their own. You’ll also get first order integration with other <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> services and great support. So let’s move on and talk about the multi-model data support. </p>
<p>This I think is perhaps Cosmos DB’s most intriguing feature. Cosmos DB offers APIs for Cassandra, Gremlin, MongoDB, SQL, and Table Key-Value API. This means that with a single Cosmos DB account, you can run multiple database engines. So if a portion of your data is best suited for Cassandra, you can set up Cassandra key spaces. And then if a subset of your data needs a document paradigm, you can use Mongo. If you happen to need a graph database and a relational database as well, you can add them as well using Gremlin and SQL. This means you have the flexibility of using the right data model for the job. It means you can easily migrate an existing heterogeneous data architecture into Cosmos DB with little hassle. Now there are some important trade-offs and restrictions that come from using multiple APIs. We’ll dig into that in later sections. Next, let’s talk about throughput and consistency. As far as the cap theorem goes, Cosmos DB is very strong on partition tolerance and availability. Like Cassandra, consistency is tunable and throughput is a function of your request units and consistency settings. Cosmos DB features five different consistency settings. </p>
<p>In order from strongest to weakest guarantees, they are strong, bounded staleness, session, consistent prefix, and eventual. If you need to ensure that always the most recent data is read, choose the strong consistency level. It ensures that no reads are processed until rights are completed durably by a quorum of replicas. With bounded staleness, you get a configurable level of consistency. Reads will lag behind writes by either an adjustable time interval or a number of item revisions. Then there’s the session consistency level. This gives you a read your own writes guarantee suitable for scenarios where you need guarantees at the level of individual clients. It’s considerably cheaper than bounded staleness and strong consistency levels, but you get no consistency guarantee outside of individual client session. And then lastly you have the consistent prefix and eventual consistency levels. Both of these guarantee that your data will eventually converge to the most recently written. With the consistent prefix, at least you get an additional guarantee that data will never be out of order. So even if you don’t get the most recent data on read, you can at least be sure that you’re not skipping over data inadvertently. Both of these consistency levels allow for fast throughput and are relatively inexpensive. The more inconsistency you can tolerate, the more you can save money on request unit usage. </p>
<p>Let’s now talk about partitioning and indexing a bit. In Cosmos DB, there are physical partitions that compromise compute hardware resources. SSD storage, CPU, memory, logical partitions, which are a subset of the physical ones. In other words, a physical partition may be made up of several logical partitions. The basic abstraction for sets of data is a container. A container in Cosmos DB can span multiple physical partitions and will be responsible for storing your collections, graphs, SQL tables, et cetera. Every document in Cosmos DB is uniquely identifiable by the combination of its partition key and row key. The partition key, specifically, acts as a logical partition for your data and helps to create boundaries to enable cosmos DB to map data to specific physical resources. In Cosmos DB, the data for a single logical partition must reside on a single physical partition. When designing collections of data, two critical things to think about are partition key and indexing. On the latter point, Cosmos DB automatically indexes all of your data. However it’s possible to create custom indexing policies that let you tune trade offs between query throughput and consistency. Now regarding partition keys however, you’ll have to think carefully about the nature of your data to decide on a proper partition key. People coming from the Cassandra world will have some good intuition here. </p>
<p>The main thing you want is a column with high cardinality and a large variety of values to help distribute your workloads evenly. See Azure’s best documentation for more details. We will cover both of the indexing and partition key selection in more depth in section three of this course when we get into the practical application. And finally let’s talk a little about security. Now as a cloud-based service, Cosmos DB has many of the same security considerations as any other provider. You need to control who has access to your Azure account, who has credentials to use the API and ensure that sensitive data is properly isolated. The nice thing about Cosmos DB though is that it has very sane defaults when it comes to security. Without taking any action at all, Cosmos DB encrypts all data both at rest and in transit. Cosmos DB supports HTTPS, TLS for all client to server interactions. It also includes two different types of credentials for different use cases, master keys, and resource tokens. </p>
<p>The former are useful for administrators that need to make significant changes, while the latter can be used by clients with narrower needs. So there you have it, consider this your crash course into the world of Cosmos DB. For a more detailed breakdown, please take a look at the Cosmos DB documentation, it will answer many of your questions. Our goal in the following two sections is to go beyond the documentation and get you to actually use Cosmos DB on your own. In section two, we’ll dig into how to set up and utilize Cosmos DB futures that were described here and in section three we’ll walk through <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/introduction-to-using-cosmos-db/">creating an actual software service</a>. Good luck and see you there.</p>
<h1 id="Introduction-to-Using-Cosmos-DB"><a href="#Introduction-to-Using-Cosmos-DB" class="headerlink" title="Introduction to Using Cosmos DB"></a>Introduction to Using Cosmos DB</h1><p>In this section, we will get a little more hands-on with <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/introduction/">Cosmos DB</a>. We’re gonna learn how to actually start using Cosmos DB via the web console in various APIs. This is not a lab, so you’re not required to actually follow all of the stops. However, if you have access to an <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> account, I would suggest setting up Cosmos DB and actually trying some of what we cover on your own. We’ll start with just the initial setup via the web console. We will create a Cosmos DB account, select a data model API, and show how to manage our data via the browser. This will be a good opportunity to review several key <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/cosmos-db-features-and-capabilities/">features</a>. Next, we’ll explain how to use libraries for languages like Python and .NET to interact with our Cosmos DB storage. We will also cover using CLI tools, Powershell, and the REST API for Cosmos DB. By the time you’re done with this section, you should have a theoretical knowledge, enough to dive in and do some real work. So if you’re ready, let’s <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/getting-started-with-cosmos-db/">get started</a>.</p>
<h1 id="Getting-Started-with-Cosmos-DB"><a href="#Getting-Started-with-Cosmos-DB" class="headerlink" title="Getting Started with Cosmos DB"></a>Getting Started with Cosmos DB</h1><p>Section two, part two, Getting Started with Cosmos DB. The first and most obvious prerequisite for using Cosmos DB is having a Microsoft Azure account. Once that’s ready, you can go ahead and create a Cosmos DB account. This is as simple as clicking Create a Resource in the top left of the web UI and then clicking on Databases or just starting a search for Cosmos DB by typing that in.</p>
<p>You will then be prompted to input some basic information about your new cosmos DB resource, a name to uniquely identify it with your account, as well as a resource group name, a region, and potentially an option for replica failover region. Also, most important, you’ll have to select your API type. This is what’s gonna define the data model as we said and recall that you can select from MongoDB, Cassandra, SQL, and Gremlin and Azure table.</p>
<p>Now, once everything is filled in click create and wait for a few minutes. It’ll validate and your account will be generated. Now, remember at this point you have a Cosmos DB account resource that’s ready to use but there’s no actual database at this point. What we wanna do next is to use the web console to define a database and then a collection or a table to which we could write some data.</p>
<p>Now before we walk through the steps to do that it’s important to clarify some of the nomenclature here. Different database engines use different terms to describe database schema. So for example, Cassandra uses terms like keyspaces and column families while Mongo uses terms like collections and documents, and in SQL generally, you have a database that has tables and then a row within a table to describe an individual item and that’s kind of your hierarchy.</p>
<p>So depending on the API we pick, we’ll actually see different terms used in the web UI. Now, using the core SQL API we’re gonna see terms like database and container as our general terms. The latter container, this refers to the units of scalability and are analogous to MongoDB collections. So, the process for actually setting up our database in the web console goes something like this.</p>
<p>In the Cosmos DB dashboard we wanna select the Data Explorer option on the left menu. Now we could also start by selecting Add Container in the top menu; however, going through the data explorer makes what we’re doing a little bit more transparent and obvious.</p>
<p>So, in the data explorer UI, we can do all sorts of typical database tasks such as executing queries and changing configuration. Now once you’re in the data explorer page simply click on the New Database button to define your first database. All you need to fill in is a name and a number of RUs, request units, and remember that the RU value will define the kind of throughput performance you can expect.</p>
<p>Now once you have a database, its name should appear in the left side menu, the one that’s to the right of the leftmost menu with the other Cosmos DB options. So click on the little three dots next to your database name and you’ll get an option there to create a container.</p>
<p>So you give your collection a name, you give it an ID, and you give it a partition key, which should be optional, and then you’re done. You’ve got a database and you’ve got a container within your database. Now, that’s just the basic setup and with that clarified let’s step back for a minute and try to fully understand how request units work, because this determines our throughput and it determines our cost to a large extent. </p>
<p>How many request units should we set for our account? What is the formula? Azure offers some really good general advice in the <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-gb/azure/cosmos-db/request-units">documentation</a>. So of course, be sure to check out the <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-gb/azure/cosmos-db/request-units">links</a>. They also offer a nice request unit calculator tool where you can upload a sample JSON document and input some parameters such as reads and deletes, updates per second, kind of your expected use case, and then the calculator will spit out an estimated optimal value for how many RUs you need.</p>
<p>So, without using that, the basic formula for determining RUs is to multiply the number of desired reads per second by the average item size in kilobytes and then perform the same calculation for desired writes per second and then add those two numbers.</p>
<p>So, for example, if your item size is two kilobytes on average and you need 300 reads per second and 500 writes per second you would get 600 and 1,000 by multiplying those two numbers by two, two kilobytes. And therefore in that scenario you add those two numbers together, you should opt for roughly 1,600 RUs, okay?</p>
<p>Now, there are a few important other variables to consider here; document indexing, complexity of query patterns, and critically the desired consistency level. Now remember there’s five; strong, bounded staleness, session, consistent prefix, and eventual. All of these parameters will have an impact on the proper RU setting. So for this reason we strongly recommend taking a look at the documentation and testing out the RU calculator but do keep in mind the formula above. And that’s basically it.</p>
<p>That’s it for this lesson. Congrats, you now know how to set up the Cosmos DB account, the endpoint, and also calculate RUs, all of this using the GUI. You can create your basic config, you can execute queries, you can add arbitrary data. You’re ready to handle basic maintenance for things like request units and other config. Very magical stuff, but of course we can’t stop there. Unless you have a very unusual app, you probably want software to handle querying your database instead of humans. So, in the next lesson, we will learn all about the Cosmos DB API and how you can get computers to do all of this stuff for you. See ya there, space cowboy.</p>
<h1 id="Cosmos-DB-API"><a href="#Cosmos-DB-API" class="headerlink" title="Cosmos DB API"></a>Cosmos DB API</h1><p>So we’ve got our <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/introduction/">Cosmos DB</a> account set up. We can select a desired data API, create databases, write arbitrary data, and execute queries all from the browser. We’re ready to administer our data intelligently. Swell right? Well, in all likelihood you’ll not be doing all of your database reading and writing manually via GUI. You need applications and tools to be able to talk to Cosmos DB. You may want your web app to serve requests to Cosmos DB or you may have devops scripts that have to execute Cosmos DB queries. This is where the Cosmos DB API comes into play. The API documentation is divided by data model, meaning there are separate docs for a Cassandra API, MongoDB, Gremlin, SQL, Azure Table. When you select one you will get information for how to set up your development environment depending on your language choice. Cosmos DB has strong support for many languages including .NET, Java, Python, Ruby, JavaScript. The best way to get started is to look through the SDK documentation for the language of your choice. So for example, let’s say we wanted to use Cosmos DB’s SQL API with, oh I don’t know, how about Java. </p>
<p>The documentation will link us to a GitHub repo for the Java Cosmos DB SDK. There you’ll find a nice README and walkthrough to help you set up the SDK with your Java IDE and begin writing code that could interact with Cosmos DB. Now in some cases you won’t use a Cosmos DB SDK specifically, but rather a driver meant for whatever data model API you selected. So, for example, if we go through the Cosmos DB Python quick start guide for a Cassandra API server, the setup documentation links to the Python Cassandra driver GitHub repo. The Python code you write for Cosmos DB in this instance will be just like Python code for a Cassandra app. You will import the Python Cassandra driver and use its methods to connect, write, and query your Cosmos DB. This flexibility, I think, is one of the most powerful things about Cosmos DB. What it does is it makes it so that if you already have expertise in one database technology, like Mongo or SQL, you can leverage that and often reuse the same code in SDKs. The only new overhead is ensuring your applications have the right permissions and authorization to actually connect to your Cosmos DB account. We’ll drill down about that in section three when we build a real service. Furthermore, with Cosmos DB we have more than just SDKs, and in the web console we have CLI tools and a REST API and Powershell. </p>
<p>Using the Azure CLI tool we can do all of the things we did with the web console in the previous lessons. Now see the links below for the complete command reference. We’re not gonna go through every command. There is also a nice set of BASH scripts in that link that make use of the CLI tool to set up and manage your databases. They have them throughout the Azure documentation. With Powershell we can do everything from the CLI as well as scripting. So if you’re comfortable writing Powershell code you can do many of the same things as you would in BASH scripts, only it’ll probably require fewer lines of code. And then finally you have the REST API. This lets you do everything your own way with any programming language that can make HTTP requests or you can just use curl, if it pleases you. So as we can see from this section, Cosmos DB is both very powerful and very flexible. We can do most of our setup, configuration, and maintenance from the web console or using command line tools. When it comes time for our software to read and write data we have options for many languages and workarounds for unusual use cases. All of this surely sounds great, and by now you have enough theoretical understanding to dive in, build your own little app with Cosmos DB. However, to help ensure you start strong in section three we’re gonna walk through <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/app-creation-with-cosmos-db/">building an application</a>, using <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> services, and Cosmos DB. It’s gonna be a blast, see you there.</p>
<h1 id="Introduction-to-Creating-an-App-with-Cosmos-DB"><a href="#Introduction-to-Creating-an-App-with-Cosmos-DB" class="headerlink" title="Introduction to Creating an App with Cosmos DB"></a>Introduction to Creating an App with Cosmos DB</h1><p>By now, you should have a pretty strong theoretical understanding of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/introduction/">Cosmos DB</a>. We walked through its feature set, explained its <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/azure-cosmos-db-api/">API</a>, demonstrated its tooling and generally covered how the technology can serve as a backend for a variety of use cases. What we have not done is actually tried to build something so that we can see all this cool stuff in action. In this final section of the course, we’re gonna do just that. We’re gonna stop being polite and start getting real. </p>
<p>This isn’t a Cloud Academy lab, so you won’t actually need to create anything in a <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Microsoft Azure</a> account to follow along. Instead, we’ll just very carefully cover step-by-step how to create a working application backend using Cosmos DB. Now, to keep things simple, we’re not gonna create a frontend. The app we create will be a simple event processing system. It’ll take in event data using Azure Event Hub, transmit the events to an Azure Function where we can perform transformations, and then finally, save everything to Cosmos DB. The setup for Azure Event Hub and Azure Functions will be minimal. We will include some screenshots and explanation, but we won’t focus too much on those systems since they’re out of scope for this class. </p>
<p>There are other classes if you wanna dig into those tools. You’re welcome to skip those short lessons if you don’t feel like they’re of use to you. The meat of this section will be the creating our app backend and validating our app lessons where we will walk through the Cosmos DB endpoint setup and then run some test data through <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/azure-event-ingestion/">Event Hub</a> to see if it actually persisted in Cosmos DB. Again, you don’t actually need to do any of this yourself, but if you have access to an Azure account, it’s a great way to reinforce all that we have covered. So if you’re ready, let’s get to it.</p>
<h1 id="Event-Ingestion-in-Azure"><a href="#Event-Ingestion-in-Azure" class="headerlink" title="Event Ingestion in Azure"></a>Event Ingestion in Azure</h1><p>Okay. Welcome to our Cloud Academy demo for this course on Cosmos DB in Azure. And now for this demo section, there’ll be multiple videos and we’re going to put together a backend application using Azure Event Hubs as your functions and as your Cosmos DB.</p>
<p>So for this first video, we’re gonna start by creating an Event Hub. Now what you see here on the screen, this is my personal account. There’s some test infrastructure here. That’s pretty recent. And we’re gonna run through how to create this piece, the Event Hub.</p>
<p>Now, if we just click Event Hubs, we’ll see here it takes us first to this section, which these are namespaces. You have to first create a namespace for your Event Hub. So if you click on it here, we have this Bethune namespace. This is my last name. And then there is a bethune Event Hub, and we can create click plus to create an additional Event Hub within that. But let’s start from scratch.</p>
<p>Let’s say we don’t have any namespace at all. We can go through the, create a resource menu here. And if you want, you can actually just type Event Hubs if you can’t find it and you can click create, and it’ll take you to the wizard and it will tell you first to create a namespace.</p>
<p>Now there’s some information you fill out here. We’ll stick with pay as you go, resource group, we have an existing one, but let’s say we wanna create a new one. We’ll call it, let’s create a new one and we’ll call it bethune2 and so we have a new resource group that will be for this namespace. And then the namespace name we’ll also just call that bethune2.</p>
<p>We wanna pick a region for the data center. I think East US is fine. We’ll stick with the standard pricing tier we can go with, let’s say one consumer group is enough for us and throughput units one is fine for a test. And then we can just go to review and create.</p>
<p>Now after you click review and create, it’s not actually gonna create it right away, it’s gonna just do validation. So don’t navigate away, it’s just done the validation piece. So we know that this configuration is okay, and then we have to click create. And now it’s actually deploying the infrastructure for our Event Hub namespace. That doesn’t take very long, but we have to, we’ll give it a minute and we’ll refresh. Okay.</p>
<p>So eventually your deployment for the Event Hub namespace will complete. It’ll get to this point and we can just click on, go to resource and we can see here at bethune2 Event Hub namespace, and we can navigate there from the home menu as well.</p>
<p>If we click on Event Hubs and we’ll see there’s the additional namespace right there, it’s still in status activating, but that’ll be done very soon. So at this point, we don’t have an actual Event Hub yet. We just have a namespace. So to create an Event Hub, we click on the namespace bethune2 that we created and we want to do we wanna add an Event Hub we do plus Event Hub. And this is pretty simple as well. We just have to give it a name. We’ll call this as well bethune2 partition count of two is fine. Just for test purposes. We don’t need to worry about message retention or capture at this point.</p>
<p>So we’ll just click create and that’ll trigger the validation. And it’ll take a second, but eventually, we’ll see spin up right there bethune2. Down there, we can see the Event Hub. These create very, very quickly, but after you’ve done that, congrats, you’re done. You have your ready-to-use Event Hub right here. No messages or traffic yet, but we’ll get to that soon enough.</p>
<h1 id="Creating-our-App-Backend-with-Cosmos-DB"><a href="#Creating-our-App-Backend-with-Cosmos-DB" class="headerlink" title="Creating our App Backend with Cosmos DB"></a>Creating our App Backend with Cosmos DB</h1><p>Okay, so now in this next demonstration, we’re gonna go through the process of setting up an Azure Cosmos DB account. Now that we have a new event hub, namespace, and event hub, we need a backend to save data. And in the final section, we’ll do. In the section after this, we’ll talk about Azure functions, something to actually process data.</p>
<p>So we have here a sample account, bethune. Now I’ll walk through the steps of how we created it. Similarly, we can do the Create a Resource wizard if we want, and we can just search for Cosmos DB. And so we click on create, and again, we just go, to the fill in the information. We’re gonna go through the same resource group we just created before, bethune2, we’ll say pay as you go and a name for the account. Let’s just keep it as bethune2.</p>
<p>API, this is very important. As you know, Cosmos DB can support many different data structures and API types. So we can do Cassandra. We can do Gremlin. We’re going to just stick with the SQL for this demo. We’ll keep it, keep it simple.</p>
<p>We’ll do the provision throughput capacity mode here. There’s a serverless version in preview mode as of this recording but we’ll stick with the provision for the location. Let’s keep it in the same place as our event, hub US East. And then there’s some additional configuration options here. We don’t really need any of this stuff. Multi-region geo-redundancy. This is, if you want a greater, greater resilience and more robust deployment, we don’t really need to worry about this stuff.</p>
<p>So review and create, and as before it’ll do a validation first. So it’s valid. There’s nothing wrong with this config. We then click create, and this will just take a moment to deploy. So the account is in progress and it’s important to remember once this is done, you don’t have a database yet. You just have the account. So you have to actually create the actual schema, the collections and, you know, DB instances manually, or you can actually have your software created. You can have an Azure function, or you could submit a SQL query. There’s many ways to, to create the schema afterward, but here we can see a deployment is in progress. </p>
<p>Usually only takes about a minute or so, and we can see, well, if we click refresh, we’ll see if it’s making any progress. Alright, well, let’s, let’s give this a sec. We’ll come back when this is done.</p>
<p>Okay. So it took a few minutes longer than I thought, but it did eventually complete. We have here our Azure Cosmos DB bethune2 account, which successfully finished. So what we can do is now actually look at the data, although there’s no data there, I’ll, I’m gonna show you how we can create a database, which will be our, our storage for our application.</p>
<p>So there’s the bethune1 here, which was done for test purposes. This is bethune2 account that we just created. Now, if we go into it, there’s nothing there right now. So to create a database within the account, there’s a lot of ways you can do that. You can get with the API, you can get with it with the query. We’re going to go through the Data Explorer piece here. And in this window, you can see, they give us a few options. You can create a container, which is a sort of a fixed storage and then throughput unit. Or you can go through here to create the database directly, which will give us our initial schema. And remember, this is all SQL API.</p>
<p>So what we’ll do is we’ll, we’ll just create a database to start. We’ll give it a unique ID to call it. We’ll call it the database bethunetest, just to give it a slightly different name. You know, the, the throughput is fine. We can pick the default. We don’t really need to worry about scaling or anything right now. So we’ll just click okay for that. And in a few seconds we should have our database backend. Good to go. Fetching. Okay. There it is.</p>
<p>Now that’s coming up and we can see there’s no data in there. Now, if we go to this older one that does have data, we can see what it would look like. What, what we should hope to get. This one, bethune, has working data in it. I believe it’s under the bethune1 collection. Yeah, here we go.</p>
<p>So you can see here items. If you do have data, you’ll see, you know, a separate collection and you’ll see some items that will load. So this one has one unit there and this one, oh, this one actually has more of than this one under Bethune has more items, these message items here. So we’ll know that we’ve succeeded with our app. When we can go back to this one here that we just created, bethune2, and we should see a collection and items.</p>
<p>So in order to do that, we need to create an answer function, to process some data. And then we’re going to send some messages that will be captured by the event hub processed by the function and stored in our Cosmos DB backend. So next up is, Azure function, see you there.</p>
<h1 id="Azure-Functions-and-Cosmos-DB"><a href="#Azure-Functions-and-Cosmos-DB" class="headerlink" title="Azure Functions and Cosmos DB"></a>Azure Functions and Cosmos DB</h1><p>Okay, so now that we have a working Cosmos DB service and backend running and we have an Event Hub for receiving events and messages, the next thing we need is a Azure Function. That’s gonna be our actual service for processing the data we receive and we have an example here called bethune, and we’ll dig into the code and a little bit but before we do that, I wanna show how it is we set up an Azure Function app.</p>
<p>As with a lot of Azure services, there’s two parts essentially. There’s the shell, the Function app. And then there’s the code itself. The function that’s actually running. So as before we can just go through the create a resource wizard or Function app. We click Create. Pay as you go is fine. We want an existing resource group. We’ll put it in bethune2. We’ll name it bethune2 as well.</p>
<p>Our runtime stack, this is important. We’re gonna do Node.js ‘cause we wanna do a JavaScript app. And how we publish it here, we’re gonna just publish it as code. You can also save as a Docker Container. Version 12 is fine. Most recent default, Node.js version from the time of this recording. And we’ll stick to US East for our region.</p>
<p>There’s some additional configuration here. We go through our hosting. It’s gonna need a storage account so we’ll just, there isn’t an existing one in this namespace, in this account so we’ll create a new one by default. We’ll just call it new storage account, bethune, whatever, that’s fine. Operating system, Windows is okay. We’ll stick with the Windows default. And our plan type is serverless. We don’t need to pick one of the options, other options here.</p>
<p>There’s an app service plan and premium plan. If you know you need, you know, more storage and more resources. And then monitoring we can accept, well actually we’ll go with no. We don’t need to enable application insights. That’s more if we need more deep level granular monitoring. You can add that if you’d like, but for this tutorial we won’t need it. And for tags, we’re not gonna add any tags. That’s fine.</p>
<p>So we’ll go ahead and review and create. And as always, it’ll do a validation first. Config seems to be okay so we click Create and we’ll just give this a few moments and we will have our bethune2 Function app. Right? There we go. Deployment in progress, let’s give that a minute. Okay, all right.</p>
<p>So eventually the deployment will create, will complete and it shouldn’t take more than a minute or so. So once it’s finished, we can just click Go to resource, or we can find it from the dashboard. And you’ll see we now have a bethune2 Function app, and this is our sort of our container for our serverless Azure Function, our actual code.</p>
<p>So right now there’s not really any code executing, there’s just this account. So what we have to do is click on Functions and here is where we can go ahead and create our event processor. So we’ll click on Add, and this will take us through a pretty simple wizard to set something up.</p>
<p>Now, when you click New Function here, it’s gonna ask for the type of function, there’s a number of templates here. HTTP trigger, Timer trigger. These are the conditions that will determine when the code executes. So there’s many types of triggers here. For our purposes, we’re interested in this one, the Azure Event Hub trigger.</p>
<p>So with an Azure Event Hub trigger, what’ll happen is the code for the Azure Function will execute whenever a message or an event is received by that event hub. So we’ll go ahead and we’ll call this EventHubTrigger2, and then we will come up with some connection. We’ll have to create a new connection here.</p>
<p>So in order to create a connection, you’d need an existing event hub. Now fortunately we have an existing one. We just created the bethune2 event hub a little while ago. So we’ll use that. It’ll put in the rest of the config automatically. We’ll call it bethune2 connection. We’ll use the route manage access the route manage shared access key policy for that. Click OK. And now we have an event hub trigger for the event hub we created.</p>
<p>Event hub name, we’ll go ahead and call this bethune2 and we’ll give it the default consumer group. As you know, event hubs can have multiple consumer groups. So we click Create Function and this will, again, it’s not gonna give us the code for the function itself, but it will give us the configuration for the trigger. And that’s key for getting everything to be wired together properly. So just give this a second.</p>
<p>We can refresh it after a while and we should see, boom, there it is. There is our function EventHubTrigger2. And if we click on that, we can see here that the basic configuration, there’s a code here and there’s the integration.</p>
<p>Now the integration, we’ll start with that. This is defined by our trigger, by the type of function. Then we selected Event Hub. So we can see here eventHubsMessages is our trigger. And then this is where the actual function code is. I’ll come to that in a second here. But if we look at the trigger here, this is the configuration that we just set. And we can actually look at this as code in a little bit.</p>
<p>If you go to Code + Test, we can see. So here’s some default JavaScript code that’ll give us a message if we run it, we’ll try that in a second. But there’s another bit of code, this is function.json. This code is defined by the integration that we just looked at, which was the Azure Event Hub integration.</p>
<p>So we see here it’s a bindings config type eventHubTrigger. name, eventHubMessages, direction in. So this is, you know, if a message comes into the event hub, it’ll trigger this. Event Hub name, bethune2. The one we created and here’s our connection. Cardinality, many. I’ll come back to that in a bit, it deals with whether we’re dealing with individual messages or arrays of objects. And we care about the default consumer groups. So this function.json file is very important. This is our configuration for integrating with Event Hub.</p>
<p>Now the code, the actual JavaScript code is in this index.js file. And this doesn’t really do anything too fancy. If we look through it line by line, we can see it’s, it’s basically just logging some text here, context.log JavaScript eventhub trigger function called for message. It’ll print out this message object, and then context.log processed message giving us the message.</p>
<p>There’s a little for-loop here. It’ll go through every message in this object. It’s assuming that it’s receiving an array of messages. See, there’s that cardinality thing. It’s assuming that there’s multiple messages here. So we can do a test run of this if we’d like. We can just do Test and Run and click Run, and we can see it’ll connect to our function. And if we click Run we’ll see, it should just output some basic message text.</p>
<p>Okay, give that a moment. Welcome, we’re now connected to our streaming and we’ll do a quick run. So there’s 202 accepted, that’s good. And there it is, there’s our output right there. The same as the code, right? Processed message, message, right. Process to message, test message. That’s all it was setting as input, this test message here. And then we saw JavaScript eventhub trigger called, right. This is the output there and so it succeeded.</p>
<p>So we now have a working event hub triggered Azure Function with some default to JavaScript code. So now how do we integrate this with Cosmos DB? Well that’s our next challenge. Okay, so we have our function set up. We have some basic JavaScript code. We have our Event Hub trigger. So now we need to integrate with Cosmos DB and in order to do that, there’s a little bit more configuration we need to set up.</p>
<p>So what we’re gonna do is we’re gonna go back home and we’re gonna go back to our Cosmos DB account, bethune2, and we’re gonna go into the Data Explorer, and we’re gonna set up a container that will give us a collection within the database that we can use.</p>
<p>Now here in the Azure Function configuration, the main thing we need to do, if we go here we can say that, that was not set. We’ll go back to the integration and we can see here there’s no outputs defined. This is the main goal. We have to define an output so that the function knows to save its results or its output somewhere, and that’s going to be Cosmos DB.</p>
<p>Now what we need to do is we need to create a container within our bethune test DB. So we’ll click New Container. We’re gonna use this existing database and the container ID will be bethunecontainer. We’ll just call it bethune, we’ll call it bethune2container, why not. And then we will also give this a partition key. Let’s just call this testkey1, simple enough. So we have a partition key. This will help us ensure things work the right way. So click OK. And very quickly we will have a collection that we can use for storing the output of our Azure Function. All right, perfect.</p>
<p>So that’s already set and good to go. And if we click on the collection we’ll see there’s no data in it. There’s no items there. And hopefully if we do a test, we’ll see items show up. So let’s go back to our event hub and our Azure Function here, and we will add an output for this new collection.</p>
<p>Now the output, we have to pick Cosmos DB, that’s the output type we want. And then we get a few interesting bits of configuration here. This output document, that’s the parameter that we’re gonna care about in the actual code. And then the database name. We wanna use this bethune test database so we’ll put that in. And the collection we want to use would be the same as this container name, bethune2container.</p>
<p>One of the nice things is there’s this feature here called if true, create if doesn’t exist, basically. It means that if you don’t have this container or if you don’t have this database or collection existing, then the function will create it for you. So we can leave that as yes, you can leave it as no if you don’t want it automatically doing that. But what we have to also do is create a connection to the Cosmos DB account.</p>
<p>What we’ll do is we’ll click New and want to connect to the bethune2 database. We click OK. And we’ll have this connection here. Actually they’re already is an existing connection we can use, but in any event, in this part here, as long as you already have a Cosmos DB account, you should be able to just find, fill it in here and put in your connection. And then for the partition key, the partition key we had before here in this container we saw was testkey1. So we can literally just copy that and paste it and click OK.</p>
<p>So now we have an output. Now we actually have an output for our function. So how can we test this? How can we make sure that it works appropriately? So we’re not gonna test the event hub piece. We just want to test that the function can output into Cosmos DB. Well, there’s a very simple way to test that.</p>
<p>Okay, so now that we have the output defined for Cosmos DB, in order to test that it works, we have to make two changes to our function set up here. We’re gonna make a change to the JavaScript code, and we’re gonna make a change to the event hub integration piece. So the integration piece here, we can change it by just going through the wizard. You can also change the JSON which I’ll show in a little bit, but basically we wanna go to this cardinality section and change this to one.</p>
<p>Now cardinality tells the code what type of object to expect, whether we’re dealing with a one-to-one or many to one relationship. What we want is to deal with a single message object. We don’t want an array of messages to iterate through. So we change that to one, that we click Save, and then we’re gonna go, and we’re going to edit our JavaScript code, we can click here. And actually before I go into the JavaScript code, I’ll just show you the change in the function.json, we can see that this code has changed.</p>
<p>We’ve added this output section for the Cosmos DB integration. We have the parameter name for the output document here for what will actually go into Cosmos DB. We have the config for the database name, the collection, create if not exist. The string for the connection and then the partition key and the type direction. So this has all changed. And of course here, the cardinality has changed.</p>
<p>It now says one instead of many. So, you know, we can update our integration config here either using the wizard by clicking on it and we have the little boxes or we can edit this function.json file and save it. So we go to our JavaScript code, index.json, you can see that the problem here with this code is that it’s expecting an array, it wants to do a for-loop for each message on this eventHubMessages object, it wants to log them all. And what we’re gonna do is instead update the code to expect a single object, a single thing instead of an array. So we’ll just paste in some different codes so you don’t have to hear me type it all out. And really all we’ve changed is we’re still doing the logging here, but there’s no longer a for-loop.</p>
<p>So we’re taking in a single object. We have this processed output. And then this line is important. We have here the output document parameter. This is what’s gonna go into Cosmos DB. So we call this output document and we call a JSON.stringify to make sure we get a string. And this is the thing that will go into Cosmos DB. So what we’ll do is we will save this and we will do a quick test run to see if it works.</p>
<p>So we’ll click Test. Now if we go into Cosmos DB now we can see in the bethune2container collection. If we click on items there’s nothing there, right? There’s no items for us now. So if our code works, we should see something show up there. So we have a little silly message there, a test message banana face. We know for sure that that’s us. And so we just run, click Run here and cross fingers. Hopefully we should see this execute without any failures. And there we go.</p>
<p>Okay it executed. And now let’s see if this actually went into Cosmos DB, we’ll click on Items. And there it is, there’s our message, Test Message banana face. So we know that our function works in terms of the output piece. We know that we can have the Azure function connect to Cosmos DB and save messages in a collection of our choice in the database of our choice.</p>
<p>Now the last thing we need to do is test the event hub piece. We wanna see the whole thing work end to end. We want to see a message go into event hub, and then that trigger the Azure function. And then after that function is triggered, it should then save it into Cosmos DB. We know this Cosmos DB part works, but we wanna see the event hub part as well.</p>
<p>So that’s what we’ll do in the last section of this demo. It should be fun.</p>
<h1 id="Validating-Our-App"><a href="#Validating-Our-App" class="headerlink" title="Validating Our App"></a>Validating Our App</h1><p>Okay, so now we’re coming into the final section of our demo. We’re going to do an end-to-end validation of our app. What we did before with Cosmos DB, we were able to send a test message through the Azure function dashboard, and we were able to see it persisted in Cosmos DB. So that’s good, but what we really want to see is that the Event Hub works is able to capture a message and then that will trigger the Azure function, and then it will be persisted in Cosmos DB.</p>
<p>So we wanna see all three steps. Now, in order to do that we have to send a message to our Event Hub. And there’s a lot of ways we can do this. If you’re familiar with PowerShell or command line, if you can use a Python Repl, you can write some code. you could send a curl command with the right authentication and all that. But these aren’t the most user-friendly approaches if you are not, if you don’t have experience in programming.</p>
<p>So if you’re not an experienced programmer, then I would say the easiest thing to do is to just use Visual Studio and the SampleSender library that you could get from Microsoft GitHub. So we’ll give you <a target="_blank" rel="noopener" href="https://github.com/Azure/azure-event-hubs/tree/master/samples/DotNet/Microsoft.Azure.EventHubs/SampleSender">links</a> for that, downloading and installing Visual Studio is not too difficult. You can do it right, obviously on Windows works great or other platforms. And then the SampleSender library, you’ll just download that from GitHub. And once you have it, you’re just gonna open it, you’re gonna go into you’re gonna wanna open a project solution yeah that’s correct. You can look for an SLN file and that should just pop up in SampleSender directory. And you’re gonna want here SampleSender.SLN, okay. And once you have that, you’re ready to go. You’re basically ready to send your messages, although actually sorry, you’re not quite ready to go.</p>
<p>You have to change two things here. You have to put in the right name for your Event Hub and you have to put in the right authentication, the right connection string. This is the credential it’s using it. And right now it has the old ones for my previous test. So we have to get the correct name and connection string. So we have to figure out where can we get that from.</p>
<p>Well, you can get it from the dashboard and I’ll show you how to do that in one sec. Okay, so in order to get the connection string, we’re gonna go into the dashboard and I’ll show you how that’s, how you obtain it. First, we can change this to bethune2, because we know already the Event Hub name is bethune2, that’s in the dashboard.</p>
<p>If we click on bethune2 namespace, we will see here, this is the Event Hub itself bethune2. Now that connection string, in order to get that, we need to have a policy, a connection policy that will generate that credential. So in here where it says shared access policies, there’s none by default. What we can do is we click add, and then this will let us create a policy. We’ll just call it default. And we’ll say that this is for sending and for listening, we don’t need to give it management permission. I mean we can, it doesn’t really matter. This is just for a test, but for this one, we’ll go ahead and click create, we’ll call it default and we’ll see it should generate those connection strings if we… Okay yeah already created it.</p>
<p>So we click here and then here are the strings that we need. There’s a primary key, secondary key, connection string, a secondary key here. We care about this one connection string, primary key. We wanna copy this to our clipboard. And then we go into the code and we’re gonna get rid of this one here. We don’t need this anymore. This is the old one, and then we’ll just paste in the new one and there you go. And so now we have our credentials set properly.</p>
<p>So the last thing to do is so we’ll save it. We’ll make sure that this is all set there. The last thing we have to do is actually run this code and we should see the messages appear in the Cosmos DB backend.</p>
<p>Now just to show that they’re not already there as a some kind of slight of hand trick here, we’ll go into Cosmos DB now. We’ll go into our Data Explorer and we should see as it connects, if we go into the collection, we should see that there’s only maybe one or two items from when we ran the tests with the Azure function.</p>
<p>So if we go here and then go to this container, we click on items. It’s only loading that one silly test message we have here, this banana face thing. So there’s nothing else there. Cause this is selecting everything, it’s not finding anything. So if we run this code and it succeeds we should see more messages propagate.</p>
<p>So, let’s see if it works. We click on this green arrow here to run the code samplecenter, and it should start spinning everything up. We’ll see a terminal pop-up and there we go. All right, our code is executing and it should send exactly 100 messages. They’re all just small string that says the message and the number. And then if everything is working properly, these messages will hit the Event Hub trigger the Azure function, and then the function output will put them into Cosmos DB.</p>
<p>So we’ll go ahead and click anything here. Continuous X out I suppose and then we’ll close this. Now one thing we can do to validate the traffic is we can actually look at the Event Hub logs as well. We can go here to bethune2 and look at this bethune2 Event Hub. And this will tell us if any traffic or messages are going through.</p>
<p>Now it’ll take a while for them to show up. We don’t see it right away. We can also look at the, at the Azure function. We can see the logs for the Azure function. We can see if it’s executing at all. So we can go to our bethune2 function app here, and we can see if we go to our functions, we can see here this one, and we can look at the monitor for it. Well actually we don’t need the insights monitor. We can actually this, we didn’t configure application insights so we can just go to the activity log and it should tell us if anything is happening.</p>
<p>So we’re not seeing anything yet, but let’s check Cosmos DB. Let’s see if there’s any activity there. So we will go ahead and reload that and give it a moment. Close this, oh sorry one sec. Let’s go back to that Cosmos DB and we’ll see if we have any messages coming through. Oh, I hope this works all right, we’re connecting to Cosmos DB and we’ll go to our bethune test database container. We’ll click on items, drum roll please. And there it is, there are all the messages that we sent.</p>
<p>So the messages are now in Cosmos DB, which means that the function executed properly. Now we’re not seeing them in the activity logs here. It might take a minute or so for it to show up because we don’t have any advanced insights configured just yet. Actually yes, we are seeing it now.</p>
<p>So if we look at the overview, we could see this spike in activity for the function app. This shows us that the function executed, and then we may see something similar in the Event Hub. If we look at throughput, we might we should see requested messages. Well, it might take a moment for that to propagate, but the most important thing is here are the actual messages are there.</p>
<p>So now we know that the code worked successfully. Our Cosmos DB, Event hub, and Azure function app is working as designed. So congrats if you’re able to get this working on your own and thanks for playing along, cheers.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Congratulations, you made it. Give yourself a pat on the back, because it’s been a long and tough ride. We went through a lot of pretty dense material, so before we pop the champagne bottles, let’s take a minute to briefly review what we have accomplished. By completing this course, you should now have a working knowledge of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/introduction/">Cosmos DB</a>. You should understand the basic service and its features, you should know how to make use of it with an Azure account, and you should have a pretty solid idea of how to integrate Cosmos DB with a real-world application.</p>
<p>Recall our three learning objectives. Number one, the student will have a basic understanding of the Cosmos DB technology, including its feature set and design philosophy. We covered that in section one where we talked about Cosmos DB’s history, its unique capabilities, and the general architecture and design. Number two, the student will know how to use Cosmos DB via its APIs, CLI tools, and the Azure web console. Section two went over this pretty thoroughly. We walked through setting up Cosmos DB in the web console using Azure data explorer. We also talked about how to start coding with Cosmos DB SDKs and how to use both PowerShell and Azure’s CLI tool with Cosmos DB. And then number three, students will have a practical understanding of how to integrate Cosmos DB with other <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/azure/">Azure</a> services with the goal of creating a working app. This was section three where we introduced a few other Azure services and explained how to make them work with Cosmos DB. We walked through creating an app backend and even showed how to <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/introduction-azure-cosmos-db/validating-app-cosmos-db/">validate everything</a>. You should now be ready to work with Cosmos DB, both at work and in your side projects. </p>
<p>Now, remember, practice makes perfect. The best way to really solidify your knowledge is to actually go build something, so get out there and make some magic. Now that you’re done, I’d like to invite you to send any feedback you have about the course to <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. We greatly appreciate your comments, questions, and suggestions. Congratulations again on fighting through the whole course, and good luck in your future endeavors.</p>
<h2 id="5Getting-Started-with-Cosmos-DB"><a href="#5Getting-Started-with-Cosmos-DB" class="headerlink" title="5Getting Started with Cosmos DB"></a>5<strong>Getting Started with Cosmos DB</strong></h2><p><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-gb/azure/cosmos-db/request-units">Cosmos DB Request Units</a></p>
<h2 id="11Validating-Our-App"><a href="#11Validating-Our-App" class="headerlink" title="11Validating Our App"></a>11<strong>Validating Our App</strong></h2><p><a target="_blank" rel="noopener" href="https://github.com/Azure/azure-event-hubs/tree/master/samples/DotNet/Microsoft.Azure.EventHubs/SampleSender">Microsoft GitHub repo</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/14/AZ-204-Lab-Working-with-Azure-Storage-Using-PowerShell-22/" rel="prev" title="AZ-204-Lab-Working-with-Azure-Storage-Using-PowerShell-22">
      <i class="fa fa-chevron-left"></i> AZ-204-Lab-Working-with-Azure-Storage-Using-PowerShell-22
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/14/AZ-204-Lab-Developing-with-the-Cosmos-DB-Core-API-and-Change-Feed-24/" rel="next" title="AZ-204-Lab-Developing-with-the-Cosmos-DB-Core-API-and-Change-Feed-24">
      AZ-204-Lab-Developing-with-the-Cosmos-DB-Core-API-and-Change-Feed-24 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction-to-Cosmos-DB"><span class="nav-number">2.</span> <span class="nav-text">Introduction to Cosmos DB</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Cosmos-DB-Features-and-Capabilities"><span class="nav-number">3.</span> <span class="nav-text">Cosmos DB Features and Capabilities</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction-to-Using-Cosmos-DB"><span class="nav-number">4.</span> <span class="nav-text">Introduction to Using Cosmos DB</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Getting-Started-with-Cosmos-DB"><span class="nav-number">5.</span> <span class="nav-text">Getting Started with Cosmos DB</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Cosmos-DB-API"><span class="nav-number">6.</span> <span class="nav-text">Cosmos DB API</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction-to-Creating-an-App-with-Cosmos-DB"><span class="nav-number">7.</span> <span class="nav-text">Introduction to Creating an App with Cosmos DB</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Event-Ingestion-in-Azure"><span class="nav-number">8.</span> <span class="nav-text">Event Ingestion in Azure</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Creating-our-App-Backend-with-Cosmos-DB"><span class="nav-number">9.</span> <span class="nav-text">Creating our App Backend with Cosmos DB</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Azure-Functions-and-Cosmos-DB"><span class="nav-number">10.</span> <span class="nav-text">Azure Functions and Cosmos DB</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Validating-Our-App"><span class="nav-number">11.</span> <span class="nav-text">Validating Our App</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Summary"><span class="nav-number">12.</span> <span class="nav-text">Summary</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5Getting-Started-with-Cosmos-DB"><span class="nav-number">12.1.</span> <span class="nav-text">5Getting Started with Cosmos DB</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11Validating-Our-App"><span class="nav-number">12.2.</span> <span class="nav-text">11Validating Our App</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">1986</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
