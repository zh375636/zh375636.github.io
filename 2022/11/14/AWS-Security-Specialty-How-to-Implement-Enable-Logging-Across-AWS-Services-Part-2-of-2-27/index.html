<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="IntroductionResources ReferencedHow to implement &amp; Enable Logging Across AWS Services (Part 1 of 2) TranscriptHello and welcome to the second part of this two-part series of courses which have b">
<meta property="og:type" content="article">
<meta property="og:title" content="AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-2-of-2-27">
<meta property="og:url" content="https://example.com/2022/11/14/AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-2-of-2-27/index.html">
<meta property="og:site_name" content="Hang&#39;s Blog">
<meta property="og:description" content="IntroductionResources ReferencedHow to implement &amp; Enable Logging Across AWS Services (Part 1 of 2) TranscriptHello and welcome to the second part of this two-part series of courses which have b">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-14T17:52:27.000Z">
<meta property="article:modified_time" content="2022-11-20T02:54:50.000Z">
<meta property="article:author" content="Hang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://example.com/2022/11/14/AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-2-of-2-27/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-2-of-2-27 | Hang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Hang's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://example.com/2022/11/14/AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-2-of-2-27/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/123456.gif">
      <meta itemprop="name" content="Hang Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-2-of-2-27
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-14 13:52:27" itemprop="dateCreated datePublished" datetime="2022-11-14T13:52:27-04:00">2022-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-11-19 22:54:50" itemprop="dateModified" datetime="2022-11-19T22:54:50-04:00">2022-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AWS-Security-Specialty/" itemprop="url" rel="index"><span itemprop="name">AWS-Security-Specialty</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/14/AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-2-of-2-27/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/14/AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-2-of-2-27/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Resources-Referenced"><a href="#Resources-Referenced" class="headerlink" title="Resources Referenced"></a>Resources Referenced</h2><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-1-2/">How to implement &amp; Enable Logging Across AWS Services (Part 1 of 2)</a></p>
<h2 id="Transcript"><a href="#Transcript" class="headerlink" title="Transcript"></a>Transcript</h2><p>Hello and welcome to the second part of this two-part series of courses which have been designed to help you understand how <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> performs logging for a number of key services and how to use this data captured by the logs to resolve instance and identify security threats. If you haven’t already taken part one of the series, then you can use the link on the screen.</p>
<p>Before we start, I would like to introduce myself. My name is Stuart Scott. I’m one of the trainers here at Cloud Academy, specializing in AWS, Amazon Web Services. Feel free to connect with me with any questions using the detail shown on the screen. Alternatively, you can always get in touch with us here at Cloud Academy by sending an email to <a href="mailto:&#115;&#x75;&#x70;&#112;&#111;&#x72;&#116;&#x40;&#x63;&#x6c;&#x6f;&#117;&#100;&#97;&#99;&#x61;&#100;&#101;&#109;&#121;&#46;&#99;&#111;&#109;">&#115;&#x75;&#x70;&#112;&#111;&#x72;&#116;&#x40;&#x63;&#x6c;&#x6f;&#117;&#100;&#97;&#99;&#x61;&#100;&#101;&#109;&#121;&#46;&#99;&#111;&#109;</a> where one of our cloud experts will reply to your question. </p>
<p>The focus of this two-part series is to understand the logging process and how to monitor this data to your organization’s benefit from both an operational and security perspective. As a result, those who have the following or similar roles would benefit from this content: cloud security engineers, cloud security architects, cloud administrators, cloud support and operations, and compliance managers. </p>
<p>As this is part two in the series, the content will continue the theme of logging across AWS services by explaining the following: <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/cloudfront-access-logs/">CloudFront Logs</a>. Here I’ll look at how to log the requests from each user requesting access to your website and distribution. Next, I look at VPC Flow Logs. And this lecture focuses on how to log the network data, traversing your network interface cards within your VPC. Next, I focus on AWS Config Logging, and here I look at how AWS Config provides a timeline of changes against your AWS resources. And then lastly, I look at filtering and searching of log data. And within this lecture, I look at how to use Amazon Athena to query logs being stored on S3. </p>
<p>For information, part one of this series dived into the following: the benefits of logging, and in this lecture I focused on the core principle of why logging is important. I also looked at CloudWatch Logs, and within that lecture I explained how to implement logging using CloudWatch Logs and the associated agent. I also touched on CloudTrail logging, and CloudTrail records all API calls so here I explained how you can use these logs and how they are constructed. I then looked at the monitoring of those CloudTrail Logs, and here I looked at how you can use CloudWatch to monitor CloudTrail events. And finally in part one, I looked at S3 Access Logs, where this lecture focuses on the logging capabilities of S3 buckets. </p>
<p>The objectives of this series is to enable you to understand when and why you should enable logging of key services, how to configure logging to enhance incident resolution and security analysis, and you’ll understand how to extract specific data from logging data sets. This is an advanced level course series, and so you should be familiar with the following services and understand the individual use cases and feature sets. Throughout this series, I will reference a number of URL links which will help and direct you to related information on specific topics. To make these links easily available to you, I have included them at the top of the transcript within the lecture the they are referenced. </p>
<p>Feedback on our courses here at Cloud Academy are valuable to both us as trainers and any students looking to take the same course in the future. If you have any feedback, positive or negative, it would be greatly appreciated if you could contact <a href="mailto:&#115;&#x75;&#x70;&#x70;&#x6f;&#114;&#x74;&#x40;&#99;&#x6c;&#x6f;&#x75;&#x64;&#x61;&#99;&#x61;&#x64;&#101;&#109;&#121;&#x2e;&#x63;&#111;&#109;">&#115;&#x75;&#x70;&#x70;&#x6f;&#114;&#x74;&#x40;&#99;&#x6c;&#x6f;&#x75;&#x64;&#x61;&#99;&#x61;&#x64;&#101;&#109;&#121;&#x2e;&#x63;&#111;&#109;</a>.</p>
<h1 id="CloudFront-Access-Logs"><a href="#CloudFront-Access-Logs" class="headerlink" title="CloudFront Access Logs"></a>CloudFront Access Logs</h1><h2 id="Resources-Referenced-1"><a href="#Resources-Referenced-1" class="headerlink" title="Resources Referenced"></a>Resources Referenced</h2><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#BasicDistributionFileFormat">Web distribution log file format</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#StreamingDistributionLogFileFormat">RTMP distribution log file format</a></p>
<h2 id="Transcript-1"><a href="#Transcript-1" class="headerlink" title="Transcript"></a>Transcript</h2><p>Hello, and welcome to this lecture focusing on the access logs generated by Amazon CloudFront. Amazon CloudFront is AWS’s content delivery network that speeds up distribution of your static and dynamic content through its worldwide network of edge locations. When you use a request content that you’re hosting through Amazon CloudFront, the request is routed to the closest edge location which provides it the lowest latency to deliver the best performance. When CloudFront access logs are enabled you can record the request from each user requesting access to your website and distribution. As with S3 access logs, these logs are also stored on Amazon S3 for durable and persistent storage. There are no charges for enabling logging itself, however, as the logs are stored in S3 you will be stored for the storage used by S3. </p>
<p>The <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/introduction/">logging</a> process takes place at the edge location and on a per-distribution basis, meaning that there will not be data written to a log that belongs to more than one distribution. For example, distribution a, b, c, will be saved in a different log to that of distribution d, e, f. When multiple edge locations are used for the same distribution, a single log file is generated for that distribution and all edge locations write to the single file. </p>
<p>The log files capture data over a period of time and depending on the amount of requests that are received by Amazon CloudFront for that distribution will depend on the amount of log fils that are generated. It’s important to know that these log files are not created or written to on S3. S3 is simply where they are delivered to once the log file is full. Amazon CloudFront retains these logs until they are ready to be delivered to S3. Again, depending on the size of these log files this delivery can take between one and 24 hours. </p>
<p>When these log files are delivered they use a standard naming convention as follows. So let’s say for example you had the following settings. The bucket name was access-logs, the prefix was web-app-a, and you had the following distribution ID. Then your name and convention for the log would look something like this. Let me now show you a very simple demonstration on how to enable log in for your CloudFront distribution. </p>
<h3 id="Start-of-demonstration"><a href="#Start-of-demonstration" class="headerlink" title="Start of demonstration"></a>Start of demonstration</h3><p>So setting up access logs for your CloudFront distributions is very simple and easy to do. So let’s go into CloudFront. I’ll just select an existing distribution here, and then if you click on distribution settings and under the general tab you select edit, and then if we scroll down these settings here you’ll see a section where it starts referring to logging. And at the moment I have logging off. So to enable logging I simply click on on and then I select the bucket in S3 where I want the access logs to reside, so I’m going to select CloudFront Access Logs, which is an existing bucket I have set up for this. Now here I can add a log prefix if I want to, if I’ve got different distributions, etc. I’m just going to leave that as blank for this demonstration. And here we can have cooking logging on or off, which will log all cookie data within the request, and it’s as simple as that. And then once you’re happy with that you just click on yes to confirm your changes. And now any access requests that go via your CloudFront distribution will be logged via S3. And that’s it. </p>
<h3 id="End-of-demonstration"><a href="#End-of-demonstration" class="headerlink" title="End of demonstration"></a>End of demonstration</h3><p>To perform the demonstration that I just completed and to access the logs when they are stored, you will need specific permissions to the S3 bucket designated for logging. To enable the log in for your distribution, the user account activating that feature must have full control on the ACL for the S3 bucket, along with the S3 GetBucketAcl and S3 PutBucketAcl. The reason for this is that during the configuration process, CloudFront will use your credentials to add the AWS data-feeds account to the ACL with full control access. This is an account used by <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS</a> which will write the data to the log file and deliver it to your designated S3 login bucket. Therefore, if you’re trying to enable the login feature for your distribution and it’s failing, then you should check your access to ensure you have the required permissions. </p>
<p>Depending on the delivery type of your CloudFront distribution, either WEB or RTMP, the log output will vary. The number of fields within the log files differ between the two types. Web distributions have a total of 26 different fill types for each entry within the log, whereas the RTMP distributions only have 13. I won’t go through every single field explaining their purpose and use, however, I want to highlight a few points of interest starting with the web delivery type. These logs contain information which allow you to identify the following. The date and timestamp of the request of the user and which edge location received this request, source metadata of the requester including IP address details, HTTP access method of the request, such as PUT, DELETE, or GET, etc., the HTTP status codes of the request such as 200, the distribution domain name relating to the request, and the encryption and protocol data used in request such as SSL, V3, or AES256-SHA. For full information on each field and options please see the following <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#BasicDistributionFileFormat">link</a>. </p>
<p>Now looking at the RTMP delivery type, the points of interest are as follows. Again, a timestamp of the request of the user and which edge location received this request, the source IP address of the requester, the event being carried out by the requester such as play, pause, or stop, and the URL of the page where your SWF file is linked to. Again, for full information on field data captured within RTMP logs you can view the following link <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#StreamingDistributionLogFileFormat">here</a>. </p>
<p>One final feature of logging with CloudFront is cooking logging. If you enable this within your distribution, then CloudFront will include all cookie information with your CloudFront access log data. This is only recommended if your origin of your distribution points to anything other than S3 such as an EC2 instance as S3 does not process cookie data. </p>
<p>That now brings me to the end of this lecture covering AWS CloudFront logs. Coming up next I shall be looking at the logs generated at the network level within your VPC with the <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/vpc-flow-logs/">VPC flow logs</a>.</p>
<h1 id="VPC-Flow-Logs"><a href="#VPC-Flow-Logs" class="headerlink" title="VPC Flow Logs"></a>VPC Flow Logs</h1><h2 id="Transcript-2"><a href="#Transcript-2" class="headerlink" title="Transcript"></a>Transcript</h2><p>Hello and welcome to this lecture covering VPC Flow Logs. Within your VPC, you could potentially have hundreds or even thousands of resources all communicating between different subnets both public and private and also between different VPCs through VPC peering connections. VPC Flow Logs allows you to capture IP traffic information that flows between your network interfaces of your resources within your VPC. This data is useful for a number of reasons, largely to help you resolve incidents with network communication and traffic flow in addition to being used for security purposes to help spot traffic reaching a destination that should be prohibited. </p>
<p>Unlike S3 access logs and <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/cloudfront-access-logs/">CloudFront access logs</a>, the log data generated by VPC Flow Logs is not stored in S3. Instead, the log data captured is sent to CloudWatch logs. Before creating your VPC Flow Logs, you should be aware of some of the limitations which might prevent you from implementing or configuring them. If you are running a VPC peered connection, then you’ll only be able to see flow logs of peered VPCs that are within the same account. Or if you are still running resources within the EC2-Classic environment, then unfortunately you are not able to retrieve information from their interfaces. And once a VPC Flow Log has been created, it cannot be changed. To alter the VPC Flow Log configuration, you need to delete it and then recreate a new one. </p>
<p>In addition to this, the following traffic is not monitored and captured by the logs. DHCP traffic within the VPC, traffic from instances destined for the Amazon DNS Server. However, if you decide to use and implement your own DNS Server within your environment, then the traffic to this will be logged and recorded within the VPC Flow Log. Any traffic destined to the IP address for the VPC default router and traffic to and from the following addresses, 169.254.169.254 which is used for gathering instance metadata, and 169.254.169.123 which is used for the Amazon Time Sync Service. Traffic relating to an Amazon Windows activation license from a Windows instance and finally the traffic between a network load balancer interface and an endpoint network interface. All other traffic both ingress and egress can be captured at a network IP level. </p>
<p>You can set up and create a flow log against three separate resources. These being a network interface on one of your instances, a subnet within your VPC, and your VPC itself. Obviously for option two and three, this will contain a number of different resources. As a result, data is captured for all network interfaces either within the subnet or the VPC respectively. I mentioned earlier that this data is then sent to CloudWatch logs via a CloudWatch log group. For every network interface that publishes data to the CloudWatch log group, it will use a different log stream. And within each of these streams, there will be the flow log event data that shows the content of the log entries. Each of these logs captures data during a window of approximately 10 to 15 minutes. </p>
<p>To enable your flow log data to be pushed to a CloudWatch log group, an IAM role is required for permissions to do so. This role is selected during the setup configuration of the VPC Flow Log. If your role does not have the required permissions, then your log data will not be delivered to the CloudWatch group. At a minimum, the following permissions must be associated to the role. In addition to this, you will also need to ensure that the VPC Flow Log service can assume that IAM role to perform the delivery of logs to CloudWatch. This can be achieved with the following permissions. </p>
<p>While on the topic of permissions, I want to also show you the required permissions for someone to review and access the VPC Flow Logs or indeed be able to create one in the first place. The following three EC2 permissions allows you to create, delete, and describe flow logs. These being ec2:CreateFlowLogs, ec2:DeleteFlowLogs, and ec2:DescribeFlowLogs. The logs:GetLogData permissions is used to enable you to list log events from a data stream. If you wanted to create flow logs, then you need to also grant the use of the IAM permission of iam:passrole which allows the service to assume the role mentioned previously to create these flow logs on your behalf. </p>
<p>Let me now show you how to create a flow log for an interface on an instance, a subnet, and lastly the VPC itself. </p>
<h3 id="Start-of-demonstration-1"><a href="#Start-of-demonstration-1" class="headerlink" title="Start of demonstration"></a>Start of demonstration</h3><p>Okay so firstly I’m going to set up a VPC Flow Log for the running instance that we’ve used in a previous demonstration which was for the logging server. So what I need to do is go down to our network interfaces under network and security and select the ENI of the logging server. As you can see, it’s this bottom instance here. So if I select that interface, if I just drag this up a little bit, and we have three tabs here, details, flow logs, and tags. If we select the flow logs tab of this interface, we can see that there’s no flow log created as yet. </p>
<p>What we need to do is click on create flow log. Now we can select the filter for this flow log to only log either accepted requests or rejected requests so I’m going to select all so it gets accepted and rejected. We now need to select our role and I created a role earlier and I called that Flow-Logs-Role so that has the required permissions to push data to CloudWatch logs. And here we have the ARN of the role. The destination log group for CloudWatch, I set up a log group prior to this demonstration and I’ve just called this Flow-Logs. And then click on create flow log. And that’s it, it’s as simple as that. So now you can see for this eni interface here, we now have a flow log created. It gives it a flow log ID. Shows the filter which we have ALL here. Their destination log group. The ARN of the role and it’s currently active. So now any traffic going in and out of that interface on that EC2 instance will be captured and the data will be sent to the flow logs log group in CloudWatch. And let’s take a look at how you set up flow logs for a subnet. </p>
<p>So let’s go across to our VPC service. I have a couple of VPCs here and we’ll use our logging VPC. So if we go down to our subnets, and let’s select the public subnet for our logging VPC, now again we have the tabs for this subnet. We have the summary, route table, network ACL, etc, and we also again have the flow logs tab. Very simple process again. Click on create flow log. The same filters. Select the same role and the same log group. And then simply create flow log. And that’s now having the flow logs enabled on this particular subnet so all traffic going in and out of this subnet will be captured and sent to the flow logs log group. </p>
<p>And for the VPC, it’s very similar. So you simply select your VPC so we have our logging VPC here, again we have our flow logs tab. Create flow log. Select the role and the destination log group of flow logs and then create flow log and that’s it. So it’s very easy to set up your flow logs for your EC2 network interface clouds or your subnet or your entire VPC. And that’s it. </p>
<h3 id="End-of-demonstration-1"><a href="#End-of-demonstration-1" class="headerlink" title="End of demonstration"></a>End of demonstration</h3><p>Let’s now take a look at a record within one of these flow logs. When you access the logs, you will find each entry has the following syntax. These entries are defined as follows. Version, which is the version of the flow log itself. Account-id, this is your AWS account ID. Interface-id, this is the interface ID of which the log stream data applies to. Source address, this is the IP source address. Destination address, this is the IP destination address. Source port, this is the source port being used for the traffic. And the destination port is the destination port being used for the traffic. The protocol, this defines the protocol number being used for the traffic. Packets, this shows the total number of packets sent during the capture. Bytes, again this shows the total number of bytes sent during the capture. Start and end shows the timestamp of when the capture window started and finished. Action, this shows if the traffic was accepted or rejected by security groups and network access control lists. And the log-status shows the status of the logging through three different codes. OK, where data is being received by CloudWatch logs. NoData, this means there was no traffic to capture during the capture window. And SkipData, where some data within the log was captured due to an error. </p>
<p>One of the key fields from an incident response and troubleshooting perspective is the action field. For example, if you are troubleshooting an issue of traffic not being received by a particular resource, then you could check the VPC Flow Logs to see if the traffic is getting blocked at the subnet level by a network ACL. This will then allow you to review your entries within the NACL to make the changes that’s necessary from a security perspective. </p>
<h1 id="AWS-Config-Logging"><a href="#AWS-Config-Logging" class="headerlink" title="AWS Config Logging"></a>AWS Config Logging</h1><h2 id="Transcript-3"><a href="#Transcript-3" class="headerlink" title="Transcript"></a>Transcript</h2><p>Hello and welcome to this lecture regarding AWS Config. AWS Config is a great security and compliance tool that integrates well with many other <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS services</a>. As you may or may not know, AWS Config can perform the following functions. It can capture resource changes, so any change to a resource supported by Config can be recorded, which will record what changed along with other useful metadata or held within a file known as the Configuration Item, the CI. It can act as a resource inventory. AWS Config can discover supportive resources running within your environment, allowing you to see data about that resource type. It can store configuration history for individual resources. The service will record and hold all existing changes that have happened against the resource, providing a useful history record of changes. It can provide a snapshot in time of current resource configurations where an entire snapshot of all supported resources within a region can be captured that will detail their current configurations with all related metadata. It can enable notifications of when a change has occurred on a resource. So SNS is used with AWS Config to capture a configuration’s stream of changes enabling you to process and analyze the changes to resources. It can provide information on who made the change and when through AWS CloudTrail Integration. AWS CloudTrail is used AWS Config to help you identify who made the change and when and with which API. It can enforce rules that checks the compliancy of your resource against specific controls. Predefined and custom rules can be configured within AWS Config, allowing you to check resources compliance against these rules. It can perform security analysis within your AWS environment. A number of security resources can be recorded and when this is coupled with rules relating to security such as encryption checks, this can become a powerful analysis tool. And finally it can provide relationship connectivity information between resources. The AWS Management Console provides a great relationship allowing you to quickly see and identify which resources are related to any other resource. For example, when looking at an EBS volume, you’ll be able to see which EC2 instance it is connected to. </p>
<p>From a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/introduction/">logging</a> perspective, the ability to store configuration history is highly valuable. So let me look into this a little further. The configuration history uses Configuration Items, CIs, to collate and produce a history of changes to a particular resource. This allows you to see the complete set of changes made to a resource over a set period of time. The information can be accessed either programmatically though the AWS CLI using the following command, or you can also specify the resource type. So for example, if you wanted to look at the configuration history for a subnet you could enter the following into the CLI. Or you could also access this history via the AWS Management Console. Additionally, AWS Config also sends a configuration history file for each resource type to an S3 bucket that is selected during the setup of AWS Config. This configuration file is typically delivered every six hours and it contains all CI changes for all resources of a particular type. For example, there’ll be one configuration history file covering six hours for all RDS DB instant changes in one region. A Configuration Item, or CI as it’s known, is a key component of AWS Config. It is comprised of a JSON file that holds the configuration information, relationship information, and other metadata as point in time snapshot view of a supported resource. All the information that AWS Config can record for resource is captured within the CI.</p>
<p> A CI is created every time a supported resource has a change made to its configuration in any way. In addition to recording the details of the affected resource, AWS Config will also record CIs for any directly related resources to ensure the change did not affect those resources, too. For example, if there was a rule change to a security group, perhaps additional rules were added with new ports. AWS Config will record all CI information for that resource. But it also gathers CI information for any instances that were part of that security group. These will then be sent to the configuration stream. As so much data is gathered within these CIs, it’s important we look at these in further detail. </p>
<p>So for every CI generated there will be five different sections. Firstly, metadata. This essentially contains details about the configuration item itself. So within this metadata we have both a version ID and a configuration ID, which uniquely identifies the CI. In addition to this, other information includes an MD5Hash that allows you to compare other CIs already recorded against the same resource as well as ensuring there are no duplications. And then we have the time of the capture and a state ID, which puts the CIs for a particular resource into an order of sequence. </p>
<p>Attributes, this holds common attribute information against the actual resource. Within this section we also have a resource ID and any key-value tags that are associated to the resource. The resource type is also listed. For example, if this was a CI for an EC2 instance, the resource types listed could be the network interface or the EIP for that EC2 instance. The Amazon Resource Name, the ARN, for the resource would also see shown along with the availability zone that the resource belonged to. Bear in mind that for services and resources that are not fixed to a particular availability zone, such as IAM, then this section would not be applicable. Lastly, the time that the resource was created would also be given. </p>
<p>Relationships, this holds information for any connected relationships that the resource may have. So within this section it would show a clear description of any relationship to other resources that this resource had. For example, if the CI was from EC2 instance the relationship instance may show the connection to a <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/vpc-flow-logs/">VPC</a> along with a subnet that the EC2 instance resides in. </p>
<p>Current configuration. This will display the same information that would be generated if you were to perform or describe or list API call made by the AWS CLI. AWS Config uses the same API call to get the same information. So depending on the API call and resource, different information will be returned, which is resource specific. </p>
<p>Related events, and this relates to AWS CloudTrail. This will display the AWS CloudTrail event ID that is related to the change that triggered the creation of this CI. There is a new CI made for every change made against a resource. As a result, a different CloudTrail event ID will be created. This allows you to deep dive into who or what and when made the change that triggered the CI. A great feature allowing for some great analysis to be taken, specifically when this affects security resources. </p>
<p>As you can see, the configuration item is a fundamental aspect of AWS Config when recording changes and data made to a supported resource. The configuration history file is stored on the S3 bucket that was selected at the time of configuration and is used to store all the configuration history files that are generated for each resource type, which happens every six hours. If you have multiple AWS accounts you may want to aggregate your configuration history files into the same S3 bucket for your primary account. However, you’ll need to grant write access for this service principle, config.amazonaws.com, and your secondary accounts with write access to the S3 bucket in your primary account. Let me now demonstrate how to use the AWS Management Console to view configuration details and history within my account. </p>
<h3 id="Start-of-demonstration-2"><a href="#Start-of-demonstration-2" class="headerlink" title="Start of demonstration"></a>Start of demonstration</h3><p>Okay, so I’ve just logged into my AWS account, and I’m going to go up to services and you can see the AWS Config is under management tools. So if we select config, and this is the first splash screen you’ll be presented with if you don’t have AWS Config started as yet. So, let’s get started by clicking on the get started button. And then there’s three steps to setting AWS Config up. </p>
<p>So the first step is configuring the settings. And this is where we essentially start the configuration recorder, by identifying what resources we’d like included in our AWS Config configuration. So starting from the top, we can either select all resources within this region, remember, AWS Config is region specific. So we can choose to record all the resources supported within this region, and currently I’m in the London region. And we can choose to include global services such as IAM, etc. But for this demonstration we’ll just choose to record all resources in this region. </p>
<p>Here you can select specific types if you’re required. So if I unticked this we can then go down to this dropdown box and select specific resource types that we’d like set up for this configuration. So you can be quite specific. Selecting the load balancer or different elements of IAM and again different elements of RDS, etc. So there’s a list that it can go through if you just want to record a specific resource type. But like I said for this demonstration I’m just going to select all resources. </p>
<p>Next we need to define our S3 bucket. And this is where our configuration history and snapshot files are stored. So we can ask AWS Config to just create a new bucket for us and it will prefix it with this bucket name here or we can choose an existing bucket from my account, by selecting the dropdown list or we can select a bucket from another account. So if you had multiple accounts you can send the configuration history files and snapshot files for all those accounts to a single primary AWS account in a single bucket. So for this example, though, for this demonstration I’m just going to ask AWS Config to create a new bucket for us. Config bucket Cloud Academy. </p>
<p>Now moving down to the SNS topic. Now this is the configuration stream. So for any events that AWS Config picks up it will send it to this SNS topic for the configuration stream. Now we can create a new topic, and again, AWS Config will just give us topic name here or we can select to choose another topic from your account or again from another account. For this demonstration we’ll just ask AWS Config to create the topic name for us, and I’ll just add in Cloud Academy. </p>
<p>Now finally we have the AWS Config role, and this is where we spoke about the different permissions. And this is required to allow AWS Config to send the configuration history file and snapshots to S3 as well as having access to send events to the SNS topic. I’m not forgetting enabling AWS Config to be able to kind of go out and poll your resources as a describe or list API call to get the details of those resources. And again, for this demonstration, I’m just going to ask AWS Config to create a role for us. I’ll just add Cloud Academy on the end. So that’s settings. So this screen is essentially your configuration recorder. By setting this up you’re asking AWS Config to start recording. We have set up the S3 bucket to allow our configuration history files and our snapshots files to be captured. And we have created our configuration stream by configuring an SNS topic. And we have also allowed AWS Config to have the necessary permissions to carry out those functions. So once that’s all set up we’ll click on next. </p>
<p>And here we have a set of predefined AWS managed config roles. This is a number of templates that you can select to check the compliance of your resources against these rules. So for now I’m just going to click on skip. And here we’re on the final stage which is review. So we can see here the resource types we’ve selected, which are all resources, and we’ve not chosen to include global resources. We have our S3 bucket set up for our history files and snapshots and we have our SNS topic for our configuration stream configured, and we have the permissions given by the AWS Config role. And that’s essentially the elements to setting up AWS Config. So once you’re happy with that and once you’re done with that you can click on confirm, and you can see that it’s now setting up AWS Config for this region. And that’s it. It’s set up and it’s running. </p>
<p>So whatever create, deletes, or changes I make to support the resource types within this region AWS Config will not begin to monitor that and record it and log it within the configuration stream and also within the configuration history files. Now what I’ve done, I’ve already set this up in another region, and I’ve made a few changes. So what I’ll do now, I’ll swap to that region, and we can take a look at some of the other relevants such as the configuration history file, the timeline of events, etc., and look at how the relationships are set up within this dashboard. So let me swap over to another region which is island. </p>
<p>So as you can see, I’ve just swapped to the Ireland region, and we don’t have the option of setting up AWS Config because I’ve already set it up and only have it running once within the region. So let’s take a look at what we have here. Straight away here we can see that I’ve had existing rules. I had a rule name of S3 bucket versioning enabled. So I wanted to check if my S3 buckets had versioning enabled. So this is one of the config rules. So if I just open that up I can see that a number of these buckets do not have versioning enabled. And they have been marked as noncompliant. I can still use these buckets. I can still write to the buckets. I can still delete objects from those buckets. It’s just notified me that these buckets are noncompliant with this specific config rule, which is to check if, it says it checks whether versioning is enabled for your S3 buckets. </p>
<p>Now let’s have a look at some of the other resources that we have. So I can filter on specific resource type that I want to take a look at. So let me take a look at my VPC. Let me look up everything to do with my VPC. So I can see here that I have two VPCs, and let’s take a look at one of them. And this has now taken us to the timeline of events of these VPCs. So on the 15th of March at 11:25 there was a resource discovery. So that’s probably when I activated AWS Config within this region and it went out and done a discovery of all resources. And then at 11:32 there was a change on this resource item. So lets take a look at the rest of the page. So under the configuration details we have a number of details here. We have the Amazon Resource Name, the resource type, the ID, the CIDR block of the VPC. So there’s different configuration details that we can see for different items. </p>
<p>Now we can also see the tag name here, which is CA demo and further down we can look at the relationships. So this will show other resources that have a direct relationship with this VPC. So we can see we have a couple of network ACLs there. We have an instant gateway, we’ve got some root tables, security groups, and some subnets. So each of these resource types has a direct relationship with this VPC, and if I wanted to I can select straight from here to click on that network ACL and it will take me to the details for that ACL. And again, we have some resource type information here, the ARN, and the ID, etc. Again, if we click on the relationships we should see the VPC that we just came from. So let’s go back to our VPC. So as you can see it’s very easy to look at the relationships between different resources and navigate between them, and it’s kind of grouped in a logical manner to allow you to quickly get between the different resource types that you’d like to. </p>
<p>Now we can see up here that on the 15th of March 11:23 there was a change. Now if we go down to our changes here, we can have a look at what that change was. We can see it’s defined by two different categories, a configuration change or a relationship change. We can see that by the number that this change was to do with relationships. And it looks as though a new subnet was added to this VPC. And then finally, we have our CloudTrail events. And this will capture any API calls that made changes to resources. However, it will only capture these for the previous seven days. So because this change was made on the 15th of March and it is now the 30th of March, so if we look at the CloudTrail events there’s nothing there, they have expired. So what I’ll do, I’ll go and make a couple of changes. I’ll create a new subnet within this VPC, so I’ll pause the video, wait a few minutes, and then I’ll start it again and we can analyze the CloudTrail event of that new change. </p>
<p>Okay, so I’ve gone off and I’ve created a new subnet within this VPC so we can see that the 30th of March, which is today, that there was a change that occurred and two new events. So let’s go ahead and take a look at the change. So we can see that there is a new subnet. This is the subnet that I just created. And if we look at the CloudTrail events, we can see that we have the creation of the new subnet there. Now if we click on the actual CloudTrail event itself it will take us to CloudTrail and we can look at additional information. So now we’re looking at the details of the API call itself, and we can see a number of different information here. We can see the user that created it, the source IP address, the time, the events source, and also the region as well, along with any affected resources as well. </p>
<p>So here we can drill down into exactly what time it occurred. As you can see up here the date and time and by who and what event actually was created. So as you can see, clicking on that CloudTrail event you can get additional information to kind of help you with resolving instance and looking at potential security breaches to try and gather more information as to identifying who is doing what and when. So now let’s take a look at the configuration history, which is stored in S3. So let’s go across to S3. So if I go to the bucket that I use for the ireland region, and then navigate through the folders to the correct date and time of today, you can see the configuration history folder. And then if I download one of these files and then open that, we can see here that that configuration history file contained the subnet creation that we just created for our VPC, and it shows you all the different information about it, the availability zone, the CIDR block used, etc., etc. And there’s the subnet ID. And it also highlights the relationships to other resources for that new subnet such as any network ACLs that may be associated. So that’s the configuration history file that’s stored in S3 in a JSON format. That brings us to the end of this demo. So we look to how to set up AWS Config for a region. We then looked at the details of a specific resource type. We looked at the VPC and how the timeline of events work. We looked at a couple of changes and also the CloudTrail event logs as well. And then finally we looked at one of the configuration history files as a JSON document. That now brings me to the end of this lecture covering the AWS Config service and the config history login data.</p>
<h3 id="End-of-demonstration-2"><a href="#End-of-demonstration-2" class="headerlink" title="End of demonstration"></a>End of demonstration</h3><h1 id="Filter-and-Query-data-with-Amazon-Athena"><a href="#Filter-and-Query-data-with-Amazon-Athena" class="headerlink" title="Filter and Query data with Amazon Athena"></a>Filter and Query data with Amazon Athena</h1><h2 id="Transcript-4"><a href="#Transcript-4" class="headerlink" title="Transcript"></a>Transcript</h2><p>Hello and welcome to this lecture. We will learn how to analyze and search for specific data across log files being stored in S3. If your log data is being stored in S3, such as your CloudTrail logs, then you can use Amazon Athena to query that data within S3 to search for specific entries. The following demonstration has been created by Jeremy Cook, one of our AWS expert trainers here at Cloud Academy. In this demonstration, Jeremy will walk through the steps required to set up Athena to allow you to query CloudTrail log data.</p>
<h3 id="Start-of-demonstration-3"><a href="#Start-of-demonstration-3" class="headerlink" title="Start of demonstration"></a>Start of demonstration</h3><p>In this demo we’ll walk through the steps required to set up Athena to allow us to query CloudTrail log data. This demo will involve configuring CloudTrail, S3, EC2, and the Athena services. The end result will allow us to perform SQL queries against CloudTrail data stored in an S3 bucket. This type of setup will aid your DevOps and SecOps experience when building on top of the <a target="_blank" rel="noopener" href="https://cloudacademy.com/library/amazon-web-services/">AWS platform</a>. </p>
<p>Let’s get started. Within the AWS console, select the Athena service. The first step involves us creating a new Athena database, which will host our custom data table created later in this demo. This task can be accomplished either through an Athena provided wizard or manually through the query editor using an appropriate SQL create statement. We’ll perform this by using SQL statements. But for learning purposes, I will show you where the wizard resides within the Athena console. Let’s see where this is located. Clicking the catalog manager, menu item in the Athena menu bar, takes us into the catalog manager. Initially, we have only the default Athena database to work with. We can click the Add Table action. This opens the Add Table Wizard. The first step requires us to either choose an existing database or create a new database. In this case, I’m going with the create new database option. I need to provide the name for the new database. In this case, I’m going with New DB. And then I need to provide the name for the new table. I’ll go with New Table. If I were to complete this wizard, I would additionally need to specify the S3 bucket location of our input set. However, I’m now going to cancel out of this wizard and perform the same process manually using SQL statements within the query editor. </p>
<p>Clicking back on the query editor menu item, we’re taken back into the query editor. Clicking within the editor itself clears the area. I’m now going to switch over to my visual code editor that has some pre baked SQL queries. I’m taking a copy here of a create database statement. Flipping back to the query editor, I paste the create database statement into the editor pane. As you can see, this particular create database statement will create as a new database named CloudTrail DB1. The create database statement, in this example, specifies an S3 bucket location. This bucket will be used to store the new database’s catalog. Let’s go and create this S3 bucket now, opening the S3 console in a separate browser tab. Clicking the Create Bucket button. In the resulting create bucket window, we paste in our bucket name that our create database statement references. We then hit the Create button at the bottom of the window. This creates our S3 bucket that will store the database catalog. </p>
<p>Okay, great. Our bucket has been created successfully as shown here. Next, we’ll go back to the Athena query editor. The create database statement can be configured to execute with metadata that may be relevant to your cause. In this example, I’m simply going to set the creator as myself, the company to be Cloud Academy, and created to the current year. With all this in place, we can now go ahead and execute the create database statement. We do so by clicking the Run Query button. Let’s do this now. We now wait for the query to complete. As we can now see, the create database statement has executed successfully, as per the query successful response in the result section. Additionally, we can see that we have our new database now displaying in the left hand side menu. We’ll now create our first table within our new database. </p>
<p>Let’s flip over to Visual Code and take a copy of a pre built table creation statement. Back within the query editor, we paste in the table creation statement. Here you can see that our new table will be named CloudTrail logs. The create table statement specifies all the relevant column attributes that CloudTrail tracks per order record. Next, we highlight the serializer-deserializer, or SERDE in short form, that is used. In this case, we’re using the Amazon Provided CloudTrail SERDE. Finally, I draw your attention to the S3 bucket location that needs to be provided. This particular S3 URL represents the location where our raw CloudTrail logs will reside once configured. Let’s go ahead and create this bucket. Switching back over into the S3 console, click the Create Bucket button. In the resulting Create Bucket window, we paste in our bucket name that our create table statement will reference. In our case, we’ll create our new bucket with the name CA CloudTrail Logs Demo. We then hit the Create button at the bottom of the window. This creates our S3 bucket that CloudTrail will be next to configure to push logs into, and for which Athena will scan from when executing our SQL queries. </p>
<p>Okay, great. Our bucket has been successfully created, as can be seen here. Switching back into the query editor window, we now paste in the S3 bucket name we just created. Okay, everything looks ready. Let’s now click on the Run Query button. And again, our query has executed successfully. And in this case, our new CloudTrail logs table has been created. On the left hand side, we see our newly created table listed. Clicking on the preview icon to the right of the table name executes the sample query now shown in the editor pane. This query will perform a Select All across the table, but limited to the first 10 rows. Since our CloudTrail bucket has yet to be populated, it’s expected that the query will return an empty result set as it does. Next, if we expand the table name itself, we see the column names and types that define it. Finally, clicking on the table properties icon, we are presented with a view of all the respected table properties associated with our new table. Important properties include, table name, database name, S3 bucket location, and serialization library. Let’s now go and establish a new CloudTrail trail and configure it to push its logs into our S3 CloudTrail bucket. </p>
<p>Under services, select the CloudTrail service. Once in the CloudTrail console, click the Create Trail button. Give the new trail a name. Here we’re gong to call ours CA CloudTrail Logs Demo. Leave all defaults as is until we get to the storage location section. Disable the create new S3 bucket option, and instead, select the name of the S3 CloudTrail bucket that we built earlier. Next, under Advanced, disable the enable log file validation option. This is unnecessary for this demo. Finally, click the Create button at the bottom of the screen. If all goes well, we should see fairly quickly our new trail has been provisioned successfully, as we do now. </p>
<p>Let’s switch over into the S3 console, and check to see if our newly created trail is publishing events into our bucket. Clicking on our CloudTrail configured bucket and drilling down into the lowest folder, we can see that we are indeed receiving logs from CloudTrail. This is great. Let’s go back into the Athena console and perform a couple of queries against this data. Clicking on the preview icon in the right of our CloudTrail table, kicks off the sample query for us again. And we’re now successfully seeing some early results coming through. Next, we’ll flip across to the Visual Code and copy a pre configured SQL select statement. Back within the query editor, we paste in the select statement. Before we execute, let’s click the Format Query button and have the editor reformat the query for us. This is a great feature that aids the readability of any SQL statements that we craft by hand. </p>
<p>Okay, running the formatted query still returns just four rows of data. This implies we’re still waiting for more CloudTrail logs to be delivered into our S3 bucket. Okay, now that we have all of the individual parts wired up successfully, let’s try out the following scenario. We’ll create a new example only security group within the EC2 service. The security group itself won’t be attached to anything. We’re creating it only to generate and capture the associated API calls within CloudTrail, for which, we will eventually query for within Athena. We’ll add in some inbound rules on this new security group. Performing these actions will generate CloudTrail data that will be published into our CloudTrail S3 bucket. The end result being that we should be able to query and discover these actions within Athena. Right, let’s start by heading over to the EC2 console. Click into the Security Group section, and then click the Create Security Group button. Give the security group a name. Here we name ours DemoSG. Don’t worry about setting the VPC. In the inbound rule section we’ll add a couple of rules. Clicking the Add Rule button, we add the first rule, allowing incoming traffic from source IP address 1.1.1.1&#x2F;32 and to port 1000. Add a second rule. This time to allow incoming traffic from source IP address 2.2.2.2&#x2F;32 and to port 2000, and then click the Create button. Next, we need to take a copy of the security group ID for the security group we just created. We’ll use this within our Athena query. </p>
<p>Jump back into the Athena query editor and update our like clause referencing the security group ID we just copied. This now tells Athena to search for all records who your request parameters attribute contains the security group ID we pasted into the like clause. Okay, let’s now execute this query and see if we get any results. As you can see, no results have come back, likely due to relatency involved in CloudTrail receiving, processing, and saving out to the S3 bucket. Let’s try again at approximately five minutes time. Okay, running the query again now provides us with results. As you can see, there are six rows in our output. Scrolling across the fourth row until we see the request parameters column. Here we can see two of the inbound rules we attached to the security group earlier. The first inbound rule allows incoming traffic to port 1000 from source IP address of 1.1.1.1&#x2F;32. And the second inbound rule allowing incoming traffic to port 2000 from source IP address of 2.2.2.2&#x2F;32. </p>
<p>Okay, let’s now expand our query by adding an additional clause. This time we’ll filter out all events except for the authorize security group ingress event. Running this query now gives us back just the one row, as expected. Okay, let’s now take a quick look at some of the other useful features within the Athena console. Each query that you author in the editing will be saved and replayed at a later stage. So I’ll save our current query. Click the Save As button. Give the saved query a name and description. In this example, we’ll call ours Important SG Query for both name and description. Click the Save button, and our query is saved and accessible in the saved queries area. Clicking on the Saved Queries top menu item shows us all of the previously saved queries, including our just saved Important SG Query at the bottom of the list. If we click on the query, it will be recalled back into the editor pane as can now be seen. </p>
<p>Next, let’s look at the history feature. This allows us to examine all past executed queries. Here we can see the most recent query at the top of the list. This was our last query that we ran, where we added the extra and the clause to filter on the event name column. If we click this query, once again, it’s recalled to the editor pane. But additionally, it also shows us the results that were returned at the time the query was actually executed. Bonus points. Going back into the history feature, I’ll now highlight a couple of the other important attributes for each captured query. Firstly, each query has a state associated with it. Here our query succeeded. If it hadn’t, it would track as an error. Next, there is a time the query took to run captured in seconds. This is useful for performance tuning and troubleshooting. Then there is the amount of data scanned recorded in kilobytes. This is useful to understand how much each query is going to cost you. Finally, there is a download results link that allows you to get a local copy of the results. Clicking the link for this row downloads the results locally. We’ll now use our local terminal to output the contents of the file to the screen. </p>
<p>Again, we can see that the details of the two inbound rules we attached to the security group in question. The first inbound allowed incoming traffic to port 1000 from source IP address of 1.1.1.1&#x2F;32. And the second inbound allowed incoming traffic to port 2000 from source IP address of 2.2.2.2&#x2F;32. This concludes the demo. But before we finish, let’s quickly go through the process of doing some clean up within Athena. Firstly, we’ll drop our CloudTrail table. Back within the query editor we type the statement, drop table CloudTrail Logs. Running this query will drop our table, allowing us to then drop the database. Next, clear the editor and type the statement, drop database CloudTrail DB1. And execute it. This will drop our custom Athena database. Don’t forget to delete the CloudTrail trail and remove the S3 buckets as used in this demo.</p>
<h3 id="End-of-demonstration-3"><a href="#End-of-demonstration-3" class="headerlink" title="End of demonstration"></a>End of demonstration</h3><p>That now brings me to the end of this lecture. Coming up <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/course-summary/">next</a>, I will summarize the key points taken from the previous lectures of this course.</p>
<h1 id="Course-Summary"><a href="#Course-Summary" class="headerlink" title="Course Summary"></a>Course Summary</h1><h2 id="Transcript-5"><a href="#Transcript-5" class="headerlink" title="Transcript"></a>Transcript</h2><p>Hello and welcome to this final lecture within <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/introduction/">this course</a>. In this lecture, I want to summarize and highlight the key points from the previous lectures. </p>
<p>I started by talking about <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/cloudfront-access-logs/">Amazon CloudFront Access Logs</a>. During this lecture, we learned the following points. Amazon CloudFront is AWS’s content delivery network that speeds up distribution of your static and dynamic content through its worldwide network of edge locations. When a user requests content via CloudFront, the request is routed to the closest edge location providing the lowest latency. CloudFront Access Logs can record the request from each user requesting access to your website and distribution. And the logs are stored on S3 for durable and persistent storage. The logging process for CloudFront takes place at the edge location and on a per distribution basis. And the log files capture data over a period of time and are dependent on the amount of requests received. CloudFront retains the logs until they are ready to be delivered on S3. And to enable the logging for your distribution, you must have FULL_CONTROL on the ACL for the S3 Bucket, along with the s3:GetBucketAcl permission and the s3:PutBucketAcl permission. And log output varies on the distribution type, whether this be Web or RTMP. And by enabling cookie logging, it will include all cookie information with your CloudFront Access Log data. </p>
<p>Following CloudFront, I then looked at network logging at the VPC level through the use of <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/vpc-flow-logs/">VPC Flow Logs</a>. In this lecture, I explained that VPC Flow Logs allow you to capture IP traffic information that flows between your network interfaces and your resources within your VPC. The log data generated by VPC Flow Logs is then sent to CloudWatch Logs. And if you are running VPC peered connections, then you’ll only be able to see Flow Logs of peered VPCs in the same account. Flow Logs are not available for EC2-Classic environments. And once a VPC Flow Log has been created, it can’t be changed. The following traffic is not monitored and captured by the logs: DHCP traffic within the VPC, traffic from instances destined for the Amazon DNS Server, any traffic destined to the IP address of the VPC default router, traffic to and from 169.254.169.254 and 169.254.169.123, traffic relating to an Amazon Windows activation license, and traffic between a Network Load Balancer Network Interface and an Endpoint Network Interface. Flow Logs can be set up for a network interface on an instance, your subnet, or your entire VPC. And each interface that sends data to CloudWatch will do so in its own stream. Specific permissions are needed to allow VPC Flow Logs to push data to CloudWatch, as well as permissions to assume the role with the required permissions, these being CreateLogGroup, CreateLogStream, PutLogEvents, DescribeLogGroups, and DescribeLogStreams. And the log files have the following syntax. </p>
<p>Next, I reviewed how <a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-2-2/aws-config-logging/">AWS Config</a> uses configuration history to display all changes within your environment. During this lecture, we learned that AWS Config is a great security and compliance tool that integrates well with many other AWS services. The Configuration History uses Configuration Items, CIs, to collate and produce a history of changes to a particular resource. AWS Config sends a Configuration History file for each resource type to an S3 Bucket that is selected during the setup of AWS Config. And this configuration file is typically delivered every six hours. A Configuration Item is comprised of a JSON file that holds the configuration information, relationship information, and other metadata as a point in time snapshot view of a supported resource. A CI is created every time a supported resource has a change made to its configuration. And a CI consists of the following sections: metadata, attributes, relationships, current configuration, and related events. And it’s important to note that you can aggregate Configuration History files from multiple accounts into one S3 Bucket. </p>
<p>The final lecture focused on how to retrieve data from your logs that are being stored on Amazon S3, and this was shown via a demonstration. </p>
<p>That now brings me to the end of this lecture and to the end of part two of this two-part course series. If you have now viewed both parts, you should now have a deeper understanding of some of the logging capabilities that AWS provides across a number of key services. You will also have an insight into how these logs are constructed and how to search for specific information that you might need to use in your day-to-day operations. </p>
<p>If you have any feedback on this course, positive or negative, please do contact us at <a href="mailto:support@cloudacademy.com">support@cloudacademy.com</a>. Your feedback is greatly appreciated. </p>
<p>Thank you for your time, and good luck with your continued learning of cloud computing. Thank you.</p>
<h1 id="1Introduction"><a href="#1Introduction" class="headerlink" title="1Introduction"></a>1<strong>Introduction</strong></h1><p><a target="_blank" rel="noopener" href="https://cloudacademy.com/course/how-implement-enable-logging-across-aws-services-part-1-2/">How to implement &amp; Enable Logging Across AWS Services (Part 1 of 2)</a></p>
<h1 id="2CloudFront-Access-Logs"><a href="#2CloudFront-Access-Logs" class="headerlink" title="2CloudFront Access Logs"></a>2<strong>CloudFront Access Logs</strong></h1><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#BasicDistributionFileFormat">Web distribution log file format</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#StreamingDistributionLogFileFormat">RTMP distribution log file format</a></p>
<h1 id="3VPC-Flow-Logs"><a href="#3VPC-Flow-Logs" class="headerlink" title="3VPC Flow Logs"></a>3<strong>VPC Flow Logs</strong></h1><p><a target="_blank" rel="noopener" href="https://aws.amazon.com/about-aws/whats-new/2018/08/amazon-vpc-flow-logs-can-now-be-delivered-to-s3/">Flow Logs delivery to S3</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/14/AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-1-of-2-26/" rel="prev" title="AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-1-of-2-26">
      <i class="fa fa-chevron-left"></i> AWS-Security-Specialty-How-to-Implement-Enable-Logging-Across-AWS-Services-Part-1-of-2-26
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/11/14/AWS-Security-Specialty-Lab-Monitor-Amazon-CloudWatch-Security-Logs-for-failed-SSH-attempts-28/" rel="next" title="AWS-Security-Specialty-Lab-Monitor-Amazon-CloudWatch-Security-Logs-for-failed-SSH-attempts-28">
      AWS-Security-Specialty-Lab-Monitor-Amazon-CloudWatch-Security-Logs-for-failed-SSH-attempts-28 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Resources-Referenced"><span class="nav-number">1.1.</span> <span class="nav-text">Resources Referenced</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Transcript"><span class="nav-number">1.2.</span> <span class="nav-text">Transcript</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CloudFront-Access-Logs"><span class="nav-number">2.</span> <span class="nav-text">CloudFront Access Logs</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Resources-Referenced-1"><span class="nav-number">2.1.</span> <span class="nav-text">Resources Referenced</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Transcript-1"><span class="nav-number">2.2.</span> <span class="nav-text">Transcript</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Start-of-demonstration"><span class="nav-number">2.2.1.</span> <span class="nav-text">Start of demonstration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#End-of-demonstration"><span class="nav-number">2.2.2.</span> <span class="nav-text">End of demonstration</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VPC-Flow-Logs"><span class="nav-number">3.</span> <span class="nav-text">VPC Flow Logs</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Transcript-2"><span class="nav-number">3.1.</span> <span class="nav-text">Transcript</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Start-of-demonstration-1"><span class="nav-number">3.1.1.</span> <span class="nav-text">Start of demonstration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#End-of-demonstration-1"><span class="nav-number">3.1.2.</span> <span class="nav-text">End of demonstration</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#AWS-Config-Logging"><span class="nav-number">4.</span> <span class="nav-text">AWS Config Logging</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Transcript-3"><span class="nav-number">4.1.</span> <span class="nav-text">Transcript</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Start-of-demonstration-2"><span class="nav-number">4.1.1.</span> <span class="nav-text">Start of demonstration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#End-of-demonstration-2"><span class="nav-number">4.1.2.</span> <span class="nav-text">End of demonstration</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Filter-and-Query-data-with-Amazon-Athena"><span class="nav-number">5.</span> <span class="nav-text">Filter and Query data with Amazon Athena</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Transcript-4"><span class="nav-number">5.1.</span> <span class="nav-text">Transcript</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Start-of-demonstration-3"><span class="nav-number">5.1.1.</span> <span class="nav-text">Start of demonstration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#End-of-demonstration-3"><span class="nav-number">5.1.2.</span> <span class="nav-text">End of demonstration</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Course-Summary"><span class="nav-number">6.</span> <span class="nav-text">Course Summary</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Transcript-5"><span class="nav-number">6.1.</span> <span class="nav-text">Transcript</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1Introduction"><span class="nav-number">7.</span> <span class="nav-text">1Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2CloudFront-Access-Logs"><span class="nav-number">8.</span> <span class="nav-text">2CloudFront Access Logs</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3VPC-Flow-Logs"><span class="nav-number">9.</span> <span class="nav-text">3VPC Flow Logs</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hang Zhang"
      src="/images/123456.gif">
  <p class="site-author-name" itemprop="name">Hang Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2736</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zh375636" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zh375636" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hang.zhang.network@gmail.com" title="E-Mail → mailto:hang.zhang.network@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hang Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>



// 在最后添加
<script src="/js/code-unfold.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '40GUvOAaitQh1SZe7ua9cvss-MdYXbMMI',
      appKey     : 'iUO2yON0j55WMdu59zx12dCG',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
